# Học tập Tự-tiến hóa cho Mixup: Tăng cường Dữ liệu Tăng cường trong Các tác vụ Phân loại Văn bản Số lượng mẫu Ít

Haoqi Zheng1∗ ∗, Qihuang Zhong2∗, Liang Ding3, Zhiliang Tian1† †,
Xin Niu1†,Changjian Wang1,Dongsheng Li1,Dacheng Tao4
1Khoa Máy tính, Trường Đại học Quốc phòng
2Khoa Khoa học Máy tính, Đại học Vũ Hán 3Viện Khám phá JD 4Đại học Sydney

Tóm tắt
Các tác vụ phân loại văn bản thường gặp phải các tình huống số lượng mẫu ít với dữ liệu được gán nhãn hạn chế, và việc giải quyết tình trạng thiếu hụt dữ liệu là rất quan trọng. Tăng cường dữ liệu với mixup kết hợp các cặp mẫu để tạo ra các mẫu giả mới, có thể làm giảm vấn đề thiếu dữ liệu trong phân loại văn bản. Tuy nhiên, chất lượng của các mẫu giả được tạo ra bởi mixup thể hiện sự biến thiên đáng kể. Hầu hết các phương pháp mixup đều không xem xét đến mức độ khó khăn học tập khác nhau trong các giai đoạn khác nhau của quá trình huấn luyện. Và mixup tạo ra các mẫu mới với nhãn one-hot, điều này khuyến khích mô hình tạo ra điểm dự đoán cao cho lớp chính xác lớn hơn nhiều so với các lớp khác, dẫn đến sự quá tự tin của mô hình. Trong bài báo này, chúng tôi đề xuất một phương pháp mixup dựa trên học tập tự-tiến hóa (SE) để tăng cường dữ liệu trong phân loại văn bản, có thể tạo ra các mẫu giả thích ứng hơn và thân thiện với mô hình cho việc huấn luyện mô hình. SE phù hợp với sự tăng trưởng của khả năng học tập của mô hình và thích ứng với khả năng này khi tạo ra các mẫu huấn luyện. Để giảm thiểu sự quá tự tin của mô hình, chúng tôi giới thiệu một phương pháp điều chỉnh làm mượt nhãn cụ thể cho từng thực thể, phương pháp này nội suy tuyến tính giữa đầu ra của mô hình và nhãn one-hot của các mẫu gốc để tạo ra nhãn mềm mới cho việc trộn nhãn. Thông qua phân tích thực nghiệm, các thí nghiệm cho thấy SE của chúng tôi mang lại những cải thiện nhất quán và đáng kể trên các phương pháp mixup khác nhau. Các phân tích sâu chứng minh rằng SE tăng cường khả năng tổng quát hóa của mô hình.

1 Giới thiệu
Gần đây, các mô hình ngôn ngữ lớn sinh tạo (LLMs) đã giành được sự phổ biến lớn trong xử lý ngôn ngữ tự nhiên (NLP), và đã đạt được hiệu suất ấn tượng trên nhiều tác vụ NLP khác nhau (Kocoń et al., 2023; Peng et al., 2023; Lu et al., 2023c). Tuy nhiên, các nghiên cứu thực nghiệm (Zhong et al., 2023) cho thấy rằng LLMs không luôn vượt trội hơn BERT trong một số tác vụ hiểu ngôn ngữ. Do đó, sử dụng BERT vẫn là một lựa chọn khả thi trong một số ứng dụng. Các tác vụ phân loại văn bản thường gặp phải các tình huống số lượng mẫu ít (ví dụ: các tác vụ NLI và Paraphrase), nơi có dữ liệu được gán nhãn phù hợp hạn chế có sẵn để huấn luyện. Tăng cường dữ liệu (DA) tạo ra dữ liệu mới bằng cách thay đổi dữ liệu gốc thông qua các phương pháp khác nhau, điều này mở rộng tập dữ liệu huấn luyện để giảm thiểu vấn đề thiếu hụt dữ liệu.

Trong các tác vụ phân loại văn bản, các phương pháp DA có thể được chia thành hai loại: các phương pháp DA như EDA (Wei và Zou, 2019), Back-Translation (Kobayashi, 2018), và các phương pháp khác dựa trên tổng hợp như mixup. Loại đầu tiên thực hiện DA bằng cách chỉ thay đổi đầu vào. Những phương pháp này chỉ thay đổi đầu vào để tạo ra dữ liệu mới trong khi duy trì nhãn gốc. Những phương pháp này dễ thực hiện, nhưng đầu vào chỉ thay đổi một chút nên dẫn đến các đầu vào được tăng cường với sự đa dạng hạn chế, có thể làm giảm tính tổng quát hóa của mô hình. Loại thứ hai của các phương pháp DA sửa đổi cả đầu vào và nhãn, thay đổi các mẫu đầu vào theo một cách nhất định và đồng thời thay đổi các nhãn tương ứng để tạo thành một mẫu mới. Những phương pháp này có xu hướng tạo ra các mẫu khác biệt hơn so với các mẫu gốc.

Mixup là một phương pháp DA sửa đổi cả đầu vào và nhãn. Nó trộn đầu vào của các mẫu và nhãn của chúng, nơi nhãn thường được biểu diễn bằng mã hóa one-hot. Hầu hết các phương pháp này trộn đầu vào của hai mẫu trên văn bản đầu vào của chúng (Yun et al., 2019) hoặc các biểu diễn ở mức ẩn (Verma et al., 2019). Tuy nhiên, mẫu giả, đơn giản được kết hợp với hai mẫu, có thể không thích ứng với khả năng học tập của mô hình và không thân thiện với việc huấn luyện mô hình. Gần đây, một số công trình (Sawhney et al., 2022; Park và Caragea, 2022) đã tập trung vào việc lựa chọn các cặp mẫu tương tự cho mixup. Sawhney et al. (2022) lựa chọn các mẫu theo độ tương tự embedding. Park và Caragea (2022) kết hợp một mẫu xem xét độ tin cậy của các dự đoán của mô hình. Hơn nữa, trong các tình huống số lượng mẫu ít, việc sử dụng nhãn cứng (nhãn one-hot) có thể dẫn đến các vấn đề, nơi các nhãn one-hot không thể cung cấp sự không chắc chắn của đầu vào vì tất cả khối lượng xác suất được gán cho một lớp. Điều này dẫn đến các mô hình quá tự tin vì logit lớn nhất trở nên lớn hơn các logit khác, loại bỏ sự không chắc chắn của không gian nhãn (Szegedy et al., 2016). Các kỹ thuật làm mượt nhãn hiện tại tạo ra các nhãn mềm không thể thích ứng động với khả năng tăng dần của mô hình khi quá trình huấn luyện tiến triển, vì vậy chúng cũng không thể điều chỉnh theo hiệu suất của mô hình ở giai đoạn hiện tại.

Trong bài báo này, chúng tôi đề xuất học tập tự-tiến hóa cho mixup để đạt được tăng cường dữ liệu trong các tác vụ phân loại văn bản. Để phù hợp với khả năng học tập của mô hình, đầu tiên chúng tôi chia dữ liệu huấn luyện thành các tập con dễ học và khó học. Chúng tôi dần dần bắt đầu từ mixup của các mẫu dễ học và sau đó dần dần chuyển sang thao tác mixup của các mẫu khó học. Để tránh sự quá tự tin của mô hình, chúng tôi giới thiệu một phương pháp làm mượt nhãn cụ thể cho từng thực thể, nơi chúng tôi nội suy tuyến tính giữa phân phối xác suất dự đoán của mẫu gốc và nhãn one-hot của nó để có được một nhãn mềm. Sử dụng nhãn mềm này làm giảm sự khác biệt giữa xác suất dự đoán của mô hình cho các lớp khác nhau, có thể làm giảm sự quá tự tin của mô hình. Ngoài ra, nhãn cụ thể cho từng thực thể này có thể thích ứng động với sự tăng trưởng của khả năng tăng dần của mô hình và có thể được tùy chỉnh theo hiệu suất hiện tại của mô hình. Phương pháp của chúng tôi đã được chứng minh thực nghiệm rằng việc trộn theo thứ tự độ khó tăng dần có thể làm cho các mẫu được tạo ra thích ứng hơn cho việc huấn luyện mô hình so với các mẫu được chọn ngẫu nhiên.

Những đóng góp của chúng tôi như sau:
• Chúng tôi đề xuất học tập tự-tiến hóa (SE) cho mixup để xem xét độ khó học tập của các mẫu cho việc tăng cường dữ liệu trong các tác vụ phân loại văn bản.
• Chúng tôi đề xuất một phương pháp làm mượt nhãn cụ thể cho từng thực thể để điều chỉnh có thể có được nhãn mềm động và thích ứng để giảm thiểu sự quá tự tin của mô hình và tăng cường khả năng tổng quát hóa của mô hình.
• Các thí nghiệm mở rộng cho thấy mô hình của chúng tôi cải thiện đáng kể và mạnh mẽ phương pháp mixup trong các tác vụ phân loại văn bản số lượng mẫu ít.

2 Công trình liên quan
2.1 Phân loại Văn bản Số lượng mẫu Ít
Được thúc đẩy bởi quan sát rằng con người có thể nhanh chóng thích ứng kiến thức hiện có với các khái niệm mới với các ví dụ hạn chế, học tập số lượng mẫu ít (Fei-Fei et al., 2006) gần đây đã thu hút nhiều sự chú ý. Phân loại văn bản số lượng mẫu ít đòi hỏi thực hiện phân loại sau khi huấn luyện hoặc tinh chỉnh một mô hình chỉ trên một vài ví dụ. Một số nghiên cứu (Yu et al., 2018; Bailey và Chopra, 2018; Geng et al., 2020) đã khám phá nhiều phương pháp khác nhau cho phân loại văn bản số lượng mẫu ít, chủ yếu liên quan đến các kỹ thuật học máy truyền thống để lựa chọn các mẫu con danh mục tối ưu.

Gần đây hơn, kể từ khi Devlin et al. (2019); Brown et al. (2020) cho thấy hiệu suất ấn tượng của các mô hình ngôn ngữ được huấn luyện trước (PLMs) trên nhiều tác vụ NLP khác nhau, rất nhiều công trình (Wu et al., 2019; Bansal et al., 2020) có xu hướng sử dụng PLMs để giải quyết vấn đề phân loại văn bản số lượng mẫu ít. Một hướng nghiên cứu nhằm mục đích tinh chỉnh PLMs (chủ yếu cho PLMs phân biệt, như BERT (Devlin et al., 2019)) với dữ liệu huấn luyện số lượng mẫu ít. Tương ứng, cách thiết kế các phương pháp tăng cường dữ liệu để làm phong phú hơn dữ liệu huấn luyện đã trở thành trọng tâm của những công trình này. Thay vì tinh chỉnh PLMs, một hướng nghiên cứu riêng biệt nhằm mục đích tận dụng tối đa khả năng học tập số lượng mẫu ít mới nổi của PLMs lớn hơn, tức là GPT-3 (Brown et al., 2020) và InstructGPT (Ouyang et al., 2022), và sử dụng dữ liệu huấn luyện số lượng mẫu ít làm minh họa cho việc thực hiện quá trình học tập trong ngữ cảnh (Lu et al., 2023b,a). Xem xét PLMs dựa trên BERT phù hợp hơn cho các tác vụ phân loại văn bản, chúng tôi theo hướng nghiên cứu trước và tập trung vào khám phá khả năng của PLMs dựa trên BERT trong phân loại văn bản số lượng mẫu ít.

2.2 Tăng cường Dữ liệu trong NLP
Vì nút thắt cổ chai trong học tập số lượng mẫu ít là thiếu dữ liệu, hiệu suất có thể được cải thiện dễ dàng nếu chúng ta có thể tạo ra nhiều dữ liệu được gán nhãn hơn. Do đó, nhiều kỹ thuật tăng cường dữ liệu NLP khác nhau đã được đề xuất, như EDA (Wei và Zou, 2019), Back-Translation (Kobayashi, 2018) và CBERT (Wu et al., 2019). Những phương pháp này cho thấy hiệu suất đáng chú ý trong một số tình huống cụ thể, tuy nhiên, chúng chủ yếu tập trung vào việc thay đổi đầu vào gốc, dẫn đến thiếu sự đa dạng trong các mẫu được tạo ra.

Để giải quyết vấn đề này, Szegedy et al. (2016) đầu tiên đề xuất một kỹ thuật tăng cường dữ liệu độc lập với miền (tức là mixup) trong lĩnh vực thị giác máy tính, nội suy tuyến tính các đầu vào hình ảnh trên không gian đặc trưng dựa trên pixel. Guo et al. (2019) sau đó tích hợp mixup với CNN và LSTM cho các ứng dụng văn bản. Hơn nữa, để đạt được hiệu suất tốt hơn, nhiều công trình khác nhau (Sun et al., 2020; Cao et al., 2021; Chen et al., 2020; Yoon et al., 2021; Zhang et al., 2022) cố gắng cải thiện kỹ thuật mixup từ hai khía cạnh: 1) cách kết hợp tốt hơn hai biểu diễn ẩn, và 2) cách thực hiện trực tiếp mixup trên các câu đầu vào.

Mặc dù đạt được hiệu suất đáng chú ý, những chiến lược mixup trước đây này vẫn có một số hạn chế. Cụ thể, chúng (thường) chọn ngẫu nhiên các mẫu để trộn và không xem xét khả năng học tập của mô hình. Một số công trình (Sawhney et al., 2022; Park và Caragea, 2022) cũng đã tập trung vào việc giải quyết vấn đề này và đề xuất nhiều phương pháp khác nhau để lựa chọn các mẫu một cách hiệu quả. Sawhney et al. (2022) lựa chọn các mẫu theo độ tương tự embedding. Park và Caragea (2022) kết hợp một mẫu xem xét độ tin cậy của các dự đoán của mô hình. Cùng hướng nghiên cứu này, trong bài báo này, chúng tôi cải thiện mixup với một cơ chế học tập tự-tiến hóa đơn giản nhưng hiệu quả hơn.

3 Phương pháp
3.1 Tổng quan
Đối với tác vụ phân loại văn bản trong tình huống số lượng mẫu ít, chúng tôi đề xuất một phương pháp tăng cường dữ liệu thông qua mixup, nơi việc huấn luyện theo một lịch trình từ dễ đến khó trên dữ liệu được tăng cường. Đầu tiên, chúng tôi xây dựng một mô hình phân loại văn bản dựa trên BERT và sau đó sử dụng một phương pháp mixup để tăng cường dữ liệu nhằm mở rộng lượng dữ liệu (Mục 3.2). Để làm cho mixup thích ứng với khả năng học tập của mô hình, chúng tôi đề xuất học tập tự-tiến hóa cho mixup (Mục 3.3). Để giảm thiểu vấn đề quá tự tin của mô hình, chúng tôi đề xuất một phương pháp điều chỉnh làm mượt nhãn cụ thể cho từng thực thể, nội suy tuyến tính giữa các đầu ra của mô hình và nhãn one-hot của các mẫu gốc để tạo ra nhãn mềm mới làm nhãn cho việc trộn (Mục 3.4).

3.2 Mô hình Phân loại Văn bản và Mixup
Chúng tôi sử dụng BERT (Devlin et al., 2018) cho các tác vụ phân loại văn bản, nơi mô hình BERT sử dụng kiến trúc bộ mã hóa Transformer hai chiều đa lớp và được huấn luyện trước trên văn bản thuần túy cho mô hình hóa ngôn ngữ có mặt nạ.

BERT nhận một chuỗi từ làm đầu vào và xuất ra biểu diễn của chuỗi. Đối với các tác vụ phân loại văn bản, BERT lấy trạng thái ẩn cuối cùng h của token đầu tiên [CLS] làm biểu diễn câu. Sau đó, chúng tôi thêm một hàm softmax với một phép biến đổi tuyến tính để tạo ra một phân phối xác suất và nhãn được dự đoán.

Để giảm thiểu sự thiếu hụt dữ liệu trong các tình huống số lượng mẫu ít, chúng tôi đề xuất một phương pháp tăng cường dữ liệu để tạo ra các mẫu giả cho việc huấn luyện mô hình BERT. Ý tưởng cốt lõi của mixup là chọn hai điểm dữ liệu được gán nhãn (xi, yi) và (xj, yj), nơi x là đầu vào và y là nhãn. Thuật toán sau đó tạo ra một mẫu mới (x̃, ỹ) thông qua nội suy tuyến tính:

x̃ = λxi + (1-λ)xj (1)
ỹ = λyi + (1-λ)yj (2)

nơi λ ∈ [0,1] biểu thị tỷ lệ trộn của hai mẫu.

3.3 Học tập Tự-tiến hóa cho Mixup
Để làm cho các mẫu được trộn thích ứng hơn và thân thiện hơn với việc huấn luyện mô hình, chúng tôi đề xuất một chiến lược huấn luyện mixup mới: huấn luyện mixup tiến bộ từ dễ đến khó. Ý tưởng này được lấy cảm hứng từ hành vi học tập của con người: lịch trình học tập của con người thường bắt đầu từ các tác vụ dễ dàng hơn và dần dần tiến triển đến các tác vụ thách thức hơn. Đầu tiên chúng tôi đề xuất mức độ khó khăn để đo lường độ khó khăn của mô hình trong việc học các mẫu và sau đó thực hiện mixup trong hai giai đoạn: (1) chia tập dữ liệu dựa trên mức độ khó khăn, và (2) trộn hai mẫu theo thứ tự độ khó khăn từ dễ đến khó.

Để có được mức độ khó khăn d(xi) cho mẫu xi, chúng tôi tính toán sự khác biệt giữa xác suất dự đoán của mô hình trên nhãn chính xác p(yi|xi) và xác suất dự đoán tối đa trong các nhãn sai như Phương trình 3:

d(xi) = 1-(p(yi|xi)-max y∈C,y≠yi p(y|xi)), (3)

nơi yi biểu thị nhãn sự thật cơ bản, và C biểu thị tập hợp của tất cả các nhãn ứng viên.

Trong giai đoạn đầu tiên của học tập tự-tiến hóa (SE), chúng tôi chia dữ liệu huấn luyện thành hai tập dữ liệu theo mức độ khó khăn. Cho một tập huấn luyện D, chúng tôi tính toán mức độ khó khăn của mỗi mẫu như đã đề cập trong Phương trình 3. Sau đó, chúng tôi sử dụng trung vị của mức độ khó khăn để phân chia tập dữ liệu: chúng tôi gán các mẫu có mức độ khó khăn nhỏ hơn trung vị cho tập dữ liệu dễ học Deasy, và các mẫu có mức độ khó khăn lớn hơn trung vị cho tập dữ liệu khó học Dhard.

Trong giai đoạn thứ hai của học tập tự-tiến hóa, chúng tôi thực hiện mixup từ Deasy đến Dhard. Đối với dữ liệu dễ học, chúng tôi thực hiện các thao tác mixup trên Deasy. Cho một mẫu xi từ Deasy, chúng tôi tìm kiếm mẫu tương tự nhất xj trong Deasy, nơi độ tương tự được đo bằng độ tương tự cosine. Sau đó, chúng tôi trộn hai mẫu bằng cách nội suy các đầu vào (xi và xj) và nhãn (yi và yj) như Phương trình 1 và Phương trình 2. Dữ liệu được chọn theo quy trình trên sau đó được sử dụng để huấn luyện, và dữ liệu được tạo ra kết quả được thêm vào việc huấn luyện mô hình. Trong tập dữ liệu khó học, chúng tôi làm theo cách tương tự chọn hai mẫu tương tự nhất và trộn để tạo thành một mẫu giả. Mẫu này phục vụ như một mẫu mới để tăng cường dữ liệu huấn luyện. Thuật toán 1 tóm tắt quy trình trên.

3.4 Làm mượt Nhãn Cụ thể cho từng Thực thể để Điều chỉnh
Để tránh sự quá tự tin gây ra bởi nhãn cứng trong các tình huống số lượng mẫu ít, chúng tôi đề xuất một phương pháp làm mượt nhãn cụ thể cho từng thực thể (ILS) mới để điều chỉnh thích ứng việc huấn luyện và cải thiện khả năng tổng quát hóa của mô hình phân loại.

Phương pháp làm mượt nhãn truyền thống (LS) thay thế phân phối nhãn cứng yi bằng y'i như Phương trình 4, nơi y'i là một hỗn hợp của phân phối nhãn gốc yi và một phân phối ui. ui thường là một phân phối đồng nhất.

y'i = (1-α) * yi + αui (4)

LS truyền thống làm giảm giá trị của nhãn chính xác và tăng tất cả những nhãn khác, điều này thành công ngăn chặn điểm dự đoán lớn nhất lớn hơn nhiều so với tất cả những điểm khác (Szegedy et al., 2016). Tuy nhiên, trong LS truyền thống, phân phối của u được cố định và u không thể tạo ra nhãn động để thích ứng với việc học mô hình.

Được thúc đẩy bởi quan sát này, trong việc làm mượt nhãn cụ thể cho từng thực thể của chúng tôi, chúng tôi đề xuất một phân phối tiên nghiệm nhận biết mẫu để làm mượt các nhãn. Cụ thể, chúng tôi thay thế phân phối cố định u bằng một phân phối động và thông tin được tạo ra thích ứng bởi chính mô hình phân loại. Trong thực tế, tương tự như Phương trình 4, chúng tôi làm mượt nhãn bằng cách nội suy nhãn gốc yi với p(y|xi) được dự đoán bởi mô hình phân loại. Trên tất cả các lớp ứng viên yi là một vectơ one-hot, nơi giá trị của nó (tức là xác suất) trên lớp chính xác là 1 và giá trị của nó trên lớp khác là 0. p(y|xi) là phân phối xác suất dự đoán của mô hình trên tất cả các lớp. Chúng tôi xem xét dự đoán mô hình p(y|xi) như khả năng là nhãn chính xác từ quan điểm của mô hình. Khi mô hình được tối ưu hóa, dự đoán mô hình trở nên ngày càng chính xác hơn và nhãn được dự đoán bởi mô hình tiếp cận nhãn lý tưởng. Chúng tôi có được nhãn được làm mượt cuối cùng y'i như:

y'i = (1-α) * yi + αri (5)

Sau đó chúng tôi nhận được nhãn mượt được trộn ỹ'i thông qua Phương trình 2. Cuối cùng, trong giai đoạn huấn luyện SE, chúng tôi sử dụng mất mát cross-entropy như sau:

LLS = -1/m Σ(i=1 to m) ỹ'i log pi (6)

4 Thí nghiệm
4.1 Tập dữ liệu
Để điều tra tính hiệu quả của phương pháp của chúng tôi, chúng tôi tiến hành các thí nghiệm mở rộng trên nhiều tác vụ hiểu ngôn ngữ khác nhau, bao gồm một sự đa dạng của các tác vụ từ GLUE (Wang et al., 2018), SuperGLUE (Wang et al., 2019) và các tiêu chuẩn khác, tức là phân tích cảm xúc (SST-2, Rotten tomato), suy luận ngôn ngữ tự nhiên (RTE, CB), paraphrase (MRPC), và phân loại văn bản (SUBJ, Amazon counterfactual). Để mô phỏng các tình huống số lượng mẫu ít, chúng tôi chọn ngẫu nhiên 10 mẫu mỗi lớp từ tập huấn luyện cho mỗi tác vụ, và sử dụng chúng để huấn luyện các mô hình. Để đánh giá, chúng tôi sử dụng Độ chính xác làm thước đo và báo cáo kết quả trung bình trên 5 hạt giống ngẫu nhiên để tránh tính ngẫu nhiên. Do hạn chế về không gian, chúng tôi hiển thị chi tiết của tất cả các tác vụ và tập dữ liệu trong Phụ lục A.1 (Bảng 5).

4.2 Chi tiết Thực hiện
Chúng tôi sử dụng các mô hình BERT (Devlin et al., 2019) -BASE và -LARGE đại diện làm PLMs xương sống, và tinh chỉnh chúng theo cách hai giai đoạn. Cụ thể, theo nhiều phương pháp mixup trước đây (Chen et al., 2020; Yoon et al., 2021), đầu tiên chúng tôi huấn luyện PLMs xương sống (không sử dụng mixup) với tỷ lệ học 5e-5, và sau đó tiếp tục tinh chỉnh các mô hình sử dụng chiến lược mixup với tỷ lệ học 1e-5. Lưu ý rằng các phương pháp của chúng tôi chỉ được sử dụng trong giai đoạn thứ hai.

Chúng tôi đặt độ dài chuỗi tối đa là 128 và kích thước batch là 32. Bộ tối ưu hóa AdamW (Loshchilov và Hutter, 2018) với trọng số suy giảm 1e-4 được sử dụng để tối ưu hóa mô hình. Chúng tôi sử dụng một bộ lập lịch tuyến tính với khởi động cho 10% tổng bước huấn luyện.

4.3 Các phương pháp So sánh
Chúng tôi so sánh phương pháp của chúng tôi với các đối tác tiên tiến khác. Cụ thể, lấy TMix (Chen et al., 2020) làm phương pháp mixup cơ bản, chúng tôi sử dụng các chiến lược sau để cải thiện hiệu suất của nó:

• AUM (Park và Caragea, 2022): AUM so sánh logits để phân loại các mẫu thành hai tập hợp và sau đó nội suy các mẫu giữa những tập hợp này bằng cách xác định các mẫu tương tự nhất và không tương tự nhất từ tập hợp đối lập.

• DMix (Sawhney et al., 2022): DMix chọn các mẫu dựa trên sự đa dạng của chúng trong không gian embedding.

• SE (Của chúng tôi): SE chia tập dữ liệu thành dễ học và khó học và sau đó trộn hai mẫu theo thứ tự độ khó khăn từ dễ đến khó.

Ngoài ra, để tham khảo, chúng tôi báo cáo kết quả của một số phương pháp tăng cường dữ liệu truyền thống, tức là EDA (Wei và Zou, 2019), Back Translation (Shleifer, 2019) và CBERT (Wu et al., 2019). Để xác minh tính phổ quát của SE của chúng tôi, chúng tôi cũng cố gắng sử dụng nó cho các phương pháp mixup cơ bản khác, tức là EmbedMix (Guo et al., 2019), SSMix (Yoon et al., 2021) và TreeMix (Zhang et al., 2022).

4.4 Kết quả Chính
Kết quả đầy đủ của BERT-BASE và -LARGE được hiển thị trong Bảng 1 và Bảng 2, và chúng tôi có thể thấy rằng:

SE vượt trội hơn các đối tác tiên tiến trong hầu hết các thiết lập. Khi sử dụng TMix làm phương pháp cơ bản, SE của chúng tôi mang lại cải thiện hiệu suất tốt hơn nhiều so với các đối tác khác (AUM và DMix), tức là lên đến +4.51 điểm trung bình. Ngoài ra, so với các phương pháp DA truyền thống khác, SE cũng có thể đạt được hiệu suất vượt trội. Những kết quả này cho thấy tính hiệu quả của phương pháp SE của chúng tôi.

SE mang lại những cải thiện hiệu suất nhất quán và đáng kể trong tất cả các đường cơ sở. Ngoài TMix, chúng tôi cũng sử dụng SE của chúng tôi cho nhiều phương pháp mixup cơ bản hơn, tức là SSMix, EmbedMix và TreeMix, và hiển thị kết quả tương phản trong Bảng 1. Như thấy, so với các đường cơ sở, SE của chúng tôi có thể mang lại những cải thiện hiệu suất nhất quán và đáng kể trong tất cả những phương pháp này, chỉ ra tính phổ quát của nó.

SE hoạt động tốt trong cả hai kích thước mô hình. Ở đây, chúng tôi xác minh liệu SE của chúng tôi có thể vẫn hoạt động trong các tình huống mô hình lớn. Lấy một số tác vụ làm ví dụ, chúng tôi hiển thị kết quả tương phản trong Bảng 2. Có thể thấy rằng, với sự giúp đỡ của SE của chúng tôi, BERT-large đạt được hiệu suất tốt hơn nhiều so với các đường cơ sở. Những kết quả này chứng minh tính hiệu quả của SE của chúng tôi trong cả hai kích thước mô hình.

4.5 Nghiên cứu Loại bỏ
Chúng tôi đánh giá tác động của từng thành phần của SE của chúng tôi, bao gồm i) chiến lược học tập trên mixup, ii) phương pháp làm mượt nhãn cụ thể cho từng thực thể, iii) hệ số α.

Tác động của Chiến lược Học tập trên Mixup. Như đã đề cập trong §3.3, chúng tôi thực hiện quy trình mixup theo cách từ dễ đến khó, tức là đầu tiên trộn các mẫu dễ và sau đó trộn các mẫu khó. Ở đây, để điều tra tác động của các chiến lược học tập khác nhau trên mixup, chúng tôi tiến hành các thí nghiệm tương phản như sau: 1) "Ngẫu nhiên": chúng tôi chọn ngẫu nhiên các mẫu từ tập dữ liệu đầy đủ; 2) "Dễ đến khó": chúng tôi đầu tiên huấn luyện mô hình với các mẫu dễ và sau đó với các mẫu khó; 2) "Khó đến dễ": thứ tự học tập ngược lại với "Dễ đến khó". Kết quả chi tiết được liệt kê trong Bảng 3, và chúng tôi có thể thấy rằng cả hai chiến lược học tập theo thứ tự đều vượt trội hơn đường cơ sở "Ngẫu nhiên", chỉ ra tầm quan trọng của học tập tiến hóa. Cụ thể hơn, "Dễ đến khó" đạt được hiệu suất tốt nhất, do đó để lại nó như thiết lập mặc định.

So sánh các Phương pháp Làm mượt Nhãn Khác nhau. Một công nghệ quan trọng trong phương pháp của chúng tôi là phương pháp làm mượt nhãn cụ thể cho từng thực thể. Để xác minh tính hiệu quả của nó, chúng tôi so sánh nó với làm mượt nhãn vanilla và báo cáo kết quả trong Bảng 4. Chúng tôi cho thấy rằng 1) cả hai phương pháp làm mượt nhãn đều đạt được hiệu suất tốt hơn so với đường cơ sở, xác nhận sự cần thiết để giảm thiểu vấn đề quá tự tin; 2) phương pháp của chúng tôi có thể cải thiện thêm kết quả bằng một biên rõ ràng so với làm mượt nhãn vanilla. Những kết quả này chứng minh tính hiệu quả của phương pháp ILS của chúng tôi.

Tác động của Hệ số α. Trọng số α trong Phương trình 4 được sử dụng để kiểm soát tỷ lệ của làm mượt nhãn, đây là một siêu tham số quan trọng. Trong phần này, chúng tôi kiểm tra tác động của nó bằng cách đánh giá hiệu suất với α khác nhau trên tác vụ SUBJ, và minh họa kết quả trong Hình 2. Như được hiển thị, so với đường cơ sở, phương pháp của chúng tôi liên tục đạt được hiệu suất tốt hơn trên tất cả các tỷ lệ của α. Cụ thể hơn, trường hợp α = 0.1 hoạt động tốt nhất, và chúng tôi do đó sử dụng thiết lập này trong các thí nghiệm của chúng tôi.

4.6 Mở rộng đến Các Tình huống Tài nguyên Cao
Mặc dù công việc của chúng tôi chủ yếu tập trung vào tăng cường dữ liệu trong các tác vụ số lượng mẫu ít, chúng tôi cũng điều tra xem phương pháp của chúng tôi có vẫn hoạt động trong các tình huống tài nguyên cao hay không. Cụ thể, chúng tôi thay đổi tỷ lệ phần trăm của dữ liệu huấn luyện được sử dụng từ 20% đến 100% và minh họa kết quả của một số tác vụ trong Hình 3.

Như mong đợi, phương pháp của chúng tôi đạt được những cải thiện hiệu suất đáng kể khi lượng dữ liệu huấn luyện cực kỳ hạn chế, tiếp tục xác nhận tính hiệu quả của phương pháp của chúng tôi. Hơn nữa, chúng tôi cũng có thể quan sát những cải thiện hiệu suất do SE của chúng tôi mang lại trong các tình huống tài nguyên tương đối cao khác. Những kết quả này chứng minh tính phổ quát của phương pháp của chúng tôi.

4.7 Phân tích Tổng quát hóa Mô hình
Để điều tra xem SE của chúng tôi có thể mang lại tổng quát hóa mô hình tốt hơn hay không, chúng tôi tiến hành các thí nghiệm từ hai khía cạnh: i) đo lường hiệu suất zero-shot xuyên tác vụ, và ii) trực quan hóa cảnh quan mất mát của các mô hình.

Tổng quát hóa Tác vụ. Hiệu suất của dữ liệu ngoài miền (OOD) được sử dụng rộng rãi để xác minh tổng quát hóa mô hình (Xu et al., 2021; Zhong et al., 2022). Do đó, chúng tôi làm theo Zhong et al. (2022) và đánh giá hiệu suất của các mô hình trên một số dữ liệu OOD. Trong thực tế, đầu tiên chúng tôi tinh chỉnh các mô hình dựa trên BERT được huấn luyện với các phương pháp khác nhau (bao gồm "Đường cơ sở", "SSMiX", và "SSMix+SE") trên tác vụ Rotten Tomato, và sau đó suy luận trên các tác vụ khác, tức là SST2, MRPC, RTE, và Amazon. Kết quả được minh họa trong Hình 4. Chúng tôi quan sát rằng "SSMix+SE" liên tục vượt trội hơn các đối tác khác. Cụ thể hơn, so với đường cơ sở, SE của chúng tôi mang lại điểm cải thiện trung bình +0.47 trên những tác vụ này, chỉ ra rằng phương pháp của chúng tôi tăng cường hiệu suất của các mô hình trên dữ liệu OOD.

Trực quan hóa Cảnh quan Mất mát. Để có cái nhìn gần hơn, chúng tôi cũng trực quan hóa cảnh quan mất mát của các mô hình BERT-base khác nhau được tinh chỉnh trên tác vụ Rotten Tomato. Trong thực tế, chúng tôi làm theo thiết lập "filter normalized" trong Li et al. (2018) và hiển thị kết quả bề mặt mất mát 3D trong Hình 5. Chúng tôi có thể thấy rằng phương pháp của chúng tôi có các bề mặt phẳng hơn mượt mà hơn so với các phương pháp khác. Kết quả này chứng minh rằng SE có thể làm mượt cảnh quan mất mát và cải thiện tổng quát hóa của các mô hình một cách hiệu quả.

5 Kết luận
Trong bài báo này, chúng tôi đề xuất một cơ chế học tập tự-tiến hóa (SE) đơn giản nhưng hiệu quả để cải thiện các phương pháp mixup hiện có trong các tác vụ phân loại văn bản. SE cho mixup theo hai giai đoạn: tiến hành phân chia dữ liệu dựa trên mức độ khó khăn và mixup dựa trên thứ tự từ dễ đến khó. SE có thể được sử dụng trong nhiều phương pháp mixup khác nhau để tạo ra các mẫu giả thích ứng hơn và thân thiện với mô hình cho việc huấn luyện mô hình. Ngoài ra, để tránh sự quá tự tin trong mô hình, chúng tôi đề xuất một phương pháp làm mượt nhãn cụ thể cho từng thực thể mới. Các thí nghiệm mở rộng trên bốn phương pháp mixup phổ biến, EmbedMix, TMix, SSMix, và TreeMix, xác minh tính hiệu quả của phương pháp của chúng tôi. Các phân tích định lượng và thảo luận sâu cho thấy phương pháp của chúng tôi cải thiện tổng quát hóa, và tính mạnh mẽ của các mô hình.

Hạn chế
Công việc của chúng tôi có một số hạn chế tiềm năng. Đầu tiên, do tài nguyên tính toán hạn chế, chúng tôi chỉ xác thực học tập tự-tiến hóa của chúng tôi trên các mô hình BERT kích thước base và large. Mở rộng các thí nghiệm của chúng tôi đến các kích thước mô hình lớn hơn sẽ làm cho công việc của chúng tôi thuyết phục hơn. Mặt khác, đối với kết quả của các phương pháp đường cơ sở, chúng tôi nên so sánh kết quả của chúng tôi với những kết quả trong bài báo gốc để có sự so sánh công bằng. Tuy nhiên, do sự khác biệt của PLMs và các tác vụ được sử dụng trong các đường cơ sở khác và của chúng tôi, việc so sánh kết quả trực tiếp là không hợp lý. Do đó, như một lựa chọn thay thế, chúng tôi chỉ tái tạo kết quả trong thiết lập của chúng tôi sử dụng mã trong các bài báo tương ứng.

Tuyên bố Đạo đức
Chúng tôi rất coi trọng các cân nhắc đạo đức, và tuân thủ nghiêm ngặt Chính sách Đạo đức EMNLP. Bài báo này đề xuất một thuật toán học tập tự-tiến hóa để cải thiện chiến lược mixup hiện có. Phương pháp được đề xuất nhằm mục đích tăng cường chính xác dữ liệu huấn luyện số lượng mẫu ít với kho ngữ liệu huấn luyện gốc, thay vì khuyến khích mô hình tạo ra các câu mới có thể gây ra vấn đề đạo đức. Hơn nữa, tất cả các mô hình ngôn ngữ được huấn luyện trước và tập dữ liệu downstream được sử dụng trong bài báo này đều có sẵn công khai và đã được các nhà nghiên cứu sử dụng rộng rãi. Vì vậy, chúng tôi tin rằng nghiên cứu này sẽ không đặt ra các vấn đề đạo đức.

Lời cảm ơn
Công việc này được hỗ trợ bởi các quỹ sau: Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc dưới Số hiệu 62025208 và Số hiệu 62306330, Quỹ Phòng thí nghiệm Xiangjiang dưới Số hiệu 22XJ01012.

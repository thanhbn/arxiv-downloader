# 2204.11406.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/data-augmentation/2204.11406.pdf
# Kích thước tệp: 601399 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Tự tăng cường dữ liệu mạnh mẽ cho nhận dạng thực thể có tên với cơ chế tái trọng số meta
Linzhi Wu1, Pengjun Xie, Jie Zhou2, Meishan Zhang3y,
Chunping Ma, Guangwei Xu, Min Zhang3
1Trường Truyền thông và Phương tiện Mới, Đại học Thiên Tân
2Trường Thông tin Điện tử và Kỹ thuật Điện, Đại học Giao thông Thượng Hải
3Viện Tính toán và Trí tuệ, Đại học Công nghệ Harbin (Thâm Quyến)
{tjuwlz2020, machunpingjj}@163.com, sanny02@sjtu.edu.cn
{xpjandy, mason.zms, ahxgwOnePiece}@gmail.com, zhangmin2021@hit.edu.cn
Tóm tắt
Tự tăng cường dữ liệu gần đây đã nhận được sự quan tâm nghiên cứu ngày càng tăng để cải thiện hiệu suất nhận dạng thực thể có tên (NER) trong các tình huống ít tài nguyên. Thay thế token và mixup là hai kỹ thuật tự tăng cường dữ liệu không đồng nhất khả thi cho NER có thể đạt được hiệu suất hiệu quả với những nỗ lực chuyên biệt nhất định. Đáng chú ý, tự tăng cường dữ liệu có thể đưa vào dữ liệu tăng cường có tiềm năng nhiễu. Nghiên cứu trước đây chủ yếu dựa vào các ràng buộc dựa trên quy tắc thực nghiệm để giảm nhiễu cho các phương pháp tự tăng cường dữ liệu cụ thể một cách riêng lẻ. Trong bài báo này, chúng tôi xem xét lại hai phương pháp tự tăng cường dữ liệu điển hình này cho NER, và đề xuất một chiến lược tái trọng số meta thống nhất để tích hợp chúng một cách tự nhiên. Phương pháp của chúng tôi dễ dàng mở rộng, tác động ít đến một phương pháp tự tăng cường dữ liệu cụ thể. Các thí nghiệm trên các chuẩn NER tiếng Trung và tiếng Anh khác nhau cho thấy rằng phương pháp thay thế token và mixup của chúng tôi, cũng như sự tích hợp của chúng, có thể đạt được cải thiện hiệu suất hiệu quả. Dựa trên cơ chế tái trọng số meta, chúng tôi có thể tăng cường các ưu điểm của các kỹ thuật tự tăng cường dữ liệu mà không cần nỗ lực thêm nhiều.

1 Giới thiệu
Nhận dạng thực thể có tên (NER), nhằm trích xuất các thực thể có tên được định nghĩa trước từ một đoạn văn bản không có cấu trúc, là một nhiệm vụ cơ bản trong cộng đồng xử lý ngôn ngữ tự nhiên (NLP), và đã được nghiên cứu rộng rãi trong vài thập kỷ (Hammerton, 2003; Huang et al., 2015; Chiu và Nichols, 2016; Ma và Hovy, 2016). Gần đây, các mô hình mạng nơ-ron gán nhãn chuỗi có giám sát đã được khai thác phổ biến nhất cho NER, dẫn đến hiệu suất hiện đại nhất (SOTA) (Zhang và Yang, 2018; Li et al., 2020a; Ma et al., 2020).
Mặc dù đã có tiến bộ lớn, việc phát triển một mô hình NER hiệu quả thường yêu cầu một bộ dữ liệu huấn luyện có gán nhãn quy mô lớn và chất lượng cao, điều này thường khó có được trong các tình huống thực tế do việc chú thích tốn kém và mất thời gian của các chuyên gia con người. Hơn nữa, điều này sẽ cực kỳ nghiêm trọng vì ngôn ngữ đích, lĩnh vực đích và loại thực thể mong muốn đều có thể biến đổi vô hạn. Do đó, cài đặt ít tài nguyên với chỉ một lượng nhỏ bộ dữ liệu có chú thích có sẵn phổ biến hơn nhiều trong thực tế, mặc dù nó có thể dẫn đến sự suy giảm hiệu suất đáng kể do vấn đề overfitting.
Tự tăng cường dữ liệu là một giải pháp tiềm năng cho vấn đề này, đã nhận được sự chú ý rộng rãi (Zhang et al., 2018; Wei và Zou, 2019; Dai và Adel, 2020; Chen et al., 2020; Karimi et al., 2021). Động lực chính là tự động tạo ra một tập ví dụ huấn luyện giả được suy ra từ dữ liệu huấn luyện có gán nhãn vàng gốc. Đối với NER, một nhiệm vụ cấp token, các kỹ thuật tự tăng cường dữ liệu khả thi bao gồm thay thế token (Dai và Adel, 2020; Zeng et al., 2020) và mixup (Zhang et al., 2020a; Chen et al., 2020), được biến đổi ở đầu vào cấp thấp và biểu diễn ẩn cấp cao tương ứng.
Tuy nhiên, hiện tại vẫn còn một số hạn chế đối với các phương pháp thay thế token và mixup nói trên. Một mặt, cả hai đều yêu cầu một số nỗ lực chuyên biệt để cải thiện hiệu quả của chúng do tiếng ồn tiềm tăng được đưa vào bởi việc tự tăng cường dữ liệu, có thể hạn chế biểu diễn ngữ nghĩa hợp lệ của dữ liệu được tăng cường. Ví dụ, thay thế token thường bị hạn chế đối với các thực thể có tên trong bộ dữ liệu huấn luyện (Wu et al., 2019), và mixup có xu hướng được áp dụng trên các cặp ví dụ với khoảng cách ngữ nghĩa nhỏ (Chen et al., 2020). Mặt khác, mặc dù hai kỹ thuật này có vẻ trực giao và có thể bổ sung cho nhau, việc tích hợp chúng một cách hiệu quả và tự nhiên vẫn là một thách thức tiềm tàng.
Trong công trình này, chúng tôi xem xét lại các phương pháp thay thế token và mixup cho NER, và khảo sát hai kỹ thuật không đồng nhất dưới một khung tái trọng số meta thống nhất (như minh họa trong Hình 1). Đầu tiên, chúng tôi cố gắng nới lỏng các ràng buộc trước đây thành phạm vi rộng hơn cho các phương pháp này, cho phép các ví dụ huấn luyện giả đa dạng hơn và quy mô lớn hơn. Tuy nhiên, điều này không tránh khỏi sẽ tạo ra một số ví dụ tăng cường chất lượng thấp (tức là dữ liệu giả nhiễu) về tính đúng đắn ngôn ngữ học, có thể ảnh hưởng tiêu cực đến hiệu suất mô hình. Để giải quyết vấn đề này, chúng tôi trình bày một chiến lược tái trọng số meta để kiểm soát chất lượng của các ví dụ tăng cường và dẫn đến huấn luyện kháng nhiễu. Ngoài ra, chúng tôi có thể tích hợp hai phương pháp một cách tự nhiên bằng cách sử dụng cơ chế tái trọng số ví dụ, mà không cần bất kỳ sự chuyên biệt hóa nào trong một phương pháp tự tăng cường dữ liệu cụ thể.
Cuối cùng, chúng tôi thực hiện các thí nghiệm trên một số bộ dữ liệu chuẩn NER tiếng Trung và tiếng Anh để đánh giá các phương pháp được đề xuất. Chúng tôi chủ yếu tập trung vào các cài đặt ít tài nguyên, có thể được mô phỏng bằng cách chỉ sử dụng một phần của tập huấn luyện tiêu chuẩn khi quy mô lớn. Kết quả thí nghiệm cho thấy rằng cả phương pháp thay thế token và mixup của chúng tôi kết hợp với tái trọng số meta đều có thể cải thiện hiệu suất của mô hình baseline một cách hiệu quả, và sự kết hợp có thể mang lại cải thiện nhất quán. Các lợi ích tích cực trở nên đáng kể hơn khi quy mô dữ liệu huấn luyện giảm, cho thấy rằng các phương pháp tự tăng cường dữ liệu của chúng tôi có thể xử lý tốt NER ít tài nguyên. Ngoài ra, các phương pháp của chúng tôi vẫn có thể hoạt động ngay cả với lượng lớn dữ liệu huấn luyện. Mã nguồn có sẵn tại https://github.com/LindgeW/MetaAug4NER.

2 Phương pháp của chúng tôi
Trong phần này, trước tiên chúng tôi mô tả mô hình baseline. Sau đó, chúng tôi trình bày các phương pháp tự tăng cường dữ liệu để nâng cao mô hình baseline trong các cài đặt ít tài nguyên. Cuối cùng, chúng tôi elaborating về chiến lược tái trọng số meta, nhằm giảm thiểu tác động tiêu cực của các ví dụ tăng cường nhiễu gây ra bởi việc tự tăng cường dữ liệu đồng thời kết hợp các phương pháp tăng cường này một cách tinh tế.

2.1 Mô hình Baseline
Nhiệm vụ NER thường được hình thức hóa như một bài toán gán nhãn chuỗi, biến đổi các thực thể/không thực thể thành chuỗi nhãn ranh giới cấp token bằng cách sử dụng lược đồ BIO hoặc BIOES (Huang et al., 2015; Lample et al., 2016). Trong công trình này, chúng tôi áp dụng BERT-BiLSTM-CRF như kiến trúc mô hình cơ bản bao gồm bốn thành phần: (1) biểu diễn đầu vào, (2) mã hóa BiLSTM, (3) giải mã CRF, và (4) mục tiêu huấn luyện.

Biểu diễn đầu vào Cho một chuỗi đầu vào X = (x₁, ..., xₙ) có độ dài n, chúng tôi đầu tiên chuyển đổi nó thành các vectơ ẩn tuần tự sử dụng BERT được đào tạo trước (Devlin et al., 2019):
e₁, ..., eₙ = BERT(X); (1)
trong đó mỗi token được ánh xạ tới một biểu diễn ngữ cảnh hóa tương ứng.

Mã hóa Chúng tôi sử dụng một lớp LSTM hai chiều để trích xuất thêm các biểu diễn ngữ cảnh, quá trình này có thể được hình thức hóa như:
h₁, ..., hₙ = BiLSTM(e₁, ..., eₙ); (2)
trong đó hᵢ là đầu ra trạng thái ẩn của token thứ i trong chuỗi (i ∈ [1, n]).

Giải mã Đầu tiên, một lớp biến đổi tuyến tính được sử dụng để tính toán điểm số nhãn ban đầu. Sau đó, một ma trận chuyển đổi nhãn T được sử dụng để mô hình hóa sự phụ thuộc nhãn. Gọi Y = (y₁, ..., yₙ) là một chuỗi nhãn, điểm số s(Y|X) có thể được tính toán bởi:
oᵢ = Whᵢ + b;
s(Y|X) = ∑ᵢ₌₁ⁿ (T_{yᵢ₋₁,yᵢ} + oᵢ[yᵢ]); (3)
trong đó W, b và T là các tham số mô hình. Cuối cùng, chúng tôi sử dụng thuật toán Viterbi (Viterbi, 1967) để tìm chuỗi nhãn tốt nhất Y*.

Mục tiêu huấn luyện Chúng tôi khai thác mục tiêu cross-entropy cấp câu để huấn luyện. Cho một ví dụ huấn luyện có gán nhãn vàng (X, Y), chúng tôi có xác suất có điều kiện p(Y|X) dựa trên

--- TRANG 2 ---
hàm tính điểm được định nghĩa trong Phương trình 3, và sau đó áp dụng hàm cross-entropy để tính toán mất mát ví dụ đơn:
p(Y|X) = exp(s(Y|X)) / ∑_{Ỹ} exp(s(Ỹ|X));
L(X, Y) = -log p(Y|X); (4)
trong đó Ỹ biểu thị các chuỗi nhãn ứng viên.

2.2 Tự tăng cường dữ liệu
Các phương pháp tự tăng cường dữ liệu có thể giảm nhu cầu về các ví dụ có chú thích thủ công phong phú, có thể được thực hiện ở cấp đầu vào và cấp biểu diễn. Thay thế token và mixup là hai phương pháp phổ biến cho NER tương ứng với hai cấp độ khác biệt này. Ở đây, chúng tôi cố gắng mở rộng hai phương pháp tự tăng cường dữ liệu này.

Thay thế Token Thay thế token nhằm tạo ra các ví dụ giả dựa trên dữ liệu huấn luyện có gán nhãn vàng gốc bằng cách thay thế các token của câu đầu vào bằng các thay thế từ đồng nghĩa (Wu et al., 2019; Dai và Adel, 2020). Đối với NER, Wu et al. (2019) đã áp dụng phương pháp này để có được lợi ích hiệu suất trên các bộ dữ liệu tiếng Trung, trong đó các đối tượng được thay thế được giới hạn ở các thực thể có tên. Dai và Adel (2020) đã chứng minh thực nghiệm về tính ưu việt của việc thay thế từ đồng nghĩa giữa các lược đồ tăng cường khác nhau, trong đó các từ đồng nghĩa được truy xuất từ từ điển đồng nghĩa WordNet có sẵn.

Việc thay thế token của chúng tôi được thực hiện bằng cách xây dựng một từ điển đồng nghĩa, bao gồm các từ đồng nghĩa của thực thể có tên cũng như nhiều từ đồng nghĩa bình thường. Theo Wu et al. (2019), chúng tôi coi tất cả các thực thể cùng loại từ tập huấn luyện là từ đồng nghĩa, được thêm vào từ điển thực thể. Chúng tôi gọi nó là thay thế đề cập thực thể (EMS). Đồng thời, chúng tôi mở rộng việc thay thế đến các token không phải thực thể (tức là nhãn tương ứng là 'O'), được gọi là thay thế từ bình thường (NWS). Vì dữ liệu không có nhãn trong một lĩnh vực cụ thể dễ dàng truy cập, chúng tôi áp dụng thuật toán dựa trên word2vec (Mikolov et al., 2013; Pennington et al., 2014) để khai thác các token có ngữ nghĩa tương tự trên Wikidata thông qua biểu diễn từ phân tán (Yamada et al., 2020), và xây dựng một từ điển đồng nghĩa từ bình thường từ tập k-nearest token dựa trên khoảng cách độ tương tự cosine. Lưu ý rằng lược đồ này không yêu cầu truy cập đến từ điển đồng nghĩa cho một lĩnh vực cụ thể để có được từ đồng nghĩa.

Hình 2 trình bày một ví dụ về thay thế token, trong đó cả EMS và NWS đều tham gia. Cụ thể, cho một ví dụ huấn luyện có gán nhãn vàng (X, Y), chúng tôi thay thế token thực thể của X bằng một thực thể được lấy mẫu từ từ điển thực thể có cùng loại thực thể, và đồng thời thay thế token không phải thực thể của X bằng một từ đồng nghĩa được lấy mẫu. Sau đó, chúng tôi có thể có được một ví dụ giả (X', Y'). Đặc biệt, chúng tôi cân bằng các chiến lược EMS và NWS dựa trên tỷ lệ δ bằng cách điều chỉnh tỷ lệ phần trăm của các thao tác EMS, nhằm đạt được sự cân bằng tốt giữa tính đa dạng thực thể và tính đa dạng ngữ cảnh. Và, chúng tôi gọi phương pháp này là TS trong phần còn lại của bài báo cho ngắn gọn.

Mixup cho CRF Không giống như thay thế token được thực hiện ở đầu vào cơ bản, kỹ thuật mixup (Zhang et al., 2018) tạo ra các ví dụ ảo ở cấp biểu diễn đặc trưng trong lĩnh vực NLP (Guo et al., 2019). Ý tưởng chính là thực hiện nội suy tuyến tính trên cả đầu vào và đầu ra sự thật cơ bản giữa các cặp ví dụ được lấy mẫu ngẫu nhiên từ tập huấn luyện đã cho. Chen et al. (2020) đã trình bày công trình đầu tiên dựa trên khung phân loại token cho nhiệm vụ NER, và chiến lược mixup được hạn chế đối với các cặp ví dụ trong đó các câu đầu vào có ngữ nghĩa tương tự bằng cách sử dụng các quy tắc thực nghiệm cụ thể. Khác với phương pháp của họ, chúng tôi mở rộng kỹ thuật mixup đến việc giải mã CRF.

Chính thức, cho một cặp ví dụ (X₁, Y₁) và (X₂, Y₂) được lấy mẫu ngẫu nhiên từ tập huấn luyện có gán nhãn vàng, chúng tôi đầu tiên có được biểu diễn vectơ của chúng thông qua Phương trình 1, dẫn đến e₁,₁...e₁,n₁, và e₂,₁...e₂,n₂, tương ứng. Sau đó chúng tôi áp dụng nội suy tuyến tính để có được một ví dụ huấn luyện ảo mới (X', Y'). Ở đây chúng tôi giả định một chính quy hóa của nội suy tuyến tính từng cặp trên biểu diễn đầu vào và điểm số đầu ra, trong đó các thuộc tính sau đây phải được thỏa mãn:

X': {
    BERT(X') = e₁...eₙ
    eᵢ = λe₁,ᵢ + (1-λ)e₂,ᵢ; i ∈ [1, n]
Y': s(Y'|X') = λs(Y₁|X') + (1-λ)s(Y₂|X'); (5)

trong đó n = max(n₁, n₂) và λ được lấy mẫu từ phân phối Beta(α, α) (λ ∈ [0, 1] và α > 0). Theo công thức này, hàm mất mát có thể được tái công thức hóa như:

L(X', Y') = -log [exp(s(Y'|X')) / ∑_{Ỹ} exp(s(Ỹ|X'))]
         = λL(X', Y₁) + (1-λ)L(X', Y₂); (6)

điều này phù hợp với mục tiêu huấn luyện của Phương trình 4. Bằng cách này, phương pháp mixup của chúng tôi có thể phù hợp tốt với việc giải mã có cấu trúc.

2.3 Tái trọng số Meta
Mặc dù các kỹ thuật tự tăng cường dữ liệu có thể tạo ra nhiều ví dụ huấn luyện giả một cách hiệu quả, cách kiểm soát chất lượng của các ví dụ tăng cường là một thách thức tiềm tàng không thể bỏ qua. Đặc biệt, không giống như các nhiệm vụ phân loại cấp câu, nhận dạng thực thể rất nhạy cảm với ngữ nghĩa của ngữ cảnh. Trong khi các ví dụ tăng cường tích cực có thể giúp mô hình của chúng tôi tiến bộ, một số ví dụ tăng cường chất lượng thấp không tránh khỏi được đưa vào trong quá trình tự tăng cường dữ liệu có thể làm tổn hại hiệu suất mô hình cuối cùng.

Trong bài báo này, chúng tôi tận dụng một cơ chế tái trọng số meta để động và thích ứng gán

--- TRANG 3 ---
trọng số theo ví dụ cho mỗi mini-batch dữ liệu huấn luyện, được truyền cảm hứng từ Ren et al. (2018). Ý tưởng chính là một tập meta-data nhỏ và sạch được áp dụng để hướng dẫn huấn luyện các tham số mô hình, và mất mát được tạo ra bởi mini-batch của meta-data được khai thác để tái trọng số các ví dụ tăng cường trong mỗi batch trực tuyến. Một cách trực quan, nếu phân phối dữ liệu và hướng gradient-descent của ví dụ tăng cường tương tự với những ví dụ trong tập meta-data, mô hình của chúng tôi có thể phù hợp tốt hơn với mẫu tăng cường tích cực này và tăng trọng số của nó, và ngược lại. Nói cách khác, các ví dụ tăng cường sạch và hợp lệ có khả năng được huấn luyện đầy đủ hơn.

Cụ thể hơn, giả sử chúng tôi có một tập N ví dụ huấn luyện tăng cường D̂ = {(X_i, Y_i)}_{i=1}^N, mục tiêu tối ưu hóa cuối cùng của chúng tôi có thể được hình thức hóa như một mất mát có trọng số như sau:

θ*(w) = arg min_θ ∑_{i=1}^N w_i L(f(X_i; θ), Y_i); (7)

trong đó w_i ≥ 0 là trọng số có thể học được cho mất mát của ví dụ huấn luyện thứ i. f(·; θ) biểu diễn quá trình forward của mô hình chúng tôi (với tham số θ). Tham số tối ưu w* được xác định thêm bằng cách tối thiểu hóa mất mát sau đây được tính toán trên tập ví dụ meta D = {(X_i^m, Y_i^m)}_{i=1}^M (M ≪ N):

w* = arg min_w (1/M) ∑_{i=1}^M L(f(X_i^m; θ*(w)), Y_i^m); (8)

Tương ứng, chúng tôi cần tính toán θ* và w* tối ưu trong Phương trình 7 và 8 dựa trên hai vòng lặp tối ưu hóa lồng nhau một cách lặp đi lặp lại. Để đơn giản và hiệu quả, chúng tôi thực hiện một bước gradient-descent đơn cho mỗi lần lặp huấn luyện để cập nhật chúng thông qua một cách tiếp cận xấp xỉ trực tuyến. Tại mỗi bước huấn luyện t, chúng tôi lấy mẫu một mini-batch ví dụ tăng cường {(X_i, Y_i)}_{i=1}^n được khởi tạo với các trọng số có thể học. Sau một bước tối ưu hóa đơn, chúng tôi có:

θ̂^{(t+1)}(ξ) = θ^{(t)} - α∇_θ ∑_{i=1}^n ξ_i L(f(X_i; θ), Y_i); (9)

trong đó α là kích thước bước vòng lặp trong. Dựa trên các tham số được cập nhật, chúng tôi sau đó tính toán mất mát của mini-batch ví dụ meta được lấy mẫu {(X_j^{meta}, Y_j^{meta})}_{j=1}^m:

L_{meta}(θ̂) = (1/m) ∑_{j=1}^m L(f(X_j^{meta}; θ̂^{(t+1)}), Y_j^{meta}); (10)

Để khái quát hóa các tham số θ̂ tốt cho tập meta-data, chúng tôi lấy gradients của θ̂ w.r.t mất mát meta để tạo ra trọng số ví dụ và chuẩn hóa nó dọc theo mini-batch:

ξ̂_i = σ(∇_{ξ_i} L_{meta}(θ̂)|_{ξ_i=0});
w_i = ξ̂_i / (∑_j ξ̂_j + ε); (11)

trong đó σ(·) là hàm sigmoid và ε là một giá trị nhỏ để tránh chia cho zero. Cuối cùng, chúng tôi tối ưu hóa các tham số mô hình trên các ví dụ tăng cường với các trọng số được tính toán.

Thuật toán 1 minh họa quy trình huấn luyện chi tiết của chiến lược tái trọng số meta. Điều đáng chú ý là các ví dụ huấn luyện tăng cường chứa các ví dụ huấn luyện sạch gốc, phục vụ như meta-data không thiên vị. Vì việc thực thi thuật toán chỉ yêu cầu một định nghĩa rõ ràng về mục tiêu huấn luyện cho các ví dụ đầu vào, nó cũng có thể thích ứng tốt cho các ví dụ tăng cường ảo được tạo ra bởi phương pháp mixup của chúng tôi.

3 Thí nghiệm

3.1 Thiết lập
Bộ dữ liệu Để xác thực các phương pháp của chúng tôi, chúng tôi thực hiện thí nghiệm trên các chuẩn tiếng Trung: OntoNotes 4.0 (Weischedel et al., 2011) và Weibo NER (Peng và Dredze, 2015), cũng như các chuẩn tiếng Anh: CoNLL 2003 (Sang và Meulder, 2003) và OntoNotes 5.0 (Pradhan et al., 2013). Các bộ dữ liệu tiếng Trung được chia thành các phần huấn luyện, phát triển và kiểm tra theo Zhang và Yang (2018) trong khi chúng tôi thực hiện cùng phân chia dữ liệu như Benikova et al. (2014) và Pradhan et al. (2012) trên các bộ dữ liệu tiếng Anh. Chúng tôi theo Lample et al. (2016) sử dụng lược đồ gán thẻ BIOES cho tất cả các bộ dữ liệu. Thống kê chi tiết có thể được tìm thấy trong Bảng 4.

Chi tiết thực hiện Chúng tôi sử dụng BiLSTM một lớp và kích thước ẩn được đặt là 768. Tỷ lệ dropout được đặt là 0.5 cho đầu vào và đầu ra của BiLSTM. Về BERT, chúng tôi áp dụng mô hình BERT-base (BERT-base-cased cho NER tiếng Anh) và fine-tune các tham số bên trong cùng với tất cả các tham số module khác. Chúng tôi sử dụng bộ tối ưu hóa AdamW (Loshchilov và Hutter, 2019) để cập nhật các tham số có thể huấn luyện với β₁ = 0.9 và β₂ = 0.99. Đối với các tham số BERT, tốc độ học được đặt là 2e-5. Đối với các tham số module khác không bao gồm BERT, tốc độ học là 1e-3 và weight decay là 1e-4 được sử dụng. Gradient clipping được sử dụng để tránh gradient explosion bằng giá trị tối đa 5.0. Tất cả các mô hình được huấn luyện trên GPU NVIDIA Tesla V100 (32G). Thư viện higher được sử dụng cho việc thực hiện tối ưu hóa bậc hai liên quan đến Thuật toán 1.

Đối với NWS, chúng tôi sử dụng các vectơ từ được huấn luyện trên dữ liệu Wikipedia dựa trên mô hình GloVe (Pennington et al., 2014) và xây dựng tập từ đồng nghĩa cho bất kỳ từ không phải thực thể nào dựa trên top-5 độ tương tự cosine, trong đó các từ dừng được loại trừ. Như đã đề cập trong Phần 2.2, chúng tôi định nghĩa hai siêu tham số cốt lõi cho các phương pháp tự tăng cường dữ liệu của chúng tôi, một cho TS (tức là δ) và một cho mixup (tức là α). Cụ thể, chúng tôi đặt δ = 20% và α được lấy mẫu từ phân phối Beta(α, α) với α = 7, trong đó các chi tiết sẽ được hiển thị trong phần phân tích. Đồng thời, chúng tôi thực hiện việc tăng cường lên đến 5 lần tương ứng với dữ liệu huấn luyện gốc.

Đánh giá Chúng tôi thực hiện mỗi thí nghiệm 5 lần và báo cáo điểm F1 trung bình. Mô hình có hiệu suất tốt nhất trên tập phát triển sau đó được sử dụng để đánh giá trên tập kiểm tra.

3.2 Kết quả chính
Các kết quả chính được trình bày trong Bảng 1, 2 và 3, xác minh hiệu quả của phương pháp chúng tôi dưới cài đặt ít tài nguyên và cài đặt quy mô đầy đủ tiêu chuẩn, tương ứng. Vì Weibo là một bộ dữ liệu quy mô nhỏ, chúng tôi không xem xét tập huấn luyện một phần của nó cho cài đặt ít tài nguyên.

Cài đặt ít tài nguyên Chúng tôi lấy mẫu ngẫu nhiên 5%, 10% và 30% dữ liệu huấn luyện gốc từ OntoNotes và CoNLL03 cho các nghiên cứu mô phỏng. Bảng 1 hiển thị kết quả trong đó điểm F1 của baseline, +TS, +Mixup, và +Both được báo cáo. Chúng tôi có thể quan sát thấy rằng: (1) hiệu suất baseline sẽ giảm đáng kể khi kích thước dữ liệu huấn luyện giảm dần, điều này chứng minh hiệu suất của mô hình NER có giám sát phụ thuộc rất nhiều vào quy mô của dữ liệu huấn luyện có nhãn. (2) mặc dù số lượng ví dụ huấn luyện đã tăng, việc tự tăng cường dữ liệu vanilla (không có tái trọng số meta) có thể làm suy giảm hiệu suất mô hình do các ví dụ có nhãn giả có thể không đáng tin cậy. Chiến lược tái trọng số meta giúp trọng số thích ứng các ví dụ tăng cường trong quá trình huấn luyện, chống lại tác động tiêu cực và dẫn đến việc tăng hiệu suất ổn định và tích cực. Ngoài ra, khi quy mô dữ liệu huấn luyện giảm, hiệu quả của các phương pháp tăng cường có thể đáng kể hơn, cho thấy rằng các phương pháp tự tăng cường dữ liệu của chúng tôi có lợi rất nhiều cho các cài đặt ít tài nguyên, và sự kết hợp hai giai đoạn của hai phương pháp không đồng nhất có thể mang lại hiệu suất tốt hơn một cách nhất quán.

Cài đặt quy mô đầy đủ Bảng 2 và 3 hiển thị kết quả sử dụng dữ liệu huấn luyện quy mô đầy đủ. Kết quả chứng minh rằng mô hình baseline của chúng tôi đã mạnh. Mô hình sau khi tăng cường vanilla có thể hoạt động hơi tệ hơn vì mỗi ví dụ huấn luyện được đối xử như nhau ngay cả khi nó có nhiễu. Điều này cũng ngụ ý rằng việc tái trọng số meta của chúng tôi rất có ý nghĩa. Hơn nữa, mô hình cuối cùng của chúng tôi (+Both) có thể đạt được thêm lợi ích hiệu suất bằng cách tích hợp các phương pháp tự tăng cường dữ liệu này với cơ chế tái trọng số meta. Xu hướng tổng thể tương tự như cài đặt ít tài nguyên, nhưng các lợi ích tương đối nhỏ hơn khi dữ liệu huấn luyện đủ. Điều đó có thể được quy cho việc kích thước dữ liệu huấn luyện đủ lớn để thu hẹp khoảng cách hiệu suất giữa các mô hình baseline và tăng cường. Nó cũng gợi ý rằng phương pháp của chúng tôi không làm tổn hại hiệu suất mô hình ngay cả khi sử dụng đủ dữ liệu huấn luyện.

So sánh với công trình trước Chúng tôi cũng so sánh phương pháp của chúng tôi với công trình SOTA đại diện trước đây, trong đó tất cả các hệ thống được tham chiếu đều khai thác mô hình BERT được đào tạo trước. Như được hiển thị, so với Dai và Adel (2020) và Chen et al. (2020), phương pháp của chúng tôi hoạt động tốt hơn khi sử dụng dữ liệu huấn luyện hạn chế. Đối với Chen et al. (2020), mixup thuần túy hoạt động hơi tốt hơn do chiến lược lấy mẫu ví dụ được thiết kế tốt, nhưng khung tổng thể của chúng tôi vượt trội hơn của họ. Hơn nữa, phương pháp của chúng tôi có thể phù hợp với hiệu suất của cài đặt bán giám sát sử dụng thêm 10K dữ liệu huấn luyện không có nhãn. Bên cạnh đó, mô hình cuối cùng của chúng tôi, mà không sử dụng nhiều kiến thức bên ngoài, có thể đạt được kết quả rất cạnh tranh trên tập huấn luyện đầy đủ so với hầu hết các hệ thống trước đây.

3.3 Phân tích
Trong phần phụ này, chúng tôi tiến hành thêm các phân tích thí nghiệm chi tiết trên bộ dữ liệu CoNLL03 để hiểu rõ hơn về phương pháp của chúng tôi. Mối quan tâm chính của chúng tôi là về cài đặt ít tài nguyên, do đó các mô hình dựa trên 5%, 10% và 30% dữ liệu huấn luyện gốc là trọng tâm chính của chúng tôi.

Số lần tăng cường Kích thước của các ví dụ tăng cường là một yếu tố quan trọng trong hiệu suất mô hình cuối cùng. Thông thường, chúng tôi kiểm tra dữ liệu huấn luyện CoNLL03 5%. Như minh họa trong Hình 3, các ví dụ giả lớn hơn có thể có được hiệu suất tốt hơn trong một phạm vi nhất định. Tuy nhiên, khi số lần tăng cường tăng, xu hướng tăng của hiệu suất chậm lại. Cải thiện có xu hướng ổn định khi các mẫu giả được tăng lên khoảng 5 lần dữ liệu huấn luyện gốc. Việc tăng số lần tăng cường quá mức không nhất thiết mang lại cải thiện hiệu suất nhất quán. Và chúng tôi chọn một giá trị phù hợp cho dữ liệu huấn luyện của các kích thước khác nhau từ phạm vi [1, 8].

Ảnh hưởng của δ đối với thay thế Token Về chiến lược TS của chúng tôi, chúng tôi xem xét cả NWS và EMS đồng thời. Hai phần được pha trộn bởi một tham số tỷ lệ phần trăm δ, tức là δ cho EMS và (1-δ) cho NWS. Ở đây chúng tôi kiểm tra ảnh hưởng của δ trong mô hình tự tăng cường dữ liệu duy nhất bởi TS. Hình 4 hiển thị kết quả, trong đó δ = 0% và δ = 100% biểu thị mô hình chỉ với NWS và EMS, tương ứng. Như được hiển thị, mô hình của chúng tôi có thể đạt được hiệu suất tổng thể tốt hơn khi δ = 20%, cho thấy cả hai đều hữu ích cho chiến lược TS, và NWS có thể hơi tốt hơn. Một lý do có thể là các từ thực thể trong các ví dụ huấn luyện gốc tương đối thưa thớt (tức là nhãn 'O' chiếm ưu thế), cho phép NWS tạo ra các ví dụ giả đa dạng hơn.

Tham số Mixup Chúng tôi kiểm tra thêm mô hình chỉ với chiến lược mixup để hiểu các yếu tố quan trọng của mô hình mixup. Đầu tiên, chúng tôi phân tích ảnh hưởng của tham số trộn α. Như được mô tả trong Hình 5, chúng tôi có thể thấy rằng α thực sự ảnh hưởng đến hiệu quả của phương pháp mixup rất nhiều. Xem xét đặc điểm của phân phối Beta, λ được lấy mẫu sẽ tập trung hơn xung quanh 0.5 khi giá trị α trở nên lớn, dẫn đến trọng số tương đối cân bằng giữa các cặp ví dụ được trộn. Hiệu suất mô hình vẫn ổn định khi α khoảng 7. Thứ hai, chúng tôi nghiên cứu nơi thực hiện thao tác mixup vì có hai lựa chọn chính trong khung của chúng tôi, tức là biểu diễn ẩn của BERT hoặc BiLSTM cho nội suy tuyến tính. Bảng 5 báo cáo kết quả so sánh, chứng minh rằng cái trước là lựa chọn tốt hơn.

Nghiên cứu trường hợp Để hiểu rõ hơn về hiệu quả của cơ chế tái trọng số meta, chúng tôi trình bày một số ví dụ chất lượng cao và chất lượng thấp trong Bảng 6. Như được hiển thị, sự khác biệt giữa các ví dụ tích cực và tiêu cực cho TS có thể được phản ánh trong tính hợp lệ cú pháp và ngữ nghĩa của các ví dụ tăng cường. Tương tự, đối với mixup, có vẻ như các cặp ví dụ hợp lệ có khả năng tạo ra các ví dụ tăng cường tích cực hơn.

4 Công trình liên quan
Trong những năm gần đây, nghiên cứu về NER đã tập trung vào việc làm phong phú biểu diễn văn bản đầu vào (Zhang và Yang, 2018; Nie et al., 2020b; Ma et al., 2020) hoặc tinh chỉnh kiến trúc mô hình với các kiến thức bên ngoài khác nhau (Zhang và Yang, 2018; Ye và Ling, 2018; Li et al., 2020a; Xuan et al., 2020; Li et al., 2020b; Yu et al., 2020; Shen et al., 2021). Đặc biệt, mô hình NER, với sự hỗ trợ của các mô hình ngôn ngữ được đào tạo trước lớn (Peters et al., 2018; Devlin et al., 2019; Liu et al., 2019), đã đạt được những lợi ích hiệu suất ấn tượng. Tuy nhiên, những mô hình này chủ yếu phụ thuộc vào các chú thích thủ công phong phú, khiến chúng khó đối phó với những thách thức ít tài nguyên trong các ứng dụng thực tế. Thay vì theo đuổi một kiến trúc mô hình phức tạp, trong công trình này, chúng tôi khai thác mô hình BiLSTM-CRF kết hợp với BERT được đào tạo trước như cấu trúc mô hình cơ bản của chúng tôi.

Các phương pháp tự tăng cường dữ liệu đã được nghiên cứu rộng rãi trong các nhiệm vụ NLP khác nhau (Zhang et al., 2018; Wei và Zou, 2019; Dai và Adel, 2020; Zeng et al., 2020; Ding et al., 2020). Các phương pháp chính có thể được phân loại rộng rãi thành ba loại: (1) thay thế token (Kobayashi, 2018; Wei và Zou, 2019; Dai và Adel, 2020; Zeng et al., 2020), thực hiện thay thế cục bộ cho một câu cho trước, (2) diễn giải (Kumar et al., 2019; Xie et al., 2020; Zhang et al., 2020b), liên quan đến việc viết lại cấp câu mà không thay đổi đáng kể ngữ nghĩa, và (3) mixup (Zhang et al., 2018; Chen et al., 2020; Sun et al., 2020), thực hiện tăng cường cấp đặc trưng. Như một kỹ thuật tăng cường không phụ thuộc vào dữ liệu, mixup có thể giúp cải thiện khả năng khái quát hóa và tính mạnh mẽ của mô hình thần kinh của chúng tôi đóng vai trò như một regularizer hữu ích (Verma et al., 2019). Đối với NER, thay thế token và mixup rất phù hợp và đã được khai thác thành công với các nỗ lực chuyên biệt (Dai và Adel, 2020; Chen et al., 2020; Zeng et al., 2020), trong khi chiến lược diễn giải có thể dẫn đến sự không hoàn chỉnh cấu trúc và sự không nhất quán token-label, do đó chưa được quan tâm rộng rãi. Trong công trình này, chúng tôi chủ yếu khảo sát các kỹ thuật thay thế token và mixup cho NER, cũng như sự tích hợp của chúng. Mặc dù thành công của các phương pháp tự tăng cường dữ liệu khác nhau, việc kiểm soát chất lượng có thể là một vấn đề dễ bỏ qua bởi hầu hết các phương pháp.

Nhiều nghiên cứu trước đây đã khám phá cơ chế trọng số ví dụ trong thích ứng lĩnh vực (Jiang và Zhai, 2007; Wang et al., 2017; Osumi et al., 2019). Xia et al. (2018) và Wang et al. (2019) đã xem xét các phương pháp trọng số ví dụ cho các nhiệm vụ xuyên lĩnh vực. Ren et al. (2018) đã thích ứng thuật toán MAML (Finn et al., 2017) và đề xuất một thuật toán meta-learning để tự động trọng số các ví dụ huấn luyện của nhãn nhiễu sử dụng một tập validation nhỏ không thiên vị. Được truyền cảm hứng từ công trình của họ, chúng tôi mở rộng cơ chế tái trọng số ví dụ meta cho nhiệm vụ NER, được khai thác để thích ứng tái trọng số các ví dụ tăng cường mini-batch trong quá trình huấn luyện. Mục đích chính là giảm thiểu các tác động tiếng ồn tiềm tàng mang lại bởi các kỹ thuật tự tăng cường dữ liệu, thúc đẩy một mô hình kháng nhiễu, đặc biệt trong các tình huống ít tài nguyên.

5 Kết luận
Trong bài báo này, chúng tôi xem xét lại hai phương pháp tự tăng cường dữ liệu không đồng nhất (tức là TS và mixup) cho NER, mở rộng chúng thành các tăng cường không hạn chế hơn mà không có các ràng buộc thực nghiệm. Chúng tôi khai thác thêm một chiến lược tái trọng số meta để giảm thiểu tác động tiêu cực tiềm tàng của các ví dụ tăng cường nhiễu được đưa vào bởi sự nới lỏng nói trên. Các thí nghiệm được thực hiện trên một số chuẩn cho thấy rằng các phương pháp tự tăng cường dữ liệu của chúng tôi cùng với cơ chế tái trọng số meta rất hiệu quả trong các cài đặt ít tài nguyên, và vẫn hoạt động khi đủ dữ liệu huấn luyện được sử dụng. Sự kết hợp của hai phương pháp có thể dẫn đến cải thiện hiệu suất nhất quán trên tất cả các bộ dữ liệu. Vì khung của chúng tôi là tổng quát và không dựa vào một backbone mô hình cụ thể, chúng tôi sẽ khảo sát thêm các cấu trúc mô hình khả thi khác.

Lời cảm ơn
Chúng tôi cảm ơn các nhận xét có giá trị của tất cả các reviewer ẩn danh. Công trình này được hỗ trợ bởi các khoản tài trợ từ Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc (Số 62176180).

Tài liệu tham khảo
[Các tài liệu tham khảo được liệt kê trong văn bản gốc]

# 2306.15766.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/data-augmentation/2306.15766.pdf
# Kích thước tệp: 484668 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Mô hình Ngôn ngữ Lớn làm Người chú thích: Tăng cường Khả năng Tổng quát hóa của Mô hình NLP với Chi phí Tối thiểu
Parikshit Bansal
Microsoft Research India
parikshitb52@gmail.com

Amit Sharma
Microsoft Research India
amshar@microsoft.com

Tóm tắt
Các mô hình NLP có giám sát tiên tiến đạt được độ chính xác cao nhưng cũng dễ bị lỗi trên các đầu vào từ các chế độ dữ liệu thấp, như các miền không được đại diện trong dữ liệu huấn luyện. Như một phép tính gần đúng để thu thập nhãn thực tế cho miền cụ thể, chúng tôi nghiên cứu việc sử dụng mô hình ngôn ngữ lớn (LLM) để chú thích đầu vào và cải thiện khả năng tổng quát hóa của mô hình NLP. Cụ thể, với ngân sách cho các chú thích LLM, chúng tôi trình bày một thuật toán để lấy mẫu các đầu vào thông tin nhất để chú thích và huấn luyện lại mô hình NLP. Chúng tôi thấy rằng các chiến lược học tích cực phổ biến như lấy mẫu dựa trên độ không chắc chắn không hoạt động tốt. Thay vào đó, chúng tôi đề xuất một chiến lược lấy mẫu dựa trên sự khác biệt trong điểm số dự đoán giữa mô hình cơ sở và mô hình NLP được tinh chỉnh, tận dụng thực tế rằng hầu hết các mô hình NLP đều được tinh chỉnh từ một mô hình cơ sở. Các thí nghiệm với các tác vụ phân loại (tương đồng ngữ nghĩa) và xếp hạng (tìm kiếm ngữ nghĩa) cho thấy rằng chiến lược lấy mẫu của chúng tôi dẫn đến những cải thiện đáng kể về độ chính xác cho cả miền huấn luyện và miền đích.

1 Giới thiệu
Một hạn chế phổ biến của các mô hình NLP có giám sát là chúng không thể tổng quát hóa trong các chế độ dữ liệu thấp, tương ứng với các đầu vào từ các nhóm con hoặc miền có dữ liệu có nhãn hạn chế trong tập huấn luyện. Những lỗi tổng quát hóa này xảy ra do sự chuyển đổi phân phối giữa các đầu vào mới và dữ liệu huấn luyện, làm cho một số tương quan được học bởi mô hình trở nên không hợp lệ (Wang et al., 2022). Ví dụ, các mô hình có thể học các tương quan giả với các thuộc tính nhạy cảm như giới tính (Sun et al., 2019) hoặc có thể quá nhấn mạnh các mẫu từ vựng (Gururangan et al., 2018); hoặc trong một số trường hợp, các đầu vào có thể thể hiện một khái niệm mới chưa từng thấy trong dữ liệu huấn luyện (Gama et al., 2014).

Như một ví dụ động viên, xem xét nhiệm vụ xác định tương đồng ngữ nghĩa giữa một cặp câu (Reimers and Gurevych, 2019). Nhiệm vụ này tạo thành cơ sở cho các hệ thống truy xuất thông tin và đề xuất như đề xuất câu hỏi tương tự trên các diễn đàn trực tuyến (Wang et al., 2018) hoặc đề xuất sản phẩm trên các trang web thương mại điện tử (He and McAuley, 2016). Trong các hệ thống như vậy, thường gặp các miền mới chưa thấy trong quá trình triển khai. Ví dụ, việc giới thiệu danh mục sản phẩm mới hoặc người dùng từ một nhóm nhân khẩu học mới có thể gây ra lỗi cho mô hình được triển khai do sự thay đổi trong phân phối đầu vào trong hệ thống so với dữ liệu huấn luyện. Dữ liệu không có nhãn sẵn có cho sự thay đổi phân phối như vậy (tức là, các câu hỏi mới được đăng bởi người dùng hoặc các sản phẩm từ danh mục mới), nhưng việc gán nhãn dữ liệu đòi hỏi nỗ lực đáng kể của con người. Trong các trường hợp khác, lỗi có thể xảy ra do các mẫu ngữ nghĩa khó học được tìm thấy trong một thiểu số nhỏ của dữ liệu huấn luyện (xem ví dụ cặp chứa các câu hỏi tương tự về từ vựng về oxy và glucose trong Hình 1).

Một giải pháp phổ biến trong tất cả các trường hợp này là thu thập thêm dữ liệu có nhãn khác biệt với phân phối dữ liệu huấn luyện, nhưng việc gán nhãn (hoặc chú thích) dữ liệu là một quá trình đắt đỏ và thủ công. Để giải quyết vấn đề này, nghiên cứu trước đây đề xuất sử dụng các mô hình ngôn ngữ lớn (LLM, (Ouyang et al., 2022; Brown et al., 2020)) để chú thích dữ liệu. Các LLM như GPT-3 đạt được độ chính xác hứa hẹn cho việc chú thích dữ liệu cho nhiều tác vụ NLP khác nhau bao gồm phân loại cảm xúc (Ding et al., 2022), liên quan từ khóa (Choi et al., 2023; Gilardi et al., 2023) và trả lời câu hỏi (Gilardi et al., 2023). Tuy nhiên, các chú thích dựa trên LLM có thể có tiếng ồn và do lý do hiệu quả, chúng ta không thể triển khai trực tiếp các mô hình LLM.

Trong bài báo này, chúng tôi thực hiện bước tiếp theo tự nhiên và hỏi liệu các chú thích từ LLM có thể được sử dụng để tăng cường khả năng tổng quát hóa của các mô hình NLP hiện có hay không. Với một kho dữ liệu không có nhãn, chúng tôi thấy rằng việc áp dụng LLM một cách ngây thơ (chú thích đầu vào ngẫu nhiên) chỉ cung cấp những cải thiện nhỏ về độ chính xác tổng thể và trong một số trường hợp, có thể làm tồi tệ hơn độ chính xác cho các nhóm dữ liệu thấp. Để tối ưu hóa việc lấy mẫu, chúng tôi xây dựng bài toán lấy mẫu đầu vào để chú thích như một bài toán học tích cực (Zhang et al., 2022). Tuy nhiên, chúng tôi thấy rằng chiến lược lấy mẫu phổ biến dựa trên độ không chắc chắn của mô hình (Lewis, 1995) cũng không tối ưu cho việc chú thích dựa trên LLM.

Sử dụng các thí nghiệm về các tác vụ phân loại (tương đồng ngữ nghĩa) và xếp hạng (tìm kiếm ngữ nghĩa), chúng tôi đề xuất một chiến lược thay thế để lấy mẫu đầu vào. Để lấy mẫu hiệu quả về chi phí các đầu vào không có nhãn mới cho các chú thích LLM, một giải pháp trực quan là chỉ chú thích những đầu vào mà mô hình NLP được dự kiến sẽ không chính xác, tức là các đầu vào mà dự đoán của mô hình NLP và nhãn thực tế sẽ khác nhau. Trong trường hợp không có nhãn GT cho các đầu vào mới, chúng tôi đề xuất một chỉ số, Tính thông tin có điều kiện, để tính gần đúng trực giác này. Chúng tôi sử dụng thực tế rằng các mô hình NLP có giám sát tiên tiến thường được tinh chỉnh từ một mô hình cơ sở như BERT (Vaswani et al., 2017) cung cấp một embedding ban đầu cho đầu vào. Đối với một đầu vào và một tác vụ NLP nhất định, Tính thông tin có điều kiện đo lường độ lệch giữa điểm số dự đoán từ mô hình cơ sở và điểm số từ mô hình NLP được tinh chỉnh sử dụng dữ liệu có nhãn có sẵn cho tác vụ. Chúng tôi cho rằng các đầu vào có độ lệch tối đa giữa hai điểm số là những đầu vào có khả năng được dự đoán sai bởi mô hình được tinh chỉnh và do đó là những đầu vào thông tin nhất để tinh chỉnh so với mô hình cơ sở.

Chỉ số lấy mẫu của chúng tôi cung cấp một cách thực tế để cải thiện khả năng tổng quát hóa của các mô hình NLP cho một tác vụ (xem Hình 1 để minh họa). Với ngân sách cho chú thích LLM (tức là, số lượng truy vấn), chúng tôi chọn các đầu vào có Tính thông tin có điều kiện tối đa cho chú thích LLM và sau đó huấn luyện lại mô hình NLP sử dụng dữ liệu huấn luyện bổ sung này. Thuật toán của chúng tôi cho thấy những cải thiện đáng kể về độ chính xác miền đích và tổng thể, trên tập dữ liệu Quora cho tác vụ tương đồng ngữ nghĩa, và trên các tập dữ liệu Amazon và Wikipedia cho tác vụ tìm kiếm ngữ nghĩa. Thuật toán của chúng tôi cũng cung cấp những cải thiện cao hơn so với việc lấy mẫu dựa trên độ không chắc chắn từ tài liệu học tích cực. Điều này có thể là do phân phối lỗi của các chú thích LLM: chỉ đối với các đầu vào có độ lệch cao, các chú thích dựa trên LLM mới có thể được kỳ vọng chính xác hơn so với mô hình cơ sở.

Tóm lại, chúng tôi đóng góp như sau:
1) Chỉ số Tính thông tin có điều kiện để lấy mẫu đầu vào cho chú thích dựa trên LLM vượt trội hơn các phương pháp học tích cực thường được sử dụng.
2) Các thí nghiệm về các tác vụ tương đồng ngữ nghĩa và tìm kiếm cho thấy các chú thích LLM có thể cải thiện đáng kể cả độ chính xác trong miền và miền đích.

2 Nghiên cứu Liên quan
LLM để tăng cường dữ liệu. Một khung phổ biến để cải thiện khả năng tổng quát hóa của mô hình NLP là tạo ra dữ liệu mới sử dụng LLM và kiểm tra đầu ra của mô hình bằng cách sử dụng con người trong vòng lặp, tức là LLM được sử dụng cùng với những người tham gia con người để tạo dữ liệu và kiểm tra/gỡ lỗi mô hình (Ribeiro and Lundberg, 2022; Wang et al., 2021). Trong nghiên cứu gần đây, (He et al., 2023b) sử dụng cùng chiến lược để huấn luyện một mô hình NLP: họ sử dụng GPT-3 để tạo dữ liệu cho các nhóm ít được đại diện, sau đó được chú thích bởi người dùng trước khi đưa vào tập huấn luyện.

Tuy nhiên, với các LLM có khả năng hơn như ChatGPT, LLM hiện tại có khả năng không chỉ tạo dữ liệu mà còn chú thích nó (trong khi tuân thủ trung thực các hướng dẫn chú thích). Nghiên cứu gần đây (Gilardi et al., 2023; He et al., 2023a; Ding et al., 2022) đã xem xét độ chính xác chú thích cho LLM và thấy chúng ngang bằng với những người chú thích đám đông. Kết hợp tạo và chú thích, song song với chúng tôi, (Whitehouse et al., 2023) khám phá tiện ích của cả đầu vào và nhãn được tạo từ LLM cho các tác vụ lý luận thông thường xuyên ngôn ngữ. Tương tự, đối với tác vụ xây dựng embedding câu sử dụng học tương phản, (Cheng et al., 2023) sử dụng LLM để tạo ra các cặp đầu vào mới và sau đó chấm điểm sự tương đồng của chúng.

Được động viên bởi các ứng dụng thực tế từ truy xuất thông tin, chúng tôi tập trung sự chú ý vào cài đặt thích ứng miền không giám sát (Ramponi and Plank, 2020) (UDA) nơi các đầu vào không có nhãn dễ dàng có sẵn. Các phương pháp UDA giả định một miền được gán nhãn nguồn và một miền đích không có nhãn với mục tiêu thích ứng với miền đích (trong khi cũng hoạt động tốt trên miền nguồn). Ví dụ, (Saad-Falcon et al., 2023) động viên tác vụ xếp hạng lại đoạn văn nơi một số lượng lớn các đoạn văn không có nhãn có sẵn. Họ sử dụng LLM để tạo ra các truy vấn tổng hợp cho một đoạn văn nhất định và sau đó sử dụng dữ liệu được tăng cường như vậy để huấn luyện một mô hình hạ nguồn. Với tiềm năng của dữ liệu được chú thích LLM để huấn luyện các bộ phân loại hạ nguồn và các chi phí liên quan đến việc truy vấn chúng, chúng tôi nghiên cứu cách

--- TRANG 3 ---
Cặp2 Đầu ra LLM 1. Tính toán Tính thông tin có điều kiện 4. Huấn luyện mô hình
Độ không chắc chắn
2. Lấy mẫu đầu vào
Tính thông tin có điều kiện
Ngẫu nhiên
Tương đồng từ vựng Tương đồng ngữ nghĩa
Cấu trúc của glucose là gì?
Cấu trúc của oxy là gì?
Làm thế nào để kết bạn?
Làm thế nào để tôi kết bạn?
Tương đồng ngữ nghĩa thấp
Tương đồng từ vựng cao
Đầu ra tất cả các cặp câu
hỏi cùng một câu hỏi.
Cặp1: Cấu trúc của glucose là gì?,
Cấu trúc của oxy là gì?
Cặp2: Làm thế nào để kết bạn?,
Làm thế nào để tôi kết bạn?
Trả lời:
LLM 3. Chú thích LLM
Prompt đầu vào
Tương đồng ngữ nghĩa cao
Tương đồng từ vựng cao
Độ chính xác
Lấy mẫu

Hình 1: Tăng cường Tổng quát hóa sử dụng Chú thích LLM. Minh họa thuật toán của chúng tôi sử dụng tác vụ phát hiện câu hỏi trùng lặp. Chúng tôi đề xuất một chiến lược lấy mẫu dựa trên độ lệch của điểm số tương đồng của mô hình NLP so với mô hình cơ sở, gọi là tính thông tin có điều kiện (mô hình cơ sở). Đầu vào được lấy mẫu sử dụng chiến lược này (Bước 2), được chú thích sử dụng LLM (Bước 3) và sau đó được thêm vào tập huấn luyện của mô hình NLP. Chiến lược lấy mẫu của chúng tôi hoạt động tốt hơn đáng kể so với các chiến lược ngẫu nhiên hoặc dựa trên học tích cực.

sử dụng hiệu quả các chú thích này để huấn luyện một mô hình NLP tổng quát hóa hơn; cụ thể, đầu vào nào cần chú thích để có lợi ích tối đa?

Tương đồng ngữ nghĩa với dữ liệu có nhãn hạn chế.
(Chen et al., 2023) trình bày một khảo sát toàn diện về các kỹ thuật tăng cường dữ liệu cho các cài đặt dữ liệu nhãn hạn chế trong NLP. AugSBERT (Thakur et al., 2020) trình bày một chiến lược tăng cường sử dụng một mô hình cross-encoder lớn hơn (oracle) để tạo ra (pseudo-)nhãn cho các đầu vào không có nhãn. Các đầu vào này sau đó được sử dụng để huấn luyện một mô hình NLP nhỏ hơn và hiệu quả hơn. Tuy nhiên, một oracle như vậy bị giới hạn bởi dữ liệu huấn luyện trong khi LLM được biết là có khả năng zero-shot tổng quát hóa đến các miền mới (Hou et al., 2023).

Ngoài tăng cường, các phương pháp thích ứng miền không giám sát cũng đã được đề xuất. Ngoài mất mát học tác vụ chính, (Ramesh Kashyap et al., 2021) đề xuất một mất mát bổ sung để giảm thiểu sự phân kỳ giữa các biểu diễn miền nguồn và đích. Nghiên cứu gần đây UDApter (Malik et al., 2023) kết hợp các phương pháp UDA với các adapter để thích ứng miền hiệu quả. Tuy nhiên, các kỹ thuật khớp miền chỉ hoạt động dưới một tập hợp các giả định hạn chế (Li et al., 2020). Thay vào đó, chúng tôi nhằm mục đích xấp xỉ các nhãn thực tế thông qua LLM, do đó chuyển đổi bài toán không giám sát thành một bài toán học có giám sát đơn giản hơn.

(Dua et al., 2022) nghiên cứu các chế độ lỗi của trả lời câu hỏi miền mở khi đối mặt với sự thay đổi phân phối. Ngoài ra, họ đề xuất một phương pháp tăng cường dữ liệu few-shot để cải thiện khả năng tổng quát hóa của các mô hình này. Việc tăng cường sử dụng LLM để tạo ra câu hỏi cho một đoạn văn nhất định.

Học tích cực. Việc chọn đầu vào nào để chú thích đã được nghiên cứu cổ điển như một bài toán học tích cực (Settles, 2009). Trong cài đặt học tích cực, chúng ta được cho một tập nhỏ các đầu vào có nhãn L, cùng với một nhóm lớn các đầu vào không có nhãn U. Chúng ta cũng được chỉ định một ngân sách B, biểu thị số lượng đầu vào từ dữ liệu không có nhãn có thể được chú thích bởi một oracle/con người. Học tích cực khám phá cách lấy mẫu tốt nhất B đầu vào từ nhóm không có nhãn để tối đa hóa độ chính xác tổng quát hóa của mô hình cuối cùng được huấn luyện trên L ban đầu + (được chú thích) B mẫu. Học tích cực sử dụng hai tiêu chí chính để chọn mẫu: Tính thông tin và Tính đại diện (Zhang et al., 2022). Kỹ thuật tính thông tin phổ biến nhất là lấy mẫu độ không chắc chắn (Lewis, 1995; Schröder et al., 2021) và cho tính đại diện là đa dạng/mật độ. Như một ứng dụng, nghiên cứu gần đây (Margatina et al., 2023) sử dụng học tích cực trong cài đặt học trong ngữ cảnh cho LLM và cho thấy rằng lấy mẫu dựa trên tương đồng (thay vì độ không chắc chắn và đa dạng) hiệu quả nhất cho học trong ngữ cảnh. Trong bài báo này, chúng tôi tập trung vào các chú thích dựa trên LLM và đánh giá kỹ thuật lấy mẫu tính thông tin dựa trên độ không chắc chắn. Dựa trên các thí nghiệm của chúng tôi, chúng tôi cũng đề xuất một tiêu chí tính thông tin mới.

3 Tiêu chí tính thông tin có điều kiện để lấy mẫu chú thích LLM

3.1 Bối cảnh: Xây dựng bộ phân loại NLP sử dụng mô hình cơ sở
Cho một miền câu X và một tác vụ T: X → {0,1} chúng tôi xem xét việc học một hàm phân loại f: X → {0,1} tuân theo tác vụ tức là f(x) = T(x) ∀x ∈ X. Hàm này nhằm mục đích học các đặc trưng có thể dự đoán nhãn đầu ra và ánh xạ của chúng đến nhãn đầu ra. Một tập con của miền X được ký hiệu bởi X = {x₀, x₁, x₂, ..., x|X|} ⊆ X. Nhãn đầu ra của xᵢ là T(xᵢ) và được ký hiệu bởi tᵢ. Một tập các ví dụ có thể được biểu diễn như

D = {(xᵢ, tᵢ) : i ∈ [|X|]} (1)

Các ví dụ không có nhãn thiếu nhãn tác vụ tᵢ.

Tương đồng ngữ nghĩa. Như một ví dụ, xem xét tác vụ tương đồng ngữ nghĩa (Cer et al., 2017). Đầu vào cho tương đồng ngữ nghĩa đến từ X × Y nơi X và Y là một cặp miền câu. Các miền có thể giống nhau hoặc khác nhau đối với tương đồng đối xứng và bất đối xứng tương ứng. Đối với một đầu vào (xᵢ, yᵢ) cho trước, đầu ra tác vụ là 1 nếu một cặp có nghĩa tương đồng, và 0 nếu chúng không. Bộ phân loại cho tương đồng ngữ nghĩa do đó được định nghĩa là f: X × Y → {0,1}. Chúng tôi ký hiệu một tập huấn luyện là:

D = {((xᵢ, yᵢ), tᵢ) : i ∈ [|X|]} (2)

Chi tiết thêm về tương đồng ngữ nghĩa có trong Phụ lục E.

Tinh chỉnh trên mô hình cơ sở. Các mô hình NLP thường được tinh chỉnh trên các mô hình văn bản được huấn luyện trước (ví dụ, chúng tôi sử dụng MSMARCO-DistilBERT-v4 cho tương đồng ngữ nghĩa) được gọi là mô hình cơ sở. Mô hình cơ sở tuân thủ một xấp xỉ của tác vụ dựa trên tập dữ liệu huấn luyện trước và cung cấp embedding ban đầu cho đầu vào. Chúng tôi gọi các đặc trưng này được định nghĩa bởi mô hình cơ sở là các đặc trưng được huấn luyện trước.

3.2 Một nghiên cứu trường hợp thích ứng miền: Đầu vào nào cần chú thích?
Để đánh giá các kỹ thuật lấy mẫu đầu vào khác nhau cho chú thích LLM, chúng tôi xem xét tác vụ tương đồng ngữ nghĩa của phát hiện câu hỏi trùng lặp. Chúng tôi huấn luyện các bi-encoder (SBERT (Reimers and Gurevych, 2019)) trên tập dữ liệu Quora Questions Pair (Wang et al., 2018), sử dụng MSMARCO-DistilBERT-v4 làm mô hình cơ sở. Để mô phỏng một miền đích thử thách, chúng tôi loại bỏ 60% các ví dụ "cực đoan" từ tập dữ liệu huấn luyện. Đây là những ví dụ mà mô hình cơ sở đạt được lỗi bình phương trung bình thấp nhất w.r.t. nhãn thực tế hoặc đạt được lỗi bình phương trung bình cao nhất. Tức là, một nửa số ví dụ (30%) là những ví dụ dễ mà mô hình cơ sở (gần như) đúng nhất và nửa còn lại là những ví dụ khó mà mô hình cơ sở (gần như) sai nhất. Hơn nữa, chúng tôi loại bỏ nhãn từ miền đích. Do đó từ dữ liệu ban đầu, chúng tôi có 40% ví dụ "nguồn" có nhãn và 60% ví dụ "đích" không có nhãn. Để đánh giá độ chính xác trên cả miền nguồn và đích, chúng tôi cũng tạo ra các miền tương tự trên tập kiểm tra.

Chúng tôi xem xét một cài đặt học tích cực nơi các đầu vào được chọn từ miền đích có thể được chú thích bởi một LLM và được tăng cường trong tập huấn luyện. Sau khi tăng cường, mô hình được huấn luyện trên miền nguồn + tập dữ liệu được tăng cường. Chúng tôi xem xét hai phương pháp lấy mẫu tích cực phổ biến trong tài liệu: Lấy mẫu ngẫu nhiên và dựa trên độ không chắc chắn. Ngoài những phương pháp này, chúng tôi bao gồm hai kỹ thuật lấy mẫu bổ sung dựa trên kiến thức của chúng tôi về miền đích: base-consistent-sample và base-inconsistent-sample. Những phương pháp này được thiết kế để bắt các ví dụ dễ và khó tạo thành miền đích. Cho dữ liệu có nhãn L, đầu vào không có nhãn U và ngân sách cho chú thích là B, chúng tôi có:

• random-sampling. Chúng tôi chọn ngẫu nhiên B đầu vào từ các đầu vào không có nhãn U để chú thích.
• uncertainty-sampling. Chúng tôi trước tiên tinh chỉnh mô hình cơ sở trên dữ liệu có nhãn L cho sẵn và sau đó chọn B (ngân sách) đầu vào không có nhãn không chắc chắn nhất (theo mô hình được tinh chỉnh) (từ U).
• base-consistent-sampling. Chúng tôi chọn B ví dụ hàng đầu có lỗi (MSE) thấp nhất trên dự đoán mô hình cơ sở với nhãn GT.
• base-inconsistent-sampling. Chúng tôi chọn B ví dụ hàng đầu có lỗi (MSE) cao nhất trên dự đoán mô hình cơ sở với nhãn GT.

Những B đầu vào này sau đó được chú thích và bao gồm để huấn luyện cuối cùng trên L+B.

AUC dưới các chiến lược lấy mẫu khác nhau. Sử dụng gpt-3.5-turbo làm LLM chú thích, chúng tôi báo cáo AUC (diện tích dưới đường cong ROC) trong Bảng 1. Chúng tôi đặt ngân sách B là 10% của tập dữ liệu để chú thích. Để biết chi tiết về các prompt được sử dụng, xem Phần 4.1.

Nhìn vào chỉ số AUC cho toàn bộ miền đích, chúng tôi quan sát thấy rằng random-sampling và uncertain-sampling dẫn đến những cải thiện tương tự so với tập huấn luyện. So với các kỹ thuật học tích cực này, base-inconsistent-sampling dẫn đến cải thiện AUC gần gấp đôi. Tức là, các chú thích với LLM tốt nhất dưới base-inconsistent-sampling. Đáng chú ý, chỉ với 10% ví dụ được chú thích, AUC với base-inconsistent-sampling thậm chí còn cao hơn cài đặt nơi chúng tôi tăng cường toàn bộ miền đích (100% ví dụ). Ngược lại, base-consistent-sampling làm tổn hại khả năng tổng quát hóa. Mặc dù base-consistent-sampling được thiết kế để lấy mẫu các ví dụ với lỗi mô hình cơ sở thấp, nó đạt được AUC tồi tệ hơn base-inconsistent-sampling trên các ví dụ kiểm tra với lỗi mô hình cơ sở thấp. Kết quả về việc sử dụng nhãn thực tế (GT) cho chú thích (thay vì chú thích LLM) có trong Bảng 11 Phụ lục.

Hàm ý. Các kết quả trên chỉ ra rằng đối với chú thích LLM, uncertainty-sampling có thể không phải là kỹ thuật tốt nhất. Để hiểu những kết quả này, lưu ý rằng mô hình ban đầu được tinh chỉnh trên tập huấn luyện (hàng đầu tiên trong Bảng 1, không có tăng cường từ miền đích) có khả năng tổng quát hóa cao (AUC) cho các đầu vào lỗi cơ sở thấp trong khi tổng quát hóa kém cho các đầu vào lỗi cơ sở cao. Chú thích với base-consistent-sampling do đó là lãng phí ngân sách vì mô hình cơ sở và mô hình tinh chỉnh đơn giản đã tốt trên các đầu vào lỗi cơ sở thấp. Hơn nữa, vì các chú thích LLM không hoàn hảo, tăng cường với base-consistent-sampling đưa tiếng ồn vào mô hình, khi mô hình đã có độ chính xác cao.

Mặt khác, các ví dụ lỗi cơ sở cao, được nhắm mục tiêu bởi base-inconsistent-sampling, có chỗ cho cải thiện AUC đáng kể khi xem xét mô hình tinh chỉnh ban đầu. Điều này chỉ ra rằng chú thích LLM chỉ nên tập trung vào các đầu vào base-inconsistent-sampling, vì các chú thích như vậy có thể có thông tin nhất.

3.3 Chỉ số Tính thông tin có điều kiện
Dựa trên các thí nghiệm ở trên, chúng tôi thấy rằng khi được chú thích bởi LLM, các ví dụ lỗi cơ sở cao hoặc base-inconsistent có thông tin nhất để huấn luyện. Nhưng base-inconsistent-sampling, như mô tả ở trên, không thực tế vì nó đòi hỏi kiến thức về nhãn thực tế của các đầu vào. Do đó trong phần này, chúng tôi phát triển một chỉ số xấp xỉ để định lượng mức độ base-inconsistency của các đầu vào không có nhãn.

Chúng tôi sử dụng một chỉ số đo lường độ lệch của mô hình NLP được tinh chỉnh so với mô hình cơ sở, và gọi nó là Tính thông tin có điều kiện, vì nó phụ thuộc vào mô hình cơ sở ngoài mô hình được tinh chỉnh. Đối với một đầu vào xᵢ, chúng tôi định nghĩa nó là

zᵢ(f, f⁰) = Dev(f(xᵢ), f⁰(xᵢ)) (3)

trong đó f⁰ là mô hình cơ sở, f là mô hình được tinh chỉnh và Dev là một thước đo độ lệch. Chúng tôi sử dụng lỗi bình phương đơn giản trong công trình của chúng tôi. Trực giác là trong quá trình tinh chỉnh với mục tiêu giảm thiểu lỗi, một mô hình có nhiều khả năng lệch khỏi điểm số của mô hình cơ sở trên một đầu vào nếu mô hình cơ sở có lỗi cao trên đầu vào đó. Ở đây chúng tôi giả định rằng độ lệch điểm số của mô hình được tinh chỉnh nắm bắt khái niệm lỗi cơ sở này, có thể được tổng quát hóa cho các đầu vào không có nhãn.

Chúng tôi trình bày các ví dụ định tính từ chỉ số của chúng tôi trên tập dữ liệu Quora trong Bảng 2. Những đầu vào này được chọn bởi chỉ số Tính thông tin có điều kiện của chúng tôi như có độ lệch cao. Trong khi đối với cặp ví dụ đầu tiên, tương đồng từ vựng (ngữ nghĩa cơ sở) của cặp thấp, nghĩa ngữ nghĩa của chúng (ngữ nghĩa câu hỏi trùng lặp) giống nhau, trong khi đối với cặp thứ hai, trong khi tương đồng từ vựng cao, tương đồng ngữ nghĩa của chúng thấp. Khi thực hiện chú thích LLM, các đầu vào như thế này sẽ có thông tin nhất để huấn luyện.

Công thức ở trên định nghĩa Tính thông tin có điều kiện dựa trên độ lệch của điểm số tương đồng ngữ nghĩa đầu vào riêng lẻ. Nhưng chúng tôi cũng có thể định nghĩa Tính thông tin có điều kiện sử dụng độ lệch ở cấp độ miền. Ví dụ, đối với một tập dữ liệu đa miền với thông tin miền cho mỗi đầu vào, chỉ số có thể được tính trung bình trên toàn bộ miền để tìm ra các miền phù hợp nhất cho chú thích LLM.

--- TRANG 6 ---
Dữ liệu | Kiểm tra đầy đủ | Lỗi cơ sở cao | Lỗi cơ sở thấp
Tập huấn luyện ban đầu | 86.824 ±0.038 | 59.335 ±0.139 | 99.068 ±0.048
+ 100% (miền đích đầy đủ) | 87.544 ±0.035 | 65.785 ±0.121 | 98.164 ±0.044
+ Random-sampling 10% | 87.052 ±0.151 | 60.551 ±0.701 | 98.805 ±0.058
+ Uncertain-sampling 10% | 87.620 ±0.029 | 61.594 ±0.433 | 99.081 ±0.024
+ Base-consistent-sampling 10% | 86.763 ±0.149 | 59.986 ±0.340 | 98.833 ±0.024
+ Base-inconsistent-sampling 10% | 88.108 ±0.062 | 65.538 ±0.175 | 98.861 ±0.046

Bảng 1: AUC cho tác vụ câu hỏi trùng lặp Quora, trước và sau khi bao gồm các chú thích dựa trên LLM sử dụng bốn kỹ thuật lấy mẫu khác nhau: ngẫu nhiên, độ không chắc chắn, base-consistent và base-inconsistent. AUC được đánh giá trên tập kiểm tra đầy đủ, tập con kiểm tra với lỗi mô hình cơ sở cao và tập con kiểm tra với lỗi mô hình cơ sở thấp. Lấy mẫu chỉ 10% dữ liệu để chú thích sử dụng base-inconsistent-sampling tốt hơn việc chú thích với tập dữ liệu đích đầy đủ (100%).

Cặp | Tương đồng | Cơ sở | Được tinh chỉnh
Kế hoạch ăn uống tốt cho người đi lại muốn tăng cân là gì? | Thấp | Cao
Tôi nên ăn gì để tăng cân?
Làm thế nào để xác định cấu trúc của glucose? | Cao | Thấp
Làm thế nào để xác định cấu trúc của oxy?

Bảng 2: Các ví dụ kiểm tra Quora có Tính thông tin có điều kiện cao, tức là dự đoán được tinh chỉnh khác với dự đoán mô hình cơ sở. Mô hình cơ sở nắm bắt tương đồng từ vựng trong khi được tinh chỉnh nắm bắt ngữ nghĩa đích.

4 EAGLE: Tăng cường Tổng quát hóa sử dụng Chú thích LLM

Dựa trên chỉ số Tính thông tin có điều kiện, chúng tôi bây giờ trình bày thuật toán EAGLE để tăng cường khả năng tổng quát hóa của các mô hình NLP sử dụng chú thích LLM. Như trong Phần 3, chúng tôi xem xét một cài đặt học tích cực nơi chúng tôi được cho một số ví dụ có nhãn L và một nhóm đầu vào không có nhãn U cùng với ngân sách B để chú thích đầu vào không có nhãn (sử dụng LLM). Ngoài các tác vụ phân loại tiêu chuẩn, thuật toán của chúng tôi cũng có thể hoạt động cho các tác vụ khác như xếp hạng. Chúng tôi trước tiên trình bày thuật toán tổng quát và sau đó trình bày các thể hiện của nó cho một tác vụ phân loại (tương đồng ngữ nghĩa) và một tác vụ xếp hạng (tìm kiếm ngữ nghĩa).

4.1 Thuật toán EAGLE

Bước 1: Tính toán Tính thông tin có điều kiện
Như bước đầu tiên, chúng tôi tinh chỉnh mô hình cơ sở của chúng tôi trên dữ liệu có nhãn L để có được một mô hình được tinh chỉnh f tức là,
f = argminfE(xi,ti)∈L[L(f(xi), ti)] (4)

Sử dụng f, chúng tôi tính toán điểm số Tính thông tin có điều kiện zi(f, f⁰) trong đó f⁰ là mô hình cơ sở, cho mỗi đầu vào không có nhãn xi ∈ U tức là
z = {zi(f, f⁰) : xi ∈ U} (5)

Bước 2: Lấy mẫu đầu vào sử dụng Tính thông tin có điều kiện
Bước tiếp theo liên quan đến việc lấy mẫu đầu vào phù hợp cho chú thích LLM. Chúng tôi chọn thực hiện lấy mẫu Tính thông tin có điều kiện theo đầu vào, hoặc nếu dữ liệu được chú thích miền, chúng tôi có thể thực hiện chú thích cấp độ miền. Đối với lấy mẫu theo đầu vào, chúng tôi chọn B mẫu hàng đầu tức là
Usampled = {xi : zi ∈ top(z, B)} (6)

Đối với chú thích cấp độ miền, chúng tôi có thể thu được chỉ số Tính thông tin có điều kiện cấp độ miền (bằng cách tính trung bình chỉ số trên các đầu vào thuộc miền). Trong trường hợp này, ngân sách B được phân phối đều trên các đầu vào trong các miền được chọn.

Bước 3: Chú thích các đầu vào được lấy mẫu sử dụng LLM
Cho một tập các đầu vào không có nhãn được lấy mẫu Usampled, chúng tôi sử dụng chú thích LLM cho các đầu vào này để có được một tập được chú thích là L′sampled. Chúng tôi ký hiệu hàm chú thích LLM bởi T′: X → {0,1}, và do đó chú thích LLM cho đầu vào xi là t′i ∈ {0,1}. Tập dữ liệu được tăng cường được tạo từ U do đó là L′

L′sampled = {(xi, t′i) : xi ∈ U} (7)

Bước 4: Tinh chỉnh bộ phân loại trên dữ liệu có nhãn được tăng cường
Cuối cùng, chúng tôi tinh chỉnh mô hình cơ sở trên tập dữ liệu được tăng cường L + L′sampled sử dụng Eq 4.

4.2 Ứng dụng: Tương đồng ngữ nghĩa
Chúng tôi trình bày cách thuật toán của chúng tôi có thể được sử dụng cho tác vụ tương đồng ngữ nghĩa được mô tả trong Phần 3. Bước 1 tuân theo từ thuật toán chính. Việc tính toán Tính thông tin có điều kiện tuân theo Eq 3, với lưu ý duy nhất là hàm phân loại bây giờ nhận hai đầu vào:
zi(f, f⁰) = Dev(f(xi, yi), f⁰(xi, yi)) (8)

Lấy mẫu được thực hiện theo cách tương tự với thuật toán chọn B đầu vào hàng đầu có zi cao nhất.

Chi tiết chú thích LLM
Xem xét một tập các ví dụ không có nhãn U bao gồm các cặp (xi, yi) được chú thích bởi LLM. Chúng tôi xây dựng một prompt bao gồm tập các cặp (xi, yi) của các câu. Để tiết kiệm chi phí, chúng tôi xem xét 10 cặp trong mỗi prompt cho các thí nghiệm của chúng tôi. Prompt yêu cầu LLM xuất ra tất cả các cặp có nghĩa tương đồng (với ngữ nghĩa được định nghĩa thích hợp trong prompt). Tất cả các cặp được LLM xuất ra là tương đồng được coi là tương đồng trong khi phần còn lại thì không. Xem Bảng 3 để có ví dụ về đầu ra chú thích trên tập dữ liệu Quora.

Cặp | Độ lệch | GT | LLM
Tại sao Cuba dung thứ sự hiện diện của Căn cứ Hải quân Vịnh Guantanamo? | Thấp | 0 | 1
Vấn đề với Vịnh Guantanamo là gì? Tại sao nó chưa được đóng?
Những headhunter tốt nhất ở Mexico là ai? | Thấp | 1 | 0
Ai là những headhunter tốt nhất ở Mexico?
Mô hình định giá thứ ba là gì? | Cao | 0 | 0
Mô hình định giá là gì?
Giao dịch được thực hiện như thế nào ở Ấn Độ cổ đại? | Cao | 1 | 1
Có bằng chứng về việc người Ấn Độ cổ đại giao dịch nước ngoài không? Nếu có, họ giao dịch gì và với những quốc gia nào?

Bảng 3: Chú thích LLM (gpt-3.5-turbo) cho một số ví dụ độ lệch thấp và cao. LLM có thể đoán chính xác những ví dụ độ lệch cao trong khi không chính xác trên những ví dụ độ lệch thấp. Độ chính xác chú thích LLM là bất khả tri của độ lệch. Xem Phụ lục A để biết prompt được sử dụng.

4.3 Ứng dụng: Tìm kiếm ngữ nghĩa
Trong khi tương đồng ngữ nghĩa là một tác vụ cơ bản, các ứng dụng thế giới thực thường dựa vào tìm kiếm ngữ nghĩa. Trong các ứng dụng như vậy, X được gọi là tập tất cả các truy vấn được ký hiệu là X = {x₀, x₁, x₂, ..., x|X|}, trong khi Y là tập các nhãn được ký hiệu là Y = {y₀, y₁, y₂, ..., y|Y|}. Những tìm kiếm này tìm kiếm một khớp ngữ nghĩa tối ưu cho một câu x ∈ X từ tập Y, tức là

g(x,T) = argmaxyi∈Y T(x, yi) (9)

Trong thực tế, vì chúng ta không có ngữ nghĩa thực T (ví dụ, liên quan đến truy vấn), chúng ta sử dụng một số xấp xỉ của ngữ nghĩa cho argmax. Chúng ta ký hiệu một tập các ví dụ bởi:

Dsearch = {((xi, Y), Ti) : i ∈ [|X|]} (10)

trong đó
Ti = {tij : j ∈ [|Y|]} (11)

Các mẫu không có nhãn thiếu thông tin Ti. Theo Eqn. 3, Tính thông tin có điều kiện trên tập X được định nghĩa là

y = g(xi, f⁰)
zi(f, f⁰) = Dev(f(xi, y), f⁰(xi, y)) (12)

trong đó g(.) tìm yj ∈ Y gần nhất cho xi theo hàm embedding cơ sở f⁰ (Eqn 9).

Chi tiết chú thích LLM
Tập không có nhãn U bây giờ bao gồm các cặp (xi, Y) được chú thích bởi LLM. Truy vấn tương đồng ngữ nghĩa cho mỗi cặp truy vấn, nhãn {(xi, yj) : yj ∈ Y} rất tốn kém. Do đó, chúng tôi trước tiên tạo một tập nhãn được lọc từ một mô hình tương đồng ngữ nghĩa (trong trường hợp của chúng tôi là mô hình được tinh chỉnh) f. Với việc lạm dụng ký hiệu nhẹ, chúng tôi xem xét một mở rộng của hàm g trong Eq 9 là g(x, f, K) trong đó g bây giờ xuất ra một tập K nhãn hàng đầu cho mỗi truy vấn. Tập được lọc của chúng tôi do đó là Y′ = g(x, f, K) trong đó f là mô hình được tinh chỉnh. Tập Y′ do đó bao gồm K nhãn xếp hạng hàng đầu cho một truy vấn theo mô hình được tinh chỉnh f. Phần còn lại của các nhãn (không có trong xếp hạng K hàng đầu của mô hình được tinh chỉnh) tức là Y/Y′ có tương đồng ngữ nghĩa của chúng được đặt thành 0. Chúng tôi truy vấn LLM về tương đồng ngữ nghĩa của các nhãn trong tập được lọc Y′, trong đó |Y′| = K. Do đó điều này giúp chúng tôi giảm độ phức tạp của việc tìm kiếm qua toàn bộ không gian nhãn bằng cách hạn chế không gian tìm kiếm sử dụng mô hình được tinh chỉnh f. Chúng tôi lấy K = 10 cho tất cả các thí nghiệm. Đối với mỗi cặp {(xi, yj) : yj ∈ Y′}, chúng tôi sau đó có thể truy vấn LLM tương tự như cài đặt tương đồng ngữ nghĩa ở trên.

L′ = {((xi, Y), T′i) : (xi, Y) ∈ U} (13)

Chúng tôi quan sát thực nghiệm rằng tốt hơn là cung cấp một prompt cho mỗi truy vấn cùng với K nhãn được lọc hàng đầu của nó. Các nhãn nên được sắp xếp theo điểm số tương đồng ngữ nghĩa của chúng theo mô hình f trong prompt. Ví dụ về prompt được sử dụng trong các thí nghiệm của chúng tôi có thể tìm thấy trong Phụ lục A. Bước lọc trong tìm kiếm ngữ nghĩa có thể sử dụng bất kỳ mô hình tương đồng tốt nào. Trong các thí nghiệm của chúng tôi, chúng tôi sử dụng mô hình được tinh chỉnh f của chúng tôi cho bước lọc.

5 Thí nghiệm
Chúng tôi đánh giá thuật toán EAGLE trên hai tác vụ: 1) tương đồng ngữ nghĩa, một tác vụ cơ bản; 2) tìm kiếm ngữ nghĩa, một tác vụ thực tế được thúc đẩy bởi các ứng dụng truy xuất thông tin. Chúng tôi giả định rằng ngoài một số ví dụ có nhãn, chúng tôi cũng được cung cấp một nhóm lớn các đầu vào không có nhãn. Đối với tương đồng ngữ nghĩa, chúng tôi xem xét khả năng tổng quát hóa trong cài đặt dữ liệu có nhãn hạn chế, trong khi đối với tìm kiếm ngữ nghĩa, chúng tôi đánh giá khả năng tổng quát hóa đến các miền đích không có nhãn. Trong cài đặt dữ liệu có nhãn hạn chế, cả đầu vào có nhãn và không có nhãn đều tuân theo cùng một phân phối trong khi khi thích ứng với miền đích không có nhãn (đầu vào không có nhãn), có sự thay đổi phân phối trong các đầu vào của các ví dụ có nhãn và không có nhãn. Chúng tôi cho thấy cách lấy mẫu đầu vào dựa trên Tính thông tin có điều kiện của chúng tôi giúp cải thiện khả năng tổng quát hóa trong cả hai cài đặt này. Chúng tôi thực hiện các thí nghiệm trên tương đồng ngữ nghĩa/tìm kiếm dựa trên embedding như được định nghĩa dưới đây.

Tương đồng ngữ nghĩa/Tìm kiếm dựa trên embedding
Thao tác tìm kiếm argmax (Eq 9) trên tập truy vấn đầy đủ |X| là bậc hai (tức là |X| × |Y|). Để tính toán hiệu quả, chúng tôi sử dụng tương đồng ngữ nghĩa dựa trên embedding (SBERT (Reimers and Gurevych, 2019)), trong đó cả truy vấn và nhãn được embedding riêng biệt vào một không gian chuẩn hóa N chiều. Tích số chấm giữa các biểu diễn embedded của các câu đưa ra tương đồng ngữ nghĩa. Do đó mục tiêu là học một hàm embedding h: X ∪ Y → RN sao cho h(xi)ᵀh(yi) đưa ra tương đồng ngữ nghĩa giữa các hàm.

Phương pháp lấy mẫu. Ngoài Tính thông tin có điều kiện, chúng tôi xem xét random-sampling và thuật toán lấy mẫu dựa trên độ không chắc chắn của học tích cực. Như một oracle, chúng tôi cũng xem xét nhãn thực tế cho cùng các đầu vào được lấy mẫu bởi mỗi thuật toán lấy mẫu này.

Chi tiết triển khai. Chúng tôi xem xét mô hình cơ sở là MSMARCO-DistilBERT-v4 cho cả hai tác vụ. Đối với chú thích dựa trên LLM, chúng tôi sử dụng GPT-3.5-Turbo. Xem Phụ lục A để biết prompt được sử dụng trong các thí nghiệm. Chúng tôi đã thử các mô hình mã nguồn mở như TogetherComputer/RedPajama-INCITE-7B-Base (cùng với phiên bản Chat và Instruct) hoặc MosaicML/mpt-7b-chat nhưng không đạt được độ chính xác chú thích tốt. Tất cả kết quả được báo cáo cho 3 seed. Các chi tiết huấn luyện khác có trong Phụ lục C.

5.1 Tương đồng ngữ nghĩa

Cài đặt
Chúng tôi tiến hành các thí nghiệm trên tập dữ liệu Quora Question Pairs (Wang et al., 2018), bao gồm các cặp câu hỏi. Nhiệm vụ là gán nhãn cho mỗi cặp là trùng lặp hoặc không, tức là, liệu các câu hỏi có cùng ý định hay không. Chúng tôi lấy mẫu con 38400 cặp huấn luyện từ tập huấn luyện. Chúng tôi xem xét một cài đặt nơi 10% của tập dữ liệu Quora được gán nhãn bởi thực tế, trong khi 90% còn lại tạo thành nhóm dữ liệu không có nhãn. Chúng tôi trình bày các số AUC kiểm tra (Area-Under-ROC) làm chỉ số đánh giá.

--- TRANG 9 ---
Wikipedia Amazon
USA Total Books Total
Tập huấn luyện ban đầu 12.530 ±0.034 19.048 ±0.019 17.226 ±0.008 24.904 ±0.076
+ Target LLM Random 40% 13.188 ±0.073 19.232 ±0.024 17.959 ±0.075 25.065 ±0.049
+ Target LLM Tính thông tin có điều kiện (40% thấp nhất) 13.089 ±0.079 19.209 ±0.034 18.021 ±0.033 25.110 ±0.038
+ Target LLM Tính thông tin có điều kiện (40% giữa) 13.166 ±0.021 19.228 ±0.022 18.123 ±0.060 25.216 ±0.012
+ Target LLM Tính thông tin có điều kiện (40% cao nhất) 13.372 ±0.058 19.363 ±0.023 18.351 ±0.028 25.271 ±0.030
+ Target GT Random 40% 13.893 ±0.047 19.430 ±0.052 18.375 ±0.068 25.329 ±0.051
+ Target GT Tính thông tin có điều kiện (40% thấp nhất) 13.911 ±0.032 19.395 ±0.013 18.455 ±0.054 25.271 ±0.020
+ Target GT Tính thông tin có điều kiện (40% giữa) 13.973 ±0.070 19.327 ±0.023 18.400 ±0.027 25.213 ±0.075
+ Target GT Tính thông tin có điều kiện (40% cao nhất) 13.878 ±0.015 19.414 ±0.015 18.613 ±0.043 25.285 ±0.057

Bảng 5: P@1 cho miền đích kiểm tra (USA trong Wikipedia và Books trong Amazon) và tập kiểm tra đầy đủ. Đối với chú thích dựa trên LLM, 40% mẫu hàng đầu theo Tính thông tin có điều kiện của chúng tôi là tối ưu cho độ chính xác tổng thể (đồng thời cũng tối ưu cho độ chính xác miền đích). Đối với chú thích dựa trên GT, Lấy mẫu ngẫu nhiên là tốt nhất cho độ chính xác tổng thể. Phương pháp độ chính xác miền đích tốt nhất cho GT là không kết luận.

So sánh với Lấy mẫu ngẫu nhiên và Độ không chắc chắn
Chúng tôi tuân theo Thuật toán từ 4.1 cho tương đồng ngữ nghĩa. Sử dụng mô hình được tinh chỉnh trên dữ liệu có nhãn, chúng tôi lấy mẫu 10% dữ liệu không có nhãn để chú thích, theo các chiến lược lấy mẫu khác nhau (cụ thể là ngẫu nhiên, độ không chắc chắn và Tính thông tin có điều kiện). Để biết chi tiết về cách thực hiện chú thích LLM, xem Phần 4.2. Chúng tôi cũng trình bày kết quả về chú thích với nhãn thực tế tức là t′ᵢ = tᵢ (Phần 4.2). Trong Bảng 4, chúng tôi cho thấy rằng đối với chú thích dựa trên LLM, lấy mẫu dựa trên Tính thông tin có điều kiện đạt được AUC kiểm tra tốt hơn đáng kể so với lấy mẫu ngẫu nhiên và độ không chắc chắn. Để so sánh, đối với chú thích với nhãn GT, cả lấy mẫu dựa trên độ không chắc chắn và Tính thông tin có điều kiện đều mang lại AUC cao.

Đánh giá các Phần tư dựa trên Tính thông tin có điều kiện
Để tìm hiểu tại sao lấy mẫu dựa trên độ không chắc chắn không hoạt động đối với chú thích LLM, chúng tôi chia dữ liệu thành 20 phần tư, mỗi phần có 5% dữ liệu không có nhãn dựa trên chỉ số Tính thông tin có điều kiện. Hình 2 cho thấy sự gia tăng AUC khi bao gồm các mẫu này (được chú thích LLM hoặc GT) với dữ liệu huấn luyện. Như một so sánh, đường màu cam trong biểu đồ biểu thị độ chính xác khi lấy mẫu 5% từ chỉ số độ không chắc chắn (phần tô màu là lỗi tiêu chuẩn). Đối với chú thích LLM, chúng tôi quan sát thấy rằng độ không chắc chắn không phải là một kỹ thuật tốt để lấy mẫu và lấy mẫu dựa trên Tính thông tin có điều kiện tốt hơn, trong khi đối với các tăng cường dựa trên GT, lấy mẫu dựa trên độ không chắc chắn cung cấp những cải thiện tốt hơn so với lấy mẫu dựa trên Tính thông tin có điều kiện.

5.2 Tìm kiếm ngữ nghĩa

Tiếp theo, chúng tôi đánh giá tiện ích của lấy mẫu Tính thông tin có điều kiện cho khả năng tổng quát hóa đến các miền đích không có nhãn trong các tác vụ tìm kiếm ngữ nghĩa.

Tập dữ liệu
Chúng tôi xem xét hai tập dữ liệu đề xuất cho tìm kiếm ngữ nghĩa: 1) LF-WikiSeeAlsoTitles-320K (Bhatia et al., 2016) (tức là, Wikipedia) xem xét một cài đặt đề xuất/truy xuất. Tập huấn luyện bao gồm các tiêu đề trang Wikipedia (truy vấn X) cùng với một tập lớn các tiêu đề trang (nhãn Y). Đối với Wikipedia, một nhãn yⱼ có nghĩa tương đồng với một truy vấn xᵢ nếu nhãn có khả năng xuất hiện trong phần SeeAlso của trang wiki của bài viết truy vấn. Như mô tả trong Phần 4.3 cho tác vụ tìm kiếm ngữ nghĩa, tập các nhãn vẫn được cố định là Y. Nhiệm vụ là học các embedding tuân theo ngữ nghĩa ở trên. Đối với mỗi bài viết X, chúng tôi cũng phân tích thông tin danh mục của nó, mà chúng tôi sử dụng như nhãn miền của nó. Nếu đối với một bài viết xᵢ, thông tin phân loại của nó chứa "USA" hoặc "America", nó thuộc về miền USA, nếu không thì không. 2) LF-AmazonTitles-131K (Bhatia et al., 2016) (tức là, Amazon) xem xét các đề xuất trong cài đặt sản phẩm AlsoBought thương mại điện tử. Cho một sản phẩm truy vấn (X), các nhãn tương ứng với các sản phẩm có thể mà người dùng có thể mua (Y). Ở đây chúng tôi cũng xem xét thông tin phân loại cho tất cả các sản phẩm truy vấn X. Chúng tôi xây dựng hai miền trong Amazon. Tất cả các sản phẩm trong danh mục "Books" có trong miền Books, trong khi tất cả các sản phẩm trong danh mục "Kitchen and Dining" tạo thành miền Kitchen.

Cài đặt
Đối với Wikipedia, chúng tôi xem xét miền USA làm miền đích không có nhãn của chúng tôi, và phần còn lại của tập dữ liệu làm dữ liệu có nhãn của chúng tôi. Tương tự đối với Amazon, chúng tôi xây dựng hai phiên bản của tập dữ liệu, một phiên bản chúng tôi xem xét miền Books làm miền đích không có nhãn và một phiên bản khác chúng tôi xem xét Kitchen làm miền đích không có nhãn. Chúng tôi sử dụng chỉ số Precision@1 (P@1) để đánh giá, tức là phần các truy vấn có nhãn xếp hạng hàng đầu có nghĩa tương đồng (hoặc liên quan) với truy vấn, tức là,

Precision@1 = Exᵢ∈X[T(xᵢ, g(xᵢ, f))]

Đối với oracle chú thích GT, chúng tôi chú thích K nhãn được lấy mẫu hàng đầu (sử dụng mô hình được tinh chỉnh f) với thông tin thực tế tức là đối với một truy vấn xᵢ, t′ᵢⱼ = tᵢⱼ ∀yⱼ ∈ Y′ và t′ᵢⱼ = 0 ∀yⱼ ∉ Y′. Xem Phần 4.3 để biết ký hiệu (Eq 11,13). Lưu ý rằng đối với tất cả các nhãn không được xếp hạng trong K hàng đầu bởi mô hình được tinh chỉnh có tương đồng ngữ nghĩa của chúng được đặt thành 0, ngay cả khi chúng có liên quan trong GT. Để biết chi tiết khác, tham khảo Phụ lục C.

Kết quả
Chúng tôi trình bày P@1 kiểm tra cho các miền đích (miền USA trong Wikipedia và miền Books trong Amazon) và các tập kiểm tra miền nguồn + đích đầy đủ trong Bảng 5. Chúng tôi thấy rằng khi tăng cường với chú thích dựa trên LLM, việc chọn các đầu vào nằm trong 40% đầu vào hàng đầu theo Tính thông tin có điều kiện của chúng tôi là tối ưu cho độ chính xác tổng thể (đồng thời cũng tối ưu cho độ chính xác miền đích). Đối với chú thích dựa trên GT, Lấy mẫu ngẫu nhiên là tốt nhất cho độ chính xác tổng thể, mặc dù kết quả không có ý nghĩa.

Sử dụng Kiến thức miền để Đo lường định tính Tính thông tin có điều kiện
Trên tác vụ đề xuất Amazon, xem xét thích ứng miền cho miền Books hoặc Kitchen. Đối với đề xuất Books chỉ sử dụng tiêu đề sách (ví dụ, nói The Kite Runner cho A Thousand Splendid Suns) Tính thông tin có điều kiện sẽ cao đối với các mô hình dựa trên encoder (giả định rằng encoder không có kiến thức miền cần thiết cho đề xuất sách, tức là, hai cuốn sách chia sẻ cùng một tác giả). Tức là, nó sẽ đòi hỏi nhiều kiến thức thế giới hơn so với các miền như Kitchen, (ví dụ, Kaiser Bakeware Muffin Pan cho Nordic Ware Brownie Pan) có nhiều khả năng phù hợp với ngữ nghĩa của mô hình cơ sở (trong trường hợp này là tương đồng từ vựng).

Đối với miền Kitchen, chúng tôi có thể thấy trong Bảng 6 rằng việc bao gồm chú thích dựa trên LLM cho miền Kitchen không cung cấp bất kỳ cải thiện nào so với mô hình cơ sở. Để so sánh, đối với các miền khác như Books, chú thích LLM dẫn đến khả năng tổng quát hóa tốt hơn so với cả mô hình cơ sở và mô hình được tinh chỉnh tập huấn luyện. Tham khảo Phụ lục B để biết biểu đồ cho thấy cách LLM không tốt hơn mô hình được tinh chỉnh/cơ sở cho miền Amazon(Kitchen), trong khi đối với Wiki(USA) và Amazon(Books) LLM tốt hơn đáng kể (Hình 3). Đối với cải thiện độ chính xác trên miền Kitchen, các kỹ thuật sử dụng regularization đối với mô hình cơ sở có thể phù hợp và LLM có thể không cần thiết.

6 Kết luận
Chúng tôi đã cho thấy cách LLM có thể được sử dụng để chú thích và cách lấy mẫu đầu vào đóng vai trò quan trọng trong việc cải thiện khả năng tổng quát hóa của mô hình NLP. Để đạt được điều này, chúng tôi đã trình bày một thuật toán lấy mẫu mới để lựa chọn đầu vào hoạt động tốt hơn kỹ thuật phổ biến của lấy mẫu dựa trên độ không chắc chắn. Như công việc tương lai, chúng tôi muốn kiểm tra xem chỉ số Tính thông tin có điều kiện có áp dụng cho các tác vụ NLP khác ngoài tương đồng ngữ nghĩa hay không. Đối với cài đặt tìm kiếm ngữ nghĩa, với khả năng tạo sinh của LLM, một hướng tương lai thú vị là sử dụng LLM để tạo ra nhãn cho các truy vấn trong khi hạn chế tập nhãn được tạo ra đối với tập nhãn đích của chúng tôi.

Tài liệu tham khảo
[Các tài liệu tham khảo được giữ nguyên như bản gốc]

--- TRANG 13 ---
A Prompt LLM

A.1 Tương đồng ngữ nghĩa
Prompt được sử dụng: Hệ thống và prompt câu hỏi
Xem Bảng 7

A.2 Tìm kiếm ngữ nghĩa: Lấy mẫu K hàng đầu với Tinh chỉnh cho Đề xuất
Prompt được sử dụng: Hệ thống và prompt câu hỏi
Xem Bảng 8, Bảng 9, Bảng 9.

B Độ chính xác chú thích LLM
Đối với các phần tư dựa trên Tính thông tin có điều kiện thực tế khác nhau (tức là chỉ số được tính toán trên lỗi mô hình cơ sở với nhãn thực tế thay vì độ lệch với mô hình được tinh chỉnh), chúng tôi cho thấy độ chính xác của chú thích LLM so với các mô hình Tinh chỉnh và Cơ sở trên các tập dữ liệu khác nhau. Đối với Quora (Hình 3a), chúng tôi có thể thấy rằng hiệu suất tăng cường LLM luôn tồi tệ hơn mô hình được tinh chỉnh và chỉ có thể so sánh ở các phần tư cao nhất. Tương tự đối với Wikipedia-USA (Hình 3b), chúng tôi có thể thấy rằng LLM tốt hơn mô hình được tinh chỉnh cho khoảng 50% các phần tư cao hơn trong khi đối với Amazon-Books (Hình 3c) LLM luôn tốt hơn/có thể so sánh với mô hình được tinh chỉnh. Đối với Amazon-Kitchen (Hình 3d), LLM có thể so sánh với mô hình được tinh chỉnh và cơ sở và do đó không cung cấp nhiều lợi thế. Phân tích này có thể được sử dụng bởi người thực hành để quyết định miền nào cần tăng cường với LLM.

C Chi tiết huấn luyện

C.1 Tương đồng ngữ nghĩa
Chúng tôi tinh chỉnh sử dụng quora với tỷ lệ học 1e-4 trong 2 epoch cho tất cả các thí nghiệm. Chúng tôi sử dụng kích thước batch là 32 và có bộ lập lịch tỷ lệ học suy giảm tuyến tính. Chúng tôi sử dụng MSE Loss để huấn luyện. Tập dữ liệu quora ban đầu được lấy mẫu con với hệ số 10 (tức là 38400 mẫu). Chúng tôi tiếp tục lấy mẫu con với hệ số 10 cho cài đặt học tích cực.

C.2 Tìm kiếm ngữ nghĩa
Đề xuất được huấn luyện sử dụng thuật toán tiên tiến gần đây (Dahiya et al., 2023). Chúng tôi cũng lấy mẫu con cả hai tập dữ liệu với hệ số 10. Chúng tôi tinh chỉnh cả hai mô hình trong 100 epoch.

D Chú thích thực tế cho Miền đích Khó/Dễ trong Quora
Xem Bảng 11

E Chính thức hóa Tương đồng ngữ nghĩa
Cho một cặp miền câu (văn bản ngắn), X và Y, nhiệm vụ tương đồng ngữ nghĩa liên quan đến việc học một hàm f: X × Y → {0,1} mà đối với một cặp câu (xi, yj) cho trước từ tập X × Y xuất ra 1 (hoặc 0) để cho thấy rằng xi (hoặc không) có nghĩa tương đồng với yj. Đối với các tác vụ đối xứng (như phát hiện câu hỏi trùng lặp), tập X và Y có thể giống nhau, nhưng chúng tôi xem xét trường hợp tổng quát. Ngữ nghĩa được định nghĩa rộng rãi và phụ thuộc vào tác vụ đích. Ví dụ, đối với tác vụ phát hiện câu hỏi trùng lặp (chẳng hạn trên quora), một mô hình f tốt xuất ra liệu đối với một cặp câu hỏi, câu trả lời cho một trong các câu hỏi có trả lời câu hỏi thứ hai hay không. Đối với tác vụ chẳng hạn như đề xuất sách, ngữ nghĩa có thể yêu cầu nắm bắt sự tương đồng trong các cặp câu trong bối cảnh của các tác giả của sách, thể loại sách, đối tượng mục tiêu của chúng, v.v. Do đó chúng tôi ký hiệu ngữ nghĩa toán học là S: X × Y → {0,1}.

Chúng tôi xem xét tập con của các miền này là X = {x₀, x₁, ..., x|X|} ⊆ X, Y = {y₀, y₁, ..., y|Y|} ⊆ Y. Tương đồng giữa một cặp (xi, yj) do đó là S(xi, yj) được rút gọn thành sij. Đối với tìm kiếm ngữ nghĩa, một tập các ví dụ có thể được biểu diễn đầy đủ bởi tập con của các cặp chỉ số D⁰ ⊆ [|X|] × [|Y|] được ký hiệu bởi

D = {(xi, yj, sij) : (i, j) ∈ D⁰} (14)

trong đó xi, yj là cặp câu và sij là tương đồng ngữ nghĩa. Dữ liệu không có nhãn thiếu thông tin sij.

--- TRANG 14 ---
[Nội dung của các bảng prompt và hình ảnh được giữ nguyên như bản gốc]

--- TRANG 15 ---
[Nội dung của các bảng prompt tiếp theo được giữ nguyên như bản gốc]

--- TRANG 16 ---
[Nội dung của bảng cuối cùng được giữ nguyên như bản gốc]

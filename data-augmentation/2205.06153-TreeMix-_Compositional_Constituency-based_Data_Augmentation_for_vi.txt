TreeMix: Tăng cường Dữ liệu Hợp thành Dựa trên Cấu trúc Cú pháp cho
Hiểu biết Ngôn ngữ Tự nhiên

Le Zhang
Đại học Fudan
zhangle18@fudan.edu.cn

Zichao Yang
CMU
yangtze2301@gmail.com

Diyi Yang
Georgia Tech
dyang888@gatech.edu

Tóm tắt

Tăng cường dữ liệu là một phương pháp hiệu quả để giải quyết vấn đề overfitting. Nhiều nghiên cứu trước đây đã đề xuất các chiến lược tăng cường dữ liệu khác nhau cho NLP, chẳng hạn như tiêm nhiễu, thay thế từ, dịch ngược, v.v. Mặc dù hiệu quả, chúng đã bỏ lỡ một đặc điểm quan trọng của ngôn ngữ - tính hợp thành, nghĩa là ý nghĩa của một biểu thức phức tạp được xây dựng từ các thành phần con của nó. Được thúc đẩy bởi điều này, chúng tôi đề xuất một phương pháp tăng cường dữ liệu hợp thành cho hiểu biết ngôn ngữ tự nhiên được gọi là TreeMix. Cụ thể, TreeMix tận dụng cây phân tích cú pháp để phân tách câu thành các cấu trúc thành phần con và kỹ thuật tăng cường dữ liệu Mixup để kết hợp lại chúng nhằm tạo ra các câu mới. So với các phương pháp trước đây, TreeMix đưa ra sự đa dạng lớn hơn cho các mẫu được tạo ra và khuyến khích các mô hình học tính hợp thành của dữ liệu NLP. Các thí nghiệm mở rộng về phân loại văn bản và SCAN chứng minh rằng TreeMix vượt trội hơn các phương pháp tăng cường dữ liệu hiện đại hiện tại. Chúng tôi đã công bố mã nguồn của mình tại https://github.com/Magiccircuit/TreeMix.

1 Giới thiệu

Tăng cường dữ liệu (DA) đã trở nên rất phổ biến trong xử lý ngôn ngữ tự nhiên (NLP) (Chen et al., 2021; Feng et al., 2021) do nhu cầu ngày càng tăng về dữ liệu và chi phí đắt đỏ cho việc gán nhãn. DA nhằm mục đích tăng số lượng và sự đa dạng của bộ dữ liệu bằng cách tạo ra nhiều mẫu hơn dựa trên những mẫu hiện có, điều này giúp làm cho quá trình huấn luyện nhất quán hơn và cải thiện khả năng khái quát hóa của mô hình (Xie et al., 2020). Ví dụ, các phương pháp DA hiện có thường tận dụng thao tác ở mức từ (Wei và Zou, 2019; Kobayashi, 2018; Karimi et al., 2021) và tạo câu dựa trên mô hình (Edunov et al., 2018; Ng et al., 2020). Khi tăng cường dựa trên mixup (Zhang et al., 2018) đạt được thành công lớn trong thị giác máy tính (Yun et al., 2019; Uddin et al., 2021; Kim et al., 2021), một số công trình gần đây bắt đầu điều chỉnh mixup cho NLP, chẳng hạn như ở mức ẩn (Guo et al., 2019; Chen et al., 2020b) và ở mức đầu vào (Yoon et al., 2021; Shi et al., 2021).

Mặc dù có những thành công thực nghiệm này, các phương pháp DA vẫn gặp phải những hạn chế chính. Các phương pháp tăng cường dựa trên quy tắc đơn giản (Wei và Zou, 2019; Kobayashi, 2018; Karimi et al., 2021) cho thấy ít hoặc không có tác dụng đối với các mô hình ngôn ngữ được huấn luyện trước lớn. Trong khi các phương pháp tăng cường dựa trên mixup thể hiện tiềm năng to lớn, việc nội suy như vậy ở mức ẩn hoặc đầu vào có khả năng hạn chế trong việc nắm bắt các thuộc tính ngôn ngữ rõ ràng trong văn bản (Guo et al., 2019; Chen et al., 2020b; Yoon et al., 2021). Hơn nữa, các phương pháp DA hiện tại thể hiện khả năng hạn chế trong khái quát hóa hợp thành. Hãy xem xét ví dụ sau từ một mô hình dựa trên BERT được tinh chỉnh bằng bộ dữ liệu SST2 từ GLUE Benchmark:

Bộ phim này hay và mọi người đều thích nó. → 99%
Bộ phim này dở và tôi không thích nó. → 99%
Bộ phim này hay và tôi không thích nó. → 99%

Hai ví dụ đầu tiên được phân loại chính xác. Mặc dù ví dụ cuối cùng được cấu thành từ các đoạn của hai ví dụ đầu tiên, mô hình không thể đưa ra nhãn chính xác hoặc hợp lý (về mặt đặc trưng cho cảm tình của một câu), thể hiện hiệu suất kém trong khái quát hóa hợp thành.

Tuy nhiên, tính hợp thành là một khía cạnh quan trọng của ngôn ngữ mà ý nghĩa của một câu phức tạp được xây dựng từ các phần con của nó. Công trình trước đây cũng cho thấy rằng các cây cú pháp (ví dụ, LSTM dựa trên cây) hữu ích để mô hình hóa cấu trúc câu cho phân loại văn bản tốt hơn (Shi et al., 2018). Tuy nhiên, việc tận dụng các cấu trúc hợp thành cho tăng cường dữ liệu chưa nhận được nhiều sự chú ý trong cộng đồng công nghệ ngôn ngữ, với một số ngoại lệ trong phân tích ngữ nghĩa (Andreas, 2020; Herzig và Berant, 2021).

Vì vậy, chúng tôi đề xuất một phương pháp tăng cường dữ liệu hợp thành cho hiểu biết ngôn ngữ tự nhiên, tức là TreeMix (Hình 1). TreeMix là một phương pháp mixup ở mức đầu vào sử dụng thông tin phân tích cú pháp, trong đó các đoạn khác nhau (cụm từ của một cây con) từ các câu khác nhau được kết hợp lại để tạo ra các ví dụ mới chưa từng thấy trong tập huấn luyện; các nhãn mềm mới cũng sẽ được tạo ra một cách chiến lược dựa trên các đoạn này cùng lúc. Bằng cách này, TreeMix không chỉ khai thác các đặc trưng ngôn ngữ hợp thành để tăng sự đa dạng của việc tăng cường, mà còn cung cấp nhãn mềm hợp lý cho những ví dụ được trộn này.

Về mặt thực nghiệm, chúng tôi thấy rằng TreeMix vượt trội hơn đáng kể so với các phương pháp tăng cường dữ liệu hiện có trên một tập hợp các tiêu chuẩn phân loại văn bản được sử dụng rộng rãi. Để xác thực tính hiệu quả hợp thành của TreeMix, chúng tôi thí nghiệm với SCAN (Lake và Baroni, 2018) - một nhiệm vụ đòi hỏi khả năng khái quát hóa hợp thành mạnh, và thấy rằng TreeMix thể hiện khả năng hợp lý để khái quát hóa thành các cấu trúc mới được xây dựng từ các thành phần được quan sát trong quá trình huấn luyện.

2 Công trình Liên quan

2.1 Tăng cường Dữ liệu Tổng quát

Hầu hết các công trình trước đây hoạt động tăng cường dữ liệu ở các mức độ khác nhau (Chen et al., 2021). Các phương pháp DA ở mức token thao tác các token hoặc cụm từ trong khi bảo toàn cú pháp và ý nghĩa ngữ nghĩa cũng như nhãn của văn bản gốc, chẳng hạn như thay thế từ đồng nghĩa (Wang và Yang, 2015; Zhang et al., 2015; Fadaee et al., 2017; Kobayashi, 2018; Miao et al., 2020) trong đó các từ đồng nghĩa được phát hiện theo các quy tắc được xác định trước hoặc bằng độ tương tự embedding từ. Những phương pháp này có cải thiện hạn chế (Chen et al., 2021) đối với các mô hình ngôn ngữ được huấn luyện trước lớn (PLM). Bên cạnh đó, việc đưa nhiễu bằng cách chèn, thay thế, xóa và hoán đổi ngẫu nhiên (Wang et al., 2018; Wei và Zou, 2019; Karimi et al., 2021; Xie et al., 2020) được kỳ vọng sẽ cải thiện tính bền vững của mô hình. Các phương pháp DA ở mức câu tăng sự đa dạng bằng cách tạo ra các ví dụ khác biệt, chẳng hạn như thông qua paraphrase (Yu et al., 2018; He et al., 2020; Xie et al., 2020; Kumar et al., 2020; Chen et al., 2020b; Cai et al., 2020) hoặc dịch ngược (Sennrich et al., 2016; Edunov et al., 2018). Một hướng công việc khác sử dụng các phương pháp tạo có điều kiện nhãn mà huấn luyện một mô hình tạo có điều kiện như GPT-2 hoặc VAE để tạo ra các ví dụ mới với nhãn làm điều kiện (Bergmanis et al., 2017; Liu et al., 2020b,a; Ding et al., 2020; Anaby-Tavor et al., 2020). Mặc dù những phương pháp này có thể tạo ra các mẫu văn bản mới và đa dạng không tồn tại trong bộ dữ liệu gốc, chúng đòi hỏi huấn luyện mở rộng. Các phương pháp DA ở mức ẩn chủ yếu thao tác các biểu diễn ẩn bằng nhiễu động (Miyato et al., 2019; Zhu et al., 2020; Jiang et al., 2020; Chen et al., 2020c; Shen et al., 2020; Hsu et al., 2017, 2018; Wu et al., 2019; Malandrakis et al., 2019) và nội suy như mixup (Zhang et al., 2018) để tạo ra các ví dụ mới (Miao et al., 2020; Cheng et al., 2020; Chen et al., 2020b; Guo et al., 2019, 2020; Chen et al., 2020a).

2.2 Tăng cường Dữ liệu Hợp thành

Tăng cường hợp thành nhằm mục đích tăng sự đa dạng của các bộ dữ liệu và cải thiện khả năng khái quát hóa hợp thành của các mô hình kết quả (Jia và Liang, 2016; Andreas, 2020). Những phương pháp này thường kết hợp lại các thành phần khác nhau từ các câu khác nhau để tạo ra các ví dụ mới theo một tập hợp các quy tắc ngôn ngữ được thiết kế trước như chồng chéo từ vựng (Andreas, 2020), máy stack neural-symbolic (Chen et al., 2020d), và thay thế cấu trúc con (Shi et al., 2021). Các phương pháp hợp thành đã được áp dụng trong một tập hợp các nhiệm vụ NLP, chẳng hạn như gán nhãn chuỗi (Guo et al., 2020), phân tích ngữ nghĩa (Andreas, 2020), phân tích cú pháp thành phần (Shi et al., 2020, 2021), phân tích cú pháp phụ thuộc (Dehouck và Gómez-Rodríguez, 2020; Shi et al., 2021), nhận dạng thực thể có tên (Dai và Adel, 2020), tạo văn bản (Feng et al., 2020), và phân loại văn bản (Yoon et al., 2021; Shi et al., 2021). Công trình của chúng tôi cũng thuộc về danh mục này.

Các công trình liên quan nhất là Shi et al. (2021) và Yoon et al. (2021). Tuy nhiên, Shi et al. (2021) chỉ thực hiện các kết hợp cấu trúc con thành phần với các ví dụ từ cùng một danh mục, do đó không đủ để tạo ra tăng cường đa dạng với các nhãn mới được tạo ra.

Bên cạnh đó, Yoon et al. (2021) đơn giản chỉ hoán đổi các khoảng quan trọng nhất và ít quan trọng nhất, phụ thuộc mạnh vào hiệu suất của mô hình trong việc ước tính các khoảng quan trọng, và không xem xét các cấu trúc ngôn ngữ của những câu này. TreeMix đề xuất của chúng tôi lấp đầy những khoảng trống này bằng cách cho phép kết hợp các câu từ các danh mục nhãn khác nhau, bằng cách sử dụng các cấu trúc dựa trên tính nhất quán phong phú trong văn bản, và bằng cách tạo ra nhãn mềm một cách chiến lược cho những thể hiện được tăng cường này.

3 Phương pháp

Công trình của chúng tôi được thúc đẩy bởi Mixup (Zhang et al., 2018), tạo ra các mẫu ảo bằng cách trộn các đầu vào. Với hai ví dụ được rút ngẫu nhiên (xi; yi) và (xj; yj), trong đó x biểu thị mẫu đầu vào và y là nhãn one-hot tương ứng, Mixup tạo ra một mẫu mới bằng:

x̃ = λxi + (1 − λ)xj;
ỹ = λyi + (1 − λ)yj;

trong đó λ ∈ [0, 1]. Mixup có thể được thực hiện dễ dàng trong không gian liên tục, do đó một số công trình trước đây (Chen et al., 2020b) đã mở rộng nó cho NLP bằng cách thực hiện nội suy trong không gian ẩn.

Chúng tôi cải thiện Mixup bằng cách kết hợp tính hợp thành của ngôn ngữ, một đặc tính quan trọng thiết yếu cho khái quát hóa nhưng các mô hình neural thường thiếu sót trong việc nắm bắt (Lake và Baroni, 2018). Thay vì nội suy với toàn bộ mẫu, TreeMix, phương pháp mới đề xuất của chúng tôi, tạo ra các câu mới bằng cách loại bỏ các cụm từ của câu và chèn lại các phần con từ các câu khác. TreeMix sử dụng cây thành phần để phân tách một câu thành các phần thành phần có ý nghĩa, sau đó có thể được loại bỏ và kết hợp lại để tạo ra các mẫu tăng cường mới. Chúng tôi nhằm mục đích cải thiện khả năng khái quát hóa hợp thành của mô hình bằng cách huấn luyện trên lượng lớn mẫu được tạo ra bởi TreeMix. Một ví dụ về việc sử dụng TreeMix cho phân loại câu đơn được thể hiện trong Hình 1.

3.1 TreeMix

Gọi xi = {x¹i, x²i, ..., xˡi} biểu thị một chuỗi có độ dài l và nhãn tương ứng trong mã hóa one-hot là yi. Chúng tôi chạy một trình phân tích cú pháp thành phần trên xi để có cây phân tích của nó là T(xi). Để có các phần con có ý nghĩa của một chuỗi, chúng tôi duyệt cây phân tích một cách đệ quy và có tất cả các cây con với nhiều hơn một con. Ký hiệu tập hợp các cây con là S(xi) = {tᵏi}, trong đó tᵏi biểu thị cây con thứ k của mẫu xi. Đối với một cây con tᵏi, nó bao phủ một khoảng liên tục tᵏi = [xʳᵏi, ..., xˢᵏi] của xi bắt đầu với chỉ số rk và kết thúc với chỉ số sk. Ví dụ, như thể hiện trong phần bên trái của Hình 1, các cây con của câu ví dụ có thể bao phủ các khoảng như "this poor film", "in this poor film", "no interest", v.v.

Đối với một mẫu cho trước (xi, yi), chúng tôi lấy mẫu ngẫu nhiên một điểm dữ liệu khác (xj, yj) từ tập huấn luyện. Chúng tôi chạy trình phân tích cú pháp thành phần trên cả hai câu và có các tập cây con S(xi) và S(xj) của chúng, dựa trên đó chúng tôi có thể lấy mẫu các cây con để trao đổi. Chúng tôi giới thiệu hai siêu tham số bổ sung L và U để ràng buộc độ dài của các cây con để lấy mẫu. L và U, được đo bằng tỷ lệ độ dài của cây con so với câu gốc, đặt giới hạn dưới và trên của các cây con để lấy mẫu. Một cách trực quan, kiểm soát độ chi tiết của các cụm từ mà chúng tôi nhằm mục đích trao đổi. Chúng tôi muốn rằng độ dài của cụm từ để trao đổi là hợp lý. Nếu nó quá ngắn, thì việc trao đổi không thể đưa ra đủ sự đa dạng cho mẫu được tăng cường; ngược lại nếu nó quá dài, quá trình có thể tiêm quá nhiều nhiễu vào câu gốc. Chúng tôi đặt là tỷ lệ để không phụ thuộc vào độ dài của các câu gốc. Bảng 2 cho thấy một số ví dụ cây con với các ràng buộc độ dài khác nhau. Chúng tôi định nghĩa tập cây con có ràng buộc độ dài là:

SL,U(x) = {t | t ∈ S(x); s.t. |t|/|x| ∈ [L, U]}.

Ở đây |·| biểu thị độ dài của một chuỗi hoặc một cây con. Đối với hai câu xi và xj, chúng tôi lấy mẫu ngẫu nhiên hai cây con tᵏi ∈ SL,U(xi) và tˡj ∈ SL,U(xj) và xây dựng một mẫu mới bằng cách thay thế tᵏi bằng tˡj, tức là:

x̃ = [x¹i, ..., xʳᵏ⁻¹i, xʳˡj, ..., xˢˡj, xˢᵏ⁺¹i, ..., xˡi]

trong đó tˡj = [xʳˡj, ..., xˢˡj] thay thế tᵏi = [xʳᵏi, ..., xˢᵏi]. Hình 1 cho thấy một ví dụ về TreeMix, trong đó cây con "a touching transcendent love story" thay thế cây con "this poor film".

Tạo Nhãn cho TreeMix Việc tạo một nhãn hợp lệ cho mẫu được tăng cường x̃ là một vấn đề thách thức. Tương tự như của Mixup (Zhang et al., 2018), chúng tôi sử dụng một kết hợp lồi của các nhãn gốc của hai câu làm nhãn mới cho mẫu được tăng cường:

ỹ = (li - |tᵏi|)/(li - |tᵏi| + |tˡj|) yi + |tˡj|/(li - |tᵏi| + |tˡj|) yj

trong đó li là độ dài của xi và |tᵏi|, |tˡj| là độ dài của các cây con. Trong câu mới, li - |tᵏi| từ của xi được giữ lại và |tˡj| từ của câu xj được chèn vào.

Trong Phương trình 2, (li - |tᵏi|)/(li - |tᵏi| + |tˡj|) là phần từ đến từ xi, điều này xác định trọng số của yi. Nhãn sau đó được tạo ra dựa trên phỏng đoán rằng sự thay đổi trong nhãn tỷ lệ thuận với sự thay đổi độ dài trong các câu gốc. Chúng tôi đã cung cấp một tập hợp các ví dụ tăng cường từ TreeMix trong Bảng A.1 ở Phụ lục.

Nhiệm vụ Phân loại Câu Cặp Phần trên chủ yếu sử dụng phân loại câu đơn làm ví dụ chạy cho TreeMix. Ở đây chúng tôi lập luận rằng TreeMix có thể dễ dàng được mở rộng cho vấn đề phân loại câu cặp, trong đó mối quan hệ giữa các câu là nhãn.

Chính thức, đối với một mẫu cho trước (xi, x'i, yi), chúng tôi lấy mẫu ngẫu nhiên một mẫu khác (xj, x'j, yj) và chạy trình phân tích cú pháp và có các tập cây con của mỗi câu S(xi), S(x'i) và S(xj), S(x'j). Sau đó chúng tôi lấy mẫu ngẫu nhiên các cây con tᵏi ∈ S(xi); tᵏ'i' ∈ S(x'i) và tˡj ∈ S(xj); tˡ'j' ∈ S(x'j). Chúng tôi xây dựng x̃ bằng cách thay thế tᵏi bằng tˡj và x̃' bằng cách thay thế tᵏ'i' bằng tˡ'j'. Nhãn mới được tạo ra như sau:

ỹ = (li + li' - |tᵏi| - |tᵏ'i'|)/(li + li' - |tᵏi| - |tᵏ'i'| + |tˡj| + |tˡ'j'|) yi + (|tˡj| + |tˡ'j'|)/(li + li' - |tᵏi| - |tᵏ'i'| + |tˡj| + |tˡ'j'|) yj

Ý nghĩa của các ký hiệu giống như trong Phương trình 2.

Thuật toán chính của chúng tôi được thể hiện trong Thuật toán 1. Mặc dù không phải tất cả các câu được tạo ra bởi TreeMix đều trôi chảy hoặc thậm chí là các câu mới hợp lệ, chúng chứa các phần con với ý nghĩa khác nhau khuyến khích các mô hình xây dựng biểu diễn phong phú của câu theo cách hợp thành. Lưu ý rằng các nhãn được tăng cường là kết hợp lồi của các nhãn gốc, chỉ khi mô hình học được biểu diễn của hai phần cùng nhau, chúng mới có thể dự đoán cả hai nhãn với trọng số khác nhau.

3.2 Mục tiêu Huấn luyện

Mô hình của chúng tôi được huấn luyện trên sự kết hợp của các mẫu gốc và mẫu tăng cường để có được sự đánh đổi giữa điều hòa và tiêm nhiễu. Mục tiêu huấn luyện cuối cùng là:

L = E(x,y)∼D[-y^T log P(y|x)] + α E(x̃,ỹ)∼D'[-ỹ^T log P(y|x̃)]

α là trọng số trên các mẫu tăng cường.

4 Thí nghiệm

4.1 Bộ dữ liệu

Để kiểm tra tính hiệu quả của TreeMix, chúng tôi thí nghiệm với nhiều tiêu chuẩn phân loại văn bản khác nhau, như được thể hiện trong Bảng 3. Chúng tôi sử dụng độ chính xác làm thước đo và loại trừ các bộ dữ liệu từ GLUE (Wang et al., 2019) không phù hợp với mixup, bao gồm CoLA đo lường tính chấp nhận ngôn ngữ và sẽ bị hủy hoại bởi các hoạt động mixup, và WNLI quá nhỏ để thể hiện tính hợp lệ của một phương pháp.

4.2 Thiết lập Thí nghiệm

Phương pháp TreeMix đề xuất tạo ra các mẫu mới bằng cách kết hợp các khoảng văn bản dựa trên thông tin của cây thành phần, do đó chúng tôi sử dụng bộ công cụ Stanford CoreNLP để thu được thông tin liên quan đến phân tích cú pháp (Manning et al., 2014). Chúng tôi sử dụng mô hình ngôn ngữ được huấn luyện trước bert-base-uncased cho nhiệm vụ phân loại chuỗi từ HuggingFace. Với các seed từ 0 đến 4 và L = 0.1; U = 0.3, chúng tôi sử dụng TreeMix để tạo ra gấp hai và gấp năm lần số mẫu so với tập huấn luyện gốc. Chúng tôi sao chép bộ dữ liệu gốc về cùng kích thước với bộ dữ liệu tăng cường trong giai đoạn huấn luyện để đảm bảo rằng mô hình nhận được cùng lượng dữ liệu từ bộ dữ liệu gốc và bộ dữ liệu tăng cường cho mỗi batch huấn luyện.

Nếu không được chỉ định, chúng tôi huấn luyện mô hình trong 5 epoch, với độ dài chuỗi tối đa là 128 và kích thước batch là 96. Mô hình được tối ưu hóa bằng trình tối ưu hóa AdamW với eps là 1e-8 và tốc độ học là 2e-5. Bảng C.1 trong Phụ lục chứa các thiết lập siêu tham số chi tiết cho mỗi bộ dữ liệu.

4.3 Baseline

Chúng tôi so sánh TreeMix với các tiêu chuẩn sau: (1) Không tăng cường (BERT): huấn luyện tiêu chuẩn mà không có bất kỳ tăng cường nào, (2) EDA thực hiện ngẫu nhiên chèn, thay thế, hoán đổi và xóa văn bản. (3) AEDA chèn ngẫu nhiên dấu câu vào văn bản. (4) Dịch ngược (BT) (Edunov et al., 2018): văn bản được dịch giữa tiếng Anh và tiếng Đức bằng kiến trúc Transformer được huấn luyện trên WMT16 English-German. (5) GPT3Mix (Yoo et al., 2021) thiết kế prompts và sử dụng GPT3 để tạo ra các ví dụ mới để huấn luyện mô hình. (6) SSMix (Yoon et al., 2021) áp dụng mixup dựa trên sự quan trọng (Simonyan et al., 2014) của các token, tương tự như PuzzleMix (Kim et al., 2020) và SaliencyMix (Uddin et al., 2021). (7) EmbedMix là phiên bản mô hình ngôn ngữ được huấn luyện trước của WordMixup trong Guo et al. (2019), thực hiện mixup ở mức embedding. (8) TMix (Chen et al., 2020b) đầu tiên mã hóa hai đầu vào riêng biệt, sau đó thực hiện nội suy tuyến tính của hai embedding tại một lớp encoder nhất định, và cuối cùng forward-pass embedding kết hợp trong các lớp còn lại.

5 Kết quả và Phân tích

5.1 Hiệu suất trên Bộ dữ liệu Đầy đủ

Kết quả của TreeMix trên toàn bộ bộ dữ liệu được thể hiện trong Bảng 4. TreeMix vượt trội hơn tất cả các baseline một cách đáng kể trên các nhiệm vụ phân loại câu đơn, thể hiện sự ưu việt của việc sử dụng cấu trúc con hợp thành để thay thế và tăng cường. Ví dụ, trên SST2, nó cải thiện 0.98%. So với các phương pháp khác, sự cải thiện gấp đôi.

Điều này là do, không giống như SSMix thay thế các khoảng văn bản dựa trên sự quan trọng, TreeMix của chúng tôi sử dụng thông tin thành phần để giúp xác định các cấu trúc con câu được thông báo ngôn ngữ học, và bằng cách kết hợp lại những thành phần này, sự đa dạng hợp thành của các bộ dữ liệu có thể được tối đa hóa. Với các mẫu được tạo ra bởi TreeMix, mô hình có thể thấy nhiều kết hợp hơn của các cấu trúc con trong giai đoạn huấn luyện mà không có sẵn trong tập dữ liệu gốc, dẫn đến khả năng khái quát hóa tốt hơn.

Khi nói đến các nhiệm vụ phân loại mối quan hệ câu, TreeMix cũng rất hiệu quả. Ví dụ, nó cải thiện 2.47% trên bộ dữ liệu RTE, trong khi sự cải thiện tốt nhất của các phương pháp khác chỉ là 0.3%, và nó cải thiện 0.82% trên QNLI, trong đó các phương pháp tăng cường dữ liệu khác có ít tác dụng. Chúng tôi giả định rằng, khi hai phần thành phần từ một cặp câu được nhúng vào một cặp câu khác, mối quan hệ cố có cũng được nhúng. Điều này giúp các mô hình tốt hơn trong việc xác định hai cặp mối quan hệ trong một mẫu duy nhất, điều này tiếp tục tăng khả năng của nó để phân loại những câu đối nghịch thách thức này.

Vì TreeMix hoạt động bằng cách tăng sự đa dạng của bộ dữ liệu và cung cấp cho các mô hình nhiều mẫu văn bản hơn để học, nó có những cải thiện rất đáng kể đối với những bộ dữ liệu tương đối nhỏ như RTE và TREC, so với những bộ dữ liệu lớn như AG NEWS, QQP và MNLI đã có rất nhiều đa dạng và mẫu văn bản.

5.2 Ảnh hưởng của Thông tin Thành phần

Để xác định tầm quan trọng của thông tin thành phần, chúng tôi đã thiết kế một Random Mixup (RandMix) chọn ngẫu nhiên các khoảng văn bản miễn là tỷ lệ độ dài khoảng so với độ dài câu nhỏ hơn một ngưỡng cụ thể λrand. Thiết lập còn lại của RandMix giống với TreeMix. Chúng tôi so sánh TreeMix và RandMix trên các bộ dữ liệu phân loại câu đơn trong Hình 2.

Chúng tôi thấy rằng, cả RandMix và TreeMix đều khá hiệu quả, nhưng TreeMix vượt trội hơn RandMix trên hầu hết các bộ dữ liệu. Ví dụ, TreeMix vượt trội hơn RandMix 0.8% trên SST2, 0.6% trên TREC-f, và 0.5% trên TREC-c. Một ngoại lệ là trên IMDb, nơi độ dài câu trung bình dài hơn nhiều. Lý do cho hiệu suất kém hơn của TreeMix là do kết quả phân tích cú pháp thưa thớt trên các câu dài; vì có nhiều cây con, việc thay thế bất kỳ phần đơn lẻ nào có thể mang lại thay đổi rất tối thiểu cho toàn bộ câu.

5.3 Ảnh hưởng của Kích thước Tập Huấn luyện

Để kiểm tra ảnh hưởng của TreeMix với các kích thước tập huấn luyện khác nhau, chúng tôi lấy mẫu đồng nhất 1%, 2%, 5%, 10%, và 20% dữ liệu từ tập huấn luyện để điều tra TreeMix trong các tình huống ít tài nguyên. Toàn bộ tập kiểm tra được sử dụng để đánh giá khả năng khái quát hóa của mô hình. Vì TreeMix tạo ra nhiều ví dụ hơn để huấn luyện, chúng tôi sử dụng RandMix để tạo ra cùng số lượng mẫu bổ sung làm so sánh để đảm bảo kích thước dữ liệu công bằng. Kết quả được tóm tắt trong Hình 3.

Chúng tôi thấy rằng, (1) TreeMix vượt trội hơn RandMix trong tất cả các thiết lập, tiếp tục chứng minh lợi thế của cấu trúc con hợp thành với thông tin thành phần so với các khoảng được chọn ngẫu nhiên. (2) Cả hai phương pháp mixup đều có thể cải thiện đáng kể hiệu suất của mô hình trong trường hợp thiếu dữ liệu cực đoan (ví dụ, 1% và 2%). (3) Khi lượng dữ liệu đủ (ví dụ, hơn 5%), TreeMix vượt trội hơn RandMix một cách đáng kể. Tuy nhiên, TreeMix chỉ vượt trội hơn RandMix một chút khi có sự thiếu hụt dữ liệu nghiêm trọng (ví dụ, 1% và 2%). Điều này là do các bộ dữ liệu quá nhỏ thường chứa các cấu trúc rất hạn chế, do đó hạn chế khả năng của TreeMix trong việc tăng các mẫu văn bản và đa dạng hợp thành. (4) Sự cải thiện tương đối của TreeMix so với huấn luyện thông thường không có tăng cường giảm dần khi lượng dữ liệu tăng lên, phần lớn do các mẫu văn bản được tăng cường bổ sung có thể chồng chéo với những mẫu đã tồn tại trong bộ dữ liệu, dẫn đến cải thiện hạn chế.

5.4 Ảnh hưởng của Trộn Khác Danh mục

Khác với công trình trước đây Shi et al. (2021), TreeMix cho phép kết hợp các câu từ các danh mục nhãn khác nhau. Để kiểm tra liệu việc trộn khác danh mục nhãn này có hiệu quả hơn việc trộn trong cùng danh mục nhãn hay không, chúng tôi đã tiến hành nghiên cứu loại bỏ với TreeMix trên các mẫu trong cùng lớp. Bảng 5 cho thấy kết quả. Trên tất cả các bộ dữ liệu, chúng tôi thấy rằng TreeMix kết hợp dữ liệu từ các lớp khác nhau hiệu quả hơn so với kết hợp dữ liệu từ cùng lớp, phù hợp với các phát hiện trong Zhang et al. (2018). Khi chỉ được đưa nhãn từ một danh mục, các mô hình hiện tại có xu hướng đưa ra các phán đoán đơn giản hoặc giả tạo dựa trên các từ xuất hiện thường xuyên nhất. Tuy nhiên ngữ nghĩa của câu phức tạp hơn những từ đơn giản. Ví dụ, mô hình có khả năng phân loại một câu như "Tôi thích bộ phim hay này" là tích cực vì các từ "thích" và "hay", nhưng nếu "phim hay" được thay thế bằng "phim dở", mô hình phải nhận thức được các phần thành phần khác nhau trong câu. Khả năng này chỉ có thể có được khi mô hình được huấn luyện trên các mẫu được tạo ra khác danh mục.

5.5 Ảnh hưởng của Tỷ lệ Độ dài

Ràng buộc duy nhất chúng tôi áp đặt lên TreeMix là tỷ lệ độ dài của cây con được kiểm soát bởi λ. Chúng tôi chọn các cây con có độ dài từ 10% đến 30% và từ 30% đến 50% độ dài của câu, tương ứng. Bảng 6 cho thấy kết quả.

Trên tất cả các bộ dữ liệu, λ = [0.1, 0.3] vượt trội hơn λ = [0.3, 0.5], phù hợp với quan sát của Zhang et al. (2018) rằng việc đưa ra các giá trị tỷ lệ mixup quá cao có thể dẫn đến underfitting. Một giải thích ngôn ngữ học khác cho kịch bản này như sau: Khi λ = [0.3, 0.5], TreeMix có thể chọn các khoảng văn bản dài hơn, thường chứa các thành phần thành phần độc đáo như SBAR; Việc trao đổi các khoảng này sẽ làm hỏng nghiêm trọng cấu trúc ngữ nghĩa và ngữ pháp của câu, khiến mô hình trở nên bối rối. Kết quả là, TreeMix với các khoảng chuyển đổi lớn hơn hoạt động kém và thậm chí tồi tệ hơn so với baseline trên một số bộ dữ liệu.

5.6 Khái quát hóa Hợp thành

Để định lượng khả năng khái quát hóa hợp thành tổng thể của TreeMix ngoài các nhiệm vụ phân loại, chúng tôi đã tiến hành thí nghiệm trên bộ dữ liệu SCAN (Lake và Baroni, 2018), một bộ dữ liệu thực thi lệnh được sử dụng rộng rãi để kiểm tra tính hợp thành có hệ thống. Nó chứa các lệnh nguồn đơn giản và các chuỗi hành động đích. Chúng tôi kiểm tra trên các phần chia thách thức được sử dụng phổ biến: addprim-jump, addprim-turn-left, around-right, trong đó các lệnh nguyên thủy (ví dụ "jump") chỉ xuất hiện một mình trong huấn luyện nhưng sẽ được kết hợp với các modifier khác (ví dụ "jump twice") trong kiểm tra. Một mô hình hoạt động tốt cho nhiệm vụ này nên học cách kết hợp các lệnh nguyên thủy với các modifier và tạo ra thực thi tương ứng. Với TreeMix, chúng tôi có thể tạo ra các lệnh hợp thành chưa thấy trong tập huấn luyện.

Quá trình tạo lệnh mới giống như trong phân loại câu đơn, ngoại trừ việc chúng tôi tăng ràng buộc độ dài U lên 1 để cho phép trao đổi các lệnh chỉ với một từ. Sau khi chúng tôi tổng hợp các lệnh mới, chúng tôi làm theo các quy tắc trong Lake và Baroni (2018) để dịch các lệnh hợp lệ thành hành động và lọc ra các lệnh không đúng ngữ pháp. Chúng tôi làm theo các thiết lập trong Andreas (2020) và sử dụng các phương pháp tăng cường dữ liệu sau làm baseline: (1) WordDrop loại bỏ từ ngẫu nhiên; (2) SwitchOut (Wang et al., 2018) thay thế ngẫu nhiên các từ bằng các từ ngẫu nhiên khác từ cùng từ vựng; (3) SeqMix (Guo et al., 2020) tạo ra các ví dụ tổng hợp mới bằng cách kết hợp mềm các chuỗi input/output từ tập huấn luyện, và (4) GECA (Andreas, 2020) thực hiện các hoán đổi hợp lệ được liệt kê.

Như được thể hiện trong Bảng 7, TreeMix vượt trội hơn SwitchOut và WordDrop cho tất cả các phần chia. TreeMix tự nó không hoạt động tốt bằng GECA, nhưng khi được kết hợp với GECA, nó thể hiện kết quả rất mạnh. TreeMix vượt trội hơn SeqMix trong tất cả các phần chia, do thực tế là TreeMix có thể tìm thấy chính xác hơn các phân đoạn hợp thành phong phú ngôn ngữ học của một câu, như được chứng minh bởi kết quả của các so sánh TreeMix và SSMix trong Phần 5.1 và TreeMix và RandMix trong Phần 5.3. Nhìn kỹ hơn vào những mẫu được tăng cường này cho thấy TreeMix có thể tạo ra tất cả các kết hợp có thể của "jump" và các modifier khác như "left" và "around"; những kết hợp lệnh chưa thấy trước đây này tiếp tục xác thực khả năng của TreeMix để cải thiện đa dạng hợp thành của bộ dữ liệu. TreeMix thể hiện hiệu suất yếu trên phần chia around-right, nơi mô hình quan sát các lệnh "around" và "right" riêng biệt tại giai đoạn huấn luyện, và nó phải suy ra ý nghĩa của "around right" tại thời điểm kiểm tra. Vì từ "around" không thể được phân tích cú pháp là một cây con đơn lẻ để hoán đổi. Thay vào đó, nó luôn xuất hiện trong một cây con với từ "left", ngăn cản TreeMix tạo ra cụm từ "turn right". Mặc dù có những hạn chế trên around-left, TreeMix hoạt động tốt trên tất cả các phần chia khác và có thể dễ dàng được kết hợp với các phương pháp tăng cường dữ liệu khác, thể hiện khả năng khái quát hóa hợp thành của TreeMix ngoài các nhiệm vụ phân loại.

6 Kết luận

Công trình này giới thiệu TreeMix, một phương pháp tăng cường dữ liệu hợp thành cho hiểu biết ngôn ngữ tự nhiên. TreeMix tận dụng cây phân tích cú pháp thành phần để phân tách câu thành các cấu trúc con và tiếp tục sử dụng kỹ thuật tăng cường dữ liệu mixup để kết hợp lại chúng nhằm tạo ra các câu được tăng cường mới. Các thí nghiệm trên các tiêu chuẩn phân loại văn bản và phân tích ngữ nghĩa chứng minh rằng TreeMix vượt trội hơn các baseline mạnh trước đây, đặc biệt là trong các thiết lập ít tài nguyên và khái quát hóa hợp thành.

Lời cảm ơn

Các tác giả muốn cảm ơn các nhà đánh giá vì những hiểu biết và phản hồi hữu ích của họ. Công trình này được tài trợ một phần bởi khoản tài trợ từ Salesforce.

# Hướng tới Hiểu biết về Tăng cường Dữ liệu Sinh tạo

Chenyu Zheng1,2, Guoqiang Wu3, Chongxuan Li1,2∗

1Trường Trí tuệ Nhân tạo Gaoling, Đại học Nhân dân Trung Quốc, Bắc Kinh, Trung Quốc
2Phòng thí nghiệm Trọng điểm Bắc Kinh về Phương pháp Quản lý và Phân tích Dữ liệu Lớn, Bắc Kinh, Trung Quốc
3Trường Phần mềm, Đại học Shandong, Shandong, Trung Quốc

{chenyu.zheng666, guoqiangwu90}@gmail.com; chongxuanli@ruc.edu.cn

## Tóm tắt

Tăng cường dữ liệu sinh tạo, phương pháp mở rộng tập dữ liệu bằng cách thu được các mẫu có nhãn giả từ một mô hình sinh tạo có điều kiện đã được huấn luyện, cải thiện hiệu suất phân loại trong nhiều tác vụ học tập khác nhau bao gồm học (bán) giám sát, học few-shot, và học mạnh mẽ đối kháng. Tuy nhiên, ít nghiên cứu đã khảo sát về mặt lý thuyết tác động của tăng cường dữ liệu sinh tạo. Để lấp đầy khoảng trống này, chúng tôi thiết lập một chặn ổn định tổng quát trong cài đặt không phân phối độc lập và đồng nhất (non-i.i.d.) này, nơi phân phối học được phụ thuộc vào tập huấn luyện gốc và thường không giống với phân phối thực. Kết quả lý thuyết của chúng tôi bao gồm độ phân kỳ giữa phân phối học được và phân phối thực. Nó cho thấy rằng tăng cường dữ liệu sinh tạo có thể tận hưởng tốc độ học nhanh hơn khi bậc của số hạng phân kỳ là o(max{log(m)βm, 1/√m}), trong đó m là kích thước tập huấn luyện và βm là hằng số ổn định tương ứng. Chúng tôi cụ thể hóa thêm cài đặt học tập cho mô hình hỗn hợp Gaussian và mạng đối kháng sinh tạo. Chúng tôi chứng minh rằng trong cả hai trường hợp, mặc dù tăng cường dữ liệu sinh tạo không tận hưởng tốc độ học nhanh hơn, nó có thể cải thiện các đảm bảo học tập ở mức độ hằng số khi tập huấn luyện nhỏ, điều này có ý nghĩa khi xảy ra overfitting tồi tệ. Kết quả mô phỏng trên mô hình hỗn hợp Gaussian và kết quả thực nghiệm trên mạng đối kháng sinh tạo hỗ trợ các kết luận lý thuyết của chúng tôi.

## 1 Giới thiệu

Các mô hình sinh tạo sâu đã đạt được thành công lớn trong nhiều lĩnh vực, bao gồm thị giác máy tính, xử lý ngôn ngữ tự nhiên, và học liên phương thức trong những năm gần đây. Một ứng dụng đầy hứa hẹn được xây dựng dựa trên chúng là tăng cường dữ liệu sinh tạo (GDA), phương pháp mở rộng tập huấn luyện bằng cách tạo ra các mẫu tổng hợp có nhãn dựa trên các mô hình sinh tạo có điều kiện tiên tiến. Về mặt thực nghiệm, người ta đã quan sát thấy rằng GDA có thể cải thiện hiệu suất phân loại trong nhiều cài đặt, bao gồm học giám sát, học bán giám sát, học few-shot, học zero-shot, học mạnh mẽ đối kháng, v.v.

Mặc dù các thuật toán và ứng dụng đầy hứa hẹn của GDA xuất hiện trong các cài đặt học tập khác nhau, các thí nghiệm của chúng tôi trong Phần 4 cho thấy rằng GDA không phải lúc nào cũng hoạt động, chẳng hạn như trong trường hợp có tập huấn luyện phong phú hoặc các phương pháp tăng cường chuẩn (ví dụ: flip). Bên cạnh đó, số lượng dữ liệu tăng cường có tác động đáng kể đến hiệu suất trong khi thường được điều chỉnh thủ công. Những hiện tượng này thúc đẩy chúng tôi nghiên cứu tác động của GDA. Thật không may, ít nghiên cứu đã khảo sát kỹ thuật này từ góc độ lý thuyết. Do đó, trong bài báo này, chúng tôi thực hiện bước đầu tiên hướng tới việc hiểu nó. Cụ thể, chúng tôi xem xét cài đặt phân loại có giám sát, và cố gắng trả lời các câu hỏi sau một cách nghiêm ngặt:

• Chúng ta có thể thiết lập các đảm bảo học tập cho GDA và giải thích chính xác khi nào nó hoạt động không?
• Chúng ta có thể thu được những hiểu biết lý thuyết về các siêu tham số như số lượng dữ liệu tăng cường không?

Đóng góp chính đầu tiên của chúng tôi là đề xuất một chặn ổn định thuật toán tổng quát cho GDA trong Phần 3.1. Thách thức kỹ thuật chính là GDA phá vỡ giả định i.i.d. cơ bản của các kết quả cổ điển vì phân phối học được bởi mô hình sinh tạo phụ thuộc vào tập huấn luyện được lấy mẫu và thường không giống với phân phối thực. Bên cạnh đó, không rõ liệu các chặn ổn định non-i.i.d. tổng quát hiện có có phù hợp để rút ra các đảm bảo có ý nghĩa cho GDA hay không.

Một cách không chính thức, kết quả của chúng tôi (Định lý 3.1) có thể được trình bày như sau:
|Gen-error| ≲ phân kỳ phân phối + sai số tổng quát hóa w.r.t. phân phối hỗn hợp,

trong đó Gen-error có nghĩa là sai số tổng quát hóa của GDA, và a ≲ b có nghĩa là a = O(b). Số hạng phân kỳ phân phối ở phía bên phải được gây ra bởi độ phân kỳ giữa phân phối học được bởi mô hình sinh tạo và phân phối thực. Ngoài ra, sai số tổng quát hóa còn lại w.r.t. phân phối hỗn hợp sẽ biến mất khi chúng ta tăng kích thước tăng cường. So sánh chặn này với kết quả cổ điển không có GDA (Định lý 2.1), chúng ta có thể thu được điều kiện chính xác để GDA hiệu quả: GDA có thể tận hưởng tốc độ học nhanh hơn khi bậc của số hạng phân kỳ là o(max{log(m)βm, 1/√m}), trong đó m là kích thước tập huấn luyện và βm là hằng số ổn định đồng nhất tương ứng. Điều này có nghĩa là hiệu suất của mô hình sinh tạo được chọn có tầm quan trọng rất lớn.

Đóng góp chính thứ hai của chúng tôi là cụ thể hóa các kết quả tổng quát cho mô hình hỗn hợp Gaussian nhị phân (bGMM) và mạng đối kháng sinh tạo (GANs) trong Phần 3.2 và Phần 3.3, tương ứng. Các kết quả lý thuyết của chúng tôi (Định lý 3.2 và 3.3) cho thấy rằng, trong cả hai trường hợp, bậc của số hạng phân kỳ trong chặn trên thu được là Ω(max{log(m)βm, 1/√m}). Nó gợi ý rằng: một mặt, khi kích thước tập huấn luyện đủ lớn, việc sử dụng GDA để tăng cường hiệu suất phân loại một cách đáng kể là vô vọng. Tệ hơn nữa, GDA có thể làm hỏng khả năng tổng quát hóa của thuật toán học. Mặt khác, khi kích thước tập huấn luyện nhỏ và xảy ra overfitting tồi tệ, GDA có thể cải thiện đảm bảo học tập ở mức độ hằng số, điều này có ý nghĩa trong tình huống này. Những hàm ý lý thuyết này cho thấy tiềm năng của GDA trong các vấn đề thực tế với dữ liệu hạn chế.

Cuối cùng, các thí nghiệm được trình bày trong Phần 4 xác nhận các phát hiện lý thuyết của chúng tôi. Cụ thể, trong cài đặt bGMM, kết quả thực nghiệm cho thấy rằng chặn tổng quát hóa của chúng tôi (Định lý 3.2) dự đoán tốt bậc và xu hướng của sai số tổng quát hóa thực. Bên cạnh đó, trong nghiên cứu thực nghiệm trên tập dữ liệu ảnh thực, chúng tôi thấy rằng GANs không thể tăng cường hiệu suất test một cách rõ ràng và thậm chí làm hỏng khả năng tổng quát hóa khi các phương pháp tăng cường dữ liệu chuẩn được sử dụng để xấp xỉ trường hợp có tập huấn luyện lớn. Ngược lại, GANs cải thiện hiệu suất một cách đáng kể khi kích thước tập huấn luyện nhỏ và xảy ra overfitting khủng khiếp. Tất cả các kết quả thực nghiệm này hỗ trợ các hàm ý lý thuyết của chúng tôi trong Phần 3. Hơn nữa, chúng tôi cũng tiến hành thí nghiệm với mô hình khuếch tán tiên tiến. Kết quả thực nghiệm cho thấy tiềm năng của mô hình khuếch tán trong GDA và gợi ý rằng nó có thể có tốc độ học nhanh hơn GAN.

## 2 Kiến thức cơ bản

### 2.1 Ký hiệu

Cho X ⊆ Rd là không gian đầu vào và Y ⊆ R là không gian nhãn. Chúng tôi ký hiệu bởi D phân phối quần thể trên Z = X × Y. Chuẩn Lp của một biến ngẫu nhiên X được ký hiệu là ||X||p = (E|X|p)1/p.

Cho một tập S = {z1, z2, ..., zm}, chúng tôi định nghĩa S\i là tập sau khi loại bỏ điểm dữ liệu thứ i trong tập S, và Si là tập sau khi thay thế điểm dữ liệu thứ i bằng z'i trong tập S. Cho [m] = {1, 2, ..., m}, thì với mọi tập V ⊆ [n], chúng tôi định nghĩa SV = {zi : i ∈ V}. Ngoài ra, với một hàm f = f(S) nào đó, chúng tôi ký hiệu chuẩn Lp có điều kiện của nó w.r.t. SV bởi ||f||p(SV) = (E[||f||p|SV])1/p. Bên cạnh đó, chúng tôi ký hiệu khoảng cách biến thiên toàn phần bởi dTV và phân kỳ KL bởi dKL, tương ứng.

Chúng tôi cho (Y)X là tập hợp tất cả các hàm đo được từ X đến Y, A là một thuật toán học và A(S) ∈ (Y)X là giả thuyết học được trên tập dữ liệu S. Cho một giả thuyết học được A(S) và một hàm mất mát ℓ : (Y)X × Z → R+, sai số thực RD(A(S)) w.r.t. phân phối dữ liệu D được định nghĩa là Ez∼D[ℓ(A(S), z)]. Ngoài ra, sai số thực nghiệm tương ứng R̂S(A(S)) được định nghĩa là 1/m ∑m i=1 ℓ(A(S), zi).

### 2.2 Tăng cường dữ liệu sinh tạo

Trong phần này, chúng tôi mô tả quá trình GDA theo cách toán học. Cho một tập huấn luyện S với mS mẫu i.i.d. từ D, chúng ta có thể huấn luyện một mô hình sinh tạo có điều kiện G, và ký hiệu phân phối mô hình bởi DG(S). Chúng tôi lưu ý rằng tính ngẫu nhiên từ việc huấn luyện mô hình sinh tạo được bỏ qua trong bài báo này. Ngoài ra, chúng tôi định nghĩa kỳ vọng của phân phối mô hình w.r.t. S là D̄G = ES[DG(S)]. Dựa trên mô hình sinh tạo đã huấn luyện, sau đó chúng ta có thể thu được một tập dữ liệu mới SG với mG mẫu i.i.d. từ DG(S), trong đó mG là một siêu tham số. Thông thường, chúng ta xem xét trường hợp mG = Ω(mS) nếu GDA được sử dụng. Chúng tôi ký hiệu tổng số điểm dữ liệu trong tập tăng cường S̃ = S ∪ SG bởi mT. Bên cạnh đó, chúng tôi định nghĩa phân phối hỗn hợp sau khi tăng cường là D̃(S) = (mS/mT)D + (mG/mT)DG(S). Kết quả là, một giả thuyết A(S̃) có thể được học trên tập dữ liệu tăng cường S̃. Để hiểu tác động của GDA, chúng tôi quan tâm đến sai số tổng quát hóa |RD(A(S̃)) - R̂S̃(A(S̃))| w.r.t. giả thuyết học được A(S̃). Để thuận tiện, chúng tôi ký hiệu nó bởi Gen-error trong phần còn lại của bài báo. Về mặt kỹ thuật, chúng tôi thiết lập các chặn cho Gen-error bằng cách sử dụng tính ổn định thuật toán được giới thiệu trong phần tiếp theo. Theo hiểu biết của chúng tôi, đây là công trình đầu tiên khảo sát các đảm bảo học tập cho GDA.

### 2.3 Tổng quát hóa thông qua tính ổn định thuật toán

Phân tích tính ổn định thuật toán là một công cụ quan trọng để cung cấp đảm bảo cho khả năng tổng quát hóa của các mô hình học máy. Một lợi thế chính của phân tích tính ổn định là nó khai thác các tính chất đặc biệt của thuật toán và cung cấp các chặn phụ thuộc vào thuật toán. Các khái niệm tính ổn định khác nhau đã được đề xuất và sử dụng để thiết lập các chặn xác suất cao cho sai số tổng quát hóa. Trong số đó, tính ổn định đồng nhất được sử dụng rộng rãi nhất và đã được sử dụng để phân tích khả năng tổng quát hóa của nhiều thuật toán học, bao gồm các thuật toán tối thiểu hóa rủi ro thực nghiệm có chính quy hóa (ERM) và gradient descent ngẫu nhiên (SGD). Tính ổn định đồng nhất được định nghĩa như sau.

**Định nghĩa 2.1 (Tính ổn định đồng nhất).** Thuật toán A có tính ổn định đồng nhất βm w.r.t. hàm mất mát ℓ nếu điều sau đây thỏa mãn:
∀S ∈ Zm, ∀z ∈ Z, ∀i ∈ [m], sup_z |ℓ(A(S), z) - ℓ(A(Si), z)| ≤ βm.

Cho một thuật toán học βm-ổn định, công trình mốc cung cấp một chặn tổng quát hóa xác suất cao hội tụ khi βm = o(1/√m). Điều kiện này có thể không thỏa mãn trong một số cài đặt học máy hiện đại, dẫn đến các đảm bảo vô nghĩa. Trong những năm gần đây, một số nghiên cứu đã cải thiện chặn cổ điển bằng cách thiết lập các bất đẳng thức tập trung mới và chặt chẽ hơn. Đặc biệt, đã đề xuất một chặn moment và thu được đảm bảo tổng quát hóa gần tối ưu, chỉ yêu cầu βm = o(1/log m) để hội tụ. Nó được liệt kê trong định lý tiếp theo.

**Định lý 2.1 (Hệ quả 8).** Giả sử A là thuật toán học βm-ổn định và hàm mất mát ℓ bị chặn bởi M. Cho một tập huấn luyện S với m mẫu i.i.d. được lấy từ phân phối D, thì với bất kỳ δ ∈ (0,1), với xác suất ít nhất 1 - δ, ta có:
RD(A(S)) - R̂S(A(S)) ≲ log(m)βm log(1/δ) + M√(1/m log(1/δ)).

Chúng tôi lưu ý rằng tất cả các chặn tổng quát hóa được đề cập ở trên đều yêu cầu một điều kiện cơ bản: các điểm dữ liệu được rút i.i.d. theo phân phối quần thể D. Tuy nhiên, nó không còn đúng trong cài đặt GDA. Một mặt, phân phối DG(S) học được bởi mô hình sinh tạo thường không giống với phân phối thực D. Mặt khác, DG(S) học được phụ thuộc mạnh vào tập dữ liệu S được lấy mẫu. Tính chất này tạo ra trở ngại cho việc suy ra chặn tổng quát hóa cho GDA. Hơn nữa, mặc dù tồn tại một số chặn ổn định non-i.i.d., vẫn chưa rõ liệu các kỹ thuật này có phù hợp trong cài đặt GDA hay không.

## 3 Kết quả lý thuyết chính

Trong phần này, chúng tôi trình bày các kết quả lý thuyết chính. Trong Phần 3.1, chúng tôi thiết lập một chặn tổng quát hóa tổng quát (Định lý 3.1) cho GDA. Dựa trên đảm bảo học tập tổng quát, sau đó chúng tôi cụ thể hóa cài đặt học tập cho bGMM được giới thiệu trong Phần 3.2.1 và suy ra một chặn tổng quát hóa cụ thể (Định lý 3.2). Cuối cùng, chúng tôi thảo luận về các hàm ý lý thuyết của chúng tôi đối với GANs trong các vấn đề thực tế (Định lý 3.3). Đáng chú ý, theo hiểu biết tốt nhất của chúng tôi, đây là công trình đầu tiên khảo sát đảm bảo tổng quát hóa của GDA.

### 3.1 Chặn tổng quát hóa tổng quát

Để hiểu GDA, chúng tôi quan tâm đến việc nghiên cứu sai số tổng quát hóa của giả thuyết A(S̃) học được trên tập dữ liệu S̃ sau khi tăng cường. Chính thức, chúng ta cần chặn |RD(A(S̃)) - R̂S̃(A(S̃))|, điều này đã được định nghĩa là Gen-error trong Phần 2.2. Nhớ lại rằng D̃(S) đã được định nghĩa là phân phối hỗn hợp sau khi tăng cường, để suy ra chặn như vậy, trước tiên chúng tôi phân tích Gen-error như sau:

|Gen-error| ≤ |RD(A(S̃)) - RD̃(S)(A(S̃))| + |RD̃(S)(A(S̃)) - R̂S̃(A(S̃))|

Số hạng đầu tiên ở phía bên phải có thể được chặn bởi độ phân kỳ (ví dụ: dTV, dKL) giữa phân phối hỗn hợp D̃(S) và phân phối thực D. Nó phụ thuộc mạnh vào khả năng của mô hình sinh tạo được chọn. Đối với số hạng thứ hai, chúng tôi lưu ý rằng các chặn ổn định cổ điển (ví dụ: Định lý 2.1) không thể được sử dụng trực tiếp, vì các điểm trong S̃ được rút non-i.i.d. Chúng tôi chủ yếu sử dụng một tính chất cốt lõi của S̃, đó là S thỏa mãn giả định i.i.d., và SG thỏa mãn giả định i.i.d. có điều kiện khi S được cố định. Được truyền cảm hứng bởi tính chất này, chúng tôi tiếp tục phân tích số hạng này và sử dụng các bất đẳng thức moment sắc bén để thu được chặn trên. Cuối cùng, chúng tôi kết luận với kết quả sau.

**Định lý 3.1 (Chặn tổng quát hóa cho GDA, chứng minh trong Phụ lục B.1).** Giả sử A là thuật toán học βm-ổn định và hàm mất mát ℓ bị chặn bởi M. Cho một tập S̃ được tăng cường như mô tả trong Phần 2.2, thì với bất kỳ δ ∈ (0,1), với xác suất ít nhất 1 - δ, ta có:

|Gen-error| ≲ (mG/mT)MdTV(D, DG(S)) + M(√mS + √mG) + mS√mGβmT/mT√(log(1/δ)) + βmT(mS log mS + mG log mG) + mS log mS MT(mS, mG)/mT log(1/δ),

trong đó T(mS, mG) = supi dTV(D^mG_G(S), D^mG_G(Si)).

**Nhận xét.** Tính chặt chẽ của chặn trên đề xuất. Cho mG = 0, chúng ta quan sát thấy rằng Định lý 3.1 thoái hóa thành Định lý 2.1. Do đó, chặn ổn định của chúng tôi bao gồm cài đặt i.i.d. như một trường hợp đặc biệt và hưởng lợi từ cùng một đảm bảo gần tối ưu. Phân tích thêm về tính chặt chẽ của đảm bảo của chúng tôi khi mG > 0 được để lại cho công việc tương lai.

**Nhận xét.** So sánh với các chặn ổn định non-i.i.d. hiện có. Giới thiệu chi tiết về các chặn ổn định non-i.i.d. được đặt trong Phần 5. Chúng tôi lưu ý rằng các kết quả trước đây được đề xuất cho trường hợp non-i.i.d. tổng quát. Do đó, chúng có thể không đưa ra đảm bảo tuyệt vời trong trường hợp đặc biệt này. Trong Phụ lục C, chúng tôi cho thấy rằng khó có thể suy ra chặn tốt hơn Định lý 3.1 bằng cách sử dụng trực tiếp các kết quả ổn định non-i.i.d. hiện có.

**Nhận xét.** Tính ổn định của phân phối học được DG(S). T(mS, mG) trong Định lý 3.1 phản ánh tính ổn định của phân phối học được w.r.t. việc thay đổi một điểm dữ liệu trong tập huấn luyện nhận được bởi mô hình sinh tạo. Chặn của chúng tôi gợi ý rằng phân phối mô hình càng ổn định thì hiệu suất đạt được bởi GDA càng tốt. Theo hiểu biết của chúng tôi, mặc dù tính ổn định đồng nhất của một số thuật toán học sinh tạo đã được nghiên cứu, khái niệm mới T(mS, mG) xuất hiện trong chặn của chúng tôi vẫn chưa được nghiên cứu.

**Nhận xét.** Lựa chọn kích thước tăng cường. Trước tiên chúng tôi xem xét bậc của chặn trên w.r.t. mS. Quan sát Định lý 3.1, chúng tôi thấy rằng số hạng phân kỳ phân phối không thể được kiểm soát bằng cách tăng mG trong khi sai số tổng quát hóa còn lại w.r.t. phân phối hỗn hợp sẽ biến mất. Chúng tôi lưu ý rằng tồn tại một sự đánh đổi giữa tốc độ học nhanh và tiêu thụ tăng cường. Khi bậc của số hạng phân kỳ nhỏ hơn bậc của phần còn lại, việc tăng mG có thể tạo ra sự hội tụ nhanh hơn. Ngược lại, việc tăng mG không thể dẫn đến sự hội tụ nhanh hơn mà tiêu thụ lớn hơn.

Do đó, kích thước tăng cường hiệu quả m*G,order w.r.t. bậc của mS có thể được định nghĩa như sau:
m*G,order = inf{mG : sai số tổng quát hóa w.r.t. phân phối hỗn hợp ≲ phân kỳ phân phối}.

Hơn nữa, không xem xét chi phí, số lượng tăng cường tối ưu m*G có thể đạt được bằng cách tối thiểu hóa trực tiếp chặn trên. Thật không may, khó có thể tính toán dạng tường minh của m*G,order và m*G ở đây do việc bỏ qua βmT và T(mS, mG). Chúng tôi sẽ thảo luận chúng cụ thể hơn trong các trường hợp được chỉ định.

**Nhận xét.** Điều kiện đủ cho GDA với tốc độ học (không) nhanh hơn. Chúng tôi vẫn xem xét bậc của đảm bảo học tập w.r.t. mS ở đây. Cho mG = m*G,order, có thể thấy rằng phân kỳ dTV(D, DG(S)) đóng vai trò quan trọng trong việc quyết định liệu GDA có thể tận hưởng tốc độ học nhanh hơn hay không. So sánh Định lý 3.1 với Định lý 2.1 (không có tăng cường), chúng ta có thể kết luận các điều kiện đủ như sau.

**Hệ quả 3.1.** Giả sử hàm mất mát ℓ bị chặn bởi M, chúng ta có:
• Nếu dTV(D, DG(S)) = o(max{log(m)βm, 1/√m}), thì GDA tận hưởng tốc độ học nhanh hơn.
• Nếu dTV(D, DG(S)) = Ω(max{log(m)βm, 1/√m}), thì GDA không thể tận hưởng tốc độ học nhanh hơn.

Đáng chú ý, như chúng tôi sẽ trình bày trong Phần 3.2 và 3.3, mặc dù GDA không thể tận hưởng tốc độ học nhanh hơn trong trường hợp thứ hai, vẫn có thể cải thiện đảm bảo tổng quát hóa ở mức độ hằng số khi mS nhỏ, điều này quan trọng khi xảy ra overfitting tồi tệ.

### 3.2 Kết quả lý thuyết về bGMM

bGMM là một cài đặt cổ điển nhưng không tầm thường, đã được nghiên cứu rộng rãi trong tài liệu. Trong phần này, chúng tôi khảo sát nó trong bối cảnh GDA. Mô phỏng sẽ được tiến hành trong Phần 4.1 để xác minh các kết quả này.

#### 3.2.1 Cài đặt bGMM

Trong phần này, chúng tôi giới thiệu cấu hình phân phối dữ liệu trong bGMM, cũng như bộ phân loại tuyến tính và mô hình sinh tạo có điều kiện tương ứng. Các cài đặt tương tự về phân phối và bộ phân loại đã được nhiều nghiên cứu trước đây áp dụng.

**Cài đặt phân phối.** Chúng tôi xem xét một tác vụ nhị phân trong đó Y = {-1, 1}. Cho một vector μ ∈ Rd (||μ||2 = 1) và phương sai nhiễu σ² > 0, chúng tôi giả sử rằng phân phối thỏa mãn y ~ uniform{-1, 1} và x|y ~ N(yμ, σ²Id). Bên cạnh đó, tương tự như tài liệu, chúng tôi giả sử rằng phân phối của y đã biết, điều này được thỏa mãn trong học có điều kiện với nhãn.

**Bộ phân loại tuyến tính đơn giản.** Chúng tôi xem xét một bộ phân loại tuyến tính được tham số hóa bởi θ ∈ Rd dưới dạng dự đoán ŷ = sign(θᵀx). Cho m mẫu, θ được học bằng cách thực hiện ERM w.r.t. hàm mất mát log-likelihood âm, tức là:
l(θ, (x, y)) = 1/(2σ²)(x - yθ)ᵀ(x - yθ).

Kết quả là, thuật toán học này sẽ trả về θ̂ = 1/m ∑ᵢ₌₁ᵐ yᵢxᵢ, thỏa mãn E[θ̂] = μ.

**Mô hình sinh tạo có điều kiện.** Chúng tôi xem xét một mô hình sinh tạo đơn giản được tham số hóa bởi μy, σ²k, trong đó y ∈ {-1, 1} và k ∈ [d]. Nó học trực tiếp các tham số của phân phối hỗn hợp Gaussian. Cho m điểm dữ liệu, cho my là số mẫu trong lớp y, nó trả về:
μ̂y = ∑(yᵢ=y) xᵢ/my, σ̂²k = ∑y ∑(my/m) ∑(yᵢ=y) (xᵢk - μ̂yk)²/(my - 1),

đây là các ước lượng không thiên vị của ±μ và σ² tương ứng. Dựa trên các tham số học được, chúng ta có thể thực hiện GDA bằng cách tạo ra các mẫu mới từ phân phối y ~ uniform{-1, 1}, x|y ~ N(μ̂y, Σ), trong đó Σ = diag(σ̂²1, ..., σ̂²d).

#### 3.2.2 Kết quả lý thuyết

Trong phần này, chúng tôi thiết lập chặn tổng quát hóa cho bGMM dựa trên chặn tổng quát được đề xuất trong Định lý 3.1. Để suy ra chặn như vậy, nhiệm vụ chính là chặn các số hạng M, βmT, dTV(D, DG(S)) và T(mS, mG) trong Định lý 3.1. Đối với M (Bổ đề B.5) và βmT (Bổ đề B.6), chúng tôi chủ yếu sử dụng tính chất tập trung của biến Gaussian đa biến (Bổ đề B.4). Ngoài ra, được truyền cảm hứng bởi các nghiên cứu trước đây về naïve Bayes, chúng tôi chặn dTV(D, DG(S)) (Bổ đề B.7) bằng cách thảo luận khoảng cách giữa các tham số ước lượng và tham số thực của bGMM. Bên cạnh đó, tính chất tập trung của T(mS, mG) (Bổ đề B.9) có thể được suy ra bởi thảo luận trước đó. Cuối cùng, chúng ta có thể thu được các kết quả sau.

**Định lý 3.2 (Chặn tổng quát hóa cho bGMM, chứng minh trong Phụ lục B.2).** Xem xét cài đặt được giới thiệu trong Phần 3.2.1. Cho một tập S với mS mẫu i.i.d. từ phân phối bGMM D và một tập tăng cường SG với mG mẫu i.i.d. được rút từ phân phối hỗn hợp Gaussian học được, thì với xác suất cao ít nhất 1 - δ, ta có:

|Gen-error| ≲ (19) trong Phụ lục B.2 ≲ {
  log(mS)/√mS nếu cố định d và mG = 0,
  log²(mS)/√mS nếu cố định d và mG = Θ(mS),
  log(mS)/√mS nếu cố định d và mG = m*G,order,
  d nếu cố định mS.
}

**Nhận xét.** Chặn trên tường minh của sai số tổng quát hóa. (19) cho chúng ta dạng tường minh để dự đoán sai số tổng quát hóa trong cài đặt bGMM. Kích thước tăng cường tối ưu m*G có thể được thu được bằng cách tối thiểu hóa nó. Trong Phần 4.1, chúng ta sẽ thấy rằng (19) dự đoán tốt bậc và xu hướng của sai số tổng quát hóa thực, điều này xác minh tính đúng đắn của đảm bảo học tập được đề xuất trong cài đặt bGMM.

**Nhận xét.** Tốc độ học âm của GDA. Mặc dù chúng ta ước lượng thống kê đủ của phân phối hỗn hợp Gaussian (μ và σ²) trực tiếp trong trường hợp đặc biệt này, chúng ta không thể hy vọng tận hưởng tốc độ học tốt hơn khi mG = m*G,order. Mọi thứ có thể tệ hơn khi chúng ta mô hình hóa phân phối trong thực tế (ví dụ: hình ảnh, văn bản), điều này cho thấy rằng khi các mẫu gốc dồi dào, việc tiếp tục thực hiện GDA không thể cải thiện khả năng tổng quát hóa. Định lý 3.3 hỗ trợ quan điểm này.

**Nhận xét.** Cải thiện ở mức độ hằng số có ý nghĩa rất lớn khi xảy ra overfitting. Từ (2) chúng ta biết rằng khi mS nhỏ và d lớn, lời nguyền của chiều cao xảy ra, dẫn đến sai số tổng quát hóa tồi tệ. Trong trường hợp này, mặc dù GDA chỉ có thể cải thiện nó ở mức độ hằng số bằng cách kiểm soát sai số tổng quát hóa w.r.t. phân phối hỗn hợp, tác dụng là rõ ràng do quy mô lớn của d.

### 3.3 Hàm ý đối với các mô hình sinh tạo sâu

Ngày nay, tăng cường dữ liệu với các mô hình sinh tạo sâu được sử dụng rộng rãi và nhận được nhiều sự chú ý. Do đó, hưởng lợi từ những tiến bộ gần đây trong mạng đối kháng sinh tạo (GAN) và SGD, chúng tôi thảo luận về các hàm ý của lý thuyết chúng tôi đối với các vấn đề thực tế, điều này sẽ được xác minh bởi các thí nghiệm thực nghiệm trong Phần 4.2.

#### 3.3.1 Cài đặt học tập

Chúng tôi xem xét tác vụ phân loại nhị phân tổng quát trong kỷ nguyên học sâu. Trong phần này, chúng tôi giới thiệu cài đặt phân phối dữ liệu, bộ phân loại mạng neural sâu, thuật toán học, và mô hình sinh tạo sâu.

**Cài đặt phân phối.** Chúng tôi giả sử rằng không gian đầu vào thỏa mãn X ⊆ [0,1]d, và phân tích của chúng tôi có thể dễ dàng mở rộng cho bất kỳ không gian đầu vào bị chặn nào. Giả định này thường đúng trong nhiều vấn đề thực tế, ví dụ: dữ liệu hình ảnh thỏa mãn X ⊆ [0,255]d. Tương tự như bGMM, chúng tôi cho Y = {-1, 1} và giả sử rằng phân phối của y đã biết.

**Bộ phân loại mạng neural sâu.** Chúng tôi xem xét một perceptron đa lớp (MLP) hoặc mạng neural tích chập (CNN) L-lớp tổng quát f(w,·) : Z → R, trong đó w ký hiệu trọng số của nó và wl ký hiệu trọng số trong lớp thứ l. Kiến trúc trừu tượng của nó phù hợp với kiến trúc trong tài liệu, và chi tiết có thể được tìm thấy trong Phụ lục A.1. Ngoài ra, chúng tôi giả sử rằng bộ phân loại mạng neural sâu thỏa mãn các giả định về tính mượt và tính bị chặn, được nhiều nghiên cứu trước đây áp dụng.

**Giả định 3.1 (Tính mượt).** Chúng tôi giả sử rằng f(w,·) là η-mượt w.r.t. w, tức là: |∇f(w1,·) - ∇f(w2,·)| ≤ η||w1 - w2||2 với bất kỳ w1 và w2.

**Giả định 3.2 (Tính bị chặn).** Chúng tôi giả sử rằng với mọi l ∈ [L], tồn tại một hằng số Wl thỏa mãn ||wl||2 ≤ Wl.

**Thuật toán học cho bộ phân loại mạng neural sâu.** Cài đặt thuật toán học phù hợp với thực tế. Chúng tôi giả sử rằng hàm mất mát là hàm mất mát binary cross-entropy ℓ(f,(x,y)) = log(1 + exp(-yf(w,x))) và nó được tối ưu hóa bởi SGD. Đối với bước thứ t, chúng tôi đặt tốc độ học là c/(ηt) với hằng số dương c nào đó. Bên cạnh đó, chúng tôi giả sử rằng tổng số lần lặp T = O(mT). Những cấu hình này được các nghiên cứu trước đây về tính ổn định của SGD áp dụng.

**Mô hình sinh tạo sâu.** Chúng tôi chọn GAN làm mô hình sinh tạo sâu, được tham số hóa bởi MLP. Kiến trúc trừu tượng của nó giống như trong Định lý 19, và chi tiết được đặt trong Phụ lục A.2. Bên cạnh đó, do thiếu lý thuyết mô hình sinh tạo có điều kiện, chúng tôi thực hiện một xấp xỉ ngây thơ ở đây bằng cách giả sử rằng mỗi loại được học bởi một GAN, tương ứng.

#### 3.3.2 Kết quả lý thuyết

Tương tự như cài đặt bGMM, chúng tôi thiết lập chặn tổng quát hóa cho cài đặt học sâu. Để đạt được mục tiêu này, chúng tôi chặn các số hạng M, βmT, và dTV(D, DG(S)) dựa trên các kết quả gần đây về GAN và SGD. Đầu tiên, tính bị chặn và tính Lipschitz của bộ phân loại f có thể được suy ra từ Giả định 3.2 (Bổ đề B.10). Thứ hai, tính bị chặn của f ngụ ý trực tiếp chặn trên cho M vì hàm mất mát binary cross-entropy là 1-Lipschitz w.r.t. f. Thứ ba, bằng cách kết hợp tính Lipschitz và tính mượt của f, chúng ta có thể chặn βmT cho SGD (Bổ đề B.11). Cuối cùng, dTV(D, DG(S)) có thể được chặn bởi kết quả trong tài liệu (Bổ đề B.12).

**Định lý 3.3 (Chặn tổng quát hóa cho GAN, chứng minh trong Phụ lục B.3).** Xem xét cài đặt được giới thiệu trong Phần 3.3.1. Cho một tập S với mS mẫu i.i.d. từ bất kỳ phân phối D nào và một tập tăng cường SG với mG mẫu i.i.d. được lấy từ phân phối DG(S) học được bởi GANs, thì với bất kỳ δ ∈ (0,1) cố định, với xác suất ít nhất 1 - δ, ta có:

E|Gen-error| ≲ {
  1/√mS nếu cố định W, L, d, cho mG = 0,
  max{log(mS)/m^(1/4)_S, log mS · T(mS, mG)} nếu cố định W, L, d, cho mG = Θ(mS),
  log(mS)/m^(1/4)_S nếu cố định W, L, d, cho mG = m*G,order,
  d·L²·∏^L_(l=1) ||Wl||²₂ nếu cố định mS.
}

**Nhận xét.** Tốc độ học chậm với GDA. Chặn trên trong Định lý 3.3 cho thấy rằng khi chúng ta thực hiện GDA, bậc w.r.t. mS trở nên tệ hơn một cách chặt chẽ. Do đó, nó ngụ ý rằng khi mS đủ lớn, việc tăng cường hiệu suất một cách rõ ràng bằng cách tăng cường tập huấn luyện dựa trên GANs là vô vọng. Ngược lại, GDA có thể làm cho khả năng tổng quát hóa tệ hơn.

**Nhận xét.** GDA có ý nghĩa rất lớn khi xảy ra overfitting. Từ Định lý 3.3, chúng ta biết rằng khi chiều dữ liệu và dung lượng mô hình trở nên lớn hơn, bộ phân loại mạng neural sâu được huấn luyện với SGD trở nên dễ overfit tập huấn luyện hơn và có hiệu suất tổng quát hóa tồi tệ. Trong trường hợp này, cải thiện mức độ hằng số của khả năng tổng quát hóa do GDA gây ra sẽ có ý nghĩa.

## 4 Thí nghiệm

Trong phần này, chúng tôi tiến hành thí nghiệm để xác minh các kết quả trong Phần 3, bao gồm hai khía cạnh:
• Chúng tôi tiến hành mô phỏng trong cài đặt bGMM và xác nhận kết quả trong Định lý 3.2.
• Chúng tôi nghiên cứu thực nghiệm tác động của GDA trên tập dữ liệu CIFAR-10 thực, hỗ trợ các hàm ý lý thuyết của chúng tôi về GANs.

### 4.1 Mô phỏng trên bGMM

Chúng tôi cho μ = (1/√d, ..., 1/√d)ᵀ để thỏa mãn ||μ||₂ = 1, σ² = 0.6², và tạo ngẫu nhiên 10.000 mẫu theo phân phối hỗn hợp Gaussian làm tập test. Chúng tôi xấp xỉ Gen-error bằng khoảng cách giữa training error và test error. Để loại bỏ tính ngẫu nhiên, chúng tôi lấy trung bình trên 1.000 lần chạy ngẫu nhiên và báo cáo kết quả trung bình. Chúng tôi ký hiệu γ = mG/mS trong phần này.

Đầu tiên, chúng tôi khảo sát trường hợp chiều dữ liệu d được cố định. Để xác minh bậc gần O(1/√mS) (log mS có thể được bỏ qua w.r.t. √mS), chúng tôi cố định d = 1, và thay đổi mS từ 20 đến 500. Với mỗi mS được chọn, chúng tôi điều chỉnh γ từ 0 đến 50 để tạo ra các mẫu mới ở các mức độ khác nhau. Kết quả được trình bày trong Hình 1a, cho thấy rằng sai số tổng quát hóa giảm theo bậc gần O(1/√mS). Bên cạnh đó, sai số tổng quát hóa không có GDA luôn (gần) tối ưu, điều này chứng minh thực nghiệm rằng GDA không hiệu quả khi mS đủ lớn.

Thứ hai, chúng tôi tiến hành mô phỏng trong trường hợp mS được cố định như một hằng số nhỏ. Để xác minh bậc là O(d), chúng tôi cố định mS = 10, và thay đổi d từ 2 đến 100. Với mỗi d được chọn, chúng tôi cũng điều chỉnh γ từ 0 đến 50. Kết quả được hiển thị trong Hình 1d, cho thấy rằng sai số tổng quát hóa tăng theo bậc O(d). Ngoài ra, khi d lớn (ví dụ: 100) và lời nguyền của chiều cao xảy ra, sai số tổng quát hóa với γ lớn hơn tốt hơn một cách đáng kể, cho thấy rằng mặc dù GDA chỉ có thể tăng cường nó ở mức độ hằng số, tác dụng là đáng kể khi xảy ra overfitting.

Thứ ba, chúng tôi thiết kế thí nghiệm để xác nhận liệu chặn trên trong Định lý 3.2 có thể dự đoán xu hướng sai số tổng quát hóa tốt hay không. Tương tự như các nghiên cứu lý thuyết trước đây, chúng tôi tìm một xấp xỉ của (19) trong Phụ lục B.2 làm dự đoán của chúng tôi bằng cách thay thế log(a/δ) bằng log(a) nếu a ≠ 1 ngược lại 1. Chúng tôi vẽ đồ thị sự thật cơ bản và dự đoán trong trường hợp (d, mS) = (1, 40) và (50, 10), tương ứng. Kết quả trong Hình 1 cho thấy rằng chặn của chúng tôi dự đoán xu hướng sai số tổng quát hóa tốt. Do đó, một xấp xỉ của kích thước tăng cường tối ưu m*G có thể được tìm thấy bằng cách tối thiểu hóa (19).

### 4.2 Kết quả thực nghiệm trên CIFAR-10

Trong phần này, chúng tôi tiến hành thí nghiệm trên tập dữ liệu CIFAR-10 thực với ResNets và các mô hình sinh tạo sâu khác nhau, bao gồm conditional DCGAN (cDCGAN), StyleGAN2-ADA và elucidating diffusion model (EDM). Chi tiết thí nghiệm có thể được tìm thấy trong Phụ lục D.

Để xác nhận các hàm ý lý thuyết của chúng tôi trong Phần 3.3, chúng tôi cần thảo luận hai trường hợp, trong đó một mS nhỏ và mS khác lớn. Hai trường hợp có thể được xấp xỉ bằng việc có thực hiện tăng cường dữ liệu khác hay không. Chúng tôi bổ sung sử dụng tăng cường dữ liệu chuẩn trong tài liệu để xấp xỉ trường hợp với mS lớn. Sau đó, với mỗi ResNet và mô hình sinh tạo được chọn, chúng tôi đặt mG từ 0 đến 1M và ghi lại độ chính xác của bộ phân loại được huấn luyện trên tập test CIFAR-10. Kết quả được trình bày trong Bảng 2 của Phụ lục D. Chúng tôi giải thích chúng như sau.

**GANs cải thiện hiệu suất test của các bộ phân loại khi xảy ra overfitting.** Khi không sử dụng tăng cường chuẩn, ResNets được huấn luyện trên tập huấn luyện luôn bị overfitting. Tuy nhiên, điều này có thể được giảm thiểu bằng tăng cường dữ liệu dựa trên GANs, mặc dù cDCGAN không thể tạo ra hình ảnh chất lượng cao. Hiện tượng này hỗ trợ các hàm ý từ Định lý 3.3.

**Chúng ta không thể có cải thiện rõ ràng bằng cách sử dụng GANs khi mS xấp xỉ lớn.** Khi sử dụng tăng cường chuẩn, các bộ phân loại mạng neural sâu được huấn luyện trên tập dữ liệu CIFAR-10 đạt được hiệu suất không tầm thường. Trong trường hợp này, GDA với cDCGAN luôn làm hỏng khả năng tổng quát hóa. Mặc dù chúng tôi sử dụng StyleGAN2-ADA, đạt được hiệu suất tạo ảnh có điều kiện tiên tiến trên tập dữ liệu CIFAR-10, chúng tôi không thể tăng cường hiệu suất của các bộ phân loại một cách rõ ràng, và thậm chí liên tục có được độ chính xác test tệ hơn khi mG là 500k hoặc 1M.

**Mô hình xác suất khuếch tán đầy hứa hẹn cho GDA.** Khi các mô hình khuếch tán cho thấy khả năng xuất sắc của chúng trong việc tạo hình ảnh, một câu hỏi tự nhiên xuất hiện: liệu các mô hình khuếch tán có phù hợp hơn cho GDA không? Chúng tôi chọn EDM đạt được điểm FID tiên tiến làm trình tạo. Bảng 2 trong Phụ lục D.5 cho thấy rằng EDM cải thiện độ chính xác test một cách rõ ràng, thậm chí khi tăng cường chuẩn đã được sử dụng. Điều này cho thấy rằng các mô hình khuếch tán tận hưởng dTV(D, DG(S)) với tốc độ hội tụ nhanh hơn GANs, và cho thấy tiềm năng của các mô hình khuếch tán trong GDA.

## 5 Nghiên cứu liên quan

**Lý thuyết và thực hành tăng cường dữ liệu.** Tăng cường dữ liệu là một phương pháp phổ biến để cải thiện khả năng tổng quát hóa của mạng neural sâu trong trường hợp dữ liệu huấn luyện không đủ. Các phương pháp tăng cường dữ liệu cổ điển bao gồm biến đổi hình học, biến đổi không gian màu, bộ lọc kernel, trộn hình ảnh, xóa ngẫu nhiên, tăng cường không gian đặc trưng, v.v. Cũng có nhiều nghiên cứu lý thuyết nghiên cứu tác động của các phương pháp tăng cường dữ liệu cổ điển từ các góc độ khác nhau.

Với sự tiến bộ của các mô hình sinh tạo sâu, GDA trở thành một kỹ thuật tăng cường dữ liệu mới và đầy hứa hẹn. Ví dụ, nghiên cứu cho thấy rằng việc tăng cường tập huấn luyện ImageNet với các mẫu từ các mô hình khuếch tán có điều kiện cải thiện đáng kể độ chính xác phân loại. Tuy nhiên, ít nghiên cứu đã khảo sát lý thuyết của GDA. Cả thành công thực nghiệm và khoảng trống lý thuyết đều khuyến khích chúng tôi nghiên cứu vai trò của GDA.

**Lý thuyết ổn định thuật toán.** Các kết quả cổ điển được giới thiệu chi tiết trong Phần 2 có nhiều mở rộng khác nhau. Nghiên cứu nổi bật tập trung vào tính ổn định đồng nhất của SGD và suy ra các chặn tổng quát hóa cho nó. Nghiên cứu cải thiện các kết quả và thu được các đảm bảo chặt chẽ cho tính ổn định của SGD, được sử dụng trong Định lý 3.3.

Việc thiết lập các chặn ổn định trong các cài đặt non-i.i.d. cũng đã nhận được sự quan tâm tăng cao trong những năm gần đây. Một hướng chính mô hình hóa các phụ thuộc bằng mô hình trộn và suy ra các chặn ổn định với hệ số trộn. Tuy nhiên, thường khó ước lượng định lượng các hệ số trộn. Để tránh vấn đề này, một hướng khác mô hình hóa định tính các phụ thuộc bằng đồ thị. Gần đây, nghiên cứu suy ra một chặn ổn định tổng quát cho các cài đặt phụ thuộc được đặc trưng bởi độ phức tạp rừng của đồ thị phụ thuộc. Tuy nhiên, khó sử dụng các kỹ thuật này để suy ra chặn tốt hơn Định lý 3.1 cho GDA, điều này được thảo luận chi tiết trong Phụ lục C.

**Sự hội tụ của các mô hình sinh tạo sâu.** Ngoài chặn cho dTV(D, DG(S)) w.r.t. GANs mà chúng tôi sử dụng trong Định lý 3.3, có những nỗ lực để suy ra chặn như vậy cho các mô hình khuếch tán. Một cách không chính thức, chúng chủ yếu giả sử rằng sai số ước lượng của hàm điểm bị chặn, sau đó với lựa chọn thích hợp về kích thước bước và số lần lặp, các mô hình khuếch tán xuất ra một phân phối gần với phân phối thực. Tuy nhiên, vẫn chưa rõ làm thế nào để suy ra các đảm bảo học tập w.r.t. kích thước tập huấn luyện mS một cách trực tiếp. Một khi các đảm bảo học tập như vậy được thiết lập, chúng ta có thể phân tích trực tiếp tác động của GDA với các mô hình khuếch tán bằng Định lý 3.1.

## 6 Kết luận

Trong bài báo này, chúng tôi cố gắng hiểu các kỹ thuật GDA hiện đại. Để thực hiện mục tiêu này, trước tiên chúng tôi thiết lập một chặn ổn định thuật toán tổng quát trong cài đặt non-i.i.d. này. Nó gợi ý rằng GDA tận hưởng tốc độ học nhanh hơn khi số hạng phân kỳ dTV(D, DG(S)) = o(max{log(m)βm, 1/√m}). Thứ hai, chúng tôi cụ thể hóa đảm bảo học tập cho các cài đặt bGMM và GANs. Kết quả lý thuyết cho thấy rằng, trong cả hai trường hợp, mặc dù GDA không thể tận hưởng tốc độ học nhanh hơn, nó hiệu quả khi xảy ra overfitting khủng khiếp, gợi ý tiềm năng của nó trong học tập với dữ liệu hạn chế. Cuối cùng, kết quả thực nghiệm hỗ trợ các kết luận lý thuyết của chúng tôi và hơn nữa cho thấy tiềm năng của các mô hình khuếch tán trong GDA.

**Tác động rộng hơn và hạn chế.** Đây chủ yếu là công trình lý thuyết để giúp mọi người hiểu GDA, và chúng tôi không thấy tác động xã hội tiêu cực trực tiếp của lý thuyết chúng tôi. Một hạn chế là các kết quả không tận hưởng đảm bảo tính chặt chẽ. Việc suy ra các chặn dưới có thể được để lại cho công việc tương lai.

# Các Phương Pháp Tăng Cường Dữ Liệu trong Xử Lý Ngôn Ngữ Tự Nhiên: Một Khảo Sát

Bohan Li, Yutai Hou, Wanxiang Che
Viện Công nghệ Harbin, Harbin, Trung Quốc

## Tóm tắt
Là một chiến lược hiệu quả, tăng cường dữ liệu (DA) giảm thiểu các tình huống thiếu hụt dữ liệu nơi các kỹ thuật học sâu có thể thất bại. Nó được áp dụng rộng rãi trong thị giác máy tính sau đó được giới thiệu vào xử lý ngôn ngữ tự nhiên và đạt được những cải thiện trong nhiều tác vụ. Một trong những trọng tâm chính của các phương pháp DA là cải thiện tính đa dạng của dữ liệu huấn luyện, từ đó giúp mô hình khái quát tốt hơn với dữ liệu kiểm tra chưa thấy. Trong khảo sát này, chúng tôi phân loại các phương pháp DA thành ba danh mục dựa trên tính đa dạng của dữ liệu tăng cường, bao gồm diễn giải, làm nhiễu và lấy mẫu. Bài báo của chúng tôi đặt ra mục tiêu phân tích chi tiết các phương pháp DA theo các danh mục trên. Hơn nữa, chúng tôi cũng giới thiệu ứng dụng của chúng trong các tác vụ NLP cũng như những thách thức. Một số tài nguyên hữu ích được cung cấp trong Phụ lục A.

Từ khóa: Tăng cường Dữ liệu, Xử lý Ngôn ngữ Tự nhiên

## Mục lục

1. Giới thiệu
2. Các Phương pháp Tăng cường Dữ liệu trong NLP
   2.1. Các Phương pháp dựa trên Diễn giải
   2.2. Các Phương pháp dựa trên Làm nhiễu
   2.3. Các Phương pháp dựa trên Lấy mẫu
3. Chiến lược và Thủ thuật
4. Ứng dụng trong các Tác vụ NLP
5. Các Chủ đề Liên quan
6. Thách thức và Cơ hội
7. Kết luận

## 1. Giới thiệu

Tăng cường dữ liệu đề cập đến các phương pháp được sử dụng để tăng lượng dữ liệu bằng cách thêm các bản sao được chỉnh sửa nhẹ của dữ liệu hiện có hoặc dữ liệu tổng hợp mới được tạo từ dữ liệu hiện có. Các phương pháp như vậy giảm thiểu các tình huống thiếu hụt dữ liệu nơi các kỹ thuật học sâu có thể thất bại, vì vậy DA đã nhận được sự quan tâm tích cực và nhu cầu gần đây. Tăng cường dữ liệu được áp dụng rộng rãi trong lĩnh vực thị giác máy tính, chẳng hạn như lật và xoay, sau đó được giới thiệu vào xử lý ngôn ngữ tự nhiên (NLP). Khác với hình ảnh, ngôn ngữ tự nhiên là rời rạc, điều này làm cho việc áp dụng các phương pháp DA trở nên khó khăn hơn và ít được khám phá trong NLP.

Một lượng lớn các phương pháp DA đã được đề xuất gần đây, và một khảo sát về các phương pháp hiện có sẽ có lợi để các nhà nghiên cứu có thể bắt kịp với tốc độ đổi mới. Liu et al. và Feng et al. đều trình bày các khảo sát cung cấp cái nhìn tổng quan về DA cho NLP. Họ trực tiếp phân chia các danh mục theo các phương pháp. Do đó, các danh mục này có xu hướng quá hạn chế hoặc quá chung chung, ví dụ như dịch ngược và các kỹ thuật dựa trên mô hình. Bayer et al. đăng một khảo sát về DA chỉ cho phân loại văn bản. Trong khảo sát này, chúng tôi sẽ cung cấp một tổng quan toàn diện về các phương pháp DA trong NLP. Một trong những mục tiêu chính của chúng tôi là chỉ ra bản chất của DA, tức là tại sao tăng cường dữ liệu hoạt động. Để tạo thuận lợi cho điều này, chúng tôi phân loại các phương pháp DA theo tính đa dạng của dữ liệu tăng cường, vì cải thiện tính đa dạng dữ liệu huấn luyện là một trong những động lực chính của hiệu quả DA. Chúng tôi chia các phương pháp DA thành ba danh mục, bao gồm diễn giải, làm nhiễu và lấy mẫu.

Cụ thể, các phương pháp dựa trên diễn giải tạo ra các cách diễn giải khác của dữ liệu gốc làm dữ liệu tăng cường. Danh mục này mang lại những thay đổi hạn chế so với dữ liệu gốc. Các phương pháp dựa trên làm nhiễu thêm nhiều nhiễu liên tục hoặc rời rạc vào dữ liệu gốc và liên quan đến nhiều thay đổi hơn. Các phương pháp dựa trên lấy mẫu nắm vững phân bố của dữ liệu gốc để lấy mẫu dữ liệu mới làm dữ liệu tăng cường. Với sự trợ giúp của các heuristic nhân tạo và các mô hình được huấn luyện, các phương pháp như vậy có thể lấy mẫu dữ liệu hoàn toàn mới thay vì thay đổi dữ liệu hiện có và do đó tạo ra dữ liệu đa dạng hơn.

Bài báo của chúng tôi đặt ra mục tiêu phân tích chi tiết các phương pháp DA theo các danh mục trên. Ngoài ra, chúng tôi cũng giới thiệu ứng dụng của chúng trong các tác vụ NLP cũng như những thách thức. Phần còn lại của bài báo được cấu trúc như sau:

• Phần 2 trình bày một đánh giá toàn diện về ba danh mục và phân tích từng phương pháp riêng lẻ trong những danh mục đó. Chúng tôi cũng giới thiệu các đặc điểm của các phương pháp, ví dụ như mức độ chi tiết và cấp độ.

• Phần 3 đề cập đến tóm tắt các chiến lược và thủ thuật phổ biến để cải thiện chất lượng dữ liệu tăng cường, bao gồm các chiến lược xếp chồng phương pháp, tối ưu hóa và lọc.

• Phần 4 phân tích việc áp dụng các phương pháp trên trong các tác vụ NLP. Chúng tôi cũng cho thấy sự phát triển của các phương pháp DA thông qua dòng thời gian.

• Phần 5 giới thiệu một số chủ đề liên quan của tăng cường dữ liệu, bao gồm các mô hình ngôn ngữ được huấn luyện trước, học đối chiếu, các phương pháp thao tác dữ liệu tương tự, mạng đối thủ sinh và các cuộc tấn công đối thủ. Chúng tôi nhằm mục đích kết nối tăng cường dữ liệu với các chủ đề khác và đồng thời chỉ ra sự khác biệt của chúng.

• Phần 6 liệt kê một số thách thức mà chúng tôi quan sát trong tăng cường dữ liệu NLP, bao gồm tường thuật lý thuyết và các phương pháp tổng quát hóa. Những điểm này cũng tiết lộ hướng phát triển tương lai của tăng cường dữ liệu.

• Phần 7 kết luận bài báo.

## 2. Các Phương pháp Tăng cường Dữ liệu trong NLP

Tăng cường dữ liệu nhằm mục đích tạo ra dữ liệu huấn luyện tổng hợp bổ sung trong các tình huống dữ liệu không đủ. Tăng cường dữ liệu dao động từ các kỹ thuật đơn giản như các phương pháp dựa trên quy tắc đến các phương pháp dựa trên sinh có thể học được, và tất cả các phương pháp trên về cơ bản đảm bảo tính hợp lệ của dữ liệu tăng cường. Tức là, các phương pháp DA cần đảm bảo rằng dữ liệu tăng cường là hợp lệ cho tác vụ, tức là được coi là một phần của cùng một phân bố của dữ liệu gốc. Ví dụ, ngữ nghĩa tương tự trong dịch máy và cùng nhãn trong phân loại văn bản như dữ liệu gốc.

Trên cơ sở tính hợp lệ, dữ liệu tăng cường cũng được mong đợi là đa dạng để cải thiện khả năng tổng quát hóa mô hình trên các tác vụ downstream. Điều này liên quan đến tính đa dạng của dữ liệu tăng cường. Trong khảo sát này, chúng tôi chia các phương pháp DA thành ba danh mục một cách mới lạ theo tính đa dạng của dữ liệu tăng cường của chúng: diễn giải, làm nhiễu và lấy mẫu.

• Các phương pháp dựa trên diễn giải tạo ra dữ liệu tăng cường có sự khác biệt ngữ nghĩa hạn chế so với dữ liệu gốc, dựa trên các thay đổi phù hợp và hạn chế đối với câu. Dữ liệu tăng cường truyền tải thông tin rất giống với dạng gốc.

• Các phương pháp dựa trên làm nhiễu thêm nhiễu rời rạc hoặc liên tục dưới tiền đề đảm bảo tính hợp lệ. Điểm của các phương pháp như vậy là cải thiện tính mạnh mẽ của mô hình.

• Các phương pháp dựa trên lấy mẫu nắm vững phân bố dữ liệu và lấy mẫu dữ liệu mới trong chúng. Các phương pháp như vậy xuất ra dữ liệu đa dạng hơn và thỏa mãn nhiều nhu cầu hơn của các tác vụ downstream dựa trên các heuristic nhân tạo và các mô hình được huấn luyện.

### 2.1. Các Phương pháp dựa trên Diễn giải

Là hiện tượng phổ biến trong ngôn ngữ tự nhiên, diễn giải là những cách thay thế để truyền đạt thông tin tương tự như dạng gốc. Tự nhiên, việc tạo ra các cách diễn giải là một sơ đồ phù hợp cho tăng cường dữ liệu. Diễn giải bao gồm một số cấp độ, bao gồm diễn giải từ vựng, diễn giải cụm từ và diễn giải câu. Do đó, các kỹ thuật DA dựa trên diễn giải được giới thiệu dưới đây cũng có thể được bao gồm trong ba cấp độ này.

#### 2.1.1. Từ điển đồng nghĩa

Một số công trình thay thế từ trong văn bản gốc bằng từ đồng nghĩa và từ cấp trên của chúng, để có được cách diễn đạt mới trong khi giữ ngữ nghĩa của văn bản gốc không thay đổi càng nhiều càng tốt. Các từ điển đồng nghĩa như WordNet chứa các bộ ba từ vựng như vậy và thường được sử dụng như tài nguyên bên ngoài.

Zhang et al. là những người đầu tiên áp dụng từ điển đồng nghĩa trong tăng cường dữ liệu. Họ sử dụng một từ điển đồng nghĩa được dẫn xuất từ WordNet, sắp xếp các từ đồng nghĩa của từ theo độ tương tự của chúng. Đối với mỗi câu, họ truy xuất tất cả các từ có thể thay thế và ngẫu nhiên chọn r trong số chúng để được thay thế. Xác suất của số r được xác định bởi một phân phối hình học với tham số p trong đó P[r] ∝ p^r. Cho một từ, chỉ số s của từ đồng nghĩa được chọn cũng được xác định bởi một phân phối hình học khác trong đó P[s] ∝ p^s. Phương pháp này đảm bảo rằng các từ đồng nghĩa tương tự hơn với từ gốc được chọn với xác suất lớn hơn.

Một phương pháp tăng cường văn bản được sử dụng rộng rãi có tên EDA (Kỹ thuật Tăng cường Dữ liệu Dễ dàng) cũng thay thế các từ gốc bằng từ đồng nghĩa của chúng sử dụng WordNet: họ ngẫu nhiên chọn n từ, không phải từ dừng, từ câu gốc. Mỗi từ này được thay thế bằng một từ đồng nghĩa ngẫu nhiên.

Ngoài từ đồng nghĩa, Coulombe et al. đề xuất sử dụng từ cấp trên để thay thế các từ gốc. Họ cũng khuyến nghị các loại từ của từ tăng cường theo thứ tự khó tăng dần: trạng từ, tính từ, danh từ và động từ.

**Từ điển đồng nghĩa**
Ưu điểm:
1. Dễ sử dụng.

Hạn chế:
1. Phạm vi và loại từ của từ tăng cường bị hạn chế.
2. Phương pháp này không thể giải quyết vấn đề đa nghĩa.
3. Ngữ nghĩa câu có thể bị ảnh hưởng nếu có quá nhiều thay thế.

#### 2.1.2. Nhúng ngữ nghĩa

Phương pháp này khắc phục những hạn chế về phạm vi thay thế và loại từ trong phương pháp dựa trên từ điển đồng nghĩa. Nó sử dụng các embedding từ được huấn luyện trước, chẳng hạn như Glove, Word2Vec, FastText, v.v., và thay thế từ gốc trong câu bằng neighbor gần nhất của nó trong không gian embedding.

Trong tác vụ phân loại tin nhắn Twitter, Wang et al. tiên phong sử dụng cả word embeddings và frame embeddings thay vì các từ rời rạc. Đối với word embeddings, mỗi từ gốc trong tweet được thay thế bằng một trong số k từ neighbor gần nhất sử dụng độ tương tự cosine. Ví dụ, "Being late is terrible" trở thành "Being behind are bad". Đối với frame semantic embeddings, các tác giả phân tích ngữ nghĩa 3.8 triệu tweet và xây dựng một mô hình continuous bag-of-frame để biểu diễn mỗi frame ngữ nghĩa sử dụng Word2Vec. Cách tiếp cận tăng cường dữ liệu giống như các từ sau đó được áp dụng cho các frame ngữ nghĩa.

So với Wang et al., Liu et al. chỉ sử dụng word embeddings để truy xuất từ đồng nghĩa. Trong khi đó, họ chỉnh sửa kết quả truy xuất với một từ điển đồng nghĩa để cân bằng.

**Nhúng ngữ nghĩa**
Ưu điểm:
1. Dễ sử dụng.
2. Tỷ lệ thay thế cao hơn và phạm vi thay thế toàn diện hơn.

Hạn chế:
1. Phương pháp này không thể giải quyết vấn đề đa nghĩa.
2. Ngữ nghĩa câu có thể bị ảnh hưởng nếu có quá nhiều thay thế.

#### 2.1.3. Mô hình ngôn ngữ

Các mô hình ngôn ngữ được huấn luyện trước đã trở thành các mô hình chính trong những năm gần đây do hiệu suất xuất sắc của chúng. Các mô hình ngôn ngữ bị che (MLM) như BERT và RoBERTa có thể dự đoán các từ bị che trong văn bản dựa trên ngữ cảnh, có thể được sử dụng để tăng cường dữ liệu văn bản. Hơn nữa, cách tiếp cận này giảm thiểu vấn đề đa nghĩa vì MLM xem xét toàn bộ ngữ cảnh.

Wu et al. tinh chỉnh BERT được huấn luyện trước để thực hiện tác vụ MLM có điều kiện. Họ thay đổi các segmentation embeddings thành label embeddings, được học tương ứng với các nhãn được chú thích trên các tập dữ liệu được gắn nhãn. Họ sử dụng BERT có điều kiện được tinh chỉnh này để tăng cường câu. Cụ thể, một vài từ trong câu được gắn nhãn được che ngẫu nhiên sau đó được điền bởi BERT có điều kiện.

Jiao et al. sử dụng cả word embeddings và masked language models để có được dữ liệu tăng cường. Họ áp dụng tokenizer của BERT để tokenize từ thành nhiều word pieces. Mỗi word piece được thay thế với xác suất 0.4. Nếu một word piece không phải là một từ hoàn chỉnh ("est" chẳng hạn), nó được thay thế bằng K từ neighbor gần nhất trong không gian embedding Glove. Nếu word piece là một từ hoàn chỉnh, các tác giả thay thế nó bằng [MASK] và sử dụng BERT để dự đoán K từ để điền vào chỗ trống.

**Mô hình ngôn ngữ**
Ưu điểm:
1. Cách tiếp cận này giảm thiểu vấn đề đa nghĩa.
2. Phương pháp này xem xét ngữ nghĩa ngữ cảnh.

Hạn chế:
1. Vẫn bị hạn chế ở cấp độ từ.
2. Ngữ nghĩa câu có thể bị ảnh hưởng nếu có quá nhiều thay thế.

#### 2.1.4. Quy tắc

Phương pháp này yêu cầu một số heuristic về ngôn ngữ tự nhiên để đảm bảo việc duy trì ngữ nghĩa câu.

Một mặt, một số công trình dựa vào các từ điển hiện có hoặc các heuristic cố định để tạo ra các cách diễn giải ở cấp độ từ và cụm từ. Coulombe et al. giới thiệu việc sử dụng biểu thức chính quy để chuyển đổi dạng mà không thay đổi ngữ nghĩa câu, chẳng hạn như các từ viết tắt và nguyên mẫu của động từ, động từ khuyết thiếu và phủ định. Ví dụ, thay thế "is not" bằng "isn't".

Mặt khác, một số công trình tạo ra các cách diễn giải ở cấp độ câu cho các câu gốc với một số quy tắc, ví dụ như cây phụ thuộc. Coulombe et al. sử dụng một parser cú pháp để xây dựng cây phụ thuộc cho câu gốc. Sau đó cây phụ thuộc được sử dụng cho biến đổi cú pháp. Ví dụ, thay thế "Sally embraced Peter excitedly." bằng "Peter was embraced excitedly by Sally.".

**Quy tắc**
Ưu điểm:
1. Dễ sử dụng.
2. Phương pháp này bảo toàn ngữ nghĩa câu gốc.

Hạn chế:
1. Phương pháp này yêu cầu các heuristic nhân tạo.
2. Độ bao phủ thấp và biến thể hạn chế.

#### 2.1.5. Dịch máy

Dịch thuật là một phương tiện tự nhiên của diễn giải. Với sự phát triển của các mô hình dịch máy và tính khả dụng của các API trực tuyến, dịch máy trở nên phổ biến như một phương pháp tăng cường trong nhiều tác vụ.

**Dịch ngược.** Phương pháp này có nghĩa là văn bản gốc được dịch sang các ngôn ngữ khác, và sau đó được dịch ngược lại để có được văn bản tăng cường trong ngôn ngữ gốc. Khác với các phương pháp cấp độ từ, dịch ngược không trực tiếp thay thế các từ riêng lẻ mà viết lại toàn bộ câu theo cách sinh.

Xie et al., Yu et al., và Fabbri et al. sử dụng các mô hình dịch Anh-Pháp (theo cả hai hướng) để thực hiện dịch ngược trên mỗi câu và có được các cách diễn giải của chúng. Lowell et al. cũng giới thiệu phương pháp này như một trong những phương pháp tăng cường dữ liệu không giám sát. Zhang et al. tận dụng dịch ngược để có được biểu hiện chính thức của dữ liệu gốc trong tác vụ chuyển đổi phong cách.

Ngoài một số mô hình dịch máy được huấn luyện, một số dịch vụ API đám mây như Google và DeepL là các công cụ phổ biến cho dịch ngược và được áp dụng bởi một số công trình.

Một số công trình thêm các tính năng bổ sung dựa trên dịch ngược vanilla. Nugent et al. đề xuất một loạt cài đặt nhiệt độ softmax để đảm bảo tính đa dạng trong khi bảo toàn ý nghĩa ngữ nghĩa. Qu et al. kết hợp dịch ngược với huấn luyện đối thủ, để tổng hợp các ví dụ tăng cường đa dạng và thông tin bằng cách tích hợp hữu cơ nhiều biến đổi. Zhang et al. sử dụng một discriminator để lọc các câu trong kết quả dịch ngược. Phương pháp này cải thiện đáng kể chất lượng dữ liệu tăng cường như một ngưỡng.

**Dịch một chiều.** Khác với dịch ngược, phương pháp dịch một chiều trực tiếp dịch văn bản gốc sang các ngôn ngữ khác một lần, mà không dịch ngược lại ngôn ngữ gốc. Phương pháp này thường xảy ra trong một tình huống đa ngôn ngữ.

Trong tác vụ word embeddings đa ngôn ngữ không giám sát (CLWEs), Nishikawa et al. xây dựng corpus giả song song với một mô hình dịch máy không giám sát. Các tác giả đầu tiên huấn luyện các mô hình dịch máy không giám sát (UMT) sử dụng corpus huấn luyện nguồn/đích và sau đó dịch corpus sử dụng các mô hình UMT. Corpus được dịch máy được sử dụng cùng với corpus gốc để học word embeddings đơn ngôn ngữ cho mỗi ngôn ngữ độc lập. Cuối cùng, các word embeddings đơn ngôn ngữ đã học được ánh xạ vào một không gian CLWE chia sẻ.

**Dịch máy**
Ưu điểm:
1. Dễ sử dụng.
2. Phạm vi ứng dụng rộng.
3. Cách tiếp cận này đảm bảo cú pháp chính xác và ngữ nghĩa không thay đổi.

Hạn chế:
1. Khả năng kiểm soát kém và tính đa dạng hạn chế vì các mô hình dịch máy cố định.

#### 2.1.6. Sinh mô hình

Một số phương pháp sử dụng các mô hình Seq2Seq để tạo ra các cách diễn giải trực tiếp. Các mô hình như vậy xuất ra các câu đa dạng hơn với các đối tượng huấn luyện thích hợp.

Hou et al. đề xuất một mô hình tăng cường dữ liệu Seq2Seq cho module hiểu ngôn ngữ của các hệ thống đối thoại dựa trên tác vụ. Họ đưa câu nói đầu vào đã được delexicalized và thứ hạng đa dạng được chỉ định k (ví dụ 1, 2, 3) vào mô hình Seq2Seq làm đầu vào để tạo ra một câu nói mới.

Trong tác vụ trích xuất aspect term, Li et al. áp dụng Transformer làm cấu trúc cơ bản. Các câu gốc bị che cũng như chuỗi nhãn của chúng được sử dụng để huấn luyện một mô hình M tái tạo fragment bị che làm dữ liệu tăng cường.

**Sinh mô hình**
Ưu điểm:
1. Phạm vi ứng dụng rộng.
2. Ứng dụng mạnh.

Hạn chế:
1. Yêu cầu dữ liệu huấn luyện.
2. Khó khăn huấn luyện cao.

### 2.2. Các Phương pháp dựa trên Làm nhiễu

Trọng tâm của diễn giải là làm cho ngữ nghĩa của dữ liệu tăng cường giống với dữ liệu gốc càng nhiều càng tốt. Ngược lại, các phương pháp dựa trên làm nhiễu thêm nhiễu yếu không ảnh hưởng nghiêm trọng đến ngữ nghĩa, để làm cho nó lệch khỏi dữ liệu gốc một cách phù hợp. Con người giảm đáng kể tác động của nhiễu yếu đến hiểu ngữ nghĩa thông qua việc nắm bắt các hiện tượng ngôn ngữ và kiến thức tiên nghiệm, nhưng nhiễu này có thể đặt ra thách thức cho các mô hình. Do đó, phương pháp này không chỉ mở rộng lượng dữ liệu huấn luyện mà còn cải thiện tính mạnh mẽ của mô hình.

#### 2.2.1. Hoán đổi

Ngữ nghĩa của ngôn ngữ tự nhiên nhạy cảm với thứ tự văn bản, trong khi thay đổi thứ tự nhẹ vẫn có thể đọc được đối với con người. Do đó, việc hoán đổi ngẫu nhiên giữa các từ thậm chí các câu trong phạm vi hợp lý có thể được sử dụng như một phương pháp tăng cường dữ liệu.

Wei et al. ngẫu nhiên chọn hai từ trong câu và hoán đổi vị trí của chúng. Quá trình này được lặp lại n lần, trong đó n tỷ lệ thuận với độ dài câu l. Longpre et al., Rastogi et al., và Zhang et al. cũng áp dụng phương pháp tương tự. Dai et al. chia chuỗi token thành các đoạn theo nhãn, sau đó ngẫu nhiên chọn một số đoạn để xáo trộn thứ tự của các token bên trong, với thứ tự nhãn không thay đổi.

Ngoài hoán đổi cấp độ từ, một số công trình cũng đề xuất hoán đổi cấp độ câu thậm chí cấp độ instance. Trong tác vụ phân tích cảm xúc tweet, Luque et al. chia tweet thành hai nửa. Họ ngẫu nhiên lấy mẫu và kết hợp nửa đầu với nửa sau có cùng nhãn. Mặc dù dữ liệu được tạo ra theo cách này có thể không đúng ngữ pháp và không hợp lý về ngữ nghĩa, nó vẫn mang ngữ nghĩa tương đối hoàn chỉnh và cực tính cảm xúc so với các từ riêng lẻ.

#### 2.2.2. Xóa

Phương pháp này có nghĩa là xóa ngẫu nhiên các từ trong câu hoặc xóa các câu trong tài liệu.

Đối với việc xóa cấp độ từ, Wei et al. ngẫu nhiên loại bỏ mỗi từ trong câu với xác suất p. Longpre et al., Rastogi et al., và Zhang et al. cũng áp dụng phương pháp tương tự. Trong tác vụ hiểu ngôn ngữ nói, Peng et al. tăng cường dialogue acts đầu vào bằng cách xóa giá trị slot để có được nhiều tổ hợp hơn.

Đối với việc xóa cấp độ câu, Yan et al. ngẫu nhiên xóa mỗi câu trong tài liệu pháp lý theo một xác suất nhất định. Họ làm điều này vì có nhiều câu không liên quan và việc xóa chúng sẽ không ảnh hưởng đến việc hiểu vụ án pháp lý.

#### 2.2.3. Chèn

Phương pháp này có nghĩa là chèn ngẫu nhiên các từ vào câu hoặc chèn các câu vào tài liệu.

Đối với việc chèn cấp độ từ, Wei et al. chọn một từ đồng nghĩa ngẫu nhiên của một từ ngẫu nhiên trong câu không phải là từ dừng, sau đó chèn từ đồng nghĩa đó vào vị trí ngẫu nhiên trong câu. Quá trình này được lặp lại n lần. Trong tác vụ hiểu ngôn ngữ nói, Peng et al. tăng cường dialogue acts đầu vào bằng cách chèn giá trị slot để có được nhiều tổ hợp hơn.

Trong phân loại tài liệu pháp lý, vì các tài liệu có cùng nhãn có thể có các câu tương tự, Yan et al. sử dụng chèn ngẫu nhiên cấp độ câu. Họ ngẫu nhiên chọn các câu từ các tài liệu pháp lý khác có cùng nhãn để có được dữ liệu tăng cường.

#### 2.2.4. Thay thế

Phương pháp này có nghĩa là thay thế ngẫu nhiên các từ hoặc câu bằng các chuỗi khác. Khác với các phương pháp diễn giải trên, phương pháp này thường tránh sử dụng các chuỗi có ngữ nghĩa tương tự với dữ liệu gốc.

Một số công trình thực hiện thay thế thông qua các tài nguyên bên ngoài hiện có. Coulombe et al. và Regina et al. giới thiệu danh sách các lỗi chính tả phổ biến nhất trong tiếng Anh để tạo ra các văn bản tăng cường chứa các lỗi chính tả phổ biến. Ví dụ, "across" dễ bị viết sai thành "accross". Xie et al. mượn từ ý tưởng "word-dropout" và cải thiện khả năng tổng quát hóa bằng cách giảm thông tin trong câu. Công trình này sử dụng "_" làm placeholder để thay thế các từ ngẫu nhiên, cho thấy rằng thông tin ở vị trí đó trống.

Một số công trình sử dụng các tài nguyên liên quan đến tác vụ hoặc tạo ra các chuỗi ngẫu nhiên để thay thế. Xie et al. và Xie et al. thay thế các từ gốc bằng các từ khác trong từ vựng, và họ sử dụng giá trị TF-IDF và tần suất unigram để chọn từ từ từ vựng, tương ứng.

**Làm nhiễu**
Ưu điểm:
1. Các phương pháp dựa trên làm nhiễu cải thiện tính mạnh mẽ của mô hình.

Nhược điểm:
1. Khả năng diễn giải kém.
2. Tính đa dạng hạn chế cho mỗi phương pháp riêng lẻ.

### 2.3. Các Phương pháp dựa trên Lấy mẫu

Các phương pháp dựa trên lấy mẫu nắm bắt phân bố dữ liệu và lấy mẫu dữ liệu mới trong đó. Tương tự như các mô hình dựa trên diễn giải, chúng cũng liên quan đến quy tắc và các mô hình được huấn luyện để tạo ra dữ liệu tăng cường. Sự khác biệt là các phương pháp dựa trên lấy mẫu là cụ thể cho tác vụ và yêu cầu thông tin tác vụ như nhãn và định dạng dữ liệu. Các phương pháp như vậy không chỉ đảm bảo tính hợp lệ mà còn tăng tính đa dạng. Chúng thỏa mãn nhiều nhu cầu hơn của các tác vụ downstream dựa trên các heuristic nhân tạo và các mô hình được huấn luyện, và có thể được thiết kế theo các yêu cầu tác vụ cụ thể. Do đó, chúng thường linh hoạt hơn và khó hơn so với hai danh mục trước.

#### 2.3.1. Quy tắc

Phương pháp này sử dụng một số quy tắc để trực tiếp tạo ra dữ liệu tăng cường mới. Các heuristic về ngôn ngữ tự nhiên và các nhãn tương ứng đôi khi được yêu cầu để đảm bảo tính hợp lệ của dữ liệu tăng cường. Khác với phương pháp diễn giải dựa trên quy tắc trên, phương pháp này xây dựng dữ liệu hợp lệ nhưng không được đảm bảo tương tự với dữ liệu gốc (thậm chí là các nhãn khác).

Min et al. hoán đổi chủ ngữ và tân ngữ của câu gốc, và chuyển đổi động từ vị ngữ thành dạng bị động. Ví dụ, đảo ngược "This small collection contains 16 El Grecos." thành "16 El Grecos contain this small collection.". Các nhãn của mẫu mới được xác định bởi quy tắc.

#### 2.3.2. Mô hình không được huấn luyện trước

Một số phương pháp sử dụng các mô hình không được huấn luyện trước để tạo ra dữ liệu tăng cường. Các phương pháp như vậy thường bao gồm ý tưởng dịch ngược (BT), là huấn luyện một mô hình Seq2Seq từ đích đến nguồn và sử dụng mô hình để tạo ra các câu nguồn từ các câu đích, tức là xây dựng các câu giả song song.

Sennrich et al. huấn luyện một mô hình NMT Anh-Trung sử dụng corpus song song hiện có, và sử dụng corpus đơn ngôn ngữ tiếng Anh đích để tạo ra corpus tiếng Trung thông qua mô hình Anh-Trung trên.

#### 2.3.3. Mô hình được huấn luyện trước

Trong những năm gần đây, các mô hình ngôn ngữ quy mô lớn (LM) đã đạt được thành công lớn bằng cách thu nhận kiến thức ngôn ngữ phong phú thông qua huấn luyện trước. Do đó, chúng tự nhiên được sử dụng như công cụ tăng cường.

Tavor et al. đề xuất một phương pháp tăng cường dữ liệu có tên LAMBDA. Họ tạo ra các câu tăng cường có nhãn với GPT-2, được tinh chỉnh trên tập huấn luyện trước. Sau đó các câu tăng cường được lọc bởi một classifier để đảm bảo chất lượng dữ liệu.

#### 2.3.4. Tự huấn luyện

Trong một số tình huống, dữ liệu thô không được gắn nhãn dễ dàng có được. Do đó, việc chuyển đổi dữ liệu như vậy thành dữ liệu hợp lệ sẽ tăng đáng kể lượng dữ liệu.

Thakur et al. đầu tiên tinh chỉnh BERT trên dữ liệu gốc, sau đó sử dụng BERT đã được tinh chỉnh để gắn nhãn các cặp câu không được gắn nhãn. Dữ liệu tăng cường như vậy, cũng như dữ liệu vàng, được sử dụng để huấn luyện SBERT cùng nhau.

#### 2.3.5. Mixup

Phương pháp này sử dụng các embeddings ảo thay vì văn bản dạng ngôn ngữ tự nhiên được tạo ra làm mẫu tăng cường. Dữ liệu hiện có được sử dụng làm cơ sở để lấy mẫu trong không gian vector ảo, và dữ liệu được lấy mẫu có thể có nhãn khác với dữ liệu gốc.

Ý tưởng Mixup đầu tiên xuất hiện trong lĩnh vực hình ảnh bởi Zhang et al. Được truyền cảm hứng từ công trình này, Guo et al. đề xuất hai biến thể của Mixup cho phân loại câu. Biến thể đầu tiên được gọi là wordMixup thực hiện nội suy mẫu trong không gian word embedding, và biến thể thứ hai được gọi là senMixup nội suy các trạng thái ẩn của các encoder câu.

**Mixup**
Ưu điểm:
1. Tạo ra dữ liệu tăng cường giữa các nhãn khác nhau.

Nhược điểm:
1. Khả năng diễn giải kém.

## 3. Chiến lược và Thủ thuật

Ba loại phương pháp DA bao gồm diễn giải, làm nhiễu và lấy mẫu, cũng như đặc điểm của chúng, đã được giới thiệu ở trên. Trong các ứng dụng thực tế, hiệu quả của phương pháp DA bị ảnh hưởng bởi nhiều yếu tố. Trong chương này, chúng tôi trình bày các yếu tố này để truyền cảm hứng cho độc giả sử dụng một số chiến lược và thủ thuật để chọn và xây dựng các phương pháp DA phù hợp.

### 3.1. Xếp chồng Phương pháp

Các phương pháp trong Phần 2 không bắt buộc phải được áp dụng đơn lẻ. Chúng có thể được kết hợp để có hiệu suất tốt hơn. Các kết hợp phổ biến bao gồm:

**Cùng loại Phương pháp.** Một số công trình kết hợp các phương pháp dựa trên diễn giải khác nhau và có được các cách diễn giải khác nhau, để tăng sự phong phú của dữ liệu tăng cường. Ví dụ, Liu et al. sử dụng cả từ điển đồng nghĩa và semantic embeddings, và Jiao et al. sử dụng cả semantic embeddings và MLMs.

**Phương pháp Không giám sát.** Trong một số tình huống, các phương pháp DA không giám sát đơn giản và không phụ thuộc vào tác vụ có thể đáp ứng nhu cầu. Tự nhiên, chúng được nhóm lại với nhau và được sử dụng rộng rãi. Wei et al. giới thiệu một bộ công cụ DA có tên EDA bao gồm thay thế từ đồng nghĩa, chèn ngẫu nhiên, hoán đổi ngẫu nhiên và xóa ngẫu nhiên. EDA rất phổ biến và được sử dụng cho nhiều tác vụ.

### 3.2. Tối ưu hóa

Quá trình tối ưu hóa của các phương pháp DA ảnh hưởng trực tiếp đến chất lượng dữ liệu tăng cường. Chúng tôi giới thiệu nó thông qua bốn góc độ: việc sử dụng dữ liệu tăng cường, siêu tham số, chiến lược huấn luyện và đối tượng huấn luyện.

#### 3.2.1. Việc sử dụng Dữ liệu tăng cường

Cách sử dụng dữ liệu tăng cường ảnh hưởng trực tiếp đến hiệu quả cuối cùng. Từ quan điểm chất lượng dữ liệu, dữ liệu tăng cường có thể được sử dụng để huấn luyện trước một mô hình nếu nó không có chất lượng cao; ngược lại, nó có thể được sử dụng để huấn luyện một mô hình trực tiếp.

#### 3.2.2. Siêu tham số

Tất cả các phương pháp trên đều liên quan đến các siêu tham số ảnh hưởng lớn đến hiệu quả tăng cường. Chúng tôi liệt kê một số siêu tham số phổ biến:

- Số lượng thay thế/hoạt động
- Xác suất thay thế/hoạt động
- Loại và số lượng ngôn ngữ trung gian
- Tham số trong mạng neural

#### 3.2.3. Chiến lược Huấn luyện

Một số công trình áp dụng các chiến lược huấn luyện dựa trên các phương pháp tăng cường dữ liệu cơ bản. Ví dụ, Qu et al. kết hợp dịch ngược với huấn luyện đối thủ. Tương tự, Quteineh et al. chuyển đổi mô hình được huấn luyện trước cơ bản thành một bài toán tối ưu hóa để tối đa hóa tính hữu ích của đầu ra được tạo ra.

#### 3.2.4. Đối tượng Huấn luyện

Các đối tượng huấn luyện rất cần thiết cho việc huấn luyện mô hình, đặc biệt là đối với các phương pháp DA có thể học được. Nugent et al. đề xuất một loạt cài đặt nhiệt độ softmax để đảm bảo tính đa dạng trong khi bảo toàn ý nghĩa ngữ nghĩa.

### 3.3. Lọc

Đôi khi quá trình tăng cường dữ liệu không tránh khỏi việc đưa ra một số nhiễu thậm chí lỗi, do đó các cơ chế lọc được giới thiệu để tránh vấn đề này. Một số công trình lọc dữ liệu đầu vào ở giai đoạn ban đầu để tránh đầu vào không phù hợp ảnh hưởng đến hiệu quả tăng cường. Một ví dụ điển hình là độ dài câu, tức là lọc các câu quá ngắn.

## 4. Ứng dụng trong các Tác vụ NLP

Mặc dù đã xuất hiện nhiều phương pháp tăng cường dữ liệu trong lĩnh vực NLP trong những năm gần đây, nhưng rất khó để so sánh trực tiếp hiệu suất của chúng. Điều này là do các tác vụ, metric đánh giá, tập dữ liệu, kiến trúc mô hình và cài đặt thực nghiệm khác nhau khiến việc so sánh trực tiếp trở nên vô nghĩa. Do đó, dựa trên công trình được giới thiệu ở trên, chúng tôi phân tích các phương pháp tăng cường dữ liệu từ quan điểm của các tác vụ NLP khác nhau bao gồm phân loại văn bản, tạo sinh văn bản và dự đoán có cấu trúc.

• **Phân loại văn bản** là bài toán xử lý ngôn ngữ tự nhiên đơn giản và cơ bản nhất. Tức là, đối với một đầu vào văn bản, xuất ra danh mục mà văn bản thuộc về, trong đó danh mục là một tập hợp đóng được xác định trước.

• **Tạo sinh văn bản**, như tên gọi, là tạo ra văn bản tương ứng với dữ liệu đầu vào. Ví dụ cổ điển nhất là dịch máy.

• **Vấn đề dự đoán có cấu trúc** thường là duy nhất đối với NLP. Khác với phân loại văn bản, có sự tương quan mạnh và các yêu cầu định dạng giữa các danh mục đầu ra trong vấn đề dự đoán có cấu trúc.

Trong phần này, chúng tôi cố gắng phân tích các tính năng cũng như tình trạng phát triển của DA trong các tác vụ này.

Các phương pháp DA được áp dụng rộng rãi hơn trong phân loại văn bản so với các tác vụ NLP khác nói chung và trong từng danh mục. Hơn nữa, mỗi phương pháp DA riêng lẻ đều có thể được áp dụng cho phân loại văn bản. Ưu thế ứng dụng như vậy là do dạng đơn giản của phân loại văn bản: với văn bản đầu vào, nó trực tiếp điều tra sự hiểu biết của mô hình về ngữ nghĩa bằng dự đoán nhãn. Do đó, việc tăng cường dữ liệu chỉ cần xem xét việc giữ lại ngữ nghĩa của các từ quan trọng cho phân loại là tương đối đơn giản.

Đối với tạo sinh văn bản, nó ưa thích các phương pháp dựa trên lấy mẫu để mang lại nhiều tính đa dạng ngữ nghĩa hơn. Và dự đoán có cấu trúc ưa thích các phương pháp dựa trên diễn giải vì nó nhạy cảm với định dạng dữ liệu. Do đó, nó có yêu cầu cao hơn về tính hợp lệ của dữ liệu.

Bằng cách so sánh từng phương pháp DA, chúng ta có thể thấy rằng các phương pháp không giám sát đơn giản và hiệu quả, bao gồm dịch máy, diễn giải dựa trên từ điển đồng nghĩa và thay thế ngẫu nhiên, khá phổ biến. Ngoài ra, các phương pháp có thể học được như tạo sinh mô hình dựa trên diễn giải và các mô hình được huấn luyện trước dựa trên lấy mẫu, cũng nhận được nhiều sự chú ý vì tính đa dạng và hiệu quả của chúng.

## 5. Các Chủ đề Liên quan

Tăng cường dữ liệu liên quan như thế nào đến các phương pháp học tập khác? Trong phần này, chúng tôi kết nối tăng cường dữ liệu với các chủ đề tương tự khác.

### 5.1. Mô hình Ngôn ngữ được Huấn luyện trước

Việc huấn luyện hầu hết các mô hình ngôn ngữ được huấn luyện trước (PLM) dựa trên học tự giám sát. Học tự giám sát chủ yếu sử dụng các tác vụ phụ trợ để khai thác thông tin giám sát của nó từ dữ liệu không giám sát quy mô lớn, và huấn luyện mạng thông qua thông tin giám sát được xây dựng này, để nó có thể học các biểu diễn có giá trị cho các tác vụ downstream. Từ quan điểm này, PLM cũng đưa thêm dữ liệu huấn luyện vào các tác vụ downstream, theo cách ngầm.

### 5.2. Học Đối chiếu

Học đối chiếu là học một không gian embedding trong đó các mẫu tương tự gần nhau trong khi các mẫu khác biệt ở xa nhau. Nó tập trung vào việc học các đặc trưng chung giữa các mẫu tương tự và phân biệt sự khác biệt giữa các mẫu khác biệt. Bước đầu tiên của học đối chiếu là áp dụng tăng cường dữ liệu để xây dựng các mẫu tương tự với cùng nhãn, và bước thứ hai là ngẫu nhiên chọn các instance làm mẫu âm. Do đó, học đối chiếu là một trong những ứng dụng của tăng cường dữ liệu.

### 5.3. Các Phương pháp Thao tác Dữ liệu khác

Ngoài DA, có một số phương pháp thao tác dữ liệu khác để cải thiện khả năng tổng quát hóa mô hình. Oversampling thường được sử dụng trong các tình huống mất cân bằng dữ liệu. Nó đơn giản là lấy mẫu dữ liệu gốc từ nhóm thiểu số làm mẫu mới, thay vì tạo ra dữ liệu tăng cường. Data cleaning được áp dụng bổ sung cho dữ liệu gốc để cải thiện chất lượng dữ liệu và giảm nhiễu dữ liệu.

### 5.4. Mạng Đối thủ Sinh

Mạng Đối thủ Sinh (GAN) được giới thiệu lần đầu bởi Goodfellow et al. Là một loại phương pháp bán giám sát, GAN bao gồm mô hình sinh, chủ yếu được sử dụng để thách thức discriminator của GAN, trong khi các mô hình sinh trong một số phương pháp DA được sử dụng trực tiếp để tăng cường dữ liệu huấn luyện.

### 5.5. Tấn công Đối thủ

Tấn công đối thủ là các kỹ thuật để tạo ra các ví dụ đối thủ tấn công một mô hình học máy, tức là khiến mô hình phạm sai lầm. Một số công trình sử dụng các phương pháp DA như thay thế code-switch để tạo ra các ví dụ đối thủ như regularization nhất quán.

## 6. Thách thức và Cơ hội

Tăng cường dữ liệu đã có một tiến trình lớn trong vài năm qua, và nó đã cung cấp một đóng góp lớn cho việc huấn luyện mô hình quy mô lớn cũng như sự phát triển của các tác vụ downstream. Mặc dù có tiến trình, vẫn còn những thách thức cần được giải quyết. Trong phần này, chúng tôi thảo luận về một số thách thức này và các hướng tương lai có thể giúp thúc đẩy lĩnh vực này.

**Tường thuật Lý thuyết.** Ở giai đoạn này, dường như thiếu công trình thăm dò có hệ thống và phân tích lý thuyết về các phương pháp DA trong NLP. Những công trình liên quan ít ỏi là của DA trong lĩnh vực hình ảnh, coi tăng cường dữ liệu như mã hóa kiến thức tiên nghiệm về dữ liệu hoặc tính bất biến tác vụ, giảm phương sai hoặc các phương pháp regularization. Trong NLP, hầu hết các công trình trước đây đề xuất các phương pháp mới hoặc chứng minh hiệu quả của phương pháp DA trên các tác vụ downstream, nhưng không khám phá lý do và quy luật đằng sau nó.

**Khám phá thêm về Mô hình Ngôn ngữ được Huấn luyện trước.** Trong những năm gần đây, các mô hình ngôn ngữ được huấn luyện trước đã được áp dụng rộng rãi trong NLP, chứa kiến thức phong phú thông qua tự giám sát trên quy mô lớn corpus. Có các công trình sử dụng các mô hình ngôn ngữ được huấn luyện trước cho DA, nhưng hầu hết chúng bị hạn chế trong việc hoàn thành [MASK], tạo sinh trực tiếp sau khi tinh chỉnh, hoặc tự huấn luyện. DA có còn hữu ích trong kỷ nguyên của các mô hình ngôn ngữ được huấn luyện trước không?

**Tình huống Few-shot.** Trong các tình huống few-shot, các mô hình được yêu cầu đạt được hiệu suất cạnh tranh với các mô hình học máy truyền thống, tuy nhiên lượng dữ liệu huấn luyện cực kỳ hạn chế. Các phương pháp DA cung cấp giải pháp trực tiếp cho vấn đề. Tuy nhiên, hầu hết các công trình hiện tại trong các tình huống few-shot là các phương pháp dựa trên diễn giải.

**Tăng cường Truy xuất.** Các mô hình ngôn ngữ tăng cường truy xuất tích hợp truy xuất vào huấn luyện trước và sử dụng downstream. Tăng cường truy xuất làm cho các mô hình hiệu quả hơn nhiều về tham số, vì chúng cần lưu trữ ít kiến thức hơn trong tham số của chúng và thay vào đó có thể truy xuất nó.

**Các Phương pháp Tổng quát hóa hơn cho NLP.** Ngôn ngữ tự nhiên khác biệt nhất so với hình ảnh hoặc âm thanh ở chỗ biểu diễn của nó là rời rạc. Đồng thời, NLP bao gồm các tác vụ cụ thể như dự đoán có cấu trúc không có sẵn trong các phương thức khác. Do đó, không giống như các phương pháp chung như cắt cho tăng cường hình ảnh hoặc nhiễu loạn tốc độ cho tăng cường âm thanh, hiện tại không có phương pháp DA nào có thể hiệu quả cho tất cả các tác vụ NLP.

**Làm việc với Văn bản dài và Ngôn ngữ Tài nguyên thấp.** Các phương pháp hiện có đã đạt được tiến bộ đáng kể trong văn bản ngắn và các ngôn ngữ phổ biến. Tuy nhiên, bị hạn chế bởi khả năng mô hình, các phương pháp DA trên văn bản dài vẫn đấu tranh với các phương pháp đơn giản nhất của diễn giải và làm nhiễu. Đồng thời, bị hạn chế bởi tài nguyên dữ liệu, các phương pháp tăng cường của ngôn ngữ tài nguyên thấp là khan hiếm, mặc dù chúng có nhu cầu tăng cường dữ liệu nhiều hơn.

## 7. Kết luận

Trong bài báo này, chúng tôi đã trình bày một khảo sát toàn diện và có cấu trúc về tăng cường dữ liệu cho xử lý ngôn ngữ tự nhiên. Để kiểm tra bản chất của DA, chúng tôi đã chia các phương pháp DA thành ba danh mục theo tính đa dạng của dữ liệu tăng cường, bao gồm diễn giải, làm nhiễu và lấy mẫu. Các danh mục như vậy giúp hiểu và phát triển các phương pháp DA. Chúng tôi cũng đã giới thiệu các đặc điểm của các phương pháp DA và ứng dụng của chúng trong các tác vụ NLP, sau đó phân tích chúng thông qua dòng thời gian. Ngoài ra, chúng tôi đã giới thiệu một số thủ thuật và chiến lược để các nhà nghiên cứu và thực hành có thể tham khảo để có được hiệu suất mô hình tốt hơn. Cuối cùng, chúng tôi phân biệt DA với một số chủ đề liên quan và nêu ra những thách thức hiện tại cũng như cơ hội cho nghiên cứu tương lai.

Based on the PDF content provided, I'll translate this academic paper to Vietnamese while maintaining the exact structure:

# 2303.07624.pdf
# Chuyá»ƒn Ä‘á»•i tá»« PDF sang TXT
# ÄÆ°á»ng dáº«n nguá»“n: /home/admin88/arxiv-downloader/llm-architecture/2303.07624.pdf
# KÃ­ch thÆ°á»›c tá»‡p: 383130 bytes

===============================================
Ná»˜I DUNG Tá»†P PDF
===============================================

--- TRANG 1 ---
I3D: KIáº¾N TRÃšC TRANSFORMER Vá»šI Äá»˜ SÃ‚U Äá»˜NG PHá»¤ THUá»˜C Äáº¦U VÃ€O
CHO NHáº¬N Dáº NG GIá»ŒNG NÃ“I

Yifan Peng1, Jaesong Lee2, Shinji Watanabe1
1Äáº¡i há»c Carnegie Mellon 2NA VER Corporation

TÃ“M Táº®T
Nháº­n dáº¡ng giá»ng nÃ³i Ä‘áº§u cuá»‘i Ä‘áº¿n cuá»‘i dá»±a trÃªn Transformer Ä‘Ã£ Ä‘áº¡t Ä‘Æ°á»£c thÃ nh cÃ´ng lá»›n. Tuy nhiÃªn, chi phÃ­ lÆ°u trá»¯ lá»›n vÃ  táº£i tÃ­nh toÃ¡n lÃ m cho viá»‡c triá»ƒn khai cÃ¡c mÃ´ hÃ¬nh nÃ y trong má»™t sá»‘ á»©ng dá»¥ng thá»±c táº¿ trá»Ÿ nÃªn khÃ³ khÄƒn. CÃ¡c ká»¹ thuáº­t nÃ©n mÃ´ hÃ¬nh cÃ³ thá»ƒ giáº£m kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh vÃ  tÄƒng tá»‘c suy luáº­n, nhÆ°ng mÃ´ hÃ¬nh nÃ©n cÃ³ kiáº¿n trÃºc cá»‘ Ä‘á»‹nh cÃ³ thá»ƒ khÃ´ng tá»‘i Æ°u. ChÃºng tÃ´i Ä‘á» xuáº¥t má»™t bá»™ mÃ£ hÃ³a Transformer má»›i vá»›i Äá»™ sÃ¢u Äá»™ng phá»¥ thuá»™c Äáº§u vÃ o (I3D) Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c sá»± cÃ¢n báº±ng hiá»‡u suáº¥t-hiá»‡u quáº£ máº¡nh máº½. Vá»›i sá»‘ lÆ°á»£ng lá»›p tÆ°Æ¡ng tá»± táº¡i thá»i Ä‘iá»ƒm suy luáº­n, cÃ¡c mÃ´ hÃ¬nh dá»±a trÃªn I3D vÆ°á»£t trá»™i hÆ¡n Transformer gá»‘c vÃ  mÃ´ hÃ¬nh cáº¯t tá»‰a tÄ©nh thÃ´ng qua cáº¯t tá»‰a lá»›p láº·p. ChÃºng tÃ´i cÅ©ng trÃ¬nh bÃ y phÃ¢n tÃ­ch thÃº vá»‹ vá» xÃ¡c suáº¥t cá»•ng vÃ  sá»± phá»¥ thuá»™c Ä‘áº§u vÃ o, giÃºp chÃºng ta hiá»ƒu rÃµ hÆ¡n vá» cÃ¡c bá»™ mÃ£ hÃ³a sÃ¢u.

Tá»« khÃ³a chá»‰ má»¥c â€” Äá»™ sÃ¢u Ä‘á»™ng, transformer, nháº­n dáº¡ng giá»ng nÃ³i

1. GIá»šI THIá»†U
Gáº§n Ä‘Ã¢y, nháº­n dáº¡ng giá»ng nÃ³i tá»± Ä‘á»™ng Ä‘áº§u cuá»‘i Ä‘áº¿n cuá»‘i (ASR) Ä‘Ã£ trá»Ÿ nÃªn phá»• biáº¿n. CÃ¡c framework tiÃªu biá»ƒu bao gá»“m PhÃ¢n loáº¡i Thá»i gian Káº¿t ná»‘i (CTC) [1], Bá»™ mÃ£ hÃ³a-Giáº£i mÃ£ dá»±a trÃªn ChÃº Ã½ (AED) [2â€“4], vÃ  Bá»™ chuyá»ƒn Ä‘á»•i Máº¡ng nÆ¡-ron Há»“i quy (RNN-T) [5]. Nhiá»u loáº¡i máº¡ng cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng lÃ m bá»™ mÃ£ hÃ³a trong cÃ¡c framework nÃ y, nhÆ° Máº¡ng nÆ¡-ron TÃ­ch cháº­p (CNNs), RNNs, Transformers [6] vÃ  sá»± káº¿t há»£p cá»§a chÃºng [7â€“9]. Transformers Ä‘Ã£ Ä‘áº¡t Ä‘Æ°á»£c thÃ nh cÃ´ng lá»›n trong cÃ¡c benchmark khÃ¡c nhau [10]. Tuy nhiÃªn, chÃºng thÆ°á»ng chá»©a nhiá»u khá»‘i ná»‘i tiáº¿p vÃ  do Ä‘Ã³ cÃ³ tÃ­nh toÃ¡n cao, Ä‘iá»u nÃ y cáº£n trá»Ÿ viá»‡c triá»ƒn khai trong má»™t sá»‘ á»©ng dá»¥ng thá»±c táº¿ vá»›i tÃ i nguyÃªn háº¡n cháº¿. Äá»ƒ giáº£m tÃ­nh toÃ¡n vÃ  tÄƒng tá»‘c suy luáº­n, cÃ¡c nhÃ  nghiÃªn cá»©u Ä‘Ã£ Ä‘iá»u tra cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c nhau.

Má»™t phÆ°Æ¡ng phÃ¡p phá»• biáº¿n lÃ  nÃ©n má»™t mÃ´ hÃ¬nh lá»›n Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c báº±ng cÃ¡ch sá»­ dá»¥ng chÆ°ng cáº¥t [11â€“13], cáº¯t tá»‰a [14â€“16], vÃ  lÆ°á»£ng tá»­ hÃ³a [15]. Tuy nhiÃªn, mÃ´ hÃ¬nh nÃ©n cÃ³ kiáº¿n trÃºc cá»‘ Ä‘á»‹nh cho táº¥t cáº£ cÃ¡c loáº¡i Ä‘áº§u vÃ o, cÃ³ thá»ƒ khÃ´ng tá»‘i Æ°u. VÃ­ dá»¥, mÃ´ hÃ¬nh cá»‘ Ä‘á»‹nh nÃ y cÃ³ thá»ƒ quÃ¡ tá»‘n kÃ©m cho cÃ¡c phÃ¡t ngÃ´n ráº¥t dá»… nhÆ°ng khÃ´ng Ä‘á»§ cho nhá»¯ng phÃ¡t ngÃ´n khÃ³. Äá»ƒ cÃ¢n báº±ng tá»‘t hÆ¡n hiá»‡u suáº¥t vÃ  tÃ­nh toÃ¡n, cÃ¡c nghiÃªn cá»©u trÆ°á»›c Ä‘Ã¢y Ä‘Ã£ khÃ¡m phÃ¡ cÃ¡c mÃ´ hÃ¬nh Ä‘á»™ng [17], cÃ³ thá»ƒ thÃ­ch á»©ng kiáº¿n trÃºc cá»§a chÃºng vá»›i cÃ¡c Ä‘áº§u vÃ o khÃ¡c nhau. CÃ¡c mÃ´ hÃ¬nh Ä‘á»™ng Ä‘Ã£ Ä‘Æ°á»£c chá»©ng minh lÃ  hiá»‡u quáº£ trong thá»‹ giÃ¡c mÃ¡y tÃ­nh [18â€“23], chá»§ yáº¿u dá»±a trÃªn CNNs. Äá»‘i vá»›i xá»­ lÃ½ giá»ng nÃ³i, [24] huáº¥n luyá»‡n hai bá»™ mÃ£ hÃ³a RNN cÃ³ kÃ­ch thÆ°á»›c khÃ¡c nhau vÃ  chuyá»ƒn Ä‘á»•i Ä‘á»™ng giá»¯a chÃºng Ä‘Æ°á»£c hÆ°á»›ng dáº«n bá»Ÿi phÃ¡t hiá»‡n tá»« khÃ³a. [25] Ä‘á» xuáº¥t má»™t bá»™ chuyá»ƒn Ä‘á»•i mÃ£ hÃ³a Ä‘á»™ng dá»±a trÃªn dropout lá»›p vÃ  há»c táº­p há»£p tÃ¡c. [26] Ã¡p dá»¥ng hai bá»™ mÃ£ hÃ³a RNN Ä‘á»ƒ xá»­ lÃ½ giá»ng nÃ³i gáº§n vÃ  xa. [27] cÅ©ng thiáº¿t káº¿ hai bá»™ mÃ£ hÃ³a RNN Ä‘Æ°á»£c nÃ©n á»Ÿ cÃ¡c má»©c Ä‘á»™ khÃ¡c nhau vÃ  chuyá»ƒn Ä‘á»•i giá»¯a chÃºng trÃªn cÆ¡ sá»Ÿ tá»«ng khung hÃ¬nh. [28] má»Ÿ rá»™ng Ã½ tÆ°á»Ÿng nÃ y cho Transformer-transducers vÃ  xem xÃ©t cÃ¡c máº¡ng con linh hoáº¡t hÆ¡n, nhÆ°ng nÃ³ váº«n táº­p trung vÃ o ASR streaming vÃ  kiáº¿n trÃºc váº«n Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh trÃªn cÆ¡ sá»Ÿ tá»«ng khung hÃ¬nh, Ä‘Ã²i há»i thiáº¿t káº¿ Ä‘áº·c biá»‡t cho cÃ¡c hoáº¡t Ä‘á»™ng key vÃ  query chi tiáº¿t trong self-attention. Äá»‘i vá»›i ASR khÃ´ng streaming (hoáº·c streaming dá»±a trÃªn chunk), dá»± Ä‘oÃ¡n cáº¥p khung hÃ¬nh cÃ³ thá»ƒ tá»‘n kÃ©m vÃ  khÃ´ng tá»‘i Æ°u, vÃ¬ nÃ³ chá»‰ náº¯m báº¯t cÃ¡c Ä‘áº·c trÆ°ng cá»¥c bá»™ cáº¥p khung hÃ¬nh.

ChÃºng tÃ´i Ä‘á» xuáº¥t má»™t bá»™ mÃ£ hÃ³a Transformer vá»›i Äá»™ sÃ¢u Äá»™ng phá»¥ thuá»™c Äáº§u vÃ o (I3D) cho ASR Ä‘áº§u cuá»‘i Ä‘áº¿n cuá»‘i. Thay vÃ¬ sá»­ dá»¥ng cÃ¡c hoáº¡t Ä‘á»™ng chi tiáº¿t Ä‘Æ°á»£c thiáº¿t káº¿ cáº©n tháº­n trong cÃ¡c mÃ´-Ä‘un phá»¥ nhÆ° attention, I3D dá»± Ä‘oÃ¡n liá»‡u cÃ³ bá» qua toÃ n bá»™ khá»‘i self-attention hoáº·c toÃ n bá»™ máº¡ng feed-forward thÃ´ng qua má»™t loáº¡t cÃ¡c bá»™ dá»± Ä‘oÃ¡n cá»•ng cá»¥c bá»™ hoáº·c má»™t bá»™ dá»± Ä‘oÃ¡n cá»•ng toÃ n cá»¥c duy nháº¥t. Dá»± Ä‘oÃ¡n Ä‘Æ°á»£c thá»±c hiá»‡n á»Ÿ cáº¥p phÃ¡t ngÃ´n (hoáº·c cáº¥p chunk náº¿u má»Ÿ rá»™ng cho trÆ°á»ng há»£p streaming), dá»… thá»±c hiá»‡n hÆ¡n vÃ  giáº£m chi phÃ­ bá»• sung. NÃ³ cÅ©ng náº¯m báº¯t thá»‘ng kÃª toÃ n cá»¥c cá»§a Ä‘áº§u vÃ o. NhÆ° Ä‘Æ°á»£c phÃ¢n tÃ­ch trong Pháº§n 3.4, Ä‘á»™ dÃ i cá»§a má»™t phÃ¡t ngÃ´n áº£nh hÆ°á»Ÿng Ä‘áº¿n kiáº¿n trÃºc suy luáº­n. Má»™t sá»‘ khá»‘i cÃ³ thá»ƒ há»¯u Ã­ch cho cÃ¡c Ä‘áº§u vÃ o dÃ i hÆ¡n. Káº¿t quáº£ cho tháº¥y cÃ¡c mÃ´ hÃ¬nh I3D liÃªn tá»¥c vÆ°á»£t trá»™i hÆ¡n Transformers Ä‘Æ°á»£c huáº¥n luyá»‡n tá»« Ä‘áº§u vÃ  cÃ¡c mÃ´ hÃ¬nh cáº¯t tá»‰a tÄ©nh thÃ´ng qua cáº¯t tá»‰a lá»›p láº·p [29], khi sá»­ dá»¥ng sá»‘ lÆ°á»£ng lá»›p tÆ°Æ¡ng tá»± cho suy luáº­n. ChÃºng tÃ´i cÅ©ng thá»±c hiá»‡n phÃ¢n tÃ­ch thÃº vá»‹ vá» xÃ¡c suáº¥t cá»•ng dá»± Ä‘oÃ¡n vÃ  sá»± phá»¥ thuá»™c Ä‘áº§u vÃ o, giÃºp chÃºng ta hiá»ƒu rÃµ hÆ¡n hÃ nh vi cá»§a cÃ¡c bá»™ mÃ£ hÃ³a sÃ¢u.

2. PHÆ¯Æ NG PHÃP

2.1. Bá»™ mÃ£ hÃ³a Transformer

Má»™t lá»›p bá»™ mÃ£ hÃ³a Transformer [6] chá»©a má»™t mÃ´-Ä‘un self-attention Ä‘a Ä‘áº§u (MHA) vÃ  má»™t máº¡ng feed-forward (FFN), Ä‘Æ°á»£c káº¿t há»£p tuáº§n tá»±. HÃ m cá»§a lá»›p thá»© l nhÆ° sau:

Y(l)=X(lâˆ’1)+MHA(l)(X(lâˆ’1)); (1)
X(l)=Y(l)+FFN(l)(Y(l)); (2)

trong Ä‘Ã³ X(l) lÃ  Ä‘áº§u ra cá»§a lá»›p Transformer thá»© l vÃ  X(lâˆ’1) do Ä‘Ã³ lÃ  Ä‘áº§u vÃ o cá»§a lá»›p thá»© l. Y(l) lÃ  Ä‘áº§u ra cá»§a MHA táº¡i lá»›p thá»© l, cÅ©ng lÃ  Ä‘áº§u vÃ o cá»§a FFN táº¡i lá»›p thá»© l. CÃ¡c chuá»—i nÃ y Ä‘á»u cÃ³ Ä‘á»™ dÃ i T vÃ  kÃ­ch thÆ°á»›c Ä‘áº·c trÆ°ng d.

2.2. Kiáº¿n trÃºc tá»•ng thá»ƒ cá»§a cÃ¡c bá»™ mÃ£ hÃ³a I3D

HÃ¬nh 1a cho tháº¥y kiáº¿n trÃºc tá»•ng thá»ƒ cá»§a cÃ¡c bá»™ mÃ£ hÃ³a I3D. Má»™t dáº¡ng sÃ³ng Ä‘áº§u tiÃªn Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i thÃ nh má»™t chuá»—i Ä‘áº·c trÆ°ng bá»Ÿi má»™t frontend, vÃ  Ä‘Æ°á»£c xá»­ lÃ½ thÃªm vÃ  downsampling bá»Ÿi má»™t CNN, sau Ä‘Ã³ cÃ¡c embedding vá»‹ trÃ­ Ä‘Æ°á»£c thÃªm vÃ o. Sau Ä‘Ã³, chuá»—i Ä‘Æ°á»£c xá»­ lÃ½ bá»Ÿi má»™t stack gá»“m N lá»›p bá»™ mÃ£ hÃ³a I3D Ä‘á»ƒ táº¡o ra cÃ¡c Ä‘áº·c trÆ°ng cáº¥p cao. Thiáº¿t káº¿ tá»•ng thá»ƒ nÃ y tuÃ¢n theo cá»§a Transformer. Tuy nhiÃªn, Transformer luÃ´n sá»­ dá»¥ng kiáº¿n trÃºc cá»‘ Ä‘á»‹nh báº¥t ká»ƒ Ä‘áº§u vÃ o. I3D cá»§a chÃºng tÃ´i chá»n cÃ¡c káº¿t há»£p khÃ¡c nhau cá»§a MHA vÃ  FFN tÃ¹y thuá»™c vÃ o phÃ¡t ngÃ´n Ä‘áº§u vÃ o. Äá»ƒ xÃ¡c Ä‘á»‹nh liá»‡u má»™t mÃ´-Ä‘un cÃ³ nÃªn Ä‘Æ°á»£c thá»±c thi hay bá» qua, má»™t cá»•ng nhá»‹ phÃ¢n Ä‘Æ°á»£c giá»›i thiá»‡u cho má»—i mÃ´-Ä‘un MHA hoáº·c FFN. HÃ m

arXiv:2303.07624v1 [cs.CL] 14 Mar 2023

--- TRANG 2 ---

Frontend CNN Positional Embedding Audio Waveform I3D Encoder LayerÃ—ğ‘ Encoder Output Sequence Encoder Input Sequence (a) Kiáº¿n trÃºc bá»™ mÃ£ hÃ³a tá»•ng thá»ƒ.

Multi-Head Self-Attention Feed-Forward Network â€¦Mean Local Gate Predictor I3D Encoder Layer (b) Lá»›p bá»™ mÃ£ hÃ³a I3D vá»›i bá»™ dá»± Ä‘oÃ¡n cá»•ng cá»¥c bá»™.

Multi-Head Self-Attention Feed-Forward Network â€¦Mean Global Gate Predictor Layer 1 Layer ğ‘Ã—ğ‘â€¦ Encoder Input Sequence Encoder Output Sequence (c) Bá»™ mÃ£ hÃ³a I3D vá»›i bá»™ dá»± Ä‘oÃ¡n cá»•ng toÃ n cá»¥c.

HÃ¬nh 1: Kiáº¿n trÃºc cá»§a cÃ¡c bá»™ mÃ£ hÃ³a I3D Ä‘Æ°á»£c Ä‘á» xuáº¥t cá»§a chÃºng tÃ´i.

cá»§a lá»›p thá»© l (xem Eqs. (1) vÃ  (2) cho Transformer gá»‘c) bÃ¢y giá» trá»Ÿ thÃ nh:

Y(l)=X(lâˆ’1)+g(l)MHA MHA(l)(X(lâˆ’1)); (3)
X(l)=Y(l)+g(l)FFN FFN(l)(Y(l)); (4)

trong Ä‘Ã³ g(l)MHA; g(l)FFN âˆˆ {0;1} lÃ  cÃ¡c cá»•ng phá»¥ thuá»™c Ä‘áº§u vÃ o. Náº¿u má»™t cá»•ng Ä‘Æ°á»£c dá»± Ä‘oÃ¡n lÃ  0, thÃ¬ mÃ´-Ä‘un tÆ°Æ¡ng á»©ng sáº½ bá»‹ bá» qua, Ä‘iá»u nÃ y cÃ³ hiá»‡u quáº£ giáº£m tÃ­nh toÃ¡n. Tá»•ng loss huáº¥n luyá»‡n lÃ :

Ltotal=LASR+Î»Lutility; (5)
Lutility=1/2N âˆ‘N l=1 (g(l)MHA+g(l)FFN); (6)

trong Ä‘Ã³ LASR lÃ  loss ASR tiÃªu chuáº©n vÃ  Lutility lÃ  loss regularization Ä‘o tá»· lá»‡ sá»­ dá»¥ng cá»§a táº¥t cáº£ cÃ¡c mÃ´-Ä‘un MHA vÃ  FFN. Î» > 0 lÃ  má»™t siÃªu tham sá»‘ Ä‘á»ƒ cÃ¢n báº±ng Ä‘á»™ chÃ­nh xÃ¡c nháº­n dáº¡ng vÃ  chi phÃ­ tÃ­nh toÃ¡n.Â¹ LÆ°u Ã½ ráº±ng loss utility trong Eq. (6) Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a cho má»™t phÃ¡t ngÃ´n cÃ¡ nhÃ¢n nÃªn chá»‰ sá»‘ phÃ¡t ngÃ´n bá»‹ bá» qua. Trong thá»±c táº¿, má»™t mini-batch Ä‘Æ°á»£c sá»­ dá»¥ng vÃ  loss Ä‘Æ°á»£c trung bÃ¬nh hÃ³a trÃªn cÃ¡c phÃ¡t ngÃ´n.

Má»™t váº¥n Ä‘á» chÃ­nh vá»›i má»¥c tiÃªu huáº¥n luyá»‡n nÃ y lÃ  cÃ¡c cá»•ng nhá»‹ phÃ¢n khÃ´ng kháº£ vi. Äá»ƒ giáº£i quyáº¿t váº¥n Ä‘á» nÃ y, chÃºng tÃ´i Ã¡p dá»¥ng máº¹o Gumbel-Softmax [30, 31], cho phÃ©p rÃºt máº«u cá»©ng (hoáº·c má»m) tá»« má»™t phÃ¢n phá»‘i rá»i ráº¡c. Xem xÃ©t má»™t biáº¿n ngáº«u nhiÃªn rá»i ráº¡c Z vá»›i xÃ¡c suáº¥t P(Z=k) âˆ Ï€k cho báº¥t ká»³ k = 1,...,K nÃ o. Äá»ƒ rÃºt má»™t máº«u tá»« phÃ¢n phá»‘i nÃ y, chÃºng ta cÃ³ thá»ƒ Ä‘áº§u tiÃªn rÃºt K máº«u i.i.d. {gk}Kk=1 tá»« phÃ¢n phá»‘i Gumbel tiÃªu chuáº©n vÃ  sau Ä‘Ã³ chá»n chá»‰ sá»‘ cÃ³ xÃ¡c suáº¥t log nhiá»…u loáº¡n lá»›n nháº¥t:

z = arg max kâˆˆ{1,...,K} log Ï€k + gk; (7)

Argmax khÃ´ng kháº£ vi, cÃ³ thá»ƒ Ä‘Æ°á»£c thÆ° giÃ£n thÃ nh softmax. ÄÃ£ biáº¿t ráº±ng báº¥t ká»³ máº«u nÃ o tá»« phÃ¢n phá»‘i rá»i ráº¡c cÃ³ thá»ƒ Ä‘Æ°á»£c kÃ½ hiá»‡u lÃ  má»™t vector one-hot, trong Ä‘Ã³ chá»‰ sá»‘ cá»§a entry khÃ¡c khÃ´ng duy nháº¥t lÃ  máº«u mong muá»‘n. Vá»›i kÃ½ hiá»‡u dá»±a trÃªn vector nÃ y, chÃºng ta cÃ³ thá»ƒ rÃºt má»™t máº«u má»m nhÆ° sau:

z = softmax((log Ï€ + g)/Ï„); (8)

trong Ä‘Ã³ Ï€ = (Ï€1,...,Ï€K), g = (g1,...,gK), vÃ  Ï„ lÃ  má»™t háº±ng sá»‘ nhiá»‡t Ä‘á»™. Eq. (8) lÃ  má»™t xáº¥p xá»‰ cá»§a quÃ¡ trÃ¬nh sampling

Â¹ PhÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i cÃ³ thá»ƒ Ä‘Æ°á»£c má»Ÿ rá»™ng Ä‘á»ƒ xem xÃ©t cÃ¡c chi phÃ­ khÃ¡c nhau cá»§a MHA vÃ  FFN. Trong Eq. (6), chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng trung bÃ¬nh cÃ³ trá»ng sá»‘ cá»§a hai loáº¡i cá»•ng, trong Ä‘Ã³ cÃ¡c trá»ng sá»‘ phá»¥ thuá»™c vÃ o chi phÃ­ tÃ­nh toÃ¡n cá»§a chÃºng. Sau Ä‘Ã³, viá»‡c huáº¥n luyá»‡n sáº½ tá»‘i thiá»ƒu hÃ³a tá»•ng tÃ­nh toÃ¡n thay vÃ¬ Ä‘Æ¡n giáº£n lÃ  sá»‘ lÆ°á»£ng lá»›p.

gá»‘c, nhÆ°ng nÃ³ kháº£ vi w.r.t. Ï€ vÃ  do Ä‘Ã³ phÃ¹ há»£p cho tá»‘i Æ°u hÃ³a dá»±a trÃªn gradient. Khi Ï„ â†’ 0, xáº¥p xá»‰ trá»Ÿ nÃªn gáº§n hÆ¡n vá»›i phiÃªn báº£n rá»i ráº¡c. ChÃºng tÃ´i sá»­ dá»¥ng Ï„ = 1 trong cÃ¡c thÃ­ nghiá»‡m cá»§a mÃ¬nh.

Äá»‘i vá»›i MHA thá»© l, má»™t phÃ¢n phá»‘i xÃ¡c suáº¥t rá»i ráº¡c p(l)MHA âˆˆ RÂ² trÃªn hai giÃ¡ trá»‹ cá»•ng cÃ³ thá»ƒ (0 vÃ  1) Ä‘Æ°á»£c dá»± Ä‘oÃ¡n, trong Ä‘Ã³ 0 cÃ³ nghÄ©a lÃ  bá» qua mÃ´-Ä‘un nÃ y vÃ  1 cÃ³ nghÄ©a lÃ  thá»±c thi nÃ³. Sau Ä‘Ã³, má»™t máº«u má»m Ä‘Æ°á»£c rÃºt tá»« phÃ¢n phá»‘i rá»i ráº¡c nÃ y sá»­ dá»¥ng Eq. (8), Ä‘Æ°á»£c sá»­ dá»¥ng lÃ m cá»•ng trong Eq. (3) trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n. TÆ°Æ¡ng tá»±, Ä‘á»‘i vá»›i FFN thá»© l, má»™t phÃ¢n phá»‘i p(l)FFN âˆˆ RÂ² Ä‘Æ°á»£c dá»± Ä‘oÃ¡n, tá»« Ä‘Ã³ má»™t cá»•ng má»m Ä‘Æ°á»£c rÃºt vÃ  sá»­ dá»¥ng trong Eq. (4). CÃ¡c phÃ¢n phá»‘i cá»•ng Ä‘Æ°á»£c táº¡o ra bá»Ÿi má»™t bá»™ dá»± Ä‘oÃ¡n cá»•ng dá»±a trÃªn cÃ¡c Ä‘áº·c trÆ°ng Ä‘áº§u vÃ o, nhÆ° Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a trong Pháº§n 2.3.

2.3. Bá»™ dá»± Ä‘oÃ¡n cá»•ng cá»¥c bá»™ vÃ  toÃ n cá»¥c

ChÃºng tÃ´i Ä‘á» xuáº¥t hai loáº¡i bá»™ dá»± Ä‘oÃ¡n cá»•ng, cá»¥ thá»ƒ lÃ  bá»™ dá»± Ä‘oÃ¡n cá»•ng cá»¥c bá»™ vÃ  bá»™ dá»± Ä‘oÃ¡n cá»•ng toÃ n cá»¥c. ChÃºng tÃ´i sá»­ dá»¥ng má»™t perceptron Ä‘a lá»›p (MLP) vá»›i má»™t lá»›p áº©n duy nháº¥t cÃ³ kÃ­ch thÆ°á»›c 32 trong táº¥t cáº£ cÃ¡c thÃ­ nghiá»‡m, cÃ³ Ã­t overhead tÃ­nh toÃ¡n.

Bá»™ dá»± Ä‘oÃ¡n cá»•ng cá»¥c bá»™ (LocalGP hoáº·c LGP) Ä‘Æ°á»£c liÃªn káº¿t vá»›i má»™t lá»›p bá»™ mÃ£ hÃ³a I3D cá»¥ thá»ƒ, nhÆ° Ä‘Æ°á»£c minh há»a trong HÃ¬nh 1b. Má»—i lá»›p cÃ³ bá»™ dá»± Ä‘oÃ¡n cá»•ng riÃªng cá»§a nÃ³ vá»›i cÃ¡c tham sá»‘ Ä‘á»™c láº­p. Xem xÃ©t lá»›p bá»™ mÃ£ hÃ³a thá»© l vá»›i má»™t chuá»—i Ä‘áº§u vÃ o X(lâˆ’1) âˆˆ RTÃ—d. Chuá»—i nÃ y Ä‘áº§u tiÃªn Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i thÃ nh má»™t vector d-chiá»u x(lâˆ’1) âˆˆ Rd thÃ´ng qua average pooling dá»c theo chiá»u thá»i gian. Sau Ä‘Ã³, vector Ä‘Æ°á»£c pooling nÃ y Ä‘Æ°á»£c biáº¿n Ä‘á»•i thÃ nh hai vector xÃ¡c suáº¥t 2-chiá»u cho cá»•ng MHA vÃ  cá»•ng FFN, tÆ°Æ¡ng á»©ng:

p(l)MHA, p(l)FFN = LGP(l)(x(lâˆ’1)); (9)

trong Ä‘Ã³ p(l)MHA, p(l)FFN âˆˆ RÂ² Ä‘Æ°á»£c giá»›i thiá»‡u trong Pháº§n 2.2, vÃ  LGP(l) lÃ  bá»™ dá»± Ä‘oÃ¡n cá»•ng cá»¥c bá»™ táº¡i lá»›p thá»© l. Vá»›i cÃ´ng thá»©c nÃ y, quyáº¿t Ä‘á»‹nh thá»±c thi hoáº·c bá» qua báº¥t ká»³ mÃ´-Ä‘un MHA hoáº·c FFN nÃ o phá»¥ thuá»™c vÃ o Ä‘áº§u vÃ o cá»§a lá»›p hiá»‡n táº¡i, Ä‘iá»u nÃ y phá»¥ thuá»™c thÃªm vÃ o quyáº¿t Ä‘á»‹nh Ä‘Æ°á»£c Ä‘Æ°a ra táº¡i lá»›p trÆ°á»›c Ä‘Ã³. Do Ä‘Ã³, cÃ¡c quyáº¿t Ä‘á»‹nh Ä‘Æ°á»£c Ä‘Æ°a ra tuáº§n tá»± tá»« lá»›p dÆ°á»›i Ä‘áº¿n lá»›p trÃªn. Trong quÃ¡ trÃ¬nh suy luáº­n, má»™t ngÆ°á»¡ng cá»‘ Ä‘á»‹nh Î¸ âˆˆ [0,1] Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ táº¡o ra má»™t cá»•ng nhá»‹ phÃ¢n cho má»—i mÃ´-Ä‘un:

g(l)MHA = 1 if (p(l)MHA)â‚ > Î¸ else 0; (10)
g(l)FFN = 1 if (p(l)FFN)â‚ > Î¸ else 0; (11)

trong Ä‘Ã³ (p(l)MHA)â‚ lÃ  xÃ¡c suáº¥t thá»±c thi MHA vÃ  (p(l)FFN)â‚ lÃ  xÃ¡c suáº¥t thá»±c thi FFN. ChÃºng tÃ´i sá»­ dá»¥ng Î¸ = 0.5 theo máº·c Ä‘á»‹nh, nhÆ°ng cÅ©ng cÃ³ thá»ƒ Ä‘iá»u chá»‰nh chi phÃ­ suy luáº­n báº±ng cÃ¡ch thay Ä‘á»•i Î¸.

--- TRANG 3 ---

18 20 22 24 26 28 30 32 34 36 11:5 12:0 12:5 13:0 13:5
Sá»‘ lÆ°á»£ng lá»›p trung bÃ¬nh % WER (â‰ˆ#) Transformer LayerDrop I3D-LocalGP
I3D-GlobalGP I3D-GlobalGP (Î¸ khÃ¡c nhau)

(a) LibriSpeech test clean

18 20 22 24 26 28 30 32 34 36 26:0 27:0 28:0 29:0 30:0
Sá»‘ lÆ°á»£ng lá»›p trung bÃ¬nh % WER (â‰ˆ#)

(b) LibriSpeech test other

HÃ¬nh 2: Tá»· lá»‡ lá»—i tá»« (%) cá»§a cÃ¡c mÃ´ hÃ¬nh dá»±a trÃªn CTC so vá»›i sá»‘ lÆ°á»£ng lá»›p trung bÃ¬nh Ä‘Æ°á»£c sá»­ dá»¥ng cho suy luáº­n trÃªn cÃ¡c bá»™ test LibriSpeech. Î¸ lÃ  ngÆ°á»¡ng Ä‘á»ƒ táº¡o cá»•ng nhá»‹ phÃ¢n nhÆ° Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a trong Eqs. (10) (11).

18 20 22 24 26 28 30 32 34 36 11:4 11:6 11:8 12:0 12:2 12:4
Sá»‘ lÆ°á»£ng lá»›p trung bÃ¬nh % WER (â‰ˆ#) Transformer
LayerDrop
I3D-GlobalGP

(a) LibriSpeech test clean

18 20 22 24 26 28 30 32 34 36 26:0 26:5 27:0 27:5
Sá»‘ lÆ°á»£ng lá»›p trung bÃ¬nh % WER (â‰ˆ#) Transformer
LayerDrop
I3D-GlobalGP

(b) LibriSpeech test other

HÃ¬nh 3: Tá»· lá»‡ lá»—i tá»« (%) cá»§a cÃ¡c mÃ´ hÃ¬nh dá»±a trÃªn InterCTC so vá»›i sá»‘ lÆ°á»£ng lá»›p trung bÃ¬nh Ä‘Æ°á»£c sá»­ dá»¥ng cho suy luáº­n trÃªn cÃ¡c bá»™ test LibriSpeech.

Bá»™ dá»± Ä‘oÃ¡n cá»•ng toÃ n cá»¥c (GlobalGP hoáº·c GGP), máº·t khÃ¡c, Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a cho toÃ n bá»™ bá»™ mÃ£ hÃ³a I3D, nhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 1c. NÃ³ dá»± Ä‘oÃ¡n cÃ¡c phÃ¢n phá»‘i cá»•ng cho táº¥t cáº£ cÃ¡c lá»›p dá»±a trÃªn Ä‘áº§u vÃ o cá»§a bá»™ mÃ£ hÃ³a, cÅ©ng lÃ  Ä‘áº§u vÃ o cá»§a lá»›p Ä‘áº§u tiÃªn: X = X(0) âˆˆ RTÃ—d. Cá»¥ thá»ƒ, chuá»—i Ä‘Æ°á»£c biáº¿n Ä‘á»•i thÃ nh má»™t vector duy nháº¥t x = x(0) âˆˆ Rd báº±ng average pooling. Sau Ä‘Ã³, nÃ³ Ä‘Æ°á»£c Ã¡nh xáº¡ tá»›i hai táº­p há»£p phÃ¢n phá»‘i xÃ¡c suáº¥t cho táº¥t cáº£ N cá»•ng MHA vÃ  FFN, tÆ°Æ¡ng á»©ng:

{p(l)MHA}Nl=1, {p(l)FFN}Nl=1 = GGP(x); (12)

trong Ä‘Ã³ p(l)MHA, p(l)FFN âˆˆ RÂ² lÃ  cÃ¡c phÃ¢n phá»‘i xÃ¡c suáº¥t cá»•ng táº¡i lá»›p thá»© l, vÃ  bá»™ mÃ£ hÃ³a I3D cÃ³ tá»•ng cá»™ng N lá»›p. á» Ä‘Ã¢y, cÃ¡c quyáº¿t Ä‘á»‹nh thá»±c thi hoáº·c bá» qua cÃ¡c mÃ´-Ä‘un Ä‘Æ°á»£c Ä‘Æ°a ra ngay láº­p tá»©c sau khi nhÃ¬n tháº¥y Ä‘áº§u vÃ o cá»§a bá»™ mÃ£ hÃ³a, cÃ³ overhead tÃ­nh toÃ¡n tháº¥p hÆ¡n LocalGP vÃ  cho phÃ©p kiá»ƒm soÃ¡t linh hoáº¡t hÆ¡n Ä‘á»‘i vá»›i kiáº¿n trÃºc suy luáº­n. Trong quÃ¡ trÃ¬nh suy luáº­n, chÃºng ta váº«n cÃ³ thá»ƒ sá»­ dá»¥ng má»™t ngÆ°á»¡ng cá»‘ Ä‘á»‹nh Î¸ âˆˆ [0,1] Ä‘á»ƒ táº¡o cá»•ng nhá»‹ phÃ¢n nhÆ° trong Eqs. (10) vÃ  (11).

3. THÃ NGHIá»†M

3.1. Thiáº¿t láº­p thÃ­ nghiá»‡m

ChÃºng tÃ´i sá»­ dá»¥ng PyTorch [32] vÃ  tuÃ¢n theo cÃ¡c recipes ASR trong ESPnet [33] Ä‘á»ƒ huáº¥n luyá»‡n táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh. ChÃºng tÃ´i chá»§ yáº¿u sá»­ dá»¥ng framework CTC trÃªn LibriSpeech

18 20 22 24 26 28 30 32 34 36 10 11 12 13
Sá»‘ lÆ°á»£ng lá»›p trung bÃ¬nh % WER (â‰ˆ#) Transformer I3D-LocalGP I3D-GlobalGP

HÃ¬nh 4: Tá»· lá»‡ lá»—i tá»« (%) cá»§a cÃ¡c mÃ´ hÃ¬nh dá»±a trÃªn CTC so vá»›i sá»‘ lÆ°á»£ng lá»›p trung bÃ¬nh Ä‘Æ°á»£c sá»­ dá»¥ng cho suy luáº­n trÃªn bá»™ test Tedlium2.

Báº£ng 1: Tá»· lá»‡ lá»—i tá»« (%) vÃ  sá»‘ lÆ°á»£ng lá»›p suy luáº­n trung bÃ¬nh cá»§a cÃ¡c mÃ´ hÃ¬nh dá»±a trÃªn AED trÃªn LibriSpeech 100h.

Model | dev clean | test clean
---|---|---
 | Ave #layers | WER (â‰ˆ#) | Ave #layers | WER (â‰ˆ#)
Transformer | 36 | 7.8 | 36 | 8.0
 | 27 | 8.2 | 27 | 8.5
I3D-LGP-36 | 27.3 | 7.9 | 27.1 | 8.3
I3D-GGP-36 | 27.2 | 7.8 | 27.1 | 8.2

100h [34]. Trong Pháº§n 3.5, chÃºng tÃ´i cÅ©ng cho tháº¥y ráº±ng I3D cÃ³ thá»ƒ Ä‘Æ°á»£c Ã¡p dá»¥ng cho AED vÃ  má»™t corpus khÃ¡c, Tedlium2 [35]. CÃ¡c bá»™ mÃ£ hÃ³a I3D cá»§a chÃºng tÃ´i cÃ³ tá»•ng cá»™ng 36 lá»›p. ChÃºng Ä‘Æ°á»£c khá»Ÿi táº¡o vá»›i cÃ¡c Transformers tiÃªu chuáº©n Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n vÃ  fine-tuned vá»›i tá»· lá»‡ há»c giáº£m (â‰ˆ 1eâˆ’3) vÃ  cÃ¡c Î» khÃ¡c nhau (thÆ°á»ng dao Ä‘á»™ng tá»« 1 Ä‘áº¿n 13) trong Eq. (5) Ä‘á»ƒ cÃ¢n báº±ng WER vÃ  tÃ­nh toÃ¡n. CÃ¡c epoch fine-tuning cho LibriSpeech 100h vÃ  Tedlium2 láº§n lÆ°á»£t lÃ  50 vÃ  35. ChÃºng tÃ´i so sÃ¡nh I3D vá»›i hai baseline. Äáº§u tiÃªn, chÃºng tÃ´i huáº¥n luyá»‡n cÃ¡c Transformers tiÃªu chuáº©n vá»›i sá»‘ lÆ°á»£ng lá»›p giáº£m. Thá»© hai, chÃºng tÃ´i huáº¥n luyá»‡n má»™t Transformer 36 lá»›p vá»›i LayerDrop [36, 37] hoáº·c Intermediate CTC (InterCTC) [38] vÃ  thá»±c hiá»‡n cáº¯t tá»‰a lá»›p láº·p [29] sá»­ dá»¥ng bá»™ validation Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c nhiá»u mÃ´ hÃ¬nh vá»›i kiáº¿n trÃºc nhá» hÆ¡n vÃ  cá»‘ Ä‘á»‹nh. Baseline nÃ y Ä‘Æ°á»£c kÃ½ hiá»‡u lÃ  "LayerDrop" trong HÃ¬nh 2 vÃ  3. ChÃºng ta cÃ³ thá»ƒ so sÃ¡nh I3D, cÃ³ cÃ¡c lá»›p Ä‘Æ°á»£c giáº£m Ä‘á»™ng dá»±a trÃªn Ä‘áº§u vÃ o, vá»›i cÃ¡c mÃ´ hÃ¬nh cáº¯t tá»‰a tÄ©nh.

3.2. Káº¿t quáº£ chÃ­nh

HÃ¬nh 2 so sÃ¡nh cÃ¡c mÃ´ hÃ¬nh I3D cá»§a chÃºng tÃ´i vá»›i hai baseline. ChÃºng tÃ´i huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh I3D-CTC vá»›i Î» khÃ¡c nhau trong Eq. (5) Ä‘á»ƒ Ä‘iá»u chá»‰nh Ä‘iá»ƒm hoáº¡t Ä‘á»™ng. ChÃºng tÃ´i tÃ­nh sá»‘ lÆ°á»£ng lá»›p lÃ  trung bÃ¬nh cá»§a sá»‘ lÆ°á»£ng khá»‘i MHA vÃ  sá»‘ lÆ°á»£ng khá»‘i FFN. Cáº£ I3D-LocalGP vÃ  I3D-GlobalGP Ä‘á»u vÆ°á»£t trá»™i hÆ¡n Transformer tiÃªu chuáº©n vÃ  phiÃªn báº£n cáº¯t tá»‰a sá»­ dá»¥ng cáº¯t tá»‰a lá»›p láº·p [29]. ChÃºng ta cÃ³ thá»ƒ giáº£m sá»‘ lÆ°á»£ng lá»›p trung bÃ¬nh xuá»‘ng khoáº£ng 20 trong khi váº«n khá»›p vá»›i Transformer Ä‘Æ°á»£c huáº¥n luyá»‡n tá»« Ä‘áº§u. LocalGP Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t tÆ°Æ¡ng tá»± nhÆ° GlobalGP, nhÆ°ng GlobalGP chá»‰ cÃ³ má»™t bá»™ dá»± Ä‘oÃ¡n cá»•ng, cÃ³ thá»ƒ hiá»‡u quáº£ hÆ¡n cho suy luáº­n. LÃ½ do táº¡i sao LocalGP khÃ´ng tá»‘t hÆ¡n GlobalGP cÃ³ thá»ƒ lÃ  LocalGP quyáº¿t Ä‘á»‹nh cÃ³ thá»±c thi hay bá» qua má»™t khá»‘i dá»±a trÃªn Ä‘áº§u vÃ o cá»§a lá»›p hiá»‡n táº¡i, phá»¥ thuá»™c vÃ o cÃ¡c quyáº¿t Ä‘á»‹nh táº¡i cÃ¡c lá»›p trÆ°á»›c Ä‘Ã³. Thá»§ tá»¥c tuáº§n tá»± nÃ y cÃ³ thá»ƒ dáº«n Ä‘áº¿n lan truyá»n lá»—i nghiÃªm trá»ng hÆ¡n. ChÃºng tÃ´i cÅ©ng cho tháº¥y ráº±ng cÃ³ thá»ƒ Ä‘iá»u chá»‰nh chi phÃ­ tÃ­nh toÃ¡n cá»§a má»™t mÃ´ hÃ¬nh I3D Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n báº±ng cÃ¡ch thay Ä‘á»•i Î¸ (xem Eqs. (10) (11)) táº¡i thá»i Ä‘iá»ƒm suy luáº­n. Ba mÃ´ hÃ¬nh I3D-GlobalGP Ä‘Æ°á»£c giáº£i mÃ£ vá»›i Î¸ khÃ¡c nhau. Khi Î¸ giáº£m, nhiá»u khá»‘i Ä‘Æ°á»£c sá»­ dá»¥ng hÆ¡n, vÃ  WER thÆ°á»ng Ä‘Æ°á»£c cáº£i thiá»‡n.

HÃ¬nh 3 cho tháº¥y káº¿t quáº£ sá»­ dá»¥ng InterCTC [38]. CÃ¡c WER tháº¥p hÆ¡n so vá»›i trong HÃ¬nh 2, nhá» vÃ o loss CTC phá»¥ trá»£ giÃºp regularize viá»‡c huáº¥n luyá»‡n. Má»™t láº§n ná»¯a, I3D luÃ´n tá»‘t hÆ¡n Transformer Ä‘Æ°á»£c huáº¥n luyá»‡n tá»« Ä‘áº§u vÃ  mÃ´ hÃ¬nh cáº¯t tá»‰a.

3.3. PhÃ¢n tÃ­ch cÃ¡c phÃ¢n phá»‘i cá»•ng

HÃ¬nh 5 cho tháº¥y mean vÃ  Ä‘á»™ lá»‡ch chuáº©n (std) cá»§a cÃ¡c xÃ¡c suáº¥t cá»•ng Ä‘Æ°á»£c táº¡o ra bá»Ÿi má»™t mÃ´ hÃ¬nh I3D-GlobalGP sá»­ dá»¥ng CTC trÃªn Lib-

--- TRANG 4 ---

1 6 11 16 21 26 31 36 0 0:5 1
Chá»‰ sá»‘ lá»›p XÃ¡c suáº¥t

(a) XÃ¡c suáº¥t cá»•ng MHA.

1 6 11 16 21 26 31 36 0 0:5 1
Chá»‰ sá»‘ lá»›p XÃ¡c suáº¥t

(b) XÃ¡c suáº¥t cá»•ng FFN.

HÃ¬nh 5: XÃ¡c suáº¥t cá»•ng dá»± Ä‘oÃ¡n (mean vÃ  std) táº¡i cÃ¡c lá»›p khÃ¡c nhau cá»§a má»™t mÃ´ hÃ¬nh I3D-GlobalGP trÃªn LibriSpeech test other. XÃ¡c suáº¥t cao hÆ¡n cÃ³ nghÄ©a lÃ  lá»›p cÃ³ kháº£ nÄƒng Ä‘Æ°á»£c thá»±c thi cao hÆ¡n.

1 6 11 16 21 26 31 36 0 0:5 1
Chá»‰ sá»‘ lá»›p XÃ¡c suáº¥t

(a) XÃ¡c suáº¥t cá»•ng MHA (Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i InterCTC).

1 6 11 16 21 26 31 36 0 0:5 1
Chá»‰ sá»‘ lá»›p XÃ¡c suáº¥t

(b) XÃ¡c suáº¥t cá»•ng FFN (Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i InterCTC).

HÃ¬nh 6: XÃ¡c suáº¥t cá»•ng dá»± Ä‘oÃ¡n (mean vÃ  std) táº¡i cÃ¡c lá»›p khÃ¡c nhau cá»§a má»™t mÃ´ hÃ¬nh I3D-GlobalGP vá»›i InterCTC trÃªn LibriSpeech test other. XÃ¡c suáº¥t cao hÆ¡n cÃ³ nghÄ©a lÃ  lá»›p cÃ³ kháº£ nÄƒng Ä‘Æ°á»£c thá»±c thi cao hÆ¡n.

riSpeech test-other. Háº§u háº¿t cÃ¡c lá»›p cÃ³ xÃ¡c suáº¥t á»•n Ä‘á»‹nh. Má»™t sá»‘ lá»›p cÃ³ biáº¿n thiÃªn lá»›n hÆ¡n tÃ¹y thuá»™c vÃ o Ä‘áº§u vÃ o. Äá»‘i vá»›i cáº£ MHA vÃ  FFN, cÃ¡c lá»›p trÃªn Ä‘Æ°á»£c thá»±c thi vá»›i xÃ¡c suáº¥t cao trong khi cÃ¡c lá»›p dÆ°á»›i cÃ³ xu hÆ°á»›ng bá»‹ bá» qua, Ä‘iá»u nÃ y phÃ¹ há»£p vá»›i [28].

ChÃºng tÃ´i cÅ©ng cho tháº¥y xÃ¡c suáº¥t cá»•ng tá»« má»™t mÃ´ hÃ¬nh I3D-GlobalGP Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i InterCTC [38] trong HÃ¬nh 6. ThÃº vá»‹ thay, xu hÆ°á»›ng tá»•ng thá»ƒ ráº¥t khÃ¡c so vá»›i HÃ¬nh 5. BÃ¢y giá», cÃ¡c lá»›p trÃªn háº§u nhÆ° bá»‹ bá» qua trong khi cÃ¡c lá»›p dÆ°á»›i Ä‘Æ°á»£c thá»±c thi vá»›i xÃ¡c suáº¥t ráº¥t cao, cho tháº¥y ráº±ng cÃ¡c lá»›p dÆ°á»›i cá»§a bá»™ mÃ£ hÃ³a nÃ y cÃ³ thá»ƒ há»c cÃ¡c biá»ƒu diá»…n máº¡nh máº½ cho tÃ¡c vá»¥ ASR. Äiá»u nÃ y cÃ³ thá»ƒ lÃ  do cÃ¡c loss CTC phá»¥ trá»£ Ä‘Æ°á»£c chÃ¨n vÃ o cÃ¡c lá»›p trung gian cÃ³ thá»ƒ táº¡o Ä‘iá»u kiá»‡n cho viá»‡c lan truyá»n gradient Ä‘áº¿n cÃ¡c pháº§n dÆ°á»›i cá»§a bá»™ mÃ£ hÃ³a sÃ¢u, Ä‘iá»u nÃ y hiá»‡u quáº£ cáº£i thiá»‡n kháº£ nÄƒng cá»§a nÃ³ vÃ  cáº£ hiá»‡u suáº¥t cuá»‘i cÃ¹ng.

ChÃºng tÃ´i tin ráº±ng phÃ¢n tÃ­ch cá»•ng nÃ y cÃ³ thá»ƒ cung cáº¥p má»™t cÃ¡ch Ä‘á»ƒ diá»…n giáº£i hÃ nh vi theo lá»›p cá»§a cÃ¡c máº¡ng sÃ¢u.

3.4. PhÃ¢n tÃ­ch sá»± phá»¥ thuá»™c Ä‘áº§u vÃ o

ÄÃ£ Ä‘Æ°á»£c chá»©ng minh ráº±ng cÃ¡c mÃ´ hÃ¬nh I3D cá»§a chÃºng tÃ´i cÃ³ thá»ƒ Ä‘iá»u chá»‰nh Ä‘á»™ng Ä‘á»™ sÃ¢u bá»™ mÃ£ hÃ³a dá»±a trÃªn cÃ¡c Ä‘áº·c Ä‘iá»ƒm cá»§a má»™t phÃ¡t ngÃ´n Ä‘áº§u vÃ o, Ä‘iá»u nÃ y Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t máº¡nh máº½ ngay cáº£ vá»›i tÃ­nh toÃ¡n giáº£m. NhÆ°ng váº«n chÆ°a rÃµ cÃ¡c Ä‘áº·c trÆ°ng nÃ o quan trá»ng Ä‘á»ƒ bá»™ dá»± Ä‘oÃ¡n cá»•ng xÃ¡c Ä‘á»‹nh cÃ¡c mÃ´-Ä‘un Ä‘Æ°á»£c sá»­ dá»¥ng trong quÃ¡ trÃ¬nh suy luáº­n. ChÃºng tÃ´i Ä‘Ã£ phÃ¡t hiá»‡n ra ráº±ng Ä‘á»™ dÃ i giá»ng nÃ³i nÃ³i chung áº£nh hÆ°á»Ÿng Ä‘áº¿n kiáº¿n trÃºc suy luáº­n.

HÃ¬nh 7 cho tháº¥y phÃ¢n phá»‘i Ä‘á»™ dÃ i giá»ng nÃ³i Ä‘Æ°á»£c phÃ¢n loáº¡i theo sá»‘ lÆ°á»£ng khá»‘i MHA hoáº·c FFN Ä‘Æ°á»£c sá»­ dá»¥ng bá»Ÿi má»™t mÃ´ hÃ¬nh I3D-GlobalGP trong quÃ¡ trÃ¬nh suy luáº­n. ChÃºng tÃ´i quan sÃ¡t tháº¥y ráº±ng cÃ¡c phÃ¡t ngÃ´n sá»­ dá»¥ng nhiá»u khá»‘i hÆ¡n cÃ³ xu hÆ°á»›ng dÃ i hÆ¡n. Äiá»u nÃ y cÃ³ thá»ƒ lÃ  do cÃ¡c phÃ¡t ngÃ´n dÃ i hÆ¡n chá»©a thÃ´ng tin phá»©c táº¡p hÆ¡n vÃ  phá»¥ thuá»™c táº§m xa hÆ¡n giá»¯a cÃ¡c khung hÃ¬nh, Ä‘Ã²i há»i nhiá»u khá»‘i hÆ¡n (Ä‘áº·c biá»‡t lÃ  MHA) Ä‘á»ƒ xá»­ lÃ½.

ChÃºng tÃ´i cÅ©ng xem xÃ©t hai yáº¿u tá»‘ khÃ¡c cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n suy luáº­n

0 5 10 15 20 25 0 0:2 0:4
Äá»™ dÃ i giá»ng nÃ³i Ä‘áº§u vÃ o tÃ­nh báº±ng giÃ¢y Táº§n suáº¥t 18 khá»‘i 19 khá»‘i
20 khá»‘i 21 khá»‘i

(a) MHA

0 5 10 15 20 25 0 0:1
Äá»™ dÃ i giá»ng nÃ³i Ä‘áº§u vÃ o tÃ­nh báº±ng giÃ¢y Táº§n suáº¥t 19 khá»‘i 20 khá»‘i
21 khá»‘i 22 khá»‘i

(b) FFN

HÃ¬nh 7: PhÃ¢n phá»‘i Ä‘á»™ dÃ i giá»ng nÃ³i Ä‘Æ°á»£c phÃ¢n loáº¡i theo sá»‘ lÆ°á»£ng khá»‘i MHA hoáº·c FFN Ä‘Æ°á»£c sá»­ dá»¥ng cho suy luáº­n. ÄÃ¢y lÃ  má»™t mÃ´ hÃ¬nh I3D-GlobalGP Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ trÃªn LibriSpeech test other. CÃ¡c phÃ¡t ngÃ´n sá»­ dá»¥ng nhiá»u khá»‘i hÆ¡n cÃ³ xu hÆ°á»›ng dÃ i hÆ¡n.

kiáº¿n trÃºc, cá»¥ thá»ƒ lÃ  Ä‘á»™ khÃ³ cá»§a cÃ¡c phÃ¡t ngÃ´n Ä‘Æ°á»£c Ä‘o báº±ng WERs, vÃ  cháº¥t lÆ°á»£ng Ã¢m thanh Ä‘Æ°á»£c Ä‘o báº±ng Ä‘iá»ƒm DNSMOS [39]. Tuy nhiÃªn, nÃ³i chung, chÃºng tÃ´i khÃ´ng quan sÃ¡t tháº¥y má»‘i quan há»‡ rÃµ rÃ ng giá»¯a cÃ¡c chá»‰ sá»‘ nÃ y vÃ  sá»‘ lÆ°á»£ng lá»›p Ä‘Æ°á»£c sá»­ dá»¥ng cho suy luáº­n.

3.5. Kháº£ nÄƒng tá»•ng quÃ¡t

ChÃºng tÃ´i chá»©ng minh ráº±ng cÃ¡c bá»™ mÃ£ hÃ³a I3D Ä‘Æ°á»£c Ä‘á» xuáº¥t cÃ³ thá»ƒ Ä‘Æ°á»£c Ã¡p dá»¥ng trá»±c tiáº¿p cho cÃ¡c bá»™ dá»¯ liá»‡u vÃ  frameworks ASR khÃ¡c. HÃ¬nh 4 cho tháº¥y káº¿t quáº£ cá»§a cÃ¡c mÃ´ hÃ¬nh dá»±a trÃªn CTC trÃªn Tedlium2. CÃ¡c mÃ´ hÃ¬nh I3D cá»§a chÃºng tÃ´i liÃªn tá»¥c Ä‘áº¡t Ä‘Æ°á»£c WER tháº¥p hÆ¡n so vá»›i Transformer tiÃªu chuáº©n vá»›i sá»‘ lÆ°á»£ng lá»›p tÆ°Æ¡ng tá»± hoáº·c tháº­m chÃ­ Ã­t hÆ¡n trong quÃ¡ trÃ¬nh suy luáº­n.Â² ChÃºng tÃ´i tiáº¿p tá»¥c Ã¡p dá»¥ng I3D cho framework attention-based encoder-decoder (AED). Chá»‰ cÃ³ bá»™ mÃ£ hÃ³a Ä‘Æ°á»£c thay Ä‘á»•i trong khi bá»™ giáº£i mÃ£ váº«n lÃ  bá»™ giáº£i mÃ£ Transformer tiÃªu chuáº©n. Báº£ng 1 trÃ¬nh bÃ y káº¿t quáº£ trÃªn LibriSpeech 100h. Vá»›i khoáº£ng 27 lá»›p trung bÃ¬nh trong quÃ¡ trÃ¬nh suy luáº­n, cÃ¡c mÃ´ hÃ¬nh I3D cá»§a chÃºng tÃ´i vÆ°á»£t trá»™i hÆ¡n Transformer 27 lá»›p Ä‘Æ°á»£c huáº¥n luyá»‡n tá»« Ä‘áº§u trÃªn cáº£ bá»™ dev clean vÃ  test clean. I3D vá»›i bá»™ dá»± Ä‘oÃ¡n cá»•ng toÃ n cá»¥c tá»‘t hÆ¡n má»™t chÃºt so vá»›i vá»›i bá»™ dá»± Ä‘oÃ¡n cá»•ng cá»¥c bá»™.

4. Káº¾T LUáº¬N

Trong cÃ´ng trÃ¬nh nÃ y, chÃºng tÃ´i Ä‘á» xuáº¥t I3D, má»™t bá»™ mÃ£ hÃ³a dá»±a trÃªn Transformer Ä‘iá»u chá»‰nh Ä‘á»™ng Ä‘á»™ sÃ¢u cá»§a nÃ³ dá»±a trÃªn cÃ¡c Ä‘áº·c Ä‘iá»ƒm cá»§a cÃ¡c phÃ¡t ngÃ´n Ä‘áº§u vÃ o Ä‘á»ƒ cÃ¢n báº±ng hiá»‡u suáº¥t vÃ  hiá»‡u quáº£. ChÃºng tÃ´i thiáº¿t káº¿ hai loáº¡i bá»™ dá»± Ä‘oÃ¡n cá»•ng vÃ  cho tháº¥y ráº±ng cÃ¡c mÃ´ hÃ¬nh dá»±a trÃªn I3D liÃªn tá»¥c vÆ°á»£t trá»™i hÆ¡n Transformer gá»‘c Ä‘Æ°á»£c huáº¥n luyá»‡n tá»« Ä‘áº§u vÃ  mÃ´ hÃ¬nh cáº¯t tá»‰a tÄ©nh. I3D cÃ³ thá»ƒ Ä‘Æ°á»£c Ã¡p dá»¥ng cho cÃ¡c frameworks vÃ  corpus ASR Ä‘áº§u cuá»‘i Ä‘áº¿n cuá»‘i khÃ¡c nhau. ChÃºng tÃ´i cÅ©ng trÃ¬nh bÃ y phÃ¢n tÃ­ch thÃº vá»‹ vá» cÃ¡c xÃ¡c suáº¥t cá»•ng dá»± Ä‘oÃ¡n vÃ  sá»± phá»¥ thuá»™c Ä‘áº§u vÃ o Ä‘á»ƒ diá»…n giáº£i tá»‘t hÆ¡n hÃ nh vi cá»§a cÃ¡c bá»™ mÃ£ hÃ³a sÃ¢u vÃ  hiá»‡u á»©ng cá»§a cÃ¡c ká»¹ thuáº­t regularization loss trung gian. Trong tÆ°Æ¡ng lai, chÃºng tÃ´i dá»± Ä‘á»‹nh Ã¡p dá»¥ng phÆ°Æ¡ng phÃ¡p nÃ y cho cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c lá»›n. ChÃºng tÃ´i sáº½ khÃ¡m phÃ¡ viá»‡c chá»‰ fine-tuning cÃ¡c bá»™ dá»± Ä‘oÃ¡n cá»•ng Ä‘á»ƒ giáº£m Ä‘Ã¡ng ká»ƒ chi phÃ­ huáº¥n luyá»‡n.

5. Lá»œI Cáº¢M Æ¡N

CÃ´ng trÃ¬nh nÃ y sá»­ dá»¥ng Bridges2 táº¡i PSC vÃ  Delta táº¡i NCSA thÃ´ng qua phÃ¢n bá»• CIS210014 tá»« chÆ°Æ¡ng trÃ¬nh Advanced Cyberinfrastructure Coordination Ecosystem: Services & Support (ACCESS), Ä‘Æ°á»£c há»— trá»£ bá»Ÿi cÃ¡c khoáº£n tÃ i trá»£ cá»§a National Science Foundation #2138259, #2138286, #2138307, #2137603, vÃ  #2138296.

Â² ChÃºng tÃ´i cÅ©ng Ä‘Ã£ Ä‘Ã¡nh giÃ¡ I3D trÃªn LibriSpeech 960h. CÃ¡c quan sÃ¡t phÃ¹ há»£p vá»›i LibriSpeech 100h vÃ  Tedlium2.

--- TRANG 5 ---

6. TÃ€I LIá»†U THAM KHáº¢O

[1] A. Graves, S. FernÃ¡ndez, et al., "Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks," in Proc. ICML, 2006.

[2] K. Cho, B. Merrienboer, et al., "Learning phrase representations using RNN encoder-decoder for statistical machine translation," in Proc. EMNLP, 2014.

[3] D. Bahdanau, K. Cho, et al., "Neural machine translation by jointly learning to align and translate," in Proc. ICLR, 2015.

[4] W. Chan, N. Jaitly, et al., "Listen, attend and spell: A neural network for large vocabulary conversational speech recognition," in Proc. ICASSP, 2016.

[5] A. Graves, "Sequence transduction with recurrent neural networks," arXiv:1211.3711, 2012.

[6] A. Vaswani, N. Shazeer, N. Parmar, et al., "Attention is all you need," in Proc. NeurIPS, 2017.

[7] A. Gulati, J. Qin, C.-C. Chiu, et al., "Conformer: Convolution-augmented Transformer for Speech Recognition," in Proc. Interspeech, 2020.

[8] Y. Peng, S. Dalmia, et al., "Branchformer: Parallel MLP-attention architectures to capture local and global context for speech recognition and understanding," in Proc. ICML, 2022.

[9] K. Kim, F. Wu, Y. Peng, et al., "E-branchformer: Branchformer with enhanced merging for speech recognition," arXiv:2210.00077, 2022.

[10] S. Karita, N. Chen, T. Hayashi, et al., "A comparative study on transformer vs rnn in speech applications," in Proc. ASRU, 2019.

[11] G. Hinton, O. Vinyals, J. Dean, et al., "Distilling the knowledge in a neural network," arXiv:1503.02531, 2015.

[12] H. Chang, S. Yang, and H. Lee, "Distilhubert: Speech representation learning by layer-wise distillation of hidden-unit bert," in Proc. ICASSP, 2022.

[13] R. Wang, Q. Bai, et al., "LightHuBERT: Lightweight and Configurable Speech Representation Learning with Once-for-All Hidden-Unit BERT," in Proc. Interspeech, 2022.

[14] P. Dong, S. Wang, et al., "RTMobile: Beyond Real-Time Mobile Acceleration of RNNs for Speech Recognition," in ACM/IEEE Design Automation Conference (DAC), 2020.

[15] K. Tan and D.L. Wang, "Compressing deep neural networks for efficient speech enhancement," in Proc. ICASSP, 2021.

[16] C. J. Lai, Y. Zhang, et al., "Parp: Prune, adjust and re-prune for self-supervised speech recognition," in Proc. NeurIPS, 2021.

[17] Y. Han, G. Huang, S. Song, et al., "Dynamic neural networks: A survey," IEEE Trans. Pattern Anal. Mach. Intell., vol. 44, no. 11, pp. 7436â€“7456, 2022.

[18] E. Bengio, P. Bacon, et al., "Conditional computation in neural networks for faster models," arXiv:1511.06297, 2015.

[19] A. Veit and S. Belongie, "Convolutional networks with adaptive inference graphs," in Proc. ECCV, 2018.

[20] X. Wang, F. Yu, et al., "Skipnet: Learning dynamic routing in convolutional networks," in Proc. ECCV, 2018.

[21] Z. Wu, T. Nagarajan, et al., "Blockdrop: Dynamic inference paths in residual networks," in Proc. CVPR, 2018.

[22] J. Shen, Y. Wang, et al., "Fractional skipping: Towards finer-grained dynamic cnn inference," in Proc. AAAI, 2020.

[23] C. Li, G. Wang, et al., "Dynamic slimmable network," in Proc. CVPR, 2021.

[24] J. Macoskey, G. P. Strimel, and A. Rastrow, "Bifocal neural asr: Exploiting keyword spotting for inference optimization," in Proc. ICASSP, 2021.

[25] Y. Shi, V. Nagaraja, C. Wu, et al., "Dynamic encoder transducer: a flexible solution for trading off accuracy for latency," arXiv:2104.02176, 2021.

[26] F. Weninger, M. Gaudesi, R. Leibold, R. Gemello, and P. Zhan, "Dual-encoder architecture with encoder selection for joint close-talk and far-talk speech recognition," in Proc. ASRU, 2021.

[27] J. Macoskey, G. P. Strimel, J. Su, and A. Rastrow, "Amortized neural networks for low-latency speech recognition," arXiv:2108.01553, 2021.

[28] Y. Xie, J. J. Macoskey, et al., "Compute Cost Amortized Transformer for Streaming ASR," in Proc. Interspeech, 2022.

[29] J. Lee, J. Kang, and S. Watanabe, "Layer pruning on demand with intermediate CTC," in Proc. Interspeech, 2021.

[30] E. Jang, S. Gu, and B. Poole, "Categorical reparameterization with gumbel-softmax," in Proc. ICLR, 2017.

[31] C. J. Maddison, A. Mnih, and Y. Teh, "The concrete distribution: A continuous relaxation of discrete random variables," in Proc. ICLR, 2017.

[32] A. Paszke, S. Gross, F. Massa, et al., "Pytorch: An imperative style, high-performance deep learning library," in Proc. NeurIPS, 2019.

[33] S. Watanabe, T. Hori, S. Karita, et al., "ESPnet: End-to-End Speech Processing Toolkit," in Proc. Interspeech, 2018.

[34] V. Panayotov, G. Chen, D. Povey, and S. Khudanpur, "Librispeech: An ASR corpus based on public domain audio books," in Proc. ICASSP, 2015.

[35] A. Rousseau, P. DelÃ©glise, Y. Esteve, et al., "Enhancing the ted-lium corpus with selected data for language modeling and more ted talks.," in Proc. LREC, 2014.

[36] G. Huang, Y. Sun, Z. Liu, D. Sedra, and K. Weinberger, "Deep networks with stochastic depth," in Proc. ECCV, 2016.

[37] A. Fan, E. Grave, and A. Joulin, "Reducing transformer depth on demand with structured dropout," in Proc. ICLR, 2020.

[38] J. Lee and S. Watanabe, "Intermediate loss regularization for ctc-based speech recognition," in Proc. ICASSP, 2021.

[39] C. K. Reddy, V. Gopal, and R. Cutler, "Dnsmos p.835: A non-intrusive perceptual objective speech quality metric to evaluate noise suppressors," in Proc. ICASSP, 2022.

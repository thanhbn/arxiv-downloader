# 2309.07990.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/llm-architecture/2309.07990.pdf
# Kích thước tệp: 1312054 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Tận dụng Thông tin Ngữ cảnh để Phát hiện Mức độ Nổi bật của Thực thể Hiệu quả
Rajarshi Bhowmik Marco Ponza Atharva Tendle Anant Gupta
Rebecca Jiang†Xingyu Lu Qian Zhao Daniel Preo¸ tiuc-Pietro
Bloomberg
{rbhowmik6 ,dpreotiucpie }@bloomberg.net
Tóm tắt
Trong các tài liệu văn bản như bài báo tin tức, nội dung và các sự kiện chính thường xoay quanh một tập con của tất cả các thực thể được đề cập trong tài liệu. Những thực thể này, thường được coi là các thực thể nổi bật, cung cấp các manh mối hữu ích về chủ đề của tài liệu cho người đọc. Việc xác định mức độ nổi bật của các thực thể được tìm thấy là hữu ích trong một số ứng dụng hạ nguồn như tìm kiếm, xếp hạng và tóm tắt tập trung vào thực thể, cùng nhiều ứng dụng khác. Nghiên cứu trước đây về phát hiện thực thể nổi bật chủ yếu tập trung vào các mô hình học máy cần thiết kế đặc trưng phức tạp. Chúng tôi chỉ ra rằng việc tinh chỉnh các mô hình ngôn ngữ kích thước vừa với kiến trúc kiểu cross-encoder mang lại những cải thiện hiệu suất đáng kể so với các phương pháp thiết kế đặc trưng. Để làm điều này, chúng tôi tiến hành đánh giá toàn diện trên bốn bộ dữ liệu có sẵn công khai bằng cách sử dụng các mô hình đại diện cho họ mô hình ngôn ngữ tiền huấn luyện kích thước vừa. Ngoài ra, chúng tôi chỉ ra rằng việc gợi ý zero-shot của các mô hình ngôn ngữ được điều chỉnh theo hướng dẫn cho kết quả kém hơn, cho thấy tính độc đáo và phức tạp của nhiệm vụ.

1 Giới thiệu
Nhiều nghiên cứu NLP đã nhấn mạnh tầm quan trọng của các thực thể đối với việc hiểu ngữ nghĩa của tài liệu (Wu et al., 2020b; Meij et al., 2012). Tự động xác định các thực thể trong tài liệu văn bản không có cấu trúc và liên kết chúng với cơ sở tri thức cơ bản, chẳng hạn như Wikipedia, là một trong những nhiệm vụ NLP cốt lõi, với nhiều nhiệm vụ chia sẻ (Tjong Kim Sang và De Meulder, 2003; Strauss et al., 2016), điểm chuẩn (Hoffart et al., 2011; Hovy et al., 2006; Pradhan et al., 2013; Rijhwani và Preotiuc-Pietro, 2020; Derczynski et al., 2016), và nghiên cứu (Kolitsas et al., 2018; Nguyen et al., 2014) dành riêng để giải quyết chúng.

Mặc dù một thực thể có thể đóng vai trò ngữ nghĩa quan trọng trong việc hiểu tài liệu, không phải tất cả các thực thể trong tài liệu văn bản đều đóng vai trò như nhau. Một số thực thể là chủ thể hoặc diễn viên trung tâm trong tài liệu, xung quanh đó nội dung và các sự kiện chính xoay quanh. Những thực thể khác chỉ được đề cập để cung cấp ngữ cảnh bổ sung cho sự kiện chính. Ví dụ, một số thực thể có thể là diễn viên trong các sự kiện phụ, trong khi những thực thể khác được coi là không cung cấp thông tin cho việc hiểu tài liệu. Do đó, mức độ nổi bật của thực thể trong văn bản được định nghĩa là một xếp hạng nhị phân hoặc thứ tự để định lượng mức độ mà một thực thể đích là trung tâm của một đoạn văn bản nhất định (Gamon et al., 2013; Dunietz và Gillick, 2014). Hình 1 cung cấp một ví dụ văn bản cùng với các thực thể được đề cập và mức độ nổi bật của chúng. Chúng tôi lưu ý rằng mức độ nổi bật của một thực thể đối với văn bản độc lập với sự quan tâm của người dùng khi đọc hoặc tìm kiếm tài liệu (Gamon et al., 2013), thường được gọi là mức độ liên quan của thực thể. Nó cũng khác biệt với tầm quan trọng của thực thể, vốn định lượng tầm quan trọng tổng thể của thực thể độc lập với tài liệu. Việc tự động suy luận mức độ nổi bật của thực thể được chỉ ra là hỗ trợ tìm kiếm (Gamon et al., 2013), cải thiện kết quả xếp hạng (Xiong et al., 2018), phát hiện thực thể (Trani et al., 2018), và cho phép các ứng dụng tập trung vào thực thể như tóm tắt tập trung vào thực thể (Maddela et al., 2022).arXiv:2309.07990v2  [cs.CL]  2 Apr 2024

--- TRANG 2 ---
Trong bài báo này, chúng tôi nghiên cứu hiệu quả của các Mô hình Ngôn ngữ Tiền huấn luyện dựa trên Transformer (PLMs) trong nhiệm vụ phát hiện mức độ nổi bật của thực thể. Nghiên cứu trước đây về xác định mức độ nổi bật của thực thể dựa vào thiết kế đặc trưng phức tạp để tạo ra các đặc trưng bao phủ rõ ràng các khía cạnh liên quan, chẳng hạn như tần suất thực thể (Dunietz và Gillick, 2014; Dojchinovski et al., 2016), vị trí của các đề cập thực thể trong tài liệu (Dunietz và Gillick, 2014; Trani et al., 2018), mối quan hệ với các thực thể khác (Trani et al., 2018), các đặc trưng tài liệu, như độ dài của nó (Gamon et al., 2013) và các đặc trưng từ vựng, như tên của thực thể hoặc ngữ cảnh của nó. Chỉ có một nghiên cứu gần đây duy nhất đã cố gắng sử dụng PLMs trong một quy trình bao gồm phát hiện thực thể chính, mặc dù phạm vi đánh giá bị hạn chế ở một bộ dữ liệu hiệu suất cao duy nhất (Zhao et al., 2021). Ngược lại, phương pháp được đề xuất của chúng tôi sử dụng kiến trúc cross-encoder trong đó tên hoặc bí danh của thực thể đích và các đề cập ngữ cảnh của nó trong tài liệu văn bản được mã hóa bởi một bộ mã hóa PLM. Bộ phân loại sử dụng biểu diễn ngữ cảnh và, tùy chọn, thông tin vị trí về thực thể được mã hóa thông qua vector nhúng vị trí decile của các đề cập để xác định điểm số nổi bật của thực thể đích.

Chúng tôi tiến hành thí nghiệm trên bốn bộ dữ liệu có sẵn công khai, hai bộ dữ liệu được chú thích bởi con người và hai bộ được tuyển chọn bán tự động. Chúng tôi tinh chỉnh một số cross-encoder sử dụng PLMs và chứng minh rằng chúng mang lại những cải thiện nhất quán và đáng kể so với các phương pháp dựa trên đặc trưng, cũng như gợi ý các PLMs được điều chỉnh theo hướng dẫn. Điều sau cho thấy tính mới lạ và phức tạp của nhiệm vụ phát hiện mức độ nổi bật của thực thể, đòi hỏi mô hình phải học kiến thức ngữ nghĩa cụ thể của nhiệm vụ quan trọng cho nhiệm vụ hiểu ngôn ngữ tự nhiên này.

Những đóng góp của chúng tôi trong bài báo này như sau:
•Chúng tôi đề xuất kiến trúc kiểu cross-encoder với mã hóa rõ ràng thông tin vị trí cho phát hiện mức độ nổi bật của thực thể cho thấy những cải thiện nhất quán từ 7 – 24.4 điểm F1 so với các phương pháp thiết kế đặc trưng trước đây.
•Chúng tôi thiết lập một điểm chuẩn thống nhất gồm hai bộ dữ liệu được chú thích bởi con người và hai bộ dữ liệu được tuyển chọn bán tự động cho nhiệm vụ phát hiện mức độ nổi bật của thực thể mà chúng tôi kỳ vọng sẽ có lợi cho nghiên cứu tương lai về nhiệm vụ này;
•Một phân tích nhiều khía cạnh về hành vi dự đoán của các mô hình.

2 Nghiên cứu Liên quan
Hiểu về chủ đề của tài liệu là một trong những mục tiêu lâu dài của nghiên cứu trong cả Truy xuất Thông tin và Xử lý Ngôn ngữ Tự nhiên (Gamon et al., 2013). Một số loại phương pháp đã được đề xuất, bao gồm trích xuất các thuật ngữ chính (Hulth, 2003; Mihalcea và Tarau, 2004), xác định các chủ đề tiềm ẩn (Blei et al., 2003), hoặc tạo tóm tắt văn bản (Erkan và Radev, 2004). Gần đây đã có sự tập trung vào việc sử dụng các thực thể để hiểu nội dung của tài liệu. Hướng tới mục tiêu này, nhiệm vụ về mức độ nổi bật của thực thể đã được mô tả lần đầu cho các trang web trong (Gamon et al., 2013) và cho nội dung tin tức trong (Dunietz và Gillick, 2014).

Nhiệm vụ này có thể được xem như một dạng hạn chế của trích xuất từ khóa hoặc cụm từ khóa (Alami Merrouni et al., 2020) nếu mức độ nổi bật là nhị phân. Đối với phần còn lại của nghiên cứu này, chúng tôi sẽ sử dụng khái niệm mức độ nổi bật như được mô tả trong (Gamon et al., 2013).

Các nhãn mức độ nổi bật cho các thực thể được thu thập bằng cách thuê ngoài nhãn từ nhiều người đánh giá để xác định các thực thể nổi bật (Gamon et al., 2013; Dojchinovski et al., 2016; Trani et al., 2018; Maddela et al., 2022) hoặc bằng cách sử dụng các biến số thay thế. Ví dụ, (Dunietz và Gillick, 2014) giả định rằng các thực thể nổi bật là những thực thể xuất hiện trong tóm tắt của bài báo. (Wu et al., 2020a) xác định một thực thể là nổi bật nếu danh mục Wikinews tương ứng với thực thể cũng được gắn nhãn là danh mục của bài báo.

Các nghiên cứu trước đây chủ yếu đề xuất các phương pháp học máy để suy luận mức độ nổi bật của một thực thể nhất định dựa vào các đặc trưng được tạo thủ công. Các đặc trưng có thể được tính toán từ các đề cập thực thể đích và chỉ tài liệu có thể được phân loại thành những loại sau: vị trí (ví dụ: vị trí trong tài liệu, nếu thực thể ở trong tóm tắt) (Dunietz và Gillick, 2014), dựa trên số đếm (ví dụ: số lượng tham chiếu đến thực thể) (Dunietz và Gillick, 2014; Wu et al., 2020a), ngữ cảnh cục bộ (Trani et al., 2018), hoặc ngữ cảnh toàn cục (Ponza et al., 2019). Hơn nữa, việc giải quyết mức độ nổi bật thực thể kết hợp có thể được thực hiện bằng cách tạo các đặc trưng sử dụng đồ thị thực thể (ví dụ: tính trung tâm trong đồ thị thực thể) (Dunietz và Gillick, 2014; Trani et al., 2018). Cuối cùng, nghiên cứu trước đây cũng cho thấy rằng việc kết hợp kiến thức bên ngoài về các thực thể từ cơ sở tri thức có thể tăng cường hiệu suất dự đoán (Dojchinovski et al., 2016).

Tự động suy luận mức độ nổi bật cho các thực thể có thể trực tiếp mang lại lợi ích cho nhiều ứng dụng hạ nguồn, chẳng hạn như cải thiện kết quả xếp hạng cho các truy vấn chứa thực thể (Xiong et al., 2018) hoặc cải thiện

--- TRANG 3 ---
hiệu suất phát hiện thực thể bằng mô hình kết hợp (Trani et al., 2018). Hơn nữa, bằng cách suy luận mức độ nổi bật, các ứng dụng tập trung vào thực thể mới có thể được xây dựng, chẳng hạn như làm nổi bật các thực thể nổi bật trong tìm kiếm (Gamon et al., 2013), cải thiện khả năng diễn giải của xu hướng tin tức thông qua các thực thể nổi bật (Ponza et al., 2021), hoặc xác định các thực thể để tạo tóm tắt tập trung vào thực thể của các câu chuyện tin tức (Maddela et al., 2022; Hofmann-Coyle et al., 2022).

3 Định nghĩa Vấn đề
Chúng tôi sử dụng khái niệm mức độ nổi bật như được giới thiệu trong (Gamon et al., 2013): các thực thể nổi bật là các thực thể được đề cập rõ ràng trong tài liệu có tầm quan trọng khách quan như một hàm số của cấu trúc văn bản.

Mục tiêu của mô hình mức độ nổi bật là tạo ra một điểm số mức độ nổi bật duy nhất ψ(e) cho thực thể e chỉ sử dụng tài liệu D và các đề cập thực thể rõ ràng Me. Chúng tôi coi việc sử dụng kiến thức bên ngoài, chẳng hạn như thông tin về các thực thể từ cơ sở tri thức, nằm ngoài phạm vi và để việc tích hợp kiến thức như vậy cho nghiên cứu tương lai.

4 Phương pháp
Các Mô hình Ngôn ngữ Tiền huấn luyện (PLMs) đã thể hiện khả năng đáng kể trong việc mã hóa kiến thức cú pháp và ngữ nghĩa trong các tham số của chúng (Tenney et al., 2018, 2019) có thể được tận dụng khi tinh chỉnh trên các nhiệm vụ hiểu ngôn ngữ tự nhiên hạ nguồn (NLU). Chúng tôi đưa ra giả thuyết rằng PLMs có thể được khai thác để hỗ trợ trong phát hiện mức độ nổi bật của thực thể, một nhiệm vụ NLU cấp tài liệu dựa trên mục tiêu. Trong phần này, chúng tôi trình bày một kiến trúc dựa trên thiết lập cross-encoder được điều chỉnh cho nhiệm vụ phát hiện mức độ nổi bật của thực thể.

4.1 Cross-encoder
Mã hóa Với một tài liệu D và một thực thể đích e, được đề cập trong tài liệu, chúng tôi nối tên của thực thể đích và tài liệu bằng cách sử dụng token đặc biệt [SEP]. Sau đó, chúng tôi mã hóa văn bản bằng cách sử dụng bộ mã hóa tiền huấn luyện dựa trên Transformer. Hình 2 hiển thị biểu diễn đồ họa của mô hình cross-encoder. Thiết lập này cho phép mô hình có sự chú ý chéo sâu giữa thực thể đích và toàn bộ tài liệu. Lưu ý rằng chúng tôi sử dụng các token đánh dấu đặc biệt [BEGIN_ENTITY] và [END_ENTITY] xung quanh mỗi đề cập m∈ Me của thực thể e trong tài liệu D.

[Cấu trúc mô hình Transformer được hiển thị trong hình]

Mã hóa Vị trí Chúng tôi tính toán các vị trí decile cho mỗi đề cập thực thể (m∈ Me) trong tài liệu D bằng cách lấy chỉ số vị trí pm∈ {0,1, . . . , 9}, chỉ ra phần nào của tài liệu mà đề cập thuộc về nếu tài liệu được phân chia thành 10 khối bằng nhau. Tùy thuộc vào số lượng và vị trí của các đề cập, vector có thể chứa nhiều giá trị khác không trong vector p. Ví dụ, nếu một thực thể e có 1 đề cập trong decile đầu tiên, 2 trong decile thứ hai và 1 đề cập trong decile thứ năm, thì đầu vào cho bộ mã hóa vị trí sẽ là pm= [1,1,0,0,1,0,0,0,0,0]. Lưu ý rằng chúng tôi không nắm bắt số lượng đề cập trong mỗi decile trong pm. Để có được các nhúng vị trí, chúng tôi sử dụng một lớp nhúng ánh xạ các chỉ số vị trí thành một vector dày đặc có chiều dmodel, chính thức là hpe(m) =Embedding (pm).

Chấm điểm Biểu diễn đầu ra của token [CLS] được nối với vector nhúng vị trí trung bình hpe và đưa vào mô đun chấm điểm tạo ra điểm số mức độ nổi bật ψ(e)∈[0,1] cho thực thể e. Bộ chấm điểm mức độ nổi bật là một mạng truyền tiến với đầu hàm chấm điểm sigmoid. Chính thức,
ψ(e) =σ(FFN(h[CLS]||hpe))

4.2 Tối ưu hóa
Chúng tôi tinh chỉnh mô hình được mô tả ở trên bằng cách tối thiểu hóa mất mát entropy chéo nhị phân được tính toán bằng cách sử dụng các nhãn mức độ nổi bật nhị phân thực tế và điểm số mức độ nổi bật dự đoán ψ(e).

5 Bộ dữ liệu
Trong phần này, chúng tôi mô tả điểm chuẩn mức độ nổi bật thực thể của chúng tôi, bao gồm bốn bộ dữ liệu: hai

--- TRANG 4 ---
[THIS IS TABLE: Bảng thống kê tóm tắt và phương pháp thu thập nhãn cho các bộ dữ liệu]
Bộ dữ liệu | NYT-Salience | WN-Salience | SEL | EntSUM
# Tài liệu | 110,463 | 6,956 | 365 | 693
Độ dài tài liệu (ký tự trung bình) | 5,079 | 2,106 | 1,660 | 4,995
# Thực thể duy nhất | 179,341 | 23,205 | 6,779 | 7,854
# Đề cập | 4,405,066 | 145,081 | 19,729 | 20,784
% Thực thể nổi bật | 14% | 27% | 10% | 39%
Sự thật cơ bản | Căn chỉnh Tóm tắt | Căn chỉnh Danh mục | Con người | Con người

bộ dữ liệu được tuyển chọn bằng các phương pháp bán tự động và hai bộ sử dụng chú thích của con người. Chúng tôi cung cấp thống kê tóm tắt của các bộ dữ liệu này và phương pháp thu thập nhãn trong Bảng 1.

NYT-Salience Bộ dữ liệu này được giới thiệu trong (Dunietz và Gillick, 2014) và là bộ dữ liệu lớn nhất cho đến nay để phát hiện mức độ nổi bật của thực thể. Bộ dữ liệu được tuyển chọn với giả định rằng các thực thể nổi bật được đề cập trong tóm tắt của một bài báo tin tức trong Corpus NYT (Sandhaus, 2008). Các thực thể và đề cập của chúng được xác định bằng cách sử dụng một quy trình NLP cổ điển bao gồm gán nhãn POS, phân tích cú pháp phụ thuộc và trích xuất cụm danh từ. Mặc dù có quy mô lớn, quá trình tạo bộ dữ liệu tự động có thể đưa vào nhiễu như được xác nhận bởi các số đồng thuận vừa phải với các chú thích viên con người trên một tập con của dữ liệu. Bộ dữ liệu chứa nhãn mức độ nổi bật nhị phân cho mỗi thực thể.

WN-Salience Được giới thiệu trong (Wu et al., 2020a), đây là một bộ dữ liệu được tuyển chọn tự động khác bao gồm các bài báo Wikinews. Những bài này được chú thích với các danh mục Wikinews bởi tác giả của chúng. WN-Salience xác định các thực thể nổi bật bằng cách sử dụng giả thuyết rằng một thực thể là nổi bật nếu danh mục Wikinews tương ứng với thực thể cũng được gắn nhãn là danh mục của bài báo. Tương tự như NYT-Salience, bộ dữ liệu này có nhãn mức độ nổi bật nhị phân.

SEL Đây là một bộ dữ liệu khác dựa trên Wikinews được phát hành bởi (Trani et al., 2018). Tuy nhiên, không giống như WN-Salience, bộ dữ liệu này được chú thích bởi con người, trong đó nhiều chú thích viên con người xếp hạng mức độ nổi bật của các thực thể thành một trong bốn danh mục. Để phù hợp với các nhãn nhị phân của các bộ dữ liệu khác, chúng tôi ánh xạ 4 danh mục thành nhãn nhị phân {0,1} bằng cách ánh xạ hai lớp dưới thành không nổi bật và hai lớp trên thành nổi bật.

EntSUM Bộ dữ liệu này được giới thiệu trong (Maddela et al., 2022). Để xây dựng bộ dữ liệu này, một tập hợp các thực thể được chọn ngẫu nhiên trải rộng trên một tập con 693 bài báo từ corpus NYT được gán nhãn mức độ nổi bật bởi các chú thích viên con người trên thang điểm bốn điểm, dao động từ [0,3]. Đối với mỗi cặp thực thể tài liệu, hai chú thích độc lập được thu thập, được tăng lên đến 5 trong trường hợp bất đồng. Nếu điểm chú thích trung bình lớn hơn 1.5 cho một thực thể, nó được gán nhãn mức độ nổi bật tích cực.

5.1 Làm phù dữ liệu với Đề cập Suy luận
Ngoại trừ EntSUM, các bộ dữ liệu không có offset đề cập thực thể rõ ràng làm chú thích, điều này cần thiết cho nhiều phương pháp dựa trên đặc trưng và để tính toán các nhúng vị trí. Trong khi SEL chỉ chứa văn bản bề mặt đề cập cho mỗi thực thể, NYT-Salience và WN-Salience chỉ cung cấp các chỉ số ký tự bắt đầu và kết thúc (hay offset đề cập) của đề cập đầu tiên của một thực thể. Để làm điều này, chúng tôi suy luận các đề cập bổ sung của một thực thể trong văn bản bằng cách sử dụng kết hợp Flair NER (Akbik et al., 2019) và khớp mẫu.

Đối với SEL, vì các đề cập có sẵn, chúng tôi sử dụng phương pháp khớp mẫu để khớp văn bản bề mặt của các đề cập để suy luận offset đề cập. Đối với NYT-Salience và WN-Salience, trước tiên chúng tôi sử dụng Flair NER để xác định các đề cập của các thực thể được đặt tên trong văn bản. Chúng tôi cố gắng khớp các đề cập này với đề cập đầu tiên của mỗi thực thể trong tài liệu được cung cấp trong các bộ dữ liệu tương ứng. Vì văn bản bề mặt của các đề cập khác có thể khác với đề cập đầu tiên, chúng tôi sử dụng thêm sự chồng chéo giữa văn bản bề mặt của đề cập và tên thực thể như một đề cập ứng viên cho thực thể đó. Áp dụng phương pháp này, chúng tôi suy luận các đề cập bổ sung của một thực thể trong văn bản và offset của chúng. Mặc dù quá trình này có thể đưa vào một số nhiễu, chất lượng tổng thể của các bộ dữ liệu được nâng cao thông qua quá trình này.

6 Thí nghiệm
Chúng tôi thí nghiệm trên điểm chuẩn mức độ nổi bật thực thể của chúng tôi với phương pháp dựa trên PLM được đề xuất, các phương pháp ML và dựa trên heuristic khác được sử dụng trong nghiên cứu trước đây, cũng như một PLM được điều chỉnh theo hướng dẫn.

--- TRANG 5 ---
6.1 Phân chia Dữ liệu
Các nghiên cứu trước đây (Dunietz và Gillick, 2014; Trani et al., 2018; Wu et al., 2020a) sử dụng các phân chia train/validation/test không nhất quán (hoặc không được báo cáo). Các bộ dữ liệu NYT-Salience và WN-Salience được cung cấp với phân chia train/test (nhưng không có validation), trong khi bộ dữ liệu SEL được cung cấp mà không có bất kỳ phân chia nào. Điều này khiến việc đánh giá các nghiên cứu trước đây với so sánh công bằng giữa các mô hình trở nên khó khăn. Để khắc phục vấn đề này, chúng tôi thực hiện phân chia thời gian của các tập huấn luyện gốc của NYT-Salience và WN-Salience thành các tập train/validation mới dựa trên thời gian xuất bản của các câu chuyện tin tức, điều này cung cấp thiết lập kiểm tra thực tế hơn (Huang và Paul, 2018; Rijhwani và Preotiuc-Pietro, 2020). Chúng tôi cũng thực hiện phân chia thời gian của các bộ dữ liệu SEL và EntSUM thành các tập train/validation/test. Chi tiết thêm về phân chia bộ dữ liệu được cung cấp trong Phụ lục A.

6.2 Đường cơ sở
Đầu tiên, chúng tôi liệt kê tất cả các phương pháp được sử dụng trong nghiên cứu trước đây, mà chúng tôi báo cáo kết quả từ các bài báo gốc.

•Câu đầu tiên. Phân loại một thực thể là nổi bật nếu nó xuất hiện trong câu đầu tiên của nội dung tài liệu; được sử dụng trong cả (Dunietz và Gillick, 2014) và (Wu et al., 2020a).

•Vị trí & Tần suất (Dunietz và Gillick, 2014). Đưa chỉ số câu đầu tiên và các đặc trưng tần suất của một thực thể vào mô hình hồi quy logistic.

•Tất cả Đặc trưng (Dunietz và Gillick, 2014). Sử dụng một loạt các đặc trưng dựa trên vị trí, tần suất và tín hiệu PageRank được đưa vào mô hình hồi quy logistic.

•SEL (Trani et al., 2018). Sử dụng kết hợp các đặc trưng dựa trên vị trí, tần suất và thống kê đồ thị Wikipedia được đưa vào thuật toán Gradient Boosted Decision Tree được triển khai trong sklearn (Pedregosa et al., 2011).

•SWAT (Ponza et al., 2019). Sử dụng một tập hợp các đặc trưng tương tự như Phương pháp SEL được mô tả ở trên, với việc bổ sung các đặc trưng dựa trên nhúng thực thể. Tất cả các đặc trưng được đưa vào thuật toán Gradient Boosted Decision Tree được triển khai trong XGBoost (Chen et al., 2015).

•Đặc trưng Vị trí (Wu et al., 2020a). Sử dụng chỉ số của câu đầu tiên mà thực thể được đề cập làm đặc trưng trong mô hình hồi quy logistic. Phương pháp này cung cấp kết quả tốt nhất trên bộ dữ liệu WN Salience trong (Wu et al., 2020a).

Tiếp theo, chúng tôi tái triển khai một tập hợp các phương pháp phổ biến dựa trên các đường cơ sở trên để có thể kiểm tra chúng trên tất cả bốn bộ dữ liệu. Điều này đảm bảo việc đánh giá được thực hiện trên cùng một thiết lập thí nghiệm.

•Tiêu đề Vị trí. Phân loại một thực thể là nổi bật nếu nó xuất hiện trong tiêu đề của tài liệu đầu vào.

•Tiêu đề & Dẫn đầu Vị trí. Phân loại một thực thể là nổi bật nếu nó xuất hiện trong tiêu đề của tài liệu hoặc trong câu đầu tiên (câu dẫn đầu) của tài liệu.

•Tần suất Thực thể. Phân loại một thực thể là nổi bật nếu chúng xuất hiện thường xuyên hơn một giá trị nhất định. Đối với mỗi bộ dữ liệu, chúng tôi tính toán các ngưỡng khác nhau và báo cáo kết quả tốt nhất. Các ngưỡng có thể được tìm thấy trong Phụ lục.

•Đặc trưng & GBDT. Phương pháp này sử dụng các đặc trưng phổ biến nhất từ các nghiên cứu trước đây (Dunietz và Gillick, 2014; Wu et al., 2020a; Trani et al., 2018; Ponza et al., 2019) — tức là chỉ số câu đầu tiên của thực thể và tần suất thực thể — và đưa chúng vào mô hình GBDT được triển khai bằng LightGBM (Ke et al., 2017).

•SEL GBDT. Theo phương pháp từ (Trani et al., 2018) và sử dụng GBDT của sklearn (Pedregosa et al., 2011) để huấn luyện mô hình trên các đặc trưng được cung cấp với bộ dữ liệu SEL.

•Che giấu thực thể đích. Phương pháp này đưa đầu vào vào bộ mã hóa dựa trên Transformer (RoBERTa-base) với các đề cập thực thể đích được biểu diễn thông qua token che giấu đặc biệt. Dự đoán mức độ nổi bật được thu được bằng cách gộp trung bình các biểu diễn token che giấu và chuyển điều này qua mạng truyền tiến.

•Gợi ý zero-shot. Chúng tôi kiểm tra các LLM được điều chỉnh theo hướng dẫn bằng cách sử dụng gợi ý zero-shot. Lời nhắc giới thiệu mô tả nhiệm vụ, tiếp theo là văn bản đầu vào và thực thể đích, và nó đặt câu hỏi có/không. Nó mong đợi mô hình tạo ra 'Có' hoặc 'Không' làm câu trả lời. Các LLM, đã được điều chỉnh hướng dẫn trên một bộ sưu tập lớn các nhiệm vụ NLU, cố gắng cung cấp câu trả lời dựa trên lời nhắc, văn bản đầu vào và thực thể đích. Họ mô hình này đã được chứng minh là mạnh mẽ và linh hoạt trên nhiều điểm chuẩn (Chung et al., 2022). Chúng tôi sử dụng Flan-UL2 (20B) (Tay et al., 2023) và LLaMa 2-Chat (7B) (Touvron et al., 2023) để đánh giá.

--- TRANG 6 ---
[Bảng 2: Kết quả trên các bộ dữ liệu NYT-Salience và WN-Salience với các phương pháp khác nhau, bao gồm độ chính xác (P), độ nhạy (R) và điểm F1]

[Bảng 3: Kết quả trên các bộ dữ liệu SEL và EntSUM với các phương pháp khác nhau]

6.3 Thiết lập Thí nghiệm
Chúng tôi sử dụng RoBERTa-base (Liu et al., 2019) và DeBERTa-v3-base (He et al., 2023) làm PLM cơ sở cho các thí nghiệm. Đối với mỗi mô hình cơ sở này, chúng tôi huấn luyện cả mô hình cross-encoder và mô hình cross-encoder được tăng cường với nhúng vị trí decile.

Để huấn luyện các mô hình được đề xuất, chúng tôi sử dụng AdamW (Loshchilov và Hutter, 2019) làm bộ tối ưu hóa. Chúng tôi thực hiện tìm kiếm siêu tham số cho tốc độ học bằng cách sử dụng tập giá trị sau: {0.001,0.0005,0.0002,0.0001,0.00005}. Chúng tôi huấn luyện các mô hình của chúng tôi tối đa 10 epoch với dừng sớm dựa trên hiệu suất tập validation. Chúng tôi chọn các checkpoint mô hình có hiệu suất tốt nhất cho mỗi bộ dữ liệu dựa trên hiệu suất trên tập validation. Trong Bảng 2 và 3, chúng tôi báo cáo hiệu suất của các mô hình và đường cơ sở bằng cách sử dụng các metric phân loại tiêu chuẩn (tức là Precision, Recall và F1) trên lớp tích cực (nổi bật), theo nghiên cứu trước đây về mức độ nổi bật thực thể.

Để huấn luyện và suy luận của mỗi mô hình dựa trên Transformer, chúng tôi sử dụng một GPU NVIDIA V100 duy nhất với bộ nhớ GPU 32GB, 4 CPU và 128 GB bộ nhớ chính.

6.4 Kết quả
Trong Bảng 2 và 3, chúng tôi trình bày kết quả thí nghiệm của các đường cơ sở và các mô hình được đề xuất trên bốn bộ dữ liệu được mô tả trong Phần 5.

So sánh với các phương pháp dựa trên đặc trưng. Chúng tôi

--- TRANG 7 ---
quan sát thấy rằng mô hình cross-encoder vượt trội đáng kể so với tất cả các mô hình đường cơ sở về điểm F1. Nó cũng mang lại độ chính xác tốt hơn so với các đường cơ sở cho ba trong số bốn bộ dữ liệu. Chỉ đối với bộ dữ liệu SEL, mô hình SEL GBDT được huấn luyện trên các đặc trưng được tính toán trước có sẵn công khai mới tạo ra mô hình với độ chính xác tốt hơn cross-encoder.

Chúng tôi quan sát thấy việc thêm nhúng vị trí decile với cross-encoder cải thiện độ chính xác trên tất cả các bộ dữ liệu, nhưng cũng làm giảm độ nhạy trong mọi bộ dữ liệu ngoại trừ NYT-Salience.

Phương pháp Target Entity Masking, cũng tận dụng thông tin ngữ cảnh với mô hình dựa trên transformer cho kết quả hỗn hợp. Nhìn chung, mô hình có thể đạt được độ chính xác tốt hơn các mô hình dựa trên đặc trưng cho tất cả các bộ dữ liệu ngoại trừ SEL, nhưng mô hình gặp khó khăn với độ nhạy kém trên tất cả các bộ dữ liệu, dẫn đến điểm F1 kém đáng kể đặc biệt khi so sánh với các mô hình cross-encoder.

Việc tái triển khai của chúng tôi về các phương pháp vị trí và phương pháp GBDT phù hợp với hiệu suất được báo cáo trong các nghiên cứu trước đây. Sự khác biệt về số liệu có thể được quy cho việc làm phong phú bộ dữ liệu với các đề cập suy luận (Phần 5.1) và việc phân chia dữ liệu train/dev/test rõ ràng được sử dụng trong thí nghiệm của chúng tôi (Phần 6.1).

6.5 Gợi ý zero-shot của các mô hình ngôn ngữ lớn
Chúng tôi xây dựng vấn đề phát hiện mức độ nổi bật với gợi ý zero-shot như sau: cho một định nghĩa của nhiệm vụ mức độ nổi bật thực thể và văn bản tài liệu, chúng tôi yêu cầu mô hình tạo ra "có" hoặc "không" nếu một thực thể cụ thể là nổi bật hay không. Chúng tôi thí nghiệm với hai mô hình nguồn mở (Flan-UL2 (20B) và LLaMa 2-Chat (7B)) có sẵn trên Hugging Face¹, và trình bày kết quả trong Bảng 4. Theo hiểu biết của chúng tôi, đây là đánh giá đầu tiên về gợi ý zero-shot của các mô hình được điều chỉnh hướng dẫn cho nhiệm vụ phát hiện mức độ nổi bật thực thể. Chúng tôi quan sát thấy rằng mô hình LLaMa 2-Chat với 7 tỷ tham số không thể mang lại bất kỳ kết quả có ý nghĩa nào vì nó chỉ tạo ra nhãn tích cực cho tất cả các điểm dữ liệu (do đó chúng tôi quan sát 100% độ nhạy). Mô hình Flan-UL2 có thể tạo ra cả nhãn tích cực và tiêu cực. Tuy nhiên, độ chính xác vẫn quá thấp trên các bộ dữ liệu. Chúng tôi thảo luận thêm về nguyên nhân của hiệu suất này trong Phụ lục (Phần C), cùng với chi tiết triển khai. Nhìn chung, những thí nghiệm này cho thấy rằng phát hiện mức độ nổi bật thực thể là một nhiệm vụ độc đáo không tương tự với bất kỳ nhiệm vụ nào khác mà hai mô hình này được điều chỉnh hướng dẫn.

¹www.huggingface.com

7 Phân tích
Trong phần này, chúng tôi thực hiện phân tích các dự đoán của mô hình để có thêm hiểu biết về hành vi mô hình và hiểu các hướng tiềm năng để cải thiện thêm. Do đó, chúng tôi phân tích hiệu suất theo các yếu tố khác nhau bao gồm: tầm quan trọng của việc suy luận tất cả các đề cập thực thể, vị trí của đề cập thực thể đầu tiên và tần suất đề cập thực thể.

7.1 Tác động của Đề cập Suy luận
Trong Phần 5.1, chúng tôi suy luận các đề cập bổ sung của một thực thể cho các bộ dữ liệu NYT-Salience và WN-Salience. Chúng tôi so sánh hiệu suất của mô hình tốt nhất của chúng tôi tận dụng nhiều đề cập của một thực thể với phiên bản được huấn luyện chỉ với các đề cập đầu tiên của các thực thể trong tài liệu. Các định dạng đầu vào cụ thể cho thí nghiệm này được trình bày trong Phụ lục B. Kết quả trong Bảng 5 cho thấy việc làm như vậy liên tục cải thiện hiệu suất của các mô hình của chúng tôi trên tất cả các bộ dữ liệu. Đặc biệt, đối với bộ dữ liệu lớn nhất, NYT-Salience, mô hình của chúng tôi đạt được một mức tăng đáng kể 27.3 điểm F1. Thí nghiệm này cho thấy tầm quan trọng của việc tăng cường bộ dữ liệu của chúng tôi với các đề cập bổ sung và tầm quan trọng của việc mô hình hóa rõ ràng thông tin ngữ cảnh có mặt xung quanh tất cả các đề cập thực thể.

7.2 Phân tích Phân tầng về Vị trí Đề cập Đầu tiên
Chúng tôi so sánh các mô hình cross-encoder của chúng tôi với mô hình Features & GBDT, đường cơ sở được tái triển khai của chúng tôi dựa vào các đặc trưng phổ biến nhất được sử dụng trong các nghiên cứu trước đây (Dunietz và Gillick, 2014; Wu et al., 2020a; Trani et al., 2018). Như được hiển thị trong kết quả từ Bảng 2 và 3, trong số các đặc trưng khác, các đặc trưng vị trí có tính thông tin nhất cho mức độ nổi bật. Một cách trực quan, nếu một thực thể được đề cập trong tiêu đề hoặc trong câu đầu tiên của bài báo tin tức, có xác suất cao rằng thực thể đó là nổi bật.

Hình 3 cho thấy rằng tất cả các mô hình hoạt động tốt khi đề cập đầu tiên rơi vào tiêu đề hoặc câu đầu tiên của tài liệu. Chúng tôi nhận thấy rằng các mô hình cross-encoder liên tục vượt trội so với mô hình Features & GBDT và những mức tăng lớn nhất được quan sát trong các bộ dữ liệu SEL và WN-Salience. Quan sát này cho thấy rằng các mô hình cross-encoder có thể

--- TRANG 8 ---
[Bảng 4: So sánh hiệu suất của mô hình cross-encoder với gợi ý zero-shot của LLMs]

[Bảng 5: So sánh hiệu suất của các mô hình cross-encoder chỉ với đề cập đầu tiên so với tất cả các đề cập suy luận]

[Hình 3: Phân tích phân tầng qua các mô hình và bộ dữ liệu với hai biểu đồ:
(a) Hiệu suất theo vị trí của các đề cập
(b) Hiệu suất theo tần suất của các thực thể]

--- TRANG 9 ---
có thể sử dụng ngữ cảnh để xác định rằng các đề cập xuất hiện trong tiêu đề hoặc các phần đầu của tài liệu thường nổi bật mà không cần sử dụng rõ ràng thông tin này như một đặc trưng.

Chúng tôi cũng điều tra hiệu suất của các mô hình khi đề cập đầu tiên rơi vào bên trong hoặc bên ngoài cửa sổ ngữ cảnh của PLM (ở đây, 512 token). Khi các đề cập rơi vào bên trong cửa sổ ngữ cảnh, chúng tôi quan sát thấy rằng các mô hình cross-encoder liên tục vượt trội so với mô hình Features & GBDT. Khi đề cập rơi vào bên ngoài cửa sổ ngữ cảnh, các dự đoán mô hình trở nên gần như ngẫu nhiên, điều này được mong đợi, vì mô hình không có thông tin ngữ cảnh trực tiếp xung quanh đề cập. Sử dụng các mô hình có thể xử lý đầu vào dài hơn sẽ là một hướng cải thiện đầy hứa hẹn cho các mẫu này (Beltagy et al., 2020). Thú vị là, đối với WN-Salience, mô hình Features & GBDT cũng hoạt động kém đáng kể bên ngoài 512 token đầu tiên.

7.3 Phân tích Phân tầng về Tần suất Đề cập
Tương tự như phân tích vị trí đề cập, chúng tôi so sánh các mô hình cross-encoder của chúng tôi với mô hình Features & GBDT, sử dụng tần suất đề cập như một trong các đặc trưng đầu vào của nó. Hình 3 cho thấy cách các mô hình cross-encoder và Features & GBDT so sánh với tần suất đề cập thực thể khác nhau.

Đối với các thực thể nổi bật với đề cập đơn lẻ, mô hình cross-encoder hoạt động tốt hơn đáng kể so với mô hình Features & GBDT. Đặc biệt, đối với bộ dữ liệu NYT-Salience, mô hình Features & GBDT không thể dự đoán bất kỳ thực thể đề cập đơn lẻ nào là nổi bật. Quan sát này cho thấy rằng các mô hình cross-encoder không chỉ đơn giản mô hình hóa tần suất đề cập, mà có thể tận dụng thông tin ngữ cảnh khác để xác định mức độ nổi bật của các thực thể với đề cập đơn lẻ.

Hiệu suất của mô hình Features & GBDT cải thiện với nhiều đề cập hơn mỗi thực thể. Thực tế, đối với phạm vi tần suất 6-10 đề cập mỗi thực thể, mô hình Features & GBDT hoạt động tốt hơn các mô hình cross-encoder đối với các bộ dữ liệu EntSUM và SEL. Quan sát này cho thấy sự phụ thuộc quá mức của mô hình Features & GBDT vào tần suất đề cập để xác định mức độ nổi bật, nhưng cũng cho thấy cross-encoder không thể sử dụng đầy đủ heuristic này.

8 Kết luận
Bài báo này nhằm mục đích tận dụng kiến thức ngữ nghĩa được mã hóa trong các mô hình ngôn ngữ tiền huấn luyện để phát hiện mức độ nổi bật thực thể. Chúng tôi đề xuất phương pháp cross-encoder dựa trên PLMs dựa trên Transformer với biểu diễn vị trí và so sánh hiệu suất của nó với một số phương pháp dựa trên ML, phương pháp heuristic và LLMs được điều chỉnh hướng dẫn trên bốn bộ dữ liệu khác nhau, hai bộ được chú thích bởi con người và hai bộ được tuyển chọn tự động. Trên tất cả các thí nghiệm của chúng tôi, mô hình cross-encoder dựa trên mô hình ngôn ngữ tiền huấn luyện vượt trội so với tất cả các phương pháp khác, thường với mức tăng hai chữ số trong điểm F-1. Phân tích hành vi mô hình minh họa các hiệu ứng quan trọng của tần suất đề cập, vị trí đề cập và độ dài tài liệu trên hiệu suất, làm nổi bật các lĩnh vực nghiên cứu tương lai.

9 Hạn chế
Chúng tôi chỉ nghiên cứu mức độ nổi bật trong các tài liệu tiếng Anh, nhưng các phương pháp của chúng tôi có thể áp dụng trực tiếp cho các ngôn ngữ khác miễn là có mô hình ngôn ngữ tiền huấn luyện bao phủ ngôn ngữ đích.

Chúng tôi sử dụng các đề cập thực thể như được chú thích trong dữ liệu của chúng tôi hoặc suy luận thông qua nhận dạng thực thể và phân giải thực thể để suy luận trong một số phương pháp. Thông tin này có thể không có sẵn tại thời điểm suy luận trong tất cả các ứng dụng.

Các thí nghiệm với LLMs bị hạn chế ở các gợi ý zero-shot. Chúng tôi không thí nghiệm với điều chỉnh hướng dẫn có thể giúp mô hình học nhiệm vụ phát hiện mức độ nổi bật.

Cuối cùng, chúng tôi không sử dụng kiến thức bên ngoài về các thực thể và mối quan hệ của chúng trong mô hình hóa, điều này được chỉ ra là cải thiện kết quả một cách cận biên trong các nghiên cứu trước đây (Dunietz và Gillick, 2014; Trani et al., 2018; Ponza et al., 2019). Chúng tôi coi điều này nằm ngoài phạm vi phân tích của chúng tôi và là một hướng khả thi cho nghiên cứu tương lai.

10 Tuyên bố Đạo đức
Chúng tôi sử dụng các bộ dữ liệu có sẵn công khai dành cho nhiệm vụ phát hiện mức độ nổi bật thực thể. Các bộ dữ liệu và mô hình tiền huấn luyện mà chúng tôi sử dụng có giấy phép khoan dung cho phép sử dụng nghiên cứu. Chúng tôi không dự kiến bất kỳ rủi ro tiềm ẩn nào liên quan đến nhiệm vụ được thảo luận trong bài báo này.

Tài liệu tham khảo
[Phần tài liệu tham khảo được giữ nguyên vì chúng là danh sách các nguồn học thuật]

--- TRANG 10 ---
[Tiếp tục danh sách tài liệu tham khảo]

--- TRANG 11 ---
[Tiếp tục danh sách tài liệu tham khảo]

--- TRANG 12 ---
[Tiếp tục danh sách tài liệu tham khảo]

--- TRANG 13 ---
Phụ lục

A Chi tiết Phân chia Bộ dữ liệu
Bảng 6 chứa các phân chia train, dev và test của mỗi bộ dữ liệu sau khi áp dụng chiến lược phân chia thời gian được mô tả trong Phần 6.1. Những phân chia này được sử dụng để huấn luyện và đánh giá mô hình.

B Định dạng Đầu vào cho Thí nghiệm
Như được mô tả trong Phần 4.1, chúng tôi thêm các token đánh dấu đặc biệt xung quanh mỗi đề cập của thực thể đích (tức là thực thể mà mô hình cần dự đoán nhãn mức độ nổi bật). Trong phần sau, chúng tôi cung cấp một ví dụ:

Văn bản
Musk hoàn thành thỏa thuận Twitter 44 tỷ đô la.
Elon Musk, thế giới...

Đầu vào Mô hình
[CLS] Elon Musk [SEP] [BEGIN_ENTITY] Musk [END_ENTITY] hoàn thành thỏa thuận Twitter 44 tỷ đô la. [BEGIN_ENTITY] Elon Musk [END_ENTITY], thế giới...

Đối với thí nghiệm với đề cập đầu tiên được báo cáo trong Phần 7.1, chỉ có đề cập đầu tiên được bao quanh bởi các token đánh dấu đặc biệt như được hiển thị trong ví dụ sau:

Đầu vào Mô hình
[CLS] Elon Musk [SEP] [BEGIN_ENTITY] Musk [END_ENTITY] hoàn thành thỏa thuận Twitter 44 tỷ đô la. Elon Musk, thế giới...

Lưu ý rằng đề cập thứ hai của Elon Musk không được bao quanh bởi các token đánh dấu.

C Chi tiết triển khai gợi ý zero-shot của LLMs
Hình 4 và Hình 5 hiển thị các gợi ý mà chúng tôi sử dụng cho các mô hình LLaMa 2-Chat (7B) và Flan-UL2 (20B) tương ứng. Bảng 7 liệt kê các tham số tạo. Chúng tôi suy đoán các nguyên nhân sau cho độ chính xác tương đối thấp hơn thu được bằng phương pháp này:

•Hướng dẫn định nghĩa định nghĩa nhiệm vụ mức độ nổi bật, nhưng không cung cấp bất kỳ ví dụ tham khảo nào (gợi ý few-shot) để căn chỉnh với định nghĩa mức độ nổi bật. Điều này dẫn đến việc mô hình xác định một thực thể là nổi bật dựa trên tần suất của nó trong tài liệu. Tuy nhiên, việc tạo gợi ý few-shot là thách thức vì chúng tôi cần giới hạn độ dài đầu vào tối đa của gợi ý để tránh vấn đề hết bộ nhớ.

•Chúng tôi cắt bớt văn bản tài liệu để toàn bộ gợi ý là 2048 token hoặc ít hơn, do đó loại bỏ bất kỳ thông tin tiềm năng nào có mặt ở cuối tài liệu dài.

[Hình 4: Hướng dẫn cho gợi ý zero-shot của mô hình LLaMa 2-Chat]

[Hình 5: Hướng dẫn cho gợi ý zero-shot của mô hình Flan-UL2]

D Ngưỡng cho đường cơ sở Tần suất Thực thể
Hình 6 hiển thị hiệu suất của đường cơ sở Tần suất Thực thể bằng cách thay đổi số lần tối thiểu một thực thể phải xuất hiện trong tài liệu đầu vào để được phân loại là nổi bật.

--- TRANG 14 ---
[Bảng 6: Các cặp Tài liệu-Thực thể trong các phân chia train, validation và test sau khi áp dụng phân chia thời gian]

[Bảng 7: Tham số để tạo nhãn mức độ nổi bật với gợi ý zero-shot]

[Hình 6: Hiệu suất của đường cơ sở Tần suất Thực thể với các ngưỡng khác nhau]

[Hình 7: Sơ đồ kiến trúc của mô hình Target Entity Masking]

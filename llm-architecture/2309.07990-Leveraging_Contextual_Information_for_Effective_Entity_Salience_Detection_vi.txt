# 2309.07990.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/llm-architecture/2309.07990.pdf
# Kích thước tệp: 1312054 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Tận dụng Thông tin Ngữ cảnh để Phát hiện Độ nổi bật của Thực thể Hiệu quả
Rajarshi Bhowmik Marco Ponza Atharva Tendle Anant Gupta
Rebecca Jiang†Xingyu Lu Qian Zhao Daniel Preo¸ tiuc-Pietro
Bloomberg
{rbhowmik6 ,dpreotiucpie }@bloomberg.net
Tóm tắt
Trong các tài liệu văn bản như bài báo tin tức, nội dung và các sự kiện chính thường xoay quanh một tập con của tất cả các thực thể được đề cập trong tài liệu. Những thực thể này, thường được coi là các thực thể nổi bật, cung cấp các gợi ý hữu ích về chủ đề của tài liệu cho người đọc. Việc xác định độ nổi bật của các thực thể được tìm thấy là hữu ích trong một số ứng dụng hạ nguồn như tìm kiếm, xếp hạng và tóm tắt tập trung vào thực thể, cùng với những ứng dụng khác. Các nghiên cứu trước đó về phát hiện thực thể nổi bật chủ yếu tập trung vào các mô hình học máy yêu cầu kỹ thuật đặc trưng nặng. Chúng tôi chỉ ra rằng việc tinh chỉnh các mô hình ngôn ngữ cỡ trung bình với kiến trúc kiểu cross-encoder mang lại những cải thiện hiệu suất đáng kể so với các phương pháp kỹ thuật đặc trưng. Để làm điều này, chúng tôi tiến hành một đánh giá toàn diện trên bốn tập dữ liệu có sẵn công khai sử dụng các mô hình đại diện cho họ mô hình ngôn ngữ được huấn luyện trước cỡ trung bình. Ngoài ra, chúng tôi chỉ ra rằng việc gợi ý zero-shot của các mô hình ngôn ngữ được điều chỉnh theo hướng dẫn cho kết quả kém hơn, cho thấy tính độc đáo và phức tạp của nhiệm vụ.
1 Giới thiệu
Nhiều nghiên cứu NLP đã nhấn mạnh tầm quan trọng của các thực thể trong việc hiểu ngữ nghĩa của một tài liệu (Wu et al., 2020b; Meij et al., 2012). Việc tự động xác định các thực thể trong các tài liệu văn bản không có cấu trúc và liên kết chúng với một cơ sở tri thức cơ bản, như Wikipedia, là một trong những nhiệm vụ NLP cốt lõi, với nhiều nhiệm vụ chia sẻ (Tjong Kim Sang and De Meulder, 2003; Strauss et al., 2016), các bộ đánh giá (Hoffart et al., 2011; Hovy et al., 2006; Pradhan et al., 2013; Rijhwani and Preotiuc-Pietro, 2020; Derczynski et al., 2016), và các nghiên cứu (Kolitsas et al., 2018; Nguyen et al., 2014) được dành riêng để giải quyết chúng.

Mặc dù một thực thể có thể đóng vai trò ngữ nghĩa quan trọng trong việc hiểu tài liệu, không phải tất cả các thực thể trong một tài liệu văn bản đều đóng vai trò như nhau. Một số thực thể là các chủ thể hoặc tác nhân trung tâm trong một tài liệu, xung quanh đó nội dung và các sự kiện chính xoay quanh. Những thực thể khác chỉ được đề cập để cung cấp bối cảnh bổ sung cho sự kiện chính. Ví dụ, một số thực thể có thể là các tác nhân trong các sự kiện phụ, trong khi những thực thể khác được coi là không cung cấp thông tin cho việc hiểu tài liệu. Do đó, độ nổi bật của thực thể trong một văn bản được định nghĩa là một đánh giá nhị phân hoặc thứ tự để định lượng mức độ mà một thực thể mục tiêu là trung tâm đối với một đoạn văn bản nhất định (Gamon et al., 2013; Dunietz and Gillick, 2014). Hình 1 cung cấp một ví dụ văn bản cùng với các thực thể được đề cập và độ nổi bật của chúng. Chúng tôi lưu ý rằng độ nổi bật của một thực thể đối với một văn bản là độc lập với sự quan tâm của người dùng khi đọc hoặc tìm kiếm tài liệu (Gamon et al., 2013), điều này thường được gọi là mức độ liên quan của thực thể. Nó cũng khác biệt với tầm quan trọng của thực thể, điều này định lượng tầm quan trọng tổng thể của thực thể độc lập với tài liệu. Việc tự động suy luận độ nổi bật của thực thể được chỉ ra là có thể hỗ trợ tìm kiếm (Gamon et al., 2013), cải thiện kết quả xếp hạng (Xiong et al., 2018), phát hiện thực thể (Trani et al., 2018), và cho phép các ứng dụng tập trung vào thực thể như tóm tắt tập trung vào thực thể (Maddela et al., 2022).

†Công việc được thực hiện khi tác giả liên kết với Bloomberg

Hình 1: Một ví dụ về tài liệu với các thực thể nổi bật và không nổi bật. Các đề cập thực thể được tô sáng trong văn bản.arXiv:2309.07990v2  [cs.CL]  2 Apr 2024

--- TRANG 2 ---
Trong bài báo này, chúng tôi nghiên cứu hiệu quả của các Mô hình Ngôn ngữ Được huấn luyện trước dựa trên Transformer (PLMs) trong nhiệm vụ phát hiện độ nổi bật của thực thể. Các nghiên cứu trước đó về xác định độ nổi bật của thực thể dựa vào kỹ thuật đặc trưng nặng để tạo ra các đặc trưng bao phủ rõ ràng các khía cạnh liên quan, chẳng hạn như tần suất thực thể (Dunietz and Gillick, 2014; Dojchinovski et al., 2016), vị trí của các đề cập thực thể trong một tài liệu (Dunietz and Gillick, 2014; Trani et al., 2018), quan hệ với các thực thể khác (Trani et al., 2018), các đặc trưng tài liệu, chẳng hạn như độ dài của nó (Gamon et al., 2013) và các đặc trưng từ vựng, chẳng hạn như tên của thực thể hoặc ngữ cảnh của nó. Chỉ có một nghiên cứu gần đây duy nhất đã cố gắng sử dụng PLMs trong một pipeline bao gồm phát hiện thực thể chính, mặc dù phạm vi đánh giá bị giới hạn trong một tập dữ liệu hiệu suất cao duy nhất (Zhao et al., 2021). Ngược lại, phương pháp được đề xuất của chúng tôi sử dụng kiến trúc cross-encoder nơi tên hoặc bí danh của thực thể mục tiêu và các đề cập ngữ cảnh của nó trong một tài liệu văn bản được mã hóa bởi một bộ mã hóa PLM. Bộ phân loại sử dụng biểu diễn ngữ cảnh và, tùy chọn, thông tin vị trí về thực thể được mã hóa thông qua vector nhúng vị trí decile của các đề cập để xác định điểm độ nổi bật của một thực thể mục tiêu.

Chúng tôi tiến hành thí nghiệm trên bốn tập dữ liệu có sẵn công khai, hai trong số đó được chú thích bởi con người và hai được tuyển chọn bán tự động. Chúng tôi tinh chỉnh một số cross-encoders sử dụng PLMs và chứng minh rằng chúng mang lại những cải thiện nhất quán và đáng kể so với các phương pháp dựa trên đặc trưng, cũng như việc gợi ý các PLMs được điều chỉnh theo hướng dẫn. Điều sau cho thấy tính mới lạ và phức tạp của nhiệm vụ phát hiện độ nổi bật của thực thể, điều này yêu cầu mô hình học kiến thức ngữ nghĩa đặc thù cho nhiệm vụ đáng kể cho nhiệm vụ hiểu ngôn ngữ tự nhiên này.

Các đóng góp của chúng tôi trong bài báo này là như sau:
• Chúng tôi đề xuất một kiến trúc kiểu cross-encoder với mã hóa rõ ràng thông tin vị trí để phát hiện độ nổi bật của thực thể cho thấy những cải thiện nhất quán từ 7 – 24.4 điểm F1 so với các phương pháp kỹ thuật đặc trưng trước đó.
• Chúng tôi thiết lập một bộ đánh giá thống nhất của hai tập dữ liệu được chú thích bởi con người và hai tập dữ liệu được tuyển chọn bán tự động cho nhiệm vụ phát hiện độ nổi bật của thực thể mà chúng tôi mong đợi sẽ có lợi cho nghiên cứu tương lai về nhiệm vụ này;
• Một phân tích đa mặt về hành vi dự đoán của các mô hình.

2 Nghiên cứu Liên quan
Hiểu về chủ đề của một tài liệu là một trong những mục tiêu lâu dài của nghiên cứu trong cả Truy xuất Thông tin và Xử lý Ngôn ngữ Tự nhiên (Gamon et al., 2013). Một số loại phương pháp đã được đề xuất, bao gồm trích xuất các thuật ngữ chính (Hulth, 2003; Mihalcea and Tarau, 2004), xác định các chủ đề tiềm ẩn (Blei et al., 2003), hoặc tạo tóm tắt văn bản (Erkan and Radev, 2004).

Gần đây đã có sự tập trung vào việc sử dụng các thực thể để hiểu nội dung của một tài liệu. Hướng tới mục tiêu này, nhiệm vụ độ nổi bật của thực thể đã được mô tả lần đầu cho các trang web trong (Gamon et al., 2013) và cho nội dung tin tức trong (Dunietz and Gillick, 2014).

Nhiệm vụ này có thể được xem như một dạng hạn chế của trích xuất từ khóa hoặc cụm từ khóa (Alami Merrouni et al., 2020) nếu độ nổi bật là nhị phân. Đối với phần còn lại của nghiên cứu này, chúng tôi sẽ sử dụng khái niệm độ nổi bật như được mô tả trong (Gamon et al., 2013).

Các nhãn độ nổi bật cho các thực thể được thu thập bằng cách sử dụng crowdsourcing các nhãn từ nhiều người đánh giá để xác định các thực thể nổi bật (Gamon et al., 2013; Dojchinovski et al., 2016; Trani et al., 2018; Maddela et al., 2022) hoặc bằng cách sử dụng các proxy. Ví dụ, (Dunietz and Gillick, 2014) đưa ra giả thuyết rằng các thực thể nổi bật là những thực thể xuất hiện trong tóm tắt của bài báo. (Wu et al., 2020a) xác định một thực thể là nổi bật nếu danh mục Wikinews tương ứng với thực thể cũng được gắn nhãn là danh mục của bài báo.

Các nghiên cứu trong quá khứ chủ yếu đề xuất các phương pháp học máy để suy luận độ nổi bật của một thực thể nhất định dựa vào các đặc trưng được tạo thủ công. Các đặc trưng có thể được tính toán từ các đề cập thực thể mục tiêu và chỉ tài liệu có thể được phân loại thành các loại sau: vị trí (ví dụ: vị trí trong tài liệu, nếu thực thể có trong tóm tắt) (Dunietz and Gillick, 2014), dựa trên số lượng (ví dụ: số lượng tham chiếu đến thực thể) (Dunietz and Gillick, 2014; Wu et al., 2020a), ngữ cảnh cục bộ (Trani et al., 2018), hoặc ngữ cảnh toàn cục (Ponza et al., 2019). Hơn nữa, độ phân giải độ nổi bật thực thể chung có thể được thực hiện bằng cách tạo các đặc trưng sử dụng đồ thị thực thể (ví dụ: tính trung tâm trong đồ thị thực thể) (Dunietz and Gillick, 2014; Trani et al., 2018). Cuối cùng, các nghiên cứu trong quá khứ cũng cho thấy rằng việc kết hợp kiến thức bên ngoài về các thực thể từ các cơ sở tri thức có thể tăng cường hiệu suất dự đoán (Dojchinovski et al., 2016).

Việc tự động suy luận độ nổi bật cho các thực thể có thể trực tiếp có lợi cho nhiều ứng dụng hạ nguồn, chẳng hạn như cải thiện kết quả xếp hạng cho các truy vấn chứa thực thể (Xiong et al., 2018) hoặc cải thiện

--- TRANG 3 ---
hiệu suất phát hiện thực thể bằng mô hình hóa chung (Trani et al., 2018). Hơn nữa, bằng cách suy luận độ nổi bật, các ứng dụng tập trung vào thực thể mới có thể được xây dựng, chẳng hạn như tô sáng các thực thể nổi bật trong tìm kiếm (Gamon et al., 2013), cải thiện khả năng diễn giải của các xu hướng tin tức thông qua các thực thể nổi bật (Ponza et al., 2021), hoặc xác định các thực thể để tạo tóm tắt tập trung vào thực thể của các câu chuyện tin tức (Maddela et al., 2022; Hofmann-Coyle et al., 2022).

3 Định nghĩa Vấn đề
Chúng tôi sử dụng khái niệm độ nổi bật như được giới thiệu trong (Gamon et al., 2013): các thực thể nổi bật là các thực thể được đề cập rõ ràng trong tài liệu và quan trọng một cách khách quan như một hàm của cấu trúc của văn bản.

Mục tiêu của mô hình độ nổi bật là tạo ra một điểm độ nổi bật duy nhất ψ(e) cho thực thể e chỉ sử dụng tài liệu D và các đề cập thực thể rõ ràng Me. Chúng tôi coi việc sử dụng kiến thức bên ngoài, chẳng hạn như thông tin về các thực thể từ các cơ sở tri thức, là nằm ngoài phạm vi và để dành việc tích hợp kiến thức như vậy cho nghiên cứu tương lai.

4 Phương pháp
Các Mô hình Ngôn ngữ Được huấn luyện trước (PLMs) đã cho thấy khả năng đáng chú ý trong việc mã hóa kiến thức cú pháp và ngữ nghĩa trong các tham số của chúng (Tenney et al., 2018, 2019) có thể được tận dụng khi được tinh chỉnh trên các nhiệm vụ hiểu ngôn ngữ tự nhiên (NLU) hạ nguồn. Chúng tôi đưa ra giả thuyết rằng PLMs có thể được khai thác để giúp phát hiện độ nổi bật của thực thể, một nhiệm vụ NLU cấp tài liệu dựa trên mục tiêu. Trong phần này, chúng tôi trình bày một kiến trúc dựa trên thiết lập cross-encoder được điều chỉnh cho nhiệm vụ phát hiện độ nổi bật của thực thể.

4.1 Cross-encoder
Mã hóa Cho một tài liệu D và một thực thể mục tiêu e, được đề cập trong tài liệu, chúng tôi nối tên của thực thể mục tiêu và tài liệu sử dụng một token đặc biệt [SEP]. Sau đó chúng tôi mã hóa văn bản sử dụng một bộ mã hóa được huấn luyện trước dựa trên Transformer. Hình 2 cho thấy biểu diễn đồ họa của mô hình cross-encoder. Thiết lập này cho phép mô hình có sự chú ý chéo sâu giữa thực thể mục tiêu và toàn bộ tài liệu. Lưu ý rằng chúng tôi sử dụng các token đánh dấu đặc biệt [BEGIN_ENTITY] và [END_ENTITY] xung quanh mỗi đề cập m∈ Me của thực thể e trong tài liệu D.

Transformer 
[CLS]   Tên Thực thể Mục tiêu [SEP] Văn bản Tài liệu Điểm Độ nổi bật 
Biểu diễn của [CLS] FFNN ψ(e) 
Các vị trí decile được mã hóa [h  [CLS] , h pe ] 

Hình 2: Biểu diễn đồ họa của kiến trúc cross-encoder với mã hóa vị trí decile.

Mã hóa Vị trí Chúng tôi tính toán các vị trí decile cho mỗi đề cập thực thể (m∈ Me) trong tài liệu D bằng cách lấy một chỉ số vị trí pm∈ {0,1, . . . , 9}, cho biết phần nào của tài liệu mà đề cập thuộc về nếu tài liệu được phân chia thành 10 phần bằng nhau. Tùy thuộc vào số lượng và vị trí của các đề cập, vector có thể chứa nhiều giá trị khác không trong vector p. Ví dụ, nếu một thực thể e có 1 đề cập trong decile đầu tiên, 2 trong decile thứ hai, và 1 đề cập trong decile thứ năm, thì đầu vào cho bộ mã hóa vị trí sẽ là pm= [1,1,0,0,1,0,0,0,0,0].

Lưu ý rằng chúng tôi không nắm bắt số lượng đề cập trong mỗi decile trong pm. Để có được các nhúng vị trí, chúng tôi sử dụng một lớp nhúng ánh xạ các chỉ số vị trí thành một vector dày đặc có chiều dmodel , chính thức hpe(m) =Embedding (pm).

Tính điểm Biểu diễn đầu ra của token [CLS] được nối với vector nhúng vị trí trung bình hpe và được đưa vào một mô-đun tính điểm tạo ra một điểm độ nổi bật ψ(e)∈[0,1] cho thực thể e. Bộ tính điểm độ nổi bật là một mạng truyền thẳng với một đầu hàm tính điểm sigmoid. Chính thức,

ψ(e) =σ(FFN(h[CLS]||hpe))

4.2 Tối ưu hóa
Chúng tôi tinh chỉnh mô hình được mô tả ở trên bằng cách giảm thiểu mất mát entropy chéo nhị phân được tính toán sử dụng các nhãn độ nổi bật nhị phân thực tế và điểm độ nổi bật dự đoán ψ(e).

5 Tập dữ liệu
Trong phần này, chúng tôi mô tả bộ đánh giá độ nổi bật thực thể của chúng tôi, bao gồm bốn tập dữ liệu: hai

--- TRANG 4 ---
Tập dữ liệu NYT-Salience WN-Salience SEL EntSUM
# Tài liệu 110,463 6,956 365 693
Độ dài tài liệu (ký tự trung bình) 5,079 2,106 1,660 4,995
# Thực thể duy nhất 179,341 23,205 6,779 7,854
# Đề cập 4,405,066 145,081 19,729 20,784
% Thực thể nổi bật 14% 27% 10% 39%
Thực tế cơ bản Căn chỉnh Tóm tắt Căn chỉnh Danh mục Con người Con người

Bảng 1: Thống kê tóm tắt và phương pháp thu thập nhãn cho các tập dữ liệu được sử dụng trong các thí nghiệm của chúng tôi.

tập dữ liệu được tuyển chọn sử dụng các phương pháp bán tự động và hai sử dụng chú thích của con người. Chúng tôi cung cấp thống kê tóm tắt của các tập dữ liệu này và phương pháp thu thập nhãn trong Bảng 1.

NYT-Salience Tập dữ liệu này được giới thiệu trong (Dunietz and Gillick, 2014) và là tập dữ liệu lớn nhất cho đến nay để phát hiện độ nổi bật của thực thể. Tập dữ liệu được tuyển chọn với giả định rằng các thực thể nổi bật được đề cập trong tóm tắt của một bài báo tin tức trong NYT Corpus (Sandhaus, 2008). Các thực thể và các đề cập của chúng được xác định sử dụng một pipeline NLP cổ điển bao gồm gắn thẻ POS, phân tích cú pháp phụ thuộc, và trích xuất cụm danh từ. Mặc dù quy mô lớn, quá trình tạo tập dữ liệu tự động có thể đưa vào nhiễu như được chứng thực bởi các con số thỏa thuận vừa phải với các chú thích viên con người trên một tập con của dữ liệu. Tập dữ liệu chứa một nhãn độ nổi bật nhị phân cho mỗi thực thể.

WN-Salience Được giới thiệu trong (Wu et al., 2020a), đây là một tập dữ liệu khác được tuyển chọn tự động bao gồm các bài báo Wikinews. Những bài này được chú thích với các danh mục Wikinews bởi các tác giả của chúng. WN-Salience xác định các thực thể nổi bật bằng cách sử dụng giả thuyết rằng một thực thể là nổi bật nếu danh mục Wikinews tương ứng với thực thể cũng được gắn nhãn là một danh mục của bài báo. Tương tự như NYT-Salience, tập dữ liệu này có các nhãn độ nổi bật nhị phân.

SEL Đây là một tập dữ liệu khác dựa trên Wikinews được phát hành bởi (Trani et al., 2018). Tuy nhiên, không giống như WN-Salience, tập dữ liệu này được chú thích bởi con người, nơi nhiều chú thích viên con người xếp hạng độ nổi bật của các thực thể thành một trong bốn danh mục. Để phù hợp với các nhãn nhị phân của các tập dữ liệu khác, chúng tôi ánh xạ 4 danh mục thành các nhãn nhị phân {0,1} bằng cách ánh xạ hai lớp dưới cùng thành không nổi bật và hai lớp trên cùng thành nổi bật.

EntSUM Tập dữ liệu này được giới thiệu trong (Maddela et al., 2022). Để xây dựng tập dữ liệu này, một tập các thực thể được chọn ngẫu nhiên trải rộng trên một tập con 693 bài báo từ corpus NYT được gán các nhãn độ nổi bật bởi các chú thích viên con người trên thang điểm bốn điểm, dao động từ [0,3]. Đối với mỗi cặp thực thể tài liệu, hai chú thích độc lập được thu thập, được tăng lên đến 5 trong trường hợp bất đồng. Nếu điểm chú thích trung bình lớn hơn 1.5 cho một thực thể, nó được gán một nhãn độ nổi bật tích cực.

5.1 Làm giàu Dữ liệu với Các Đề cập Được Suy luận
Ngoại trừ EntSUM, các tập dữ liệu không có các offset đề cập thực thể rõ ràng như chú thích, điều này cần thiết cho nhiều phương pháp dựa trên đặc trưng và để tính toán các nhúng vị trí. Trong khi SEL chỉ chứa các văn bản bề mặt đề cập cho mỗi thực thể, NYT-Salience và WN-Salience chỉ cung cấp các chỉ số ký tự bắt đầu và kết thúc (aka offset đề cập) của đề cập đầu tiên của một thực thể. Để làm điều này, chúng tôi suy luận các đề cập bổ sung của một thực thể trong văn bản sử dụng sự kết hợp của Flair NER (Akbik et al., 2019) và khớp mẫu.

Đối với SEL, vì các đề cập có sẵn, chúng tôi sử dụng một phương pháp khớp mẫu để khớp văn bản bề mặt của các đề cập để suy luận các offset đề cập. Đối với NYT-Salience và WN-Salience, chúng tôi đầu tiên sử dụng Flair NER để xác định các đề cập của các thực thể có tên trong văn bản. Chúng tôi cố gắng khớp các đề cập này với đề cập đầu tiên của mỗi thực thể trong tài liệu được cung cấp trong các tập dữ liệu tương ứng. Vì văn bản bề mặt của các đề cập khác có thể khác với đề cập đầu tiên, chúng tôi bổ sung sử dụng sự chồng chéo giữa văn bản bề mặt của một đề cập và tên thực thể như một đề cập ứng viên cho thực thể đó. Áp dụng phương pháp này, chúng tôi suy luận các đề cập bổ sung của một thực thể trong văn bản và các offset của chúng. Trong khi quá trình này có thể đưa vào một số nhiễu, chất lượng tổng thể của các tập dữ liệu được nâng cao thông qua quá trình này.

6 Thí nghiệm
Chúng tôi thí nghiệm trên bộ đánh giá độ nổi bật thực thể của chúng tôi với phương pháp dựa trên PLM được đề xuất, các phương pháp ML và dựa trên heuristic khác được sử dụng trong nghiên cứu trước đây, cũng như một PLM được điều chỉnh theo hướng dẫn.

--- TRANG 5 ---
6.1 Phân chia Dữ liệu
Các nghiên cứu trước đây (Dunietz and Gillick, 2014; Trani et al., 2018; Wu et al., 2020a) sử dụng các phân chia train/validation/test không nhất quán (hoặc không được báo cáo). Các tập dữ liệu NYT-Salience và WN-Salience được cung cấp với các phân chia train/test (nhưng không có validation), trong khi tập dữ liệu SEL được cung cấp mà không có bất kỳ phân chia nào. Điều này làm cho việc đánh giá các nghiên cứu trước đây với so sánh công bằng giữa các mô hình trở nên khó khăn. Để khắc phục vấn đề này, chúng tôi thực hiện phân chia theo thời gian của các tập huấn luyện ban đầu của NYT-Salience và WN-Salience thành các tập train/validation mới dựa trên thời gian xuất bản của các câu chuyện tin tức, điều này cung cấp một thiết lập kiểm tra thực tế hơn (Huang and Paul, 2018; Rijhwani and Preotiuc-Pietro, 2020). Chúng tôi cũng thực hiện phân chia theo thời gian của các tập dữ liệu SEL và EntSUM thành các tập train/validation/test. Các chi tiết thêm về phân chia tập dữ liệu được cung cấp trong Phụ lục A.

6.2 Đường cơ sở
Đầu tiên, chúng tôi liệt kê tất cả các phương pháp được sử dụng trong nghiên cứu trước đây, cho đó chúng tôi báo cáo kết quả từ các bài báo gốc.

• Câu Đầu tiên. Phân loại một thực thể là nổi bật nếu nó xuất hiện trong câu đầu tiên của phần thân tài liệu; được sử dụng trong cả (Dunietz and Gillick, 2014) và (Wu et al., 2020a).

• Vị trí & Tần suất (Dunietz and Gillick, 2014). Đưa chỉ số câu đầu tiên và các đặc trưng tần suất của một thực thể vào một mô hình hồi quy logistic.

• Tất cả Đặc trưng (Dunietz and Gillick, 2014). Sử dụng một loạt các đặc trưng dựa trên vị trí, tần suất, và tín hiệu PageRank được đưa vào một mô hình hồi quy logistic.

• SEL (Trani et al., 2018). Sử dụng một kết hợp các đặc trưng dựa trên vị trí, tần suất, và thống kê đồ thị Wikipedia được đưa vào thuật toán Gradient Boosted Decision Tree được triển khai trong sklearn (Pedregosa et al., 2011).

• SWAT (Ponza et al., 2019). Sử dụng một tập các đặc trưng tương tự như Phương pháp SEL được mô tả ở trên, với việc bổ sung các đặc trưng dựa trên nhúng thực thể. Tất cả các đặc trưng được đưa vào thuật toán Gradient Boosted Decision Tree được triển khai trong XGBoost (Chen et al., 2015).

• Đặc trưng Vị trí (Wu et al., 2020a). Sử dụng chỉ số của câu đầu tiên mà thực thể được đề cập như một đặc trưng trong một mô hình hồi quy logistic. Phương pháp này cung cấp kết quả tốt nhất trên tập dữ liệu WN Salience trong (Wu et al., 2020a).

Tiếp theo, chúng tôi tái triển khai một tập các phương pháp phổ biến dựa trên các đường cơ sở trên để có thể kiểm tra chúng trên tất cả bốn tập dữ liệu. Điều này đảm bảo việc đánh giá được thực hiện trên cùng một thiết lập thí nghiệm.

• Tiêu đề Vị trí. Phân loại một thực thể là nổi bật nếu nó xuất hiện trong tiêu đề của tài liệu đầu vào.

• Tiêu đề & Lead Vị trí. Phân loại một thực thể là nổi bật nếu nó xuất hiện trong tiêu đề của tài liệu hoặc trong câu đầu tiên (câu lead) của tài liệu.

• Tần suất Thực thể. Phân loại một thực thể là nổi bật nếu chúng thường xuyên hơn một giá trị nhất định. Đối với mỗi tập dữ liệu, chúng tôi tính toán các ngưỡng khác nhau và báo cáo kết quả tốt nhất. Các ngưỡng có thể được tìm thấy trong Phụ lục.

• Đặc trưng & GBDT. Phương pháp này sử dụng các đặc trưng phổ biến nhất từ các nghiên cứu trước đây (Dunietz and Gillick, 2014; Wu et al., 2020a; Trani et al., 2018; Ponza et al., 2019) — tức là, chỉ số câu đầu tiên của thực thể, và tần suất thực thể — và đưa chúng vào một mô hình GBDT được triển khai sử dụng LightGBM (Ke et al., 2017).

• SEL GBDT. Tuân theo phương pháp từ (Trani et al., 2018) và sử dụng GBDT của sklearn (Pedregosa et al., 2011) để huấn luyện một mô hình trên các đặc trưng được cung cấp với tập dữ liệu SEL.

• Che thực thể mục tiêu. Phương pháp này đưa đầu vào cho một bộ mã hóa dựa trên Transformer (RoBERTa-base) với các đề cập thực thể mục tiêu được biểu diễn thông qua một token mặt nạ đặc biệt. Dự đoán độ nổi bật được thu thập bằng cách tập hợp trung bình các biểu diễn token mặt nạ và truyền điều này qua một mạng truyền thẳng.

• Gợi ý zero-shot. Chúng tôi kiểm tra các LLMs được điều chỉnh theo hướng dẫn sử dụng gợi ý zero-shot. Gợi ý giới thiệu mô tả nhiệm vụ, theo sau là văn bản đầu vào và một thực thể mục tiêu, và nó đặt một câu hỏi có/không. Nó mong đợi mô hình tạo ra 'Có' hoặc 'Không' như một câu trả lời. Các LLMs, đã được điều chỉnh theo hướng dẫn trên một bộ sưu tập lớn các nhiệm vụ NLU, cố gắng cung cấp một câu trả lời dựa trên gợi ý, văn bản đầu vào, và thực thể mục tiêu. Họ mô hình này đã được chứng minh là mạnh mẽ và linh hoạt trên nhiều bộ đánh giá (Chung et al., 2022). Chúng tôi sử dụng Flan-UL2 (20B) (Tay et al., 2023) và LLaMa 2-Chat (7B) (Touvron et al., 2023) để đánh giá.

--- TRANG 6 ---
Nguồn Loại Phương pháp NYT-Salience WN-Salience
P R F1 P R F1
(Dunietz and Gillick, 2014) Heuristic Câu Đầu tiên 59.5 37.8 46.2 – – –
(Dunietz and Gillick, 2014) ML Vị trí & Tần suất 59.3 61.3 60.3 – – –
(Dunietz and Gillick, 2014) ML Tất cả Đặc trưng 60.5 63.5 62.0 – – –
(Ponza et al., 2019) ML SWAT 62.4 66.0 64.1 – – –
(Wu et al., 2020a) Heuristic Câu Đầu tiên 56.0 41.0 47.3 47.9 53.2 50.4
(Wu et al., 2020a) ML Đặc trưng Vị trí 19.0 41.3 26.0 29.1 78.9 42.5
(Wu et al., 2020a) ML Đặc trưng & GBDT 39.2 59.7 47.3 29.2 48.1 36.3
Các Triển khai của Chúng tôi Heuristic Tiêu đề Vị trí 57.5 42.0 48.5 46.1 51.5 48.7
Heuristic Tiêu đề & Lead Vị trí 49.8 55.4 52.5 41.0 60.0 48.7
Heuristic Tần suất Thực thể 53.7 53.3 53.6 37.3 61.9 46.6
ML Đặc trưng & GBDT 61.0 57.4 59.2 46.2 53.3 49.5
PLM (RoBERTa) Che Thực thể Mục tiêu 64.6 50.2 56.5 57.0 65.4 60.9
Các Mô hình của Chúng tôi PLM (RoBERTa) cross-encoder 75.9 87.1 81.1 71.8 73.6 72.7
PLM (DeBERTa) cross-encoder 77.5 87.4 82.1 71.5 78.3 74.8
PLM (RoBERTa) cross-encoder w/ position emb. 78.7 84.2 81.4 71.2 76.7 73.8
PLM (DeBERTa) cross-encoder w/ position emb. 75.9 88.4 81.7 73.3 76.1 74.7

Bảng 2: Kết quả trên các tập dữ liệu NYT-Salience và WN-Salience. Thực tế cơ bản của các tập dữ liệu này được tạo ra thông qua căn chỉnh tóm tắt/danh mục. Phần trên trình bày kết quả như được báo cáo ban đầu trong các bài báo nguồn.

Nguồn Loại Phương pháp SEL EntSUM
P R F1 P R F1
(Trani et al., 2018) ML SEL (w/ 5-fold cross val.) 50.0 61.0 52.0 – – –
(Ponza et al., 2019) ML SWAT (w/ 5-fold cross val.) 58.0 64.9 61.2 – – –
Các Triển khai của Chúng tôi Heuristic Tiêu đề Vị trí 26.6 78.4 39.7 60.7 18.5 28.4
Heuristic Tiêu đề & Lead Vị trí 22.1 87.1 35.3 51.2 31.6 39.1
Heuristic Tần suất Thực thể 13.5 57.8 21.9 48.4 54.0 51.0
ML Đặc trưng & GBDT 26.6 78.4 39.7 60.7 52.0 56.0
ML SEL GBDT 71.1 47.8 57.1 – – –
PLM (RoBERTa) Che Thực thể Mục tiêu 36.3 13.8 20.0 63.0 41.7 50.2
Các Mô hình của Chúng tôi PLM (RoBERTa) cross-encoder 51.6 73.6 60.6 65.5 60.6 63.0
PLM (DeBERTa) cross-encoder 64.1 73.6 68.5 64.9 59.2 61.9
PLM (RoBERTa) cross-encoder w/ position emb. 63.0 69.9 66.3 67.5 57.0 61.8
PLM (DeBERTa) cross-encoder w/ position emb. 67.3 62.4 64.7 72.1 51.5 60.1

Bảng 3: Kết quả trên các tập dữ liệu SEL và EntSUM. Thực tế cơ bản của các tập dữ liệu này được tạo ra thông qua chú thích của con người. Phần trên trình bày kết quả như được báo cáo ban đầu trong các bài báo nguồn.

6.3 Thiết lập Thí nghiệm
Chúng tôi sử dụng RoBERTa-base (Liu et al., 2019) và DeBERTa-v3-base (He et al., 2023) làm PLM cơ sở cho các thí nghiệm. Đối với mỗi mô hình cơ sở này, chúng tôi huấn luyện cả mô hình cross-encoder và mô hình cross-encoder được tăng cường với các nhúng vị trí decile.

Để huấn luyện các mô hình được đề xuất của chúng tôi, chúng tôi sử dụng AdamW (Loshchilov and Hutter, 2019) làm bộ tối ưu hóa. Chúng tôi thực hiện tìm kiếm siêu tham số cho tốc độ học sử dụng tập giá trị sau: {0.001,0.0005,0.0002,0.0001,0.00005}. Chúng tôi huấn luyện các mô hình của chúng tôi trong tối đa 10 epochs với dừng sớm dựa trên hiệu suất tập validation. Chúng tôi chọn các checkpoint mô hình có hiệu suất tốt nhất cho mỗi tập dữ liệu dựa trên hiệu suất trên tập validation. Trong Bảng 2 và 3, chúng tôi báo cáo hiệu suất của các mô hình của chúng tôi và các đường cơ sở sử dụng các chỉ số phân loại tiêu chuẩn (tức là, Precision, Recall, và F1) trên lớp tích cực (nổi bật), theo nghiên cứu trước đây về độ nổi bật thực thể.

Để huấn luyện và suy luận của mỗi mô hình dựa trên Transformer, chúng tôi sử dụng một GPU NVIDIA V100 với bộ nhớ GPU 32GB, 4 CPUs, và 128 GB bộ nhớ chính.

6.4 Kết quả
Trong Bảng 2 và 3, chúng tôi trình bày kết quả thí nghiệm của các đường cơ sở và các mô hình được đề xuất của chúng tôi trên bốn tập dữ liệu được mô tả trong Phần 5.

So sánh với các phương pháp dựa trên đặc trưng. Chúng tôi

--- TRANG 7 ---
quan sát rằng mô hình cross-encoder vượt trội đáng kể so với tất cả các mô hình đường cơ sở về điểm F1. Nó cũng mang lại độ chính xác tốt hơn so với các đường cơ sở cho ba trong số bốn tập dữ liệu. Chỉ đối với tập dữ liệu SEL, mô hình SEL GBDT được huấn luyện trên các đặc trưng được tính toán trước có sẵn công khai mới tạo ra một mô hình với độ chính xác tốt hơn cross-encoder.

Chúng tôi quan sát rằng việc thêm nhúng vị trí decile với cross-encoder cải thiện độ chính xác trên tất cả các tập dữ liệu, nhưng cũng làm giảm recall trong mọi tập dữ liệu ngoại trừ NYT-Salience.

Phương pháp Che Thực thể Mục tiêu, cũng tận dụng thông tin ngữ cảnh với một mô hình dựa trên transformer, mang lại kết quả hỗn hợp. Nhìn chung, mô hình có thể thu được độ chính xác tốt hơn so với các mô hình dựa trên đặc trưng cho tất cả các tập dữ liệu ngoại trừ SEL, nhưng mô hình gặp khó khăn với recall kém trên tất cả các tập dữ liệu, dẫn đến điểm F1 tệ hơn đáng kể đặc biệt khi so sánh với các mô hình cross-encoder.

Việc tái triển khai của chúng tôi về các phương pháp vị trí và phương pháp GBDT nhất quán với hiệu suất được báo cáo trong các nghiên cứu trước đây. Sự khác biệt trong các con số có thể được quy cho việc làm giàu các tập dữ liệu với các đề cập được suy luận (Phần 5.1) và việc phân chia dữ liệu train/dev/test rõ ràng được sử dụng trong các thí nghiệm của chúng tôi (Phần 6.1).

6.5 Gợi ý zero-shot của các mô hình ngôn ngữ lớn
Chúng tôi công thức hóa vấn đề phát hiện độ nổi bật với gợi ý zero-shot như sau: cho một định nghĩa về nhiệm vụ độ nổi bật thực thể và văn bản tài liệu, chúng tôi yêu cầu mô hình tạo ra "có" hoặc "không" nếu một thực thể cụ thể là nổi bật hay không. Chúng tôi thí nghiệm với hai mô hình mã nguồn mở (Flan-UL2 (20B) và LLaMa 2-Chat (7B)) có sẵn trên Hugging Face¹, và trình bày kết quả trong Bảng 4. Theo hiểu biết tốt nhất của chúng tôi, đây là đánh giá đầu tiên về gợi ý zero-shot của các mô hình được điều chỉnh theo hướng dẫn cho nhiệm vụ phát hiện độ nổi bật thực thể. Chúng tôi quan sát rằng mô hình LLaMa 2-Chat với 7 tỷ tham số không thể mang lại bất kỳ kết quả có ý nghĩa nào vì nó chỉ tạo ra các nhãn tích cực cho tất cả các điểm dữ liệu (do đó chúng tôi quan sát 100% recall). Mô hình Flan-UL2 có thể tạo ra cả nhãn tích cực và tiêu cực. Tuy nhiên, độ chính xác vẫn quá thấp trên các tập dữ liệu. Chúng tôi thảo luận thêm về nguyên nhân của hiệu suất này trong Phụ lục (Phần C), cùng với các chi tiết triển khai. Nhìn chung, các thí nghiệm này gợi ý rằng phát hiện độ nổi bật thực thể là một nhiệm vụ độc đáo không tương tự với bất kỳ nhiệm vụ nào khác mà hai mô hình này được điều chỉnh theo hướng dẫn.

¹www.huggingface.com

7 Phân tích
Trong phần này, chúng tôi thực hiện phân tích các dự đoán của mô hình để có được nhiều hiểu biết hơn về hành vi của mô hình và hiểu các hướng tiềm năng để cải thiện thêm. Do đó chúng tôi phân tích hiệu suất theo các yếu tố khác nhau bao gồm: tầm quan trọng của việc suy luận tất cả các đề cập thực thể, vị trí của đề cập thực thể đầu tiên, và tần suất đề cập thực thể.

7.1 Tác động của Các Đề cập Được Suy luận
Trong Phần 5.1, chúng tôi suy luận các đề cập bổ sung của một thực thể cho các tập dữ liệu NYT-Salience và WN-Salience. Chúng tôi so sánh hiệu suất của mô hình tốt nhất của chúng tôi tận dụng nhiều đề cập của một thực thể với phiên bản của nó được huấn luyện chỉ với các đề cập đầu tiên của các thực thể trong một tài liệu. Các định dạng đầu vào cụ thể cho thí nghiệm này được trình bày trong Phụ lục B. Kết quả trong Bảng 5 cho thấy việc làm như vậy liên tục cải thiện hiệu suất của các mô hình của chúng tôi trên tất cả các tập dữ liệu. Cụ thể, đối với tập dữ liệu lớn nhất, NYT-Salience, mô hình của chúng tôi đạt được một cải thiện đáng kể 27.3 điểm F1. Thí nghiệm này cho thấy tầm quan trọng của việc tăng cường các tập dữ liệu của chúng tôi với các đề cập bổ sung và tầm quan trọng của việc mô hình hóa rõ ràng thông tin ngữ cảnh có mặt xung quanh tất cả các đề cập thực thể.

7.2 Phân tích Phân tầng về Vị trí Đề cập Đầu tiên
Chúng tôi so sánh các mô hình cross-encoder của chúng tôi với mô hình Đặc trưng & GBDT, đường cơ sở được tái triển khai của chúng tôi dựa vào các đặc trưng phổ biến nhất được sử dụng trong các nghiên cứu trước đây (Dunietz and Gillick, 2014; Wu et al., 2020a; Trani et al., 2018). Như được hiển thị trong kết quả từ Bảng 2 và 3, trong số các đặc trưng khác, các đặc trưng vị trí là thông tin nhất cho độ nổi bật. Theo trực giác, nếu một thực thể được đề cập trong tiêu đề hoặc trong câu đầu tiên của một bài báo tin tức, có xác suất cao rằng thực thể đó là nổi bật.

Hình 3 cho thấy rằng tất cả các mô hình hoạt động tốt khi đề cập đầu tiên rơi vào tiêu đề hoặc câu đầu tiên của tài liệu. Chúng tôi nhận thấy rằng các mô hình cross-encoder liên tục vượt trội hơn mô hình Đặc trưng & GBDT và những cải thiện lớn nhất được quan sát trong các tập dữ liệu SEL và WN-Salience. Quan sát này cho thấy rằng các mô hình cross-encoder có thể

--- TRANG 8 ---
Mô hình NYT-Salience WN-Salience SEL EntSUM
P R F1 P R F1 P R F1 P R F1
Cross-encoder (DeBERTa) 77.5 87.4 82.1 71.5 78.3 74.8 64.1 73.6 68.5 64.9 59.2 61.9
Flan-UL2 31.1 72.4 43.5 30.7 90.1 45.9 16.7 98.3 28.5 27.6 83.6 41.5
LLaMa 2-Chat 14.6 100.0 25.4 27.1 100.0 42.6 9.49 100.0 17.3 19.2 100.0 32.2

Bảng 4: So sánh hiệu suất của mô hình cross-encoder với gợi ý zero-shot của LLMs.

Mô hình NYT-Salience WN-Salience SEL EntSUM
P R F1 P R F1 P R F1 P R F1
Cross-encoder w/ đề cập đầu tiên 54.2 57.5 55.8 69.6 80.4 74.6 59.8 76.1 67.0 69.1 53.2 60.2
Cross-encoder w/ tất cả đề cập 77.5 87.4 82.1 71.5 78.3 74.8 64.1 73.6 68.5 64.9 59.2 61.9

Bảng 5: So sánh hiệu suất của các mô hình cross-encoder chỉ với đề cập đầu tiên so với tất cả các đề cập được suy luận.

(a) Hiệu suất liên quan đến vị trí của các đề cập. Không có đề cập nào ngoài cửa sổ ngữ cảnh cho NYT.

(b) Hiệu suất liên quan đến tần suất của các thực thể. Phần chia test của tập dữ liệu SEL không chứa bất kỳ thực thể nào có hơn 10 đề cập trong một tài liệu.

Hình 3: Phân tích phân tầng trên các mô hình và tập dữ liệu.

--- TRANG 9 ---
sử dụng ngữ cảnh để xác định rằng các đề cập xuất hiện trong tiêu đề hoặc các phần đầu tiên của tài liệu thường nổi bật mà không cần sử dụng rõ ràng thông tin này như một đặc trưng.

Chúng tôi cũng điều tra hiệu suất của các mô hình khi đề cập đầu tiên rơi vào bên trong hoặc bên ngoài cửa sổ ngữ cảnh của PLM (ở đây, 512 tokens). Khi các đề cập rơi vào bên trong cửa sổ ngữ cảnh, chúng tôi quan sát rằng các mô hình cross-encoder liên tục vượt trội hơn mô hình Đặc trưng & GBDT. Khi đề cập rơi vào bên ngoài cửa sổ ngữ cảnh, các dự đoán của mô hình trở nên gần như ngẫu nhiên, điều này được mong đợi, vì mô hình không có thông tin ngữ cảnh tức thì xung quanh đề cập. Sử dụng các mô hình có thể xử lý đầu vào dài hơn sẽ là một hướng cải thiện đầy hứa hẹn cho các mẫu này (Beltagy et al., 2020). Thú vị, đối với WN-Salience, mô hình Đặc trưng & GBDT cũng hoạt động tệ hơn đáng kể bên ngoài 512 tokens đầu tiên.

7.3 Phân tích Phân tầng về Tần suất Đề cập
Tương tự như phân tích vị trí đề cập, chúng tôi so sánh các mô hình cross-encoder của chúng tôi với mô hình Đặc trưng & GBDT, sử dụng tần suất đề cập như một trong các đặc trưng đầu vào của nó. Hình 3 cho thấy cách các mô hình cross-encoder và Đặc trưng & GBDT so sánh với tần suất thay đổi của các đề cập thực thể.

Đối với các thực thể nổi bật với đề cập đơn lẻ, mô hình cross-encoder hoạt động tốt hơn đáng kể so với mô hình Đặc trưng & GBDT. Cụ thể, đối với tập dữ liệu NYT-Salience, mô hình Đặc trưng & GBDT không thể dự đoán bất kỳ thực thể đề cập đơn lẻ nào là nổi bật. Quan sát này cho thấy rằng các mô hình cross-encoder không chỉ đơn giản mô hình hóa tần suất đề cập, mà có tiềm năng tận dụng thông tin ngữ cảnh khác để xác định độ nổi bật của các thực thể với một đề cập đơn lẻ.

Hiệu suất của mô hình Đặc trưng & GBDT cải thiện với nhiều đề cập hơn cho mỗi thực thể. Trên thực tế, đối với phạm vi tần suất 6-10 đề cập cho mỗi thực thể, mô hình Đặc trưng & GBDT hoạt động tốt hơn các mô hình cross-encoder cho các tập dữ liệu EntSUM và SEL. Quan sát này cho thấy sự phụ thuộc quá mức của mô hình Đặc trưng & GBDT vào tần suất đề cập để xác định độ nổi bật, nhưng cũng cho thấy cross-encoder không thể sử dụng đầy đủ heuristic này.

8 Kết luận
Bài báo này nhằm tận dụng kiến thức ngữ nghĩa được mã hóa trong các mô hình ngôn ngữ được huấn luyện trước để phát hiện độ nổi bật thực thể. Chúng tôi đề xuất phương pháp cross-encoder dựa trên PLMs dựa trên Transformer với các biểu diễn vị trí và so sánh hiệu suất của nó với một số phương pháp dựa trên ML, phương pháp heuristic, và LLMs được điều chỉnh theo hướng dẫn trên bốn tập dữ liệu khác nhau, hai được chú thích bởi con người và hai được tuyển chọn tự động. Trên tất cả các thí nghiệm của chúng tôi, mô hình cross-encoder dựa trên các mô hình ngôn ngữ được huấn luyện trước vượt trội hơn tất cả các phương pháp khác, thường với những cải thiện hai chữ số trong điểm F-1. Các phân tích về hành vi mô hình minh họa những tác động quan trọng của tần suất đề cập, vị trí đề cập, và độ dài tài liệu đối với hiệu suất, làm nổi bật các lĩnh vực của nghiên cứu tương lai.

9 Hạn chế
Chúng tôi chỉ nghiên cứu độ nổi bật trong các tài liệu tiếng Anh, nhưng các phương pháp của chúng tôi có thể áp dụng trực tiếp cho các ngôn ngữ khác miễn là có một mô hình ngôn ngữ được huấn luyện trước bao phủ ngôn ngữ mục tiêu.

Chúng tôi sử dụng các đề cập thực thể như được chú thích trong dữ liệu của chúng tôi hoặc được suy luận thông qua nhận dạng thực thể và phân giải thực thể để suy luận trong một số phương pháp. Thông tin này có thể không có sẵn tại thời điểm suy luận trong tất cả các ứng dụng.

Các thí nghiệm với LLMs bị giới hạn trong các gợi ý zero-shot. Chúng tôi không thí nghiệm với điều chỉnh theo hướng dẫn có thể tiềm năng giúp mô hình học nhiệm vụ phát hiện độ nổi bật.

Cuối cùng, chúng tôi không sử dụng kiến thức bên ngoài về các thực thể và mối quan hệ của chúng trong mô hình hóa, điều này được chỉ ra là cải thiện kết quả một cách nhẹ nhàng trong các nghiên cứu trước đây (Dunietz and Gillick, 2014; Trani et al., 2018; Ponza et al., 2019). Chúng tôi coi điều này nằm ngoài phạm vi phân tích của chúng tôi và là một hướng khả thi của nghiên cứu tương lai.

10 Tuyên bố Đạo đức
Chúng tôi sử dụng các tập dữ liệu có sẵn công khai dành cho nhiệm vụ phát hiện độ nổi bật thực thể. Các tập dữ liệu và mô hình được huấn luyện trước mà chúng tôi sử dụng có giấy phép cho phép sử dụng cho nghiên cứu. Chúng tôi không hình dung bất kỳ rủi ro tiềm ẩn nào liên quan đến nhiệm vụ được thảo luận trong bài báo này.

Tài liệu tham khảo
Alan Akbik, Tanja Bergmann, Duncan Blythe, Kashif Rasul, Stefan Schweter, và Roland V ollgraf. 2019. FLAIR: An easy-to-use framework for state-of-the-art NLP. Trong NAACL 2019, 2019 Annual Conference of the North American Chapter of the Association for

--- TRANG 10 ---
Computational Linguistics (Demonstrations), trang 54–59.

Zakariae Alami Merrouni, Bouchra Frikh, và Brahim Ouhbi. 2020. Automatic keyphrase extraction: a survey and trends. Journal of Intelligent Information Systems, 54(2):391–424.

Iz Beltagy, Matthew E. Peters, và Arman Cohan. 2020. Longformer: The long-document transformer.

David M. Blei, Andrew Y . Ng, và Michael I. Jordan. 2003. Latent dirichlet allocation. J. Mach. Learn. Res., 3(null):993–1022.

Tianqi Chen, Tong He, Michael Benesty, Vadim Khotilovich, Yuan Tang, Hyunsu Cho, Kailong Chen, et al. 2015. XGBoost: Extreme Gradient Boosting. R package version 0.4-2, 1(4):1–4.

Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2022. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416.

Leon Derczynski, Kalina Bontcheva, và Ian Roberts. 2016. Broad Twitter corpus: A diverse named entity recognition resource. Trong Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers, trang 1169–1179, Osaka, Japan. The COLING 2016 Organizing Committee.

Milan Dojchinovski, Dinesh Reddy, Tomáš Kliegr, Tomáš Vitvar, và Harald Sack. 2016. Crowdsourced corpus with entity salience annotations. Trong Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC'16), trang 3307–3311, Portorož, Slovenia. European Language Resources Association (ELRA).

Jesse Dunietz và Daniel Gillick. 2014. A new entity salience task with millions of training examples. Trong Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, volume 2: Short Papers, trang 205–209, Gothenburg, Sweden. Association for Computational Linguistics.

Günes Erkan và Dragomir R. Radev. 2004. Lexrank: Graph-based lexical centrality as salience in text summarization. J. Artif. Int. Res., 22(1):457–479.

Michael Gamon, Tae Yano, Xinying Song, Johnson Apacible, và Patrick Pantel. 2013. Understanding document aboutness step one: Identifying salient entities. Technical Report MSR-TR-2013-73.

Pengcheng He, Jianfeng Gao, và Weizhu Chen. 2023. DeBERTav3: Improving deBERTa using ELECTRA-style pre-training with gradient-disentangled embedding sharing. Trong The Eleventh International Conference on Learning Representations.

Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bordino, Hagen Fürstenau, Manfred Pinkal, Marc Spaniol, Bilyana Taneva, Stefan Thater, và Gerhard Weikum. 2011. Robust disambiguation of named entities in text. Trong Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, trang 782–792, Edinburgh, Scotland, UK. Association for Computational Linguistics.

Ella Hofmann-Coyle, Mayank Kulkarni, Lingjue Xie, Mounica Maddela, và Daniel Preotiuc-Pietro. 2022. Extractive entity-centric summarization as sentence selection using bi-encoders. Trong Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), trang 326–333, Online only. Association for Computational Linguistics.

Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance Ramshaw, và Ralph Weischedel. 2006. OntoNotes: The 90% solution. Trong Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers, trang 57–60, New York City, USA. Association for Computational Linguistics.

Xiaolei Huang và Michael J. Paul. 2018. Examining temporality in document classification. Trong Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), trang 694–699, Melbourne, Australia. Association for Computational Linguistics.

Anette Hulth. 2003. Improved automatic keyword extraction given more linguistic knowledge. Trong Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing, trang 216–223.

Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, và Tie-Yan Liu. 2017. Lightgbm: A highly efficient gradient boosting decision tree. Advances in neural information processing systems, 30.

Nikolaos Kolitsas, Octavian-Eugen Ganea, và Thomas Hofmann. 2018. End-to-end neural entity linking. Trong Proceedings of the 22nd Conference on Computational Natural Language Learning, trang 519–529, Brussels, Belgium. Association for Computational Linguistics.

Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, và Veselin Stoyanov. 2019. RoBERTa: A robustly optimized BERT pretraining approach. arXiv preprint arXiv:1907.11692.

Ilya Loshchilov và Frank Hutter. 2019. Decoupled weight decay regularization. Trong International Conference on Learning Representations.

Mounica Maddela, Mayank Kulkarni, và Daniel Preotiuc-Pietro. 2022. EntSUM: A data set for entity-centric extractive summarization. Trong Proceedings of

--- TRANG 11 ---
the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 3355–3366, Dublin, Ireland. Association for Computational Linguistics.

Edgar Meij, Wouter Weerkamp, và Maarten de Rijke. 2012. Adding semantics to microblog posts. Trong Proceedings of the Fifth ACM International Conference on Web Search and Data Mining, WSDM '12, trang 563–572, New York, NY , USA. Association for Computing Machinery.

Rada Mihalcea và Paul Tarau. 2004. TextRank: Bringing order into text. Trong Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, trang 404–411, Barcelona, Spain. Association for Computational Linguistics.

Dat Ba Nguyen, Johannes Hoffart, Martin Theobald, và Gerhard Weikum. 2014. Aida-light: High-throughput named-entity disambiguation. Trong Proceedings of the Workshop on Linked Data on the Web co-located with the 23rd International World Wide Web Conference (WWW 2014), Seoul, Korea, April 8, 2014, volume 1184 của CEUR Workshop Proceedings. CEUR-WS.org.

F. Pedregosa, G. Varoquaux, A. Gramfort, V . Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V . Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, và E. Duchesnay. 2011. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12:2825–2830.

Marco Ponza, Diego Ceccarelli, Paolo Ferragina, Edgar Meij, và Sambhav Kothari. 2021. Contextualizing trending entities in news stories. Trong Proceedings of the 14th ACM International Conference on Web Search and Data Mining, trang 346–354.

Marco Ponza, Paolo Ferragina, và Francesco Piccinno. 2019. Swat: A system for detecting salient wikipedia entities in texts. Computational Intelligence, 35(4):858–890.

Sameer Pradhan, Alessandro Moschitti, Nianwen Xue, Hwee Tou Ng, Anders Björkelund, Olga Uryupina, Yuchen Zhang, và Zhi Zhong. 2013. Towards robust linguistic analysis using OntoNotes. Trong Proceedings of the Seventeenth Conference on Computational Natural Language Learning, trang 143–152, Sofia, Bulgaria. Association for Computational Linguistics.

Shruti Rijhwani và Daniel Preotiuc-Pietro. 2020. Temporally-informed analysis of named entity recognition. Trong Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, trang 7605–7617, Online. Association for Computational Linguistics.

Evan Sandhaus. 2008. The new york times annotated corpus. Linguistic Data Consortium, Philadelphia, 6(12):e26752.

Benjamin Strauss, Bethany Toma, Alan Ritter, Marie-Catherine De Marneffe, và Wei Xu. 2016. Results of the w-nut 2016 named entity recognition shared task. Trong Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT), trang 138–144.

Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Jason Wei, Xuezhi Wang, Hyung Won Chung, Siamak Shakeri, Dara Bahri, Tal Schuster, Huaixiu Steven Zheng, Denny Zhou, Neil Houlsby, và Donald Metzler. 2023. Ul2: Unifying language learning paradigms.

Ian Tenney, Dipanjan Das, và Ellie Pavlick. 2019. BERT rediscovers the classical NLP pipeline. Trong Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, trang 4593–4601, Florence, Italy. Association for Computational Linguistics.

Ian Tenney, Patrick Xia, Berlin Chen, Alex Wang, Adam Poliak, R Thomas McCoy, Najoung Kim, Benjamin Van Durme, Samuel R Bowman, Dipanjan Das, et al. 2018. What do you learn from context? probing for sentence structure in contextualized word representations. Trong International Conference on Learning Representations.

Erik F. Tjong Kim Sang và Fien De Meulder. 2003. Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition. Trong Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003, trang 142–147.

Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, và Thomas Scialom. 2023. Llama 2: Open foundation and fine-tuned chat models.

Salvatore Trani, Claudio Lucchese, Raffaele Perego, David E. Losada, Diego Ceccarelli, và Salvatore Orlando. 2018. Sel: A unified algorithm for salient entity linking. Computational Intelligence, 34(1):2–29.

--- TRANG 12 ---
Chuan Wu, Evangelos Kanoulas, Maarten de Rijke, và Wei Lu. 2020a. Wn-salience: A corpus of news articles with entity salience annotations. Trong Proceedings of The 12th Language Resources and Evaluation Conference, trang 2095–2102.

Chuan Wu, Evangelos Kanoulas, và Maarten de Rijke. 2020b. Learning entity-centric document representations using an entity facet topic model. Inf. Process. Manage., 57(3).

Chenyan Xiong, Zhengzhong Liu, Jamie Callan, và Tie-Yan Liu. 2018. Towards better text understanding and retrieval through kernel entity salience modeling. Trong The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval, trang 575–584.

Lingyun Zhao, Lin Li, Xinhao Zheng, và Jianwei Zhang. 2021. A bert based sentiment analysis and key entity detection approach for online financial texts. Trong 2021 IEEE 24th International Conference on Computer Supported Cooperative Work in Design (CSCWD), trang 1233–1238. IEEE.

--- TRANG 13 ---
Phụ lục
A Chi tiết về Phân chia Tập dữ liệu
Bảng 6 chứa các phần chia train, dev, và test của mỗi tập dữ liệu sau khi áp dụng chiến lược phân chia theo thời gian được mô tả trong Phần 6.1. Các phần chia này được sử dụng để huấn luyện và đánh giá mô hình.

B Định dạng Đầu vào cho Thí nghiệm
Như được mô tả trong Phần 4.1, chúng tôi thêm các token đánh dấu đặc biệt xung quanh mỗi đề cập của thực thể mục tiêu (tức là, thực thể mà mô hình cần dự đoán nhãn độ nổi bật.). Trong phần sau, chúng tôi cung cấp một ví dụ:

Văn bản
Musk hoàn thành thỏa thuận Twitter 44 tỷ đô la.
Elon Musk, thế giới...

Đầu vào Mô hình
[CLS] Elon Musk [SEP] [BEGIN_ENTITY] Musk [END_ENTITY] hoàn thành thỏa thuận Twitter 44 tỷ đô la. [BEGIN_ENTITY] Elon Musk [END_ENTITY], thế giới...

Đối với thí nghiệm với đề cập đầu tiên được báo cáo trong Phần 7.1, chỉ đề cập đầu tiên được bao quanh bởi các token đánh dấu đặc biệt như được hiển thị trong ví dụ sau:

Đầu vào Mô hình
[CLS] Elon Musk [SEP] [BEGIN_ENTITY] Musk [END_ENTITY] hoàn thành thỏa thuận Twitter 44 tỷ đô la. Elon Musk, thế giới...

Lưu ý rằng đề cập thứ hai của Elon Musk không được bao quanh bởi các token đánh dấu.

C Chi tiết triển khai của gợi ý zero-shot của LLMs
Hình 4 và Hình 5 cho thấy các gợi ý chúng tôi sử dụng cho các mô hình LLaMa 2-Chat (7B) và Flan-UL2 (20B) tương ứng. Bảng 7 liệt kê các tham số tạo. Chúng tôi suy đoán các nguyên nhân sau cho độ chính xác tương đối thấp hơn thu được sử dụng phương pháp này:

• Hướng dẫn định nghĩa định nghĩa nhiệm vụ độ nổi bật, nhưng không cung cấp bất kỳ ví dụ tham chiếu nào (gợi ý few-shot) để căn chỉnh với định nghĩa độ nổi bật. Điều này dẫn đến mô hình xác định một thực thể là nổi bật dựa trên tần suất của nó trong tài liệu. Tuy nhiên, việc tạo một gợi ý few-shot là thách thức vì chúng tôi cần giới hạn độ dài đầu vào tối đa của gợi ý để ngăn chặn các vấn đề hết bộ nhớ.

• Chúng tôi cắt bớt văn bản tài liệu để toàn bộ gợi ý có 2048 tokens hoặc ít hơn, do đó loại bỏ bất kỳ thông tin tiềm năng nào có mặt ở cuối một tài liệu dài.

<s> [INST]
«SYS» Độ nổi bật của một thực thể cung cấp thông tin về tầm quan trọng hoặc tính trung tâm của thực thể đó đối với toàn bộ văn bản tài liệu. Trong phần sau, cho một Thực thể và một Văn bản, bạn cần trả lời 'Có' nếu tài liệu Văn bản là về Thực thể đó và 'Không' nếu Văn bản không phải là về Thực thể đó. «/SYS»

Thực thể: entity có nổi bật trong Văn bản: text không
[/INST]

Hình 4: Hướng dẫn cho gợi ý zero-shot của mô hình LLaMa 2-Chat.

### Hướng dẫn ###
Độ nổi bật của một thực thể cung cấp thông tin về tầm quan trọng hoặc tính trung tâm của thực thể đó đối với toàn bộ văn bản tài liệu. Trong phần sau, cho một Thực thể và một Văn bản, bạn cần trả lời 'Có' nếu tài liệu Văn bản là về Thực thể đó và 'Không' nếu Văn bản không phải là về Thực thể đó.

Văn bản: text
Thực thể: entity
Câu hỏi: Thực thể trên có nổi bật trong Văn bản trên không? Vui lòng trả lời Có hoặc Không.
Trả lời:

Hình 5: Hướng dẫn cho gợi ý zero-shot của mô hình Flan-UL2.

D Ngưỡng cho đường cơ sở Tần suất Thực thể
Hình 6 cho thấy hiệu suất của đường cơ sở Tần suất Thực thể bằng cách thay đổi số lần tối thiểu một thực thể phải xuất hiện trong tài liệu đầu vào để được phân loại là nổi bật.

--- TRANG 14 ---
Tập dữ liệu # Cặp Tài liệu-Thực thể Train Validation Test
NYT-Salience 1,910,214 1,342,092 405,335 162,787
WN-Salience 62,537 41,625 11,902 9,009
SEL 12,257 6,106 2,400 3,751
EntSUM 9,934 5,206 1,861 2,867

Bảng 6: Cặp Tài liệu-Thực thể trong các phần chia train, validation, và test sau khi áp dụng phân chia theo thời gian.

Tham số tạo Giá trị
top_k 0
top_p 0
temperature 0
max_new_tokens 1

Bảng 7: Tham số để tạo một nhãn độ nổi bật với gợi ý zero-shot.

1 2 3 4 5 60.00.20.40.60.81.0F1
Tập dữ liệu = NYT-Salience
1 2 3 4 5 6
Ngưỡng Tần suất Tối thiểu
Tập dữ liệu = WN-Salience
1 2 3 4 5 6
Tập dữ liệu = SEL
1 2 3 4 5 6
Tập dữ liệu = EntSUM
Phương pháp
Precision
Recall
F1

Hình 6: Hiệu suất của đường cơ sở Tần suất Thực thể với các ngưỡng khác nhau.

Bộ mã hóa Tóm tắt (RoBERTa-base) Đặc trưng Ngữ cảnh Đặc trưng Vị trí Bộ tính điểm (Mạng Truyền thẳng) Điểm độ nổi bật từ [0, 1] cho thực thể mục tiêu

Hình 7: Sơ đồ kiến trúc mô hình Che Thực thể Mục tiêu.

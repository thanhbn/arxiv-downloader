# 2306.06635.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/ssm/2306.06635.pdf
# Kích thước tệp: 10908264 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
2-D SSM: Một Lớp Không Gian Tổng Quát
cho Transformers Thị Giác
Ethan Baron*
Khoa Khoa Học Máy Tính
Đại Học Tel Aviv
barone@mail.tau.ac.ilItamar Zimerman*
Khoa Khoa Học Máy Tính
Đại Học Tel Aviv
zimerman1@mail.tau.ac.il
Lior Wolf
Khoa Khoa Học Máy Tính
Đại Học Tel Aviv
wolf@mail.tau.ac.il
Tóm tắt
Một mục tiêu trung tâm trong thị giác máy tính là thiết kế các mô hình với thiên hướng quy nạp 2-D phù hợp. Các tiêu chí mong muốn cho thiên hướng quy nạp 2D bao gồm nhận thức vị trí hai chiều, tính địa phương không gian động, và tính bất biến đối với tịnh tiến và hoán vị. Để giải quyết những mục tiêu này, chúng tôi tận dụng một biến thể biểu cảm của Mô hình Không gian Trạng thái đa chiều (SSM). Phương pháp của chúng tôi giới thiệu tham số hóa hiệu quả, tính toán được tăng tốc, và một sơ đồ chuẩn hóa phù hợp. Thực nghiệm cho thấy việc kết hợp lớp của chúng tôi vào đầu mỗi khối transformer của Vision Transformers (ViT) cải thiện đáng kể hiệu suất cho nhiều backbone ViT và trên các tập dữ liệu. Lớp mới hiệu quả ngay cả với lượng tham số và thời gian suy luận bổ sung không đáng kể. Các nghiên cứu loại bỏ và trực quan hóa chứng minh rằng lớp này có thiên hướng quy nạp 2-D mạnh mẽ. Ví dụ, các vision transformers được trang bị lớp của chúng tôi thể hiện hiệu suất hiệu quả ngay cả khi không có mã hóa vị trí.1
1 Giới thiệu
Việc kết hợp thiên hướng quy nạp đặc thù cho hình ảnh vào các mạng thị giác máy tính có thể đóng vai trò quan trọng trong thành công của chúng, bằng cách định hình không gian giả thuyết theo cách phù hợp với dữ liệu hình ảnh và cải thiện khả năng tổng quát hóa. Các thành phần phổ biến của thiên hướng quy nạp đặc thù cho hình ảnh bao gồm cấu trúc lân cận hai chiều, tính địa phương, tính đồng biến và bất biến tịnh tiến, và trích xuất các đặc trưng phân cấp. Theo truyền thống, nó được tiêm vào mô hình thông qua kiến trúc backbone. Tuy nhiên, gần đây hơn, nó đã được mô hình hóa như một phần của dữ liệu. Ví dụ, các cấu trúc lân cận hai chiều thường được biểu hiện theo một trong hai cách: (i) Vision Transformers [10] sử dụng mã hóa vị trí 1-D [45], được coi là thiên hướng quy nạp yếu. (ii) ConvNets sử dụng kernel 2-D, cung cấp các tiên nghiệm mạnh mẽ về cấu trúc hình ảnh cơ bản [43].
Hầu hết ConvNets sử dụng các bộ lọc tương đối nhỏ trong các lớp tích chập, và sự cân bằng giữa các đặc trưng cục bộ và toàn cục được xử lý bằng cách tăng trường tiếp nhận theo chiều sâu. Tuy nhiên, các kích thước kernel khác có thể có lợi. Ví dụ, ConvNeXt cải thiện ResNet 0.7% trên Imagenet, chỉ bằng cách tăng kích thước kernel từ 3×3 lên 7×7 [33]. Tổng quát hơn, việc sử dụng các bộ lọc có kích thước cố định hạn chế loại phụ thuộc mà lớp có thể nắm bắt.
*Đóng góp bằng nhau. Thứ tự được xác định bằng tung đồng xu
1Việc triển khai phương pháp có sẵn tại https://github.com/ethanbar11/ssm_2d
Bản thảo. Đang được xem xét.arXiv:2306.06635v1 [cs.CV] 11 Jun 2023

--- TRANG 2 ---
Mục tiêu của nghiên cứu này là phát triển một lớp mới thành thạo trong việc tích hợp cả các đặc trưng không gian cục bộ và toàn cục, với trọng tâm đặc biệt vào cấu trúc lân cận hai chiều. Chúng tôi thực hiện điều này bằng cách xây dựng trên các phát triển gần đây trong các lớp dựa trên 1-D SSM, nổi tiếng với việc nắm bắt các loại phụ thuộc khác nhau. Bằng cách mở rộng khái niệm 1-D này thành 2-D, lớp của chúng tôi có gốc rễ sâu sắc trong lý thuyết điều khiển, và giống như các tiền nhiệm, vẫn duy trì thiên hướng mạnh mẽ đối với nhận thức vị trí và hiệu quả tham số.
Đóng góp chính của chúng tôi là lớp 2D-SSM, một lớp không gian mới dựa trên mô hình Roesser cho không gian trạng thái đa chiều [27]. Chúng tôi chỉ ra rằng các lựa chọn thiết kế đơn giản, như chéo hóa và chuẩn hóa, có thể làm cho lớp ổn định về mặt số học và được tính toán hiệu quả mà không cần hồi quy bằng tích chập 2-D (bảng trái của Hình 1). Lớp của chúng tôi có một số tính chất độc đáo, bao gồm: (i) Thiên hướng quy nạp mạnh mẽ đối với lân cận và tính địa phương hai chiều, xuất phát từ quy tắc hồi quy đa chiều. Theo như chúng tôi biết, khái niệm mới này không xuất hiện trong các lớp khác, (ii) Lớp mới có thể nắm bắt bối cảnh có thể kiểm soát không hạn chế. Các tham số SSM của lớp có thể tập trung vào các phụ thuộc ngắn hoặc dài, ngang, dọc, hoặc chéo (bảng giữa của Hình 1). (iii) Lớp hiệu quả về tham số và có thể biểu hiện kernel có độ dài bất kỳ thông qua 8 scalar.
Các nghiên cứu trực quan hóa và loại bỏ chứng minh những khía cạnh quan trọng này của các lớp chúng tôi. Cuối cùng, lớp được căn cứ tốt trong lý thuyết điều khiển, và phân tích lý thuyết sâu hơn cho thấy nó tổng quát hóa S4ND [37] và chứng minh tính biểu cảm lớn hơn của nó.
Về mặt thực nghiệm, chúng tôi cho thấy lớp của chúng tôi có thể được sử dụng như một bộ tăng cường đa năng cho các vision transformers (kiến trúc sơ đồ được minh họa trong bảng phải của Hình 1), với các tham số và tính toán bổ sung không đáng kể khi suy luận. Hơn nữa, có vẻ như 2D-SSM của chúng tôi vượt qua các phương pháp tiêu chuẩn, như kết hợp mã hóa vị trí, trong việc tích hợp hiệu quả thiên hướng vị trí vào Vision Transformers.
2 Bối cảnh và Ký hiệu
Khung Nghiên cứu của chúng tôi đi sâu vào hai lĩnh vực nghiên cứu mới nổi. Lĩnh vực đầu tiên tập trung vào việc phát triển các kỹ thuật tích chập toàn cục đa trục. Mặc dù tích chập toàn cục 1-D (dài) đã cho thấy hứa hẹn trong mô hình hóa chuỗi 1-D, sử dụng các phương pháp như SSM [6,17,19,20,36] hoặc các phương pháp gần đây khác [13],[38],[31], khả năng ứng dụng và hiệu quả của nó trong các nhiệm vụ thị giác máy tính hiện đại vẫn không chắc chắn. Công việc của chúng tôi nhằm khám phá và làm nổi bật tiềm năng của những kỹ thuật này trong lĩnh vực này, bằng cách mở rộng chúng thành 2-D.
Lĩnh vực thứ hai điều tra sự kết hợp hiệp đồng của attention và SSM trong mô hình hóa 1-D trên các lĩnh vực khác nhau [35,39,25,49,6,36]. Ví dụ, H3 dựa trên SSM [6] vượt trội hơn GPT-Neo-2.7B [2] (cũng như các transformers khác cùng kích thước) chỉ với 2 lớp attention. Tuy nhiên, câu hỏi liệu các thành phần này có bổ sung cho nhau trong mô hình hóa 2-D hay không vẫn chưa được trả lời. Chúng tôi cung cấp bằng chứng thực nghiệm hỗ trợ tính chất bổ sung của các thành phần này.
Mô hình Không gian Trạng thái (SSM) Mô hình không gian trạng thái ánh xạ một hàm scalar đầu vào u(t) :R→R thành một trạng thái tiềm ẩn N-D x(t) trong RN trước khi chiếu nó thành tín hiệu đầu ra y(t) :R→R:
˙x(t) =Ax(t) +Bu(t), y(t) =Cx(t) +Du(t) (1)
Việc sử dụng SSMs rộng rãi trong nhiều ngành khoa học và có liên quan chặt chẽ với các mô hình trạng thái tiềm ẩn, như Mô hình Markov Ẩn. Có một kết nối được biết đến rộng rãi giữa SSMs tuyến tính bất biến thời gian, như 1 và tích chập liên tục, do đó cho phép huấn luyện hiệu quả bằng cách sử dụng phương trình nói trên như một tích chập rời rạc. Các lớp S4 [17] và LSSL [19] tận dụng SSM như một biểu diễn hộp đen trong mô hình hóa chuỗi sâu, với các tham số học được A, B, C, và D, và đạt được kết quả mạnh mẽ trên nhiều nhiệm vụ, đặc biệt là những nhiệm vụ yêu cầu xử lý các phụ thuộc tầm xa, như Long Range Arena (LRA) [41], tạo sinh âm thanh [15], và xử lý văn bản dài [36, 16, 6].
Các lý do cơ bản cho sự phù hợp của S4 và SSMs để mô hình hóa các chuỗi dài gần đây đã được phân tích [31,13]. Người ta phát hiện rằng (i) sử dụng kernel toàn cục với cấu trúc suy giảm, và (ii) sử dụng kernel được điều chỉnh, đều là những lựa chọn thiết kế quan trọng trong lĩnh vực này.
Mô hình Không gian Trạng thái 2D của Roesser Nỗ lực mở rộng SSM cổ điển cho các hệ thống đa trục 2-D đã được nghiên cứu kỹ lưỡng trong quá khứ. [27,11,12,28,14,22] ghi nhận một số công thức khác nhau của vấn đề. Chúng tôi sử dụng mô hình SSM của Roesser [27] như mô hình đa trục rời rạc của chúng tôi, đây là dạng tổng quát nhất của các mô hình không gian trạng thái 2-trục và N-trục. Khác với các SSMs khác đã
2

--- TRANG 3 ---
Hình 1: (Trái) Lớp 2-D SSM được tham số hóa bởi A, B, C, và D. Nó được xây dựng trên đỉnh của một hồi quy tuyến tính hai trục và có thể được tính toán hiệu quả bằng tích chập 2-D. (Giữa) Vì lớp dựa trên hồi quy hai chiều, nó thể hiện thiên hướng mạnh mẽ đối với nhận thức vị trí. Hồi quy không bị hạn chế, cho phép lớp hoạt động trên các chuỗi 2-D có độ dài bất kỳ. Các giá trị của A1, A2, A3, và A4 kiểm soát trọng tâm của lớp, cho phép nó nắm bắt các phụ thuộc không gian ngắn hoặc dài theo hướng ngang, dọc, hoặc chéo, trái ngược với các mô hình dựa trên patch. (Phải) Lớp có thể được tích hợp dễ dàng vào ViT bằng cách áp dụng nó cho chuỗi hai chiều của các patch ở đầu mỗi khối transformer.
được sử dụng trong học máy, SSM này sử dụng M trạng thái, một cho mỗi trục, thay vì chỉ một. Mô hình ở dạng 2-D được trình bày ở đây:
xi,j=
xhi,j
xvi,j
, y i,j= [C1C2]
xhi,j
xvi,j
,
xhi,j+1
xvi+1,j
=
A1A2
A3A4
xhi,j
xvi,j
+
B1
B2
ui,j (2)
trong đó trạng thái xi,j trong R2N là sự nối của các trạng thái ngang xvi,j trong RN và dọc xhi,j trong RN, các ma trận hệ thống là A1, A2, A3, A4 trong RN×N và các ma trận đầu vào và đầu ra là B1, B2, C1, C2 trong RN. Cũng có một tham số học được D hoạt động như một kết nối bỏ qua, bỏ qua từ bây giờ để ngắn gọn.
2.1 Ký hiệu
Ký hiệu tuân theo gần nhất có thể ký hiệu được sử dụng trong tài liệu lớp không gian trạng thái [17, 20,18]. Cụ thể, chúng tôi sử dụng H là số kênh, N là chiều ẩn của trạng thái, L là độ dài chuỗi, nssm là số kênh không được chia sẻ, và coi A, B, C, D trong R là các ma trận hệ thống. Lưu ý rằng để ngắn gọn, các ma trận hệ thống được coi là có giá trị thực, mặc dù chúng tôi cũng thử nghiệm phiên bản phức của chúng. Số trục được đặt là M.
Chiều tín hiệu Mặc dù N-D SSM có thể được sử dụng theo cách N-Chiều, vì bài báo của chúng tôi tập trung vào việc sử dụng mô hình này như một phương pháp điều chỉnh cho các backbone ViT và để đơn giản hóa trải nghiệm đọc, chúng tôi sẽ coi nó là một 2-D SSM.
Li trong R là độ dài chuỗi dọc theo trục thứ i, Ltot=L1*L2 là tổng kích thước tín hiệu, và Lmax= max(L1, L2).
Ký hiệu Kernel K là kernel 2-D được tính toán sao cho Y=U*K, trong đó * biểu thị tích chập rời rạc.
yi,j=C1xh
i,j+C2xv
i,j=X
0<=ˆi<=iX
0<=ˆj<=j
C1kh¯i,ˆj+C2kv¯i,ˆj)
uˆi,ˆj(3)
2.2 Các công trình liên quan khác
Các lớp không gian trạng thái đa chiều Theo như chúng tôi biết, S4ND [37] là lớp dựa trên SSM duy nhất trước đây có thể xử lý dữ liệu đa chiều một cách tự nhiên. S4ND được xây dựng trên S4, và chứa M phiên bản riêng biệt của S4, trong đó M là số trục. Trên đường forward, mỗi lớp S4,
3

--- TRANG 4 ---
mà chúng tôi ký hiệu là SSM g phân tích một kernel cục bộ một chiều kg, và một kernel toàn cục K được tính toán như tích ngoài của những kernel cục bộ đó.
Các backbone Vision Transformer Để chứng minh tính linh hoạt và hiệu quả của lớp 2-D SSM của chúng tôi như một thành phần cắm và chạy tương thích với các ViTs khác nhau, chúng tôi đánh giá hiệu suất của nó khi được tích hợp vào các kiến trúc backbone sau: (i) ViT ViT gốc sử dụng self-attention trên chuỗi 1-D của các patch; nó sử dụng mã hóa vị trí 1-D có thể học được. (ii) Swin Swin Transformer [32] tinh chỉnh ViT bằng cách kết hợp cấu trúc phân cấp và kết nối cục bộ trong các cửa sổ. Nó sử dụng sơ đồ cửa sổ dịch chuyển và xử lý theo giai đoạn để nắm bắt bối cảnh toàn cục một cách hiệu quả, điều này tăng cường hiệu suất của nó trên các nhiệm vụ thị giác khác nhau. (iii) Mega Mô hình Mega [35] giới thiệu cơ chế attention có cổng đầu đơn được tăng cường với trung bình động hàm mũ, mang lại các phụ thuộc cục bộ nhận thức vị trí cho cơ chế attention. Phương pháp này giải quyết các hạn chế của cơ chế attention của Transformer, như thiên hướng quy nạp yếu. Mega thể hiện hiệu suất vượt trội trên nhiều nhiệm vụ khác nhau, bao gồm Long Range Arena, dịch máy neural, mô hình hóa ngôn ngữ, và phân loại hình ảnh và giọng nói. (iv) DeiT [42] là một sự thích ứng của ViT, kết hợp một class-token được thiết kế cho mục đích chưng cất.
Thêm thiên hướng vị trí vào transformers Theo thiết kế, Vision Transformers là bất biến hoán vị, và do đó rất nhiều công việc đã được đặt vào việc tiêm thiên hướng vào chúng. Bên cạnh mã hóa vị trí tiêu chuẩn, các phương pháp sau được đề xuất:
Trung bình động hàm mũ (EMA) EMA là một kỹ thuật phổ biến để làm mượt dữ liệu chuỗi thời gian và ưu tiên các điểm dữ liệu gần đây. Nó được tính toán bằng EMA t= (1−alpha)·EMA t−1+alpha·ut, trong đó EMA t là giá trị EMA hiện tại, EMA t−1 là giá trị trước đó và alpha là hệ số làm mượt. Nó đang được sử dụng trong MEGA [35] để kết hợp thiên hướng nhận thức vị trí vào attention.
Các đóng góp thiên hướng 2-D khác Theo thiết kế, Vision Transformers là bất biến hoán vị, và do đó rất nhiều công việc đã được đặt vào việc tiêm thiên hướng 2-D vào chúng. Một hướng nghiên cứu cụ thể nhấn mạnh việc giới thiệu thiên hướng vị trí thông qua các phương pháp mã hóa vị trí khác nhau. Ví dụ, Swin Transformer [32] sử dụng một thuật ngữ thiên hướng có thể học được được gọi là thiên hướng vị trí tương đối. Ngược lại, Convit [7] sử dụng thiên hướng vị trí tương đối trong khi mô hình hóa nó như một thiên hướng quy nạp mềm. Điều này được thực hiện bằng cách khởi tạo hàm attention như một tích chập và cho phép mô hình hội tụ về các dạng attention đa dạng. Trong các con đường nghiên cứu thay thế, các nỗ lực đã được thực hiện để sửa đổi cửa sổ attention thông qua các kỹ thuật đa dạng, như kết hợp thiên hướng cục bộ hai chiều bằng cách cắt [9] cửa sổ attention hoặc tích hợp mạng neural tích chập (CNNs) với các cơ chế attention [5], [30]. Gần đây, một kết quả thú vị trong phân loại hình ảnh đã được thực hiện khi cơ chế EMA được áp dụng cho các patch hình ảnh, như được mô tả trong [35].
3 Phương pháp
Trong phần này, chúng tôi trình bày cốt lõi của lớp 2-D SSM, đây là đóng góp kỹ thuật chính của chúng tôi. Lớp này ánh xạ một chuỗi hai chiều ui,j thành yi,j, trong đó ui,j, yi,j trong R cho tất cả 0<=i<=L1 và 0<=j<=L2. Tương tự như các lớp dựa trên SSM trước đây, chúng tôi mở rộng cốt lõi của lớp chúng tôi thành một lớp đa hướng và đa chiều, được chi tiết trong Phụ lục D.
3.1 Mô hình Không gian Trạng thái Hồi quy 2-D như Tích chập
Phương trình 2 được định nghĩa theo cách đệ quy. Tuy nhiên, vì lý do hiệu quả, tốt nhất là định nghĩa các toán tử ở dạng đóng và theo cách đồng thời với xử lý song song. Lấy cảm hứng từ công việc trước đây [17,20,35,18], chúng tôi khai thác thực tế rằng SSM là tuyến tính và do đó có thể được biểu hiện như một tích chập với kernel K. Để làm như vậy, trước tiên chúng tôi mở rộng quy tắc hồi quy và sau đó mô tả nó trong công thức dạng đóng.
Để đơn giản, chúng tôi giả định rằng các trạng thái ban đầu là zero cho tất cả j>=0 : xh−1,j= 0, và cho tất cả i>=0 : xvi,−1= 0. Các trạng thái ngang và dọc tại i= 0, j= 0 là:
xh
0,0=B1u0,0, xv
0,0=B2u0,0 (4)
Bằng cách áp dụng quy tắc hồi quy một lần tại mỗi trục:
xh
1,0=A1B1u0,0+A2B2u0,0+B1u1,0, xv
0,1=A3B1u0,0+A4B2u0,0+B2u0,1(5)
4

--- TRANG 5 ---
Hình 2: Ví dụ về các đường dẫn
từ tọa độ (ˆi,ˆj) = (0 ,0)
đến (i, j) = (4 ,4). Mỗi đường dẫn
đại diện cho một chuỗi các lần gọi đệ quy cho Phương trình 2.
Hình 3: Các kernel trước và sau các sửa đổi của Mục 3.2. Mỗi cột được tạo bởi cùng các tham số A1...A4, B1, B2, C1, C2 trong R. Hàng đầu là công thức 2-D SSM chuẩn hóa được giải thích trong 2, hàng thứ hai là kết quả của Phương trình 12 và thực hiện Phương trình 13, đây là công thức kernel mà chúng tôi sử dụng. Góc dưới bên trái của mỗi heatmap là K0,0. Các hình minh họa rằng trước khi nới lỏng, các kernel hiển thị xu hướng chéo trong khi sau đó, chúng thể hiện một mẫu đa dạng và linh hoạt hơn.
xv
1,0=B2u1,0, xh
0,1=B1u0,1 (6)
Tiếp theo, chúng tôi tính xh1,1 cho trước xh0,1 và xv0,1.
xh
1,1=A1A3B1u0,0+A1A4B2u0,0+A1B2u0,1+A2B1u0,1+B1u1,1, (7)
=kh
1,1u0,0+kh
1,0u0,1+kh
0,0u1,1 (8)
và tổng quát
xh
i,j=X
0<=ˆi<=iX
0<=ˆj<=jkh¯i,ˆjuˆi,ˆj, xv
i,j=X
0<=ˆi<=iX
0<=ˆj<=jkv¯i,ˆjuˆi,ˆj, (9)
trong đó như được giải thích trong ký hiệu, mỗi phần tử khˆi,ˆj,kvˆi,ˆj là một tập hợp các phép nhân A1, A2, A3, A4, B1, B2 (ví dụ Phương trình 7) và được liên kết với một đường dẫn duy nhất từ tọa độ (0,0) đến (i, j), như được trình bày trong Hình 2.
Bằng cách thay Phương trình 9 vào Phương trình 2, ta được:
yi,j=C1xh
i,j+C2xv
i,j=X
0<=ˆi<=iX
0<=ˆj<=j
C1kh¯i,ˆj+C2kv¯i,ˆj
uˆi,ˆj(10)
và kernel tích chập K là
cho tất cả i, j: Ki,j=C1kh¯i,ˆj+C2kv¯i,ˆj(11)
3.2 Tham số hóa Hiệu quả và Ổn định
Chéo hóa tham số Tính toán K khó khăn vì hai lý do. Thứ nhất, số phần tử trong mỗi ki,j là hàm mũ theo i và j, vì nó tương đương với số đường dẫn từ (0,0) đến (i, j). Thứ hai, tính toán lũy thừa của các ma trận không chéo A1, A2, A3, A4 trở nên tốn kém khi L1, L2 lớn. Để vượt qua những thách thức này, chúng tôi tham số hóa các ma trận hệ thống A1, A2, A3, A4 như chéo. Điều này cho phép tổng hợp hiệu quả của nhiều nhất 2Lmax phần tử trong kh
i,j. Mặc dù chéo hóa hạn chế tính biểu cảm của SSM của chúng tôi, các công trình trước đây đã chỉ ra hiệu quả của nó trong các trường hợp một chiều [18, 20, 36, 21].
Giới hạn các tham số Ai trong RN×N giờ đây là một ma trận chéo. Chúng tôi sẽ ký hiệu các giá trị riêng của Ai bằng (alpha1, alpha2...alphaN) :=diag (Ai). Mỗi giá trị alphai hoạt động riêng biệt cho đến khi tính toán K (Phương trình 11). Do đó, đối với alphai>1, limz→∞alphaz=∞. Vì vậy, chúng tôi giới hạn alphai trong [0,1] bằng cách tham số hóa nó bằng alphai:=sigmoid ( ˆalphai) và tối ưu hóa ˆalphai thay thế.
5

--- TRANG 6 ---
Chuẩn hóa Có một vấn đề tỷ lệ phát sinh từ Phương trình 7. Vì kh
1,1=A1A3B1+A1A4B2, ngay cả khi A1A3B1, A1A4B2<=1, kh
1,1 có thể lớn hơn 1. Cùng hành vi này làm cho kernel nổ tung.
Chúng tôi muốn giữ cho tất cả i, j: 0<=kh
i,j<=1 và do đó chúng tôi sử dụng một cơ chế chuẩn hóa đơn giản, trong đó chúng tôi chia cho hai mỗi khi chúng tôi tính toán Phương trình 2. Phương trình này do đó được thay thế bằng:

xhi+1,j
xvi,j+1
= 0.5
A1A2
A3A4
xhi,j
xvi,j
+
B1
B2
ui,j (12)
Nối lỏng của kernel Khi áp đặt chuẩn hóa "chia cho hai" cho mỗi ki,j, chúng tôi áp đặt một công thức kernel thiên hướng nhiều hơn đối với việc mô hình hóa các kernel chéo, tức là, nếu |i−j| nhỏ, kh
i,j lớn hơn nhiều so với khi |i−j| lớn.
Do đó, chúng tôi nới lỏng chuẩn hóa trong hàng và cột đầu tiên như sau. Khi tính toán kh
i,0, kh
0,j chúng tôi sử dụng Phương trình 2. Ngoài ra, đối với Ki,0,K0,j, chúng tôi sử dụng ˆC1= 2C1,ˆC2= 2C2 theo cách sau:
K0,j=ˆC1kh
0,j+ˆC2kv
0,j (13)
Hình 3 minh họa các ví dụ về các kernel khác nhau trước và sau khi nới lỏng.
Chúng tôi lưu ý rằng những sửa đổi này đơn giản và có lẽ không tối ưu. Việc phát triển chuẩn hóa tối ưu theo công thức kernel là một hướng thú vị cho công việc tương lai.
3.3 Tính toán và Độ phức tạp
Độ phức tạp Huấn luyện Quá trình huấn luyện có hai phần. Đầu tiên, chúng tôi tính toán kernel K. Việc tính toán chính nó được giải thích kỹ lưỡng trong Phụ lục 8 và có độ phức tạp thời gian O(LtotLmaxN), không phụ thuộc vào B, và nó nhanh hơn nhiều so với tính toán naïve nhờ một số lựa chọn thiết kế, như chéo hóa tham số, tiền xử lý, và một quy trình cache phức tạp. Tiếp theo, chúng tôi áp dụng một tích chập giữa K và U, sử dụng quy trình cổ điển của FFT, phép nhân từng phần tử, và FFT nghịch đảo. Độ phức tạp của bước này là O(BLtotlog(Ltot)) trong đó B là kích thước batch. Do đó, tổng độ phức tạp là:
O(LmaxNL+Blog(Ltot)Ltot) (14)
Độ phức tạp Suy luận Trong quá trình suy luận, 2-D SSM có thể tính trước các kernel tích chập, dẫn đến chi phí tính toán bổ sung chỉ là tích chập hai chiều của đầu vào lớp và tín hiệu, mất Ltotlog(Ltot) phép toán. Do đó, chi phí tính toán bổ sung tương đối so với ViT vanilla là tối thiểu, vì độ phức tạp bậc hai thống trị độ phức tạp tổng thể.
3.4 SSMs Phức và Thực
Trong khi hầu hết các mô hình học sâu dựa trên SSM, ví dụ S4 [17] hoặc DLR [21], sử dụng SSM phức, MEGA sử dụng EMA, có thể được hiểu như một hạn chế của SSM chéo thành các số thực. Lớp 2-D SSM của chúng tôi có thể được xây dựng trên tham số hóa thực hoặc phức. Mô hình dựa trên SSM-phức mà chúng tôi kiểm tra được mô tả chi tiết trong Phụ lục E.1.
4 Phân tích Mô hình
Trong phần này, chúng tôi nghiên cứu tính biểu cảm của lớp 2-D SSM, cũng như thiên hướng quy nạp không gian độc đáo của nó.
4.1 Tính biểu cảm
Chúng tôi so sánh tính biểu cảm của lớp 2-D SSM của chúng tôi với S4ND [37], một lớp rất gần đây cũng dựa trên SSM đa chiều đa trục. Đầu tiên chúng tôi giới thiệu các khác biệt chính giữa lớp của chúng tôi và S4ND, và sau đó chứng minh khoảng cách tính biểu cảm.
6

--- TRANG 7 ---
Mối quan hệ giữa 2-D SSM và S4ND Sự khác biệt chính giữa S4ND và 2-D SSM là S4ND chạy một SSM 1-D tiêu chuẩn trên mỗi trục độc lập, và những hàm đó được kết hợp để tạo thành một kernel toàn cục. Ngược lại, mô hình của chúng tôi học các hàm đa chiều trên dữ liệu đa trục trực tiếp. Sự khác biệt này phát sinh từ thực tế rằng 2-D SSM có các ma trận hệ thống bổ sung, A2, A3, tập hợp và xử lý thông tin từ các trục khác nhau.
2D-SSM là một tổng quát hóa của S4ND Khi giới hạn trong không gian hai chiều, cho một mô hình 2-D SSM, S4ND được thu được bằng cách giới hạn A2, A3 bằng zero, và đặt A1, A4 như các ma trận hệ thống của S4ND. Ngoài ra, để sao chép S4ND trong 2D-SSM, người ta nên khởi tạo các trạng thái của 2D-SSM bằng các kernel được phân tích từ S4ND.
Hạng tensor như một tiêu chí cho tính biểu cảm Qua nhiều năm, một số tiêu chí đã được đề xuất để đo lường tính biểu cảm của các mô hình neural và cổ điển, như VC-dimension [44], chuẩn, và độ phức tạp Rademacher [1]. Lấy cảm hứng từ [3], chúng tôi sử dụng hạng tensor như thước đo của chúng tôi, và chứng minh các định lý sau:
Định lý 4.1. 8 tham số của 2-D SSM có thể biểu hiện các kernel hạng đầy đủ
Định lý 4.2. S4ND chỉ có thể biểu hiện các kernel hạng 1.
Giả định Để đơn giản, chúng tôi giả định rằng cả lớp 2-D SSM và S4ND đều chứa một kênh và một chiều ẩn. Trong trường hợp này, các ma trận SSM là scalar. Khi giả định về số kênh được bỏ qua, hạng của các kernel mà S4ND có thể biểu hiện tăng từ 1 đến N. Tuy nhiên, điều này đến với chi phí MNr tham số bổ sung, trong đó M là số trục và r là hạng yêu cầu cho S4ND. Cần lưu ý rằng các tác giả của S4ND đã không đánh giá hiệu suất của các mô hình với r >1.
Dưới những giả định này, chứng minh của Định lý 4.1 được chỉ định trong Phụ lục C.1. Chứng minh của 4.2 là tầm thường, và xuất phát từ thực tế rằng để tính toán một kernel đa trục toàn cục K, S4ND lấy phép toán tích ngoài trên các kernel theo trục km trong CLm×1 cho tất cả m trong [M]. Vì mỗi kernel là một vector, rõ ràng rằng:
rank(K) =rank(k1⊗k2⊗. . . k M) = 1 (15)
4.2 Thiên hướng Quy nạp Đặc thù cho Hình ảnh
Nhận thức Vị trí Hai chiều Lớp của chúng tôi được căn cứ bởi một hồi quy tuyến tính hai chiều (Phương trình 2, Hình 1, trái), kết quả là, thông tin vị trí được tính đến theo thiết kế khi kernel K được tính toán từ các tham số A, B, C, và D. Đây là một tính chất độc đáo không có đối tác trong các lớp hiện đại khác. Ví dụ, transformers thiếu thiên hướng vị trí và dựa vào mã hóa vị trí bổ sung, trong khi các lớp tích chập không mã hóa thông tin vị trí rõ ràng một cách bẩm sinh; tuy nhiên, chúng học cách trích xuất các đặc trưng dựa trên các phụ thuộc không gian cục bộ.
Hơn nữa, như có thể thấy trong Mục 5, phương pháp của chúng tôi rất hiệu quả trong việc chèn thiên hướng vị trí vào transformer, thậm chí vượt trội hơn mã hóa vị trí trong một số trường hợp.
Bối cảnh Không gian Có thể kiểm soát Không hạn chế Một hạn chế đáng kể của cả CNNs và transformers là cần phải chọn kích thước patch phù hợp, có thể dẫn đến mất bối cảnh toàn cục hoặc cục bộ. Ngược lại, lớp của chúng tôi thực hiện một tích chập toàn cục có thể kiểm soát, có lợi từ bối cảnh toàn cục, và có thể kiểm soát trường tiếp nhận hiệu quả và nắm bắt hiệu quả các phụ thuộc không gian cục bộ. Hơn nữa, lớp của chúng tôi không bị giới hạn bởi các phụ thuộc giống patch và có thể nắm bắt hiệu quả các đặc trưng cục bộ và toàn cục đa dạng theo hướng ngang, dọc, hoặc chéo (Xem 1, giữa). Mô hình hóa Các tính đối xứng Tương tự như các CNNs khác, lớp của chúng tôi thể hiện tính đồng biến tịnh tiến khi các kernel trượt qua đầu vào trong quá trình tính toán. Ngoài ra, như được chi tiết trong Phụ lục D, cốt lõi của lớp chúng tôi mở rộng qua nhiều hướng, cho phép nó thích ứng với các phép quay và phản xạ một cách tự nhiên.
Hiệu quả Tham số Ngược với CNNs, tham số hóa các bộ lọc có kích thước H×W với ít nhất HW tham số, lớp của chúng tôi có một số tham số cố định và nhỏ (9 tham số mỗi kênh, A1, A2, A3, A4, B1, B2, C1, C2, D trong R), tuy nhiên, những tham số đó có thể được mở rộng thành các kernel hai chiều không giới hạn. Hơn nữa, chúng tôi sử dụng chia sẻ tham số cho tham số hóa SSM qua các kênh, tương tự như CNNs hoặc các lớp không gian trạng thái và ký hiệu nssm như số kênh không được chia sẻ.
7

--- TRANG 8 ---
5 Thí nghiệm
Chúng tôi đánh giá lớp 2-D SSM của chúng tôi như một thiên hướng quy nạp trong các backbone dựa trên ViT khác nhau. Chúng tôi chứng minh tính phổ quát của phương pháp bằng cách kết hợp nó vào các backbone khác nhau, như ViT, DeiT, Swin, và báo cáo kết quả cải thiện so với baseline trên ImageNet-1k, Celeb-A, Tiny-ImageNet và CIFAR-100, với các tham số bổ sung không đáng kể và không cần điều chỉnh siêu tham số, ngoại trừ stochastic depth. Để có cái nhìn tổng quan toàn diện về thiết lập thí nghiệm, vui lòng xem Phụ lục F
Swin, DeiT và ViT Chúng tôi áp dụng một phương pháp đơn giản để kết hợp lớp 2-D SSM của chúng tôi vào các cấu trúc backbone nói trên. Trước Transformer Block, chúng tôi áp dụng 2-D SSM cho tín hiệu đầu vào u trong RL1×L2×D, như được minh họa trong Hình 1. Chúng tôi nhấn mạnh rằng trong trường hợp của Swin Transformer, 2-D SSM hoạt động ở cấp độ patch chứ không phải cấp độ cửa sổ và do đó tiêm thiên hướng 2-D bổ sung giữa các cửa sổ.
Chúng tôi thử nghiệm Swin và ViT trên các tập dữ liệu nhỏ Tiny-ImageNet và CIFAR-100, sử dụng kết quả được báo cáo bởi [29] làm baseline. Như được hiển thị trong Bảng 1, với backbone ViT, chúng tôi cải thiện 0.8% trên CIFAR-100 và 0.5% trên Tiny-ImageNet, và với backbone Swin, chúng tôi cải thiện 3.25% trên CIFAR-100 và 4.25% trên Tiny ImageNet.
Các backbone DeiT và Swin được thử nghiệm trên tập dữ liệu quy mô lớn Celeb-A [34]. Tập dữ liệu này liên quan đến phân loại thuộc tính đa nhãn 40 chiều. Chúng tôi báo cáo độ chính xác tổng hợp trên tất cả 40 nhiệm vụ. Như có thể thấy trong Bảng 2, phiên bản phức vượt trội hơn phiên bản thực trong tất cả các thí nghiệm và đạt được cải thiện 1.41%, 0.72%, 0.6%, và 0.3% so với baseline cho các kích thước DeiT Tiny, Small, và Base, và Swin-Tiny tương ứng.
Mega Trong Mega, chúng tôi thay thế cơ chế EMA bằng 2-D SSM, có nghĩa là chúng tôi chỉ thực hiện lớp của chúng tôi trên Q, K. Chúng tôi so sánh Mega gốc (với EMA) vs Mega-ablate (không có EMA) và Mega 2-D SSM. Chúng tôi kiểm tra mô hình của chúng tôi trên CIFAR-10 Grayscale theo cách đẳng hướng (không giảm kích thước hình ảnh dọc theo kiến trúc, và không có patches), đây là một phần của benchmark Long Range Arena [41]. Như được hiển thị trong Bảng 3, chúng tôi cải thiện kết quả gần 1% so với MEGA, đạt được kết quả tốt nhất. Chúng tôi cũng tiến hành một thí nghiệm trên tập dữ liệu ImageNet-1K [8], và như được hiển thị trong Bảng 4, chúng tôi cải thiện so với kết quả ViT-T của MEGA khoảng 0.4% trong cả độ chính xác Top 1 và Top 5. Cuối cùng, chúng tôi kiểm tra các tập dữ liệu nhỏ khác (Bảng 1) và tìm thấy kết quả vượt trội cho việc kết hợp Mega với 2-D SSM so với baseline hoặc các phương pháp khác.
So sánh với lớp S4ND S4ND là lớp dựa trên SSM N-Chiều duy nhất mà chúng tôi biết; chúng tôi so sánh kết quả của chúng tôi với nó bằng cách thay thế SSM trong ViT, Mega, và Swin. Chúng tôi tiến hành thí nghiệm trên CIFAR100 và Tiny Imagenet. Như được chỉ ra trong Bảng 1, S4ND hoạt động rất kém khi được tích hợp vào backbone ViT gốc trên CIFAR-100 (thấp hơn baseline 1.21%)
Bảng 1: Kết quả sử dụng các backbone ViT, MEGA và Swin trên
các tập dữ liệu Tiny ImageNet (T-IN) và CIFAR-100 (C100). Không
điều chỉnh siêu tham số ngoại trừ stochastic depth.
Mô hình C100 T-IN Thời gian Huấn luyện # Tham số
ViT 73.81 57.07 1x 2.71M (1x)
ViT w/ S4ND. 72.60 56.10 2.22x 2.72M (1.003x)
ViT w/ SSM-r. 74.07 57.56 2.66x 2.72M (1.003)
ViT w/ SSM-c. 73.91 57.66 2.89x 2.73M (1.01x)
Mega-ablate 74.82 56.43 1.1x 2.75M (1x)
Mega 72.27 54.49 1.28x 2.98M (1.08xx)
Mega w/ S4ND 74.9 56.65 1.46x 2.80M (1.02x)
Mega 2-D SSM-r 76.02 57.95 2.03x 2.80M (1.02x)
Mega 2-D SSM-c 75.09 56.51 2.03x 2.84M (1.03x)
Swin 76.87 60.87 1x 7.15M (1x)
Swin-reprod. 77.98 61.29 1x 7.15M (1x)
Swin w/ EMA 77.01 60.13 1.39x 7.52M (1.05x)
Swin w/ S4ND 79.26 64.6 1.29x 7.18M (1.004x)
Swin w/ SSM-r 80.12 65.77 2.16x 7.25M (1.01x)
Swin w/ SSM-c 3.28 12.76 2.18x 7.26M (1.02x)Bảng 2: Kết quả cho DeiT và Swin
với các kích thước khác nhau trên tập dữ liệu
Celeb-A.
Mô hình Top 1 #Param
DeiT-T 88.43 5.532M
DeiT-T w. SSM-r 89.76 5.537M
DeiT-T w. SSM-c 89.84 5.541M
DeiT-S 89.66 21.681M
DeiT-S w. SSM-r 90.24 21.688M
DeiT-S w. SSM-c 90.38 21.691M
DeiT-B 90.13 85.829M
DeiT-B w. SSM-r 90.45 85.841M
DeiT-B w. SSM-c 90.73 85.845M
Swin-T 91.48 27.550M
Swin-T w. SSM-r 91.68 27.556M
Swin-T w. SSM-c 91.78 27.558M
8

--- TRANG 9 ---
Bảng 3: Độ chính xác trên nhiệm vụ phân loại
CIFAR-10 grayscale, là một phần của
Long Range Arena.
Mô hình Image - LRA
Transformer [45] 42.94
S4-v1 87.26
S4-v2 88.65
CCNN-1D [26] 88.90
CCNN-2D [26] 91.12
S4ND [37] 89.90
Hyena [38] 91.20
Mega Ablate 81.00
Mega 90.44
MEGA 2-D SSM 91.31Bảng 4: Độ chính xác ImageNet-1K của các biến thể MEGA.
Mô hình Top 1 Top 5 #tham số
MEGA-ablate 66.97 88.17 5.91M
EMA 69.73 89.76 6.21M
2D-SSM- R 70.11 90.19 5.96M
Hình 3: Ảnh hưởng của kích thước tập huấn luyện.
và không tối ưu khi được tích hợp vào Swin và MEGA (đạt được độ chính xác thấp hơn 1% hoặc hơn trên CIFAR-100 và Tiny-ImageNet cho cả hai backbone).
Độ phức tạp Mẫu Chúng tôi kiểm tra hành vi của mô hình với các backbone khác nhau trên các tập dữ liệu khác nhau so với baseline. Như có thể thấy trong Hình 4, 2-D SSM duy trì kết quả cải thiện so với baseline cho tất cả các backbone, điều này cho thấy chất lượng hiệu quả dữ liệu của mô hình chúng tôi.
Loại bỏ mã hóa vị trí (PE) Chúng tôi so sánh kết quả thực nghiệm thu được với kernel thực so với kernel phức, có và không có PE trong Bảng 5. Rõ ràng, complex-SSM có thể vượt trội hoặc kém hơn so với SSM dựa trên thực, tùy thuộc vào tình huống. Ngoài ra, phát hiện của chúng tôi chỉ ra rằng complex-SSM có xu hướng thể hiện sự bất ổn trong quá trình huấn luyện, có thể dẫn đến hiệu suất kém. Ổn định những mô hình này là một hướng quan trọng cho nghiên cứu tương lai.
Chạy các backbone ViT không có PE làm giảm hiệu suất đáng kể. Ngược lại, khi lớp 2D-SSM của chúng tôi được chèn vào những backbone này, chúng có lợi từ PE, và ngay cả không có PE, chúng vẫn vượt trội hơn các backbone gốc có PE. Những phát hiện này hỗ trợ một phương pháp sáng tạo để giới thiệu thiên hướng vị trí trong ViT: thay vì mã hóa thông tin vị trí trực tiếp vào biểu diễn, nó có thể được tích hợp vào tính toán bằng cách kết hợp các toán tử phụ thuộc vị trí.
Bảng 5: Các ablation. Đối với mỗi mô hình và tập dữ liệu, chúng tôi kiểm tra ảnh hưởng của việc sử dụng mã hóa vị trí gốc và SSM phức (C) so với thực (R). Cột delta đại diện cho sự khác biệt trung bình cho các mô hình có và không có PE. Như có thể thấy, các mô hình của chúng tôi kháng lại việc loại bỏ PE nhiều hơn.
Tập dữ liệu: Tiny-INet (Swin) CIFAR100 (ViT) CelebA (DeiT-T) CIFAR10 (Mega-ISO) Trung bình.
Mô hình có PE không PE có PE không PE có PE không PE có PE không PE delta
Baseline 61.29 58.97 73.26 64.09 88.43 87.99 90.44 75.21 -6.79
+Của chúng tôi (R) 65.77 65.44 74.07 74.89 89.76 89.63 91.31 90.68 -0.07
+Của chúng tôi (C) 3.28 2.16 73.91 74.67 89.84 89.83 90.46 90.79 -0.01
6 Hạn chế
Mặc dù có những kết quả hứa hẹn được trình bày trong bài báo này, có một số hạn chế cần được xem xét. Đầu tiên, việc triển khai hiện tại của lớp được đề xuất có thời gian huấn luyện tương đối chậm, như được hiển thị bởi các phép đo thời gian thực được trình bày trong phần Thí nghiệm 5. Thời gian huấn luyện chậm này có thể còn rõ rệt hơn khi áp dụng phương pháp của chúng tôi cho chuỗi patch hai chiều dài hơn, có thể hạn chế khả năng ứng dụng của nó cho các nhiệm vụ yêu cầu xử lý các phụ thuộc tầm xa đa chiều. Một phương pháp có thể để giảm thiểu thách thức này là sử dụng các scanner song song đa chiều, có thể giảm thời gian huấn luyện của lớp chúng tôi. Ý tưởng chính là mở rộng công việc của S5 [40], tận dụng các scanner song song 1-D để áp dụng SSM trên các chuỗi 1-D thành các scanner song song đa chiều và các chuỗi đa chiều.
9

--- TRANG 10 ---
7 Kết luận
Chúng tôi trình bày một lớp dựa trên SSM không gian mới tổng quát hơn các lớp hiện có, mã hóa thông tin vị trí theo thiết kế, và có thể mô hình hóa các quan hệ không gian một cách biểu cảm hơn so với các SSMs khác, bao gồm S4ND. Khi được thêm vào các backbone ViT khác nhau, nó có thể cải thiện kết quả phân loại trên các benchmark khác nhau mà không cần tối ưu hóa bất kỳ khía cạnh nào hoặc các phần khác của kiến trúc. Trong công việc tương lai, chúng tôi muốn nghiên cứu hành vi của lớp trong bối cảnh các nhiệm vụ thị giác không gian, như xử lý video, phân đoạn hình ảnh, định vị cụm từ, và inpainting hình ảnh. Trong nhiệm vụ cuối cùng, quan điểm đệ quy của lớp có thể được áp dụng trực tiếp để impute các pixel bị thiếu một cách hiệu quả.
8 Lời cảm ơn
Công việc này được hỗ trợ bởi một khoản tài trợ từ Trung tâm AI và Khoa học Dữ liệu Đại học Tel Aviv (TAD), và Quỹ Gia đình Blavatnik. Đóng góp của IZ là một phần của nghiên cứu luận án Tiến sĩ được tiến hành tại Đại học Tel Aviv.
Tài liệu tham khảo
[1]Peter L Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds and structural results. Journal of Machine Learning Research , 3(Nov):463-482, 2002.
[2]Sid Black, Leo Gao, Phil Wang, Connor Leahy, and Stella Biderman. Gpt-neo: Large scale autoregressive language modeling with mesh-tensorflow. If you use this software, please cite it using these metadata , 58, 2021.
[3]Nadav Cohen, Or Sharir, and Amnon Shashua. On the expressive power of deep learning: A tensor analysis. In Conference on learning theory , pages 698-728. PMLR, 2016.
[4]Ekin D Cubuk, Barret Zoph, Jonathon Shlens, and Quoc V Le. Randaugment: Practical automated data augmentation with a reduced search space. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops , pages 702-703, 2020.
[5]Zihang Dai, Hanxiao Liu, Quoc V Le, and Mingxing Tan. Coatnet: Marrying convolution and attention for all data sizes. arXiv preprint arXiv:2106.04803 , 2021.
[6]Tri Dao, Daniel Y Fu, Khaled K Saab, Armin W Thomas, Atri Rudra, and Christopher Ré. Hungry hungry hippos: Towards language modeling with state space models. arXiv preprint arXiv:2212.14052 , 2022.
[7]Stéphane d'Ascoli, Hugo Touvron, Matthew Leavitt, Ari Morcos, Giulio Biroli, and Levent Sagun. Convit: Improving vision transformers with soft convolutional inductive biases. arXiv preprint arXiv:2103.10697 , 2021.
[8]Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition , pages 248-255. Ieee, 2009.
[9]Xiaoyi Dong, Jianmin Bao, Dongdong Chen, Weiming Zhang, Nenghai Yu, Lu Yuan, Dong Chen, and Baining Guo. Cswin transformer: A general vision transformer backbone with cross-shaped windows, 2021.
[10] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. In International Conference on Learning Representations , 2021.
[11] Rikus Eising. Realization and stabilization of 2-d systems. IEEE Transactions on Automatic Control , 23(5):793-799, 1978.
[12] Ettore Fornasini and Giovanni Marchesini. Doubly-indexed dynamical systems: State-space models and structural properties. Mathematical systems theory , 12(1):59-72, 1978.
10

--- TRANG 11 ---
[13] Daniel Y Fu, Elliot L Epstein, Eric Nguyen, Armin W Thomas, Michael Zhang, Tri Dao, Atri Rudra, and Christopher Ré. Simple hardware-efficient long convolutions for sequence modeling. arXiv preprint arXiv:2302.06646 , 2023.
[14] Donald D Givone and Robert P Roesser. Multidimensional linear iterative circuits-general properties. IEEE Transactions on Computers , 100(10):1067-1073, 1972.
[15] Karan Goel, Albert Gu, Chris Donahue, and Christopher Ré. It's raw! audio generation with state-space models. In International Conference on Machine Learning , pages 7616-7633. PMLR, 2022.
[16] David Golub and Xiaodong He. Character-level question answering with attention. arXiv preprint arXiv:1604.00727 , 2016.
[17] Albert Gu, Karan Goel, and Christopher Ré. Efficiently modeling long sequences with structured state spaces. arXiv preprint arXiv:2111.00396 , 2021.
[18] Albert Gu, Ankit Gupta, Karan Goel, and Christopher Ré. On the parameterization and initialization of diagonal state space models. arXiv preprint arXiv:2206.11893 , 2022.
[19] Albert Gu, Isys Johnson, Karan Goel, Khaled Saab, Tri Dao, Atri Rudra, and Christopher Ré. Combining recurrent, convolutional, and continuous-time models with linear state space layers. Advances in Neural Information Processing Systems , 34, 2021.
[20] Ankit Gupta. Diagonal state spaces are as effective as structured state spaces. arXiv preprint arXiv:2203.14343 , 2022.
[21] Ankit Gupta, Harsh Mehta, and Jonathan Berant. Simplifying and understanding state space models with diagonal linear rnns. arXiv preprint arXiv:2212.00768 , 2022.
[22] Ts Hinamoto. Realizations of a state-space model from two-dimensional input-output map. IEEE Transactions on Circuits and Systems , 27(1):36-44, 1980.
[23] Elad Hoffer, Tal Ben-Nun, Itay Hubara, Niv Giladi, Torsten Hoefler, and Daniel Soudry. Augment your batch: Improving generalization through instance repetition. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8129-8138, 2020.
[24] Gao Huang, Yu Sun, Zhuang Liu, Daniel Sedra, and Kilian Q Weinberger. Deep networks with stochastic depth. In European conference on computer vision , pages 646-661. Springer, 2016.
[25] Md Mohaiminul Islam, Mahmudul Hasan, Kishan Shamsundar Athrey, Tony Braskich, and Gedas Bertasius. Efficient movie scene detection using state-space transformers. arXiv preprint arXiv:2212.14427 , 2022.
[26] David M Knigge, David W Romero, Albert Gu, Efstratios Gavves, Erik J Bekkers, Jakub M Tomczak, Mark Hoogendoorn, and Jan-Jakob Sonke. Modelling long range dependencies in nd: From task-specific to a general purpose cnn. arXiv preprint arXiv:2301.10540 , 2023.
[27] Sun-Yuan Kung, B.C. Levy, M. Morf, and T. Kailath. New results in 2-d systems theory, part ii: 2-d state-space models-realization and the notions of controllability, observability, and minimality. Proceedings of the IEEE , 65(6):945-961, 1977.
[28] J Kurek. The general state-space model for a two-dimensional linear digital system. IEEE Transactions on Automatic Control , 30(6):600-602, 1985.
[29] Seung Hoon Lee, Seunghyun Lee, and Byung Cheol Song. Vision transformer for small-size datasets. arXiv preprint arXiv:2112.13492 , 2021.
[30] Kunchang Li, Yali Wang, Junhao Zhang, Peng Gao, Guanglu Song, Yu Liu, Hongsheng Li, and Yu Qiao. Uniformer: Unifying convolution and self-attention for visual recognition, 2022.
[31] Yuhong Li, Tianle Cai, Yi Zhang, Deming Chen, and Debadeepta Dey. What makes convolutional models great on long sequence modeling? arXiv preprint arXiv:2210.09298 , 2022.
11

--- TRANG 12 ---
[32] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo. Swin transformer: Hierarchical vision transformer using shifted windows. In Proceedings of the IEEE/CVF international conference on computer vision , pages 10012-10022, 2021.
[33] Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, and Saining Xie. A convnet for the 2020s. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 11976-11986, 2022.
[34] Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild. In Proceedings of International Conference on Computer Vision (ICCV) , December 2015.
[35] Xuezhe Ma, Chunting Zhou, Xiang Kong, Junxian He, Liangke Gui, Graham Neubig, Jonathan May, and Luke Zettlemoyer. Mega: moving average equipped gated attention. arXiv preprint arXiv:2209.10655 , 2022.
[36] Harsh Mehta, Ankit Gupta, Ashok Cutkosky, and Behnam Neyshabur. Long range language modeling via gated state spaces. arXiv preprint arXiv:2206.13947 , 2022.
[37] Eric Nguyen, Karan Goel, Albert Gu, Gordon W Downs, Preey Shah, Tri Dao, Stephen A Baccus, and Christopher Ré. S4nd: Modeling images and videos as multidimensional signals using state spaces. arXiv preprint arXiv:2210.06583 , 2022.
[38] Michael Poli, Stefano Massaroli, Eric Nguyen, Daniel Y Fu, Tri Dao, Stephen Baccus, Yoshua Bengio, Stefano Ermon, and Christopher Ré. Hyena hierarchy: Towards larger convolutional language models. arXiv preprint arXiv:2302.10866 , 2023.
[39] George Saon, Ankit Gupta, and Xiaodong Cui. Diagonal state space augmented transformers for speech recognition. In ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) , pages 1-5. IEEE, 2023.
[40] Jimmy TH Smith, Andrew Warrington, and Scott W Linderman. Simplified state space layers for sequence modeling. arXiv preprint arXiv:2208.04933 , 2022.
[41] Yi Tay, Mostafa Dehghani, Samira Abnar, Yikang Shen, Dara Bahri, Philip Pham, Jinfeng Rao, Liu Yang, Sebastian Ruder, and Donald Metzler. Long range arena: A benchmark for efficient transformers. arXiv preprint arXiv:2011.04006 , 2020.
[42] Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, and Hervé Jégou. Training data-efficient image transformers & distillation through attention. In International conference on machine learning , pages 10347-10357. PMLR, 2021.
[43] Dmitry Ulyanov, Andrea Vedaldi, and Victor Lempitsky. Deep image prior. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 9446-9454, 2018.
[44] Vladimir N Vapnik and A Ya Chervonenkis. On the uniform convergence of relative frequencies of events to their probabilities. In Measures of complexity , pages 11-30. Springer, 2015.
[45] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems , 30, 2017.
[46] Sangdoo Yun, Dongyoon Han, Seong Joon Oh, Sanghyuk Chun, Junsuk Choe, and Youngjoon Yoo. Cutmix: Regularization strategy to train strong classifiers with localizable features. In Proceedings of the IEEE/CVF international conference on computer vision , pages 6023-6032, 2019.
[47] Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. mixup: Beyond empirical risk minimization. arXiv preprint arXiv:1710.09412 , 2017.
[48] Zhun Zhong, Liang Zheng, Guoliang Kang, Shaozi Li, and Yi Yang. Random erasing data augmentation. In Proceedings of the AAAI conference on artificial intelligence , volume 34, pages 13001-13008, 2020.
[49] Simiao Zuo, Xiaodong Liu, Jian Jiao, Denis Charles, Eren Manavoglu, Tuo Zhao, and Jianfeng Gao. Efficient long sequence modeling via state space augmented transformer. arXiv preprint arXiv:2212.08136 , 2022.
12

--- TRANG 13 ---
A Tính toán kernel
Chúng tôi thảo luận xh
i,j,kh
i,j. Các tính toán tương tự áp dụng cho xv
i,j,kv
i,j.
kh
i,j có thể được viết như:
cho tất cả i, j: kh
i,j=2*LmaxX
zczAz1
1Az2
2Az3
3Az4
4Bz5 (16)
Để ngắn gọn và vì nó không quan trọng đối với phương pháp, chúng tôi giới hạn việc trình bày các kết hợp lũy thừa khác nhau của các ma trận hệ thống A1, A2, A3, A4 và các ma trận đầu vào B1, B2. Như đã lưu ý ở trên, đối với mỗi kh
i,j có nhiều nhất 2Lmax phần tử.
Tiền xử lý Vấn đề tìm cz cho mỗi phần tử trong tổng là một tổng quát hóa của tam giác Pascal. Để tính toán kernel, chúng tôi tính toán tất cả các hệ số và lũy thừa của A1...A4 đến kích thước L1, L2 và cache chúng trước quá trình huấn luyện.
Trong quá trình huấn luyện, chúng tôi sử dụng một quá trình nhân ma trận để tính toán kh
i,j với các tham số học được A1, ..., A4, B1, B2.
Do đó, đối với mỗi ô có nhiều nhất 2Lmax phần tử, và đối với mỗi phần tử, chúng tôi lưu một số giá trị chi hằng số (các giá trị của z và cz). Kết quả là, kích thước của ma trận cache được giới hạn bởi O(LtotLmax).
Cần lưu ý rằng hiện tại trong phương pháp của chúng tôi, chúng tôi cache các hệ số như One Hot Encoding chứ không phải bản thân hệ số, và do đó trong triển khai cụ thể của chúng tôi, chúng tôi cần nhân độ phức tạp thời gian và độ phức tạp bộ nhớ với Lmax.
B Độ phức tạp Thời gian và Bộ nhớ của Phương pháp chúng tôi
Để hiểu độ phức tạp của phương pháp chúng tôi, chúng tôi sẽ phác thảo từng bước tính toán, bắt đầu từ tính toán cache, tạo kernel trong quá trình huấn luyện, và tính toán đầu ra Y sau đó. Như trước đây, để ngắn gọn, chúng tôi sẽ chỉ đề cập đến việc cache các ma trận xh
i,j,kh
i,j, nhưng điều tương tự áp dụng cho các ma trận dọc. Để đơn giản, chúng tôi giả định H= 1 (số kênh).
Cache Như được lưu ý trong Mục 3.3, đối với mỗi ô kh
i,j trong kernel ngang có nhiều nhất 2Lmax phần tử. Cũng như được lưu ý trong Mục 3.3, z1, z2, z3, z4<= 2Lmax. Do đó, đối với mỗi phần tử trong Phương trình 16 chúng tôi lưu z1, z2, z3, z4, z5 và các giá trị alphaz. Tổng cộng, đối với mỗi ô, chúng tôi lưu chi1Lmax giá trị, trong đó chi1 là một hằng số nhỏ. Chúng tôi có Ltot ô và do đó tổng tensor hệ số cache để tính toán Kh có kích thước
chi1*LmaxLtot (17)
Từ bây giờ chúng tôi sẽ ký hiệu các tensor hệ số ngang là CACHE trong
Rchi1×Ltot×Lmax. Lưu ý rằng có một tensor CACHE cho mỗi tham số, nghĩa là
CACHEh
A1, CACHEh
A2, CACHEh
A3, CACHEh
A4, CACHEh
B.
Tạo Kernel Để ngắn gọn, chúng tôi sử dụng Ai chéo có giá trị thực trong [0,1]N (sau sigmoid). Đầu tiên, chúng tôi tính toán Ma trận Vandermonde cho mỗi giá trị riêng A1, A2, A3, A4 đến lũy thừa cao nhất tồn tại trong kernel, là 2Lmax, và ký hiệu V AN i=V andermonde (Ai) trong R2Lmax×N.
Một lần nữa, chúng tôi có Ltot ô trong kernel ngang, mỗi ô có 2*Lmax phần tử. Chúng tôi lấy CACHE Ai chứa cho mỗi phần tử lũy thừa Ai của nó, zi và tạo một ma trận chứa cho mỗi phần tử giá trị Azi
i tương ứng của nó.
Oh
Ai=V AN i[CACHEh
Ai] trong RLtot×2Lmax×N(18)
Bây giờ chúng tôi nhân các ma trận theo từng phần tử để có được giá trị cuối cùng của mỗi phần tử:
Oh
pre−addition =Oh
A1⊙Oh
A2⊙Oh
A3⊙Oh
A4⊙Oh
B⊙Oh
alpha trong RLtot×L2Lmax×N(19)
trong đó ⊙ biểu thị phép nhân theo từng phần tử. Bây giờ đối với mỗi ô, chúng tôi tổng tất cả các phần tử trong tổng ki,j, nghĩa là tổng theo chiều thứ hai:
Oh
post−addition =sum(Oh
pre−addition , d= 1) trong RLtot×N(20)
13

--- TRANG 14 ---
Một lần nữa, tất cả các bước trên cũng được sử dụng cho trục dọc, do đó cuối cùng chúng tôi có thể tính toán kernel bằng cách sử dụng C1, C2 trong RN×1:
K=Oh
post−addition C1+Ov
post−addition C2 trong RL1×L2(21)
Nhớ rằng chúng tôi thực sự đã sử dụng nssm kênh, kích thước kernel là K trong RL1×L2×nssm. Cần lưu ý ở đây rằng việc tính toán kernel không phụ thuộc vào kích thước batch B.
Forward Pass Gọi B là kích thước batch. Chúng tôi muốn chuyển đổi tín hiệu đầu vào U trong
RB×L1×L2×H thành tín hiệu đầu ra Y trong RB×L1×L2×H. Sau khi tính toán kernel, chúng tôi chuyển đổi U, K sang miền tần số thông qua FFT:
Uf=FFT (U), Kf=FFT (K) (22)
Y=IFFT (Uf⊙Kf) (23)
Toàn bộ quá trình này tốn cho chúng tôi O(BHL totlog(Ltot))
Do đó, tổng độ phức tạp thời gian forward pass của chúng tôi là:
O(chiLTOTLmaxnssmN+BHL TOTlogLTOT) (24)
Chi tiết triển khai Chúng tôi đã triển khai quá trình cache và nhân ma trận với One Hot Encoding Vector của các lũy thừa chứ không phải bằng cách sử dụng float đại diện cho chính các lũy thừa. Do đó, kích thước của mỗi COEFFh
i trong triển khai của chúng tôi được nhân với Lmax, cũng như độ phức tạp thời gian của Phương trình 18 và 19.
C Tính biểu cảm
Định lý C.1. Một kênh của 2-D SSM có thể biểu hiện các kernel hạng đầy đủ
Chứng minh. Chúng tôi bắt đầu bằng cách giới hạn các ma trận hệ thống, đầu ra và đầu vào:
A1=A2=A3= 1, A 4= 0, C 1= 1, C2= 0, B 1= 1, B2= 0 (25)
Để đơn giản chúng tôi giả định rằng các giá trị của các trạng thái ban đầu là 0:
cho tất cả i: i=−1→xi,j= 0, cho tất cả j: j=−1→xi,j= 0 (26)
Đủ để chỉ ra rằng (i) K là một ma trận tam giác, và (ii) đường chéo của K chứa các phần tử khác zero. Đầu tiên, bằng cách thay 25,26 vào quy tắc đệ quy 2, nó có thể được đơn giản hóa:
yi,j=xh
i,j, xh
i,j=xh
i,j−1+xv
i,j−1+ui,j, xv
i,j=xh
i−1,j (27)
Cho sự đơn giản hóa này 27, cả (i) và (ii) đều có thể được chứng minh dễ dàng bằng quy nạp trên các đường chéo của K.
Để cung cấp thêm cái nhìn sâu sắc về chứng minh, Phương trình 28 minh họa các giá trị của K.

1 1 1 1 1
0 1 2 3 4
......1 3 6
.........1 4
0. . . . . . 0 1
(28)
Và tổng quát, vì rõ ràng từ 27 rằng
yi,j=xh
i,j=yi,j−1+yi−1,j−1+ui,j, cho tất cả j→k0,j= 1 (29)
Dễ hiểu rằng tam giác trên của K có thể được thu được từ một phép quay của tam giác Pascal.
14

--- TRANG 15 ---
D Mở rộng Mô hình
D.1 SSM Hai chiều
Sử dụng Mô hình Không gian Trạng thái, khi tính toán xh
i,j người ta chỉ xem xét xˆi,ˆj trong đó ˆi<=i,ˆj<=j. Để hưởng lợi từ tính hai chiều, chúng tôi sử dụng một phiên bản trong đó chúng tôi chuyển vị kernel theo hai hoặc bốn hướng (được hiển thị trong các thí nghiệm loại bỏ) và sau đó tổng hợp kết quả. Một cơ chế tương tự cho trường hợp 1-D được sử dụng trong S4, MEGA, và ở nơi khác.
D.2 SSM Đa chiều Đa trục
Để làm phong phú các phụ thuộc có thể được nắm bắt bởi các kernel của chúng tôi, chúng tôi sử dụng một kết hợp tuyến tính có trọng số của các kernel. Dưới giả định rằng các ma trận hệ thống là chéo, các tọa độ N của các trạng thái không phụ thuộc vào nhau, và do đó có thể được tính toán độc lập. Cụ thể, Phương trình 9 có thể được viết lại riêng biệt cho mỗi tọa độ : cho tất cả g trong [N]
xh
i,j[g] =X
0<=ˆi<=iX
0<=ˆj<=jkh¯i,ˆj[g]uˆi,ˆj(30)
Do đó, tăng N sẽ tăng số lượng kernel tạo nên K. Bằng cách sử dụng cấu trúc này, kernel có thể nắm bắt nhiều loại phụ thuộc, trong đó mỗi tọa độ tập trung vào một loại phụ thuộc khác nhau. Hơn nữa, phần mở rộng này thêm thời gian chạy tương đối không đáng kể khi làm việc với các batch lớn, vì chiều batch không ảnh hưởng đến độ phức tạp khi kernel được tính toán. Do đó, tăng N sẽ tăng số lượng kernel tạo thành K.
E Biện minh Các Lựa chọn Thiết kế
E.1 2D-SSM Phức của chúng tôi
Như được giải thích trong Mục 3.3, các mô hình của chúng tôi sử dụng SSMs thực thay vì phức. Để tái tạo, ở đây chúng tôi cung cấp mô tả chi tiết về biến thể SSM phức của chúng tôi: Biến thể phức của mô hình 2-D SSM của chúng tôi, vẫn giả định cho tất cả t, ui,j trong R1, cho tất cả t, yi,j trong R1 và sử dụng:
A1, A2, A3, A4 trong CNxN, B1, B2 trong CNx1, C1, C2 trong C1xN(31)
(các ma trận chéo như trên), và do đó
xh
i,j trong CN, xv
i,j trong CN(32)
Đầu ra vẫn là một số thực yi,j trong R1, và do đó phần thực của Phương trình 2 được sử dụng, cụ thể là
yout
i,j= Re( yi,j)
Đối với SSM phức, chúng tôi lưu ˆAiangle,ˆAiradius trong RN×N, và chúng tôi tính toán Ai trong CN×N theo cách sau:
Aiangle = 2pisigmoid (ˆAiangle), A iradius =sigmoid (ˆAiradius ) (33)
Ai=Airadius*(cos(Aiangle) +i*sin(Aiangle)) trong CNxN(34)
Điều tương tự cũng áp dụng cho B1, B2. Đối với C1, C2, chúng tôi thực hiện cùng phép toán mà không giới hạn kích thước bán kính (không áp dụng sigmoid cho ˆCiradius ).
E.2 Không Weight Decay trên lõi SSM
Trong khi vision transformers và MEGA điều chỉnh mô hình thông qua weight decay, các lớp dựa trên SSM thường không áp dụng điều này [20,17], vì nó làm giảm đáng kể khả năng học của mô hình, đặc biệt là trong bối cảnh các phụ thuộc tầm xa. Nói chung, các giá trị cao hơn của các tham số Ai, B, C dường như không tương ứng với overfitting. Do đó, phương pháp của chúng tôi không sử dụng weight decay trên những tham số đó.
15

--- TRANG 16 ---
F Thiết lập thí nghiệm
Chúng tôi sử dụng PyTorch cho tất cả các thí nghiệm. Như một quyết định có chủ ý, chúng tôi chọn không thực hiện điều chỉnh siêu tham số của backbone và quy trình huấn luyện, ngoại trừ stochastic depth. Tất cả kết quả thí nghiệm được tính trung bình trên seeds = [0,1,2]. Đối với tất cả các tập dữ liệu và backbone, chúng tôi đặt nssm= 8, N= 16 cho tất cả các biến thể dựa trên SSM (SSM-2D thực & phức và S4ND).
Cifar-100 và Tiny imagenet Đối với cả hai tập dữ liệu, chúng tôi sử dụng làm baseline các thí nghiệm được thực hiện bởi [29]. Điều này có nghĩa là chúng tôi tuân theo ứng dụng DeiT [42] về một danh sách dài các phương pháp tăng cường dữ liệu và điều chỉnh, bao gồm Cutmix [46], Mixup [47], stochastic depth [24], repeated augmentation [23], Rand-Augment [4], và random erasing [48]. AdamW được sử dụng làm optimizer. Weight decay được đặt thành 0.05 (ngoại trừ lớp SSM được đặt thành 0), kích thước batch thành 128, và warm-up thành 10. Tất cả các mô hình được huấn luyện trong 100 epochs, và cosine learning rate decay được sử dụng. Learning rate ban đầu được đặt thành 0.003. Trong một số tình huống nhất định, chúng tôi nhận thấy rằng các mô hình của chúng tôi hội tụ nhanh hơn so với phương pháp baseline. Chúng tôi phát hiện ra rằng một sửa đổi nhỏ, cụ thể là tăng gấp đôi stochastic depth, đã chứng minh là quan trọng trong việc tối đa hóa hiệu suất của mô hình.
Khi so sánh S4ND, chúng tôi sử dụng cùng sơ đồ tham số được sử dụng trong 2-D SSM để thực hiện so sánh hợp lệ, bằng cách làm cho C trong Cnssm,N thay vì C trong CH,N như trong bài báo gốc.
CelebA Đối với Celeb-A, kích thước hình ảnh gốc là 178x218, nó được thay đổi kích thước thành 224x224 để phù hợp với backbone DeiT [42] và kích thước patch. Tập dữ liệu bao gồm phân loại thuộc tính đa nhãn 40 chiều. Chúng tôi đang báo cáo độ chính xác trung bình của tất cả 40 nhiệm vụ. Chúng tôi sử dụng cùng tăng cường dữ liệu và siêu tham số như DeiT, và huấn luyện các mô hình trong 20 epochs, tương tự như quy trình huấn luyện của S4ND [37] trên tập dữ liệu này.
Imagenet và CIFAR-10 Grayscale Chúng tôi sử dụng chính xác cùng quy trình huấn luyện bao gồm siêu tham số, tăng cường dữ liệu và môi trường huấn luyện như được sử dụng trong kho git của baseline [35] cho những tập dữ liệu đó.
16

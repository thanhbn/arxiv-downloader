# 2406.02395.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/ssm/2406.02395.pdf
# Kích thước tệp: 5552646 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
GrootVL: Cấu trúc cây là tất cả những gì bạn cần
trong Mô hình Không gian Trạng thái
Yicheng Xiao1†*, Lin Song2,3B*,
Shaoli Huang3, Jiangshan Wang1, Siyu Song4, Yixiao Ge2,3, Xiu Li1B, Ying Shan2,3
1Trường Đại học Quốc tế Thâm Quyến Thanh Hoa, Đại học Thanh Hoa
2ARC Lab, Tencent PCG3Tencent AI Lab4Đại học Sư phạm Nam Trung Quốc
xiaoyc23@mails.tsinghua.edu.cn ronnysong@tencent.com

Tóm tắt
Các mô hình không gian trạng thái, sử dụng các đặc trưng được truyền đệ quy, thể hiện khả năng biểu diễn mạnh mẽ có thể so sánh với các mô hình Transformer và hiệu quả vượt trội. Tuy nhiên, bị hạn chế bởi các ràng buộc hình học vốn có của chuỗi, nó vẫn còn thiếu sót trong việc mô hình hóa các phụ thuộc tầm xa. Để giải quyết vấn đề này, chúng tôi đề xuất mạng GrootVL, trước tiên tự động tạo ra một cấu trúc cây dựa trên mối quan hệ không gian và đặc trưng đầu vào. Sau đó, việc truyền đặc trưng được thực hiện dựa trên đồ thị này, từ đó phá vỡ các ràng buộc chuỗi ban đầu để đạt được khả năng biểu diễn mạnh mẽ hơn. Ngoài ra, chúng tôi giới thiệu một thuật toán quy hoạch động có độ phức tạp tuyến tính để tăng cường các tương tác tầm xa mà không tăng chi phí tính toán. GrootVL là một khung đa phương thức linh hoạt có thể được áp dụng cho cả nhiệm vụ thị giác và văn bản. Các thí nghiệm mở rộng chứng minh rằng phương pháp của chúng tôi vượt trội đáng kể so với các mô hình không gian trạng thái có cấu trúc hiện có về phân loại hình ảnh, phát hiện và phân đoạn đối tượng. Bên cạnh đó, bằng cách tinh chỉnh các mô hình ngôn ngữ lớn, cách tiếp cận của chúng tôi đạt được những cải thiện nhất quán trong nhiều nhiệm vụ văn bản với chi phí huấn luyện tối thiểu. Mã nguồn có sẵn tại https://github.com/EasonXiao-888/GrootVL.

1 Giới thiệu
Các mô hình cơ bản chính thống chủ yếu dựa trên kiến trúc CNN [27,57,41,29,13] và Transformer [15,40,39,54,14], chiếm ưu thế trong các nhiệm vụ thị giác và ngôn ngữ. Tuy nhiên, trường tiếp nhận nhỏ của CNN và độ phức tạp cao của Transformer khiến việc tạo ra sự cân bằng tốt giữa hiệu quả và hiệu suất trở nên thách thức. Các mô hình không gian trạng thái (SSM) [21,23,48] cố gắng phá vỡ thế bế tắc này, mô hình hóa các chuỗi theo dạng đệ quy. Khác với các mạng nơ-ron đệ quy trước đây [28,7], những cách tiếp cận này lấy cảm hứng từ các hệ thống điều khiển, tận dụng việc khởi tạo tham số cấu trúc để đạt được tối ưu hóa ổn định và hiệu suất tính toán vượt trội.

Tuy nhiên, nó vẫn dễ bị lỗi nội tại được chia sẻ bởi các mạng nơ-ron đệ quy, tức là, thiếu hụt trong việc nắm bắt các phụ thuộc tầm xa.

Gần đây, một cơ chế lựa chọn cải tiến được gọi là Mamba [18] được đề xuất để giảm thiểu các thách thức của SSM. Cách tiếp cận này giới thiệu điều biến trọng số trong quá trình truyền, mở rộng đáng kể trường tiếp nhận hiệu quả và đạt được hiệu suất ấn tượng trong các nhiệm vụ NLP. Bên cạnh đó, nhiều nghiên cứu nhằm mở rộng Mamba vào thị giác máy tính, bằng cách sử dụng các chiến lược được định nghĩa trước khác nhau để ánh xạ đặc trưng hình ảnh 2D thành chuỗi 1D. ViM [70] và VMamba [38] sử dụng chiến lược quét raster đa hướng, trong khi LocalMamba [31] tiếp tục giới hạn phạm vi truyền của nó trong một cửa sổ cục bộ. Họ đã thành công trong việc điều chỉnh Mamba cho đầu vào hình ảnh.

Tuy nhiên, như được hiển thị trong Hình 1(a), cả chiến lược quét raster và quét cục bộ đều tạo ra sự gián đoạn không gian giữa các pixel liền kề, và các biến đổi đặc trưng trong Mamba dựa vào mối quan hệ đặc trưng, từ đó cản trở dòng thông tin hiệu quả trong một chuỗi. Ngoài ra, PlainMamba [62] giới thiệu chiến lược quét liên tục, nhằm giảm thiểu vấn đề này bằng cách đơn giản điều chỉnh hướng truyền tại các vị trí gián đoạn. Tuy nhiên, tất cả các phương pháp này dựa vào quỹ đạo truyền cố định, bỏ qua cấu trúc không gian vốn có và không thể điều chỉnh động cấu trúc dựa trên đầu vào. Do đó, bài báo này nỗ lực khám phá một góc nhìn mới: giới thiệu một mạng cấu trúc nhận biết đầu vào cho việc truyền đặc trưng trong các mô hình không gian trạng thái.

Để đạt được điều này, chúng tôi phát triển một mô hình không gian trạng thái cây và đề xuất một khung mới, được gọi là GrootVL, tự động tạo ra cấu trúc cây dựa trên đặc trưng đầu vào và sau đó thực hiện truyền đặc trưng trên đó. Cụ thể, hai mạng con, GrootV và GrootL, được thiết kế cho các nhiệm vụ thị giác và ngôn ngữ tương ứng, được minh họa trong Hình 1(b) và Hình 1(d). Đối với nhiệm vụ thị giác, được thúc đẩy bởi [64,50], chúng tôi đầu tiên sử dụng sự khác biệt giữa các đặc trưng liền kề để xây dựng cây khung tối thiểu trên đồ thị phẳng bốn kết nối. Quá trình này có thể mã hóa thích ứng thông tin không gian và ngữ nghĩa thành đồ thị cây [64,50]. Sau đó, chúng tôi lặp qua từng pixel, coi nó là đỉnh gốc, và tổng hợp các đặc trưng của các pixel khác sử dụng hàm chuyển trạng thái của Mamba. Một cách trực quan, hoạt động này yêu cầu hai cấp độ duyệt qua toàn bộ tập pixel, dẫn đến độ phức tạp bậc hai không thể chấp nhận được so với số lượng pixel. Tuy nhiên, với việc đồ thị cây không có chu trình, chúng tôi đề xuất một thuật toán quy hoạch động để đạt được truyền có độ phức tạp tuyến tính. Với cấu trúc cây nhận biết đầu vào như vậy, cách tiếp cận của chúng tôi cho phép các tương tác tầm xa hiệu quả hơn trong khi duy trì độ phức tạp tuyến tính nhất quán với Mamba.

Hơn nữa, phương pháp của chúng tôi cũng có thể được áp dụng cho các nhiệm vụ ngôn ngữ bằng cách xây dựng cấu trúc cây dựa trên sự khác biệt giữa các đặc trưng token, vượt qua các ràng buộc hình học của chuỗi văn bản. Sử dụng quy trình tổng hợp tương tự như GrootV, GrootL có thể nâng cao đáng kể biểu diễn ngôn ngữ của Mô hình Ngôn ngữ Lớn được đào tạo trước [18].

Chúng tôi tiến hành các thí nghiệm mở rộng để xác thực hiệu quả của GrootV trên nhiều điểm chuẩn thị giác, tức là phân loại hình ảnh trên ImageNet [12], phát hiện đối tượng và phân đoạn thể hiện trên MSCOCO [36] cũng như phân đoạn ngữ nghĩa trên ADE20K [68]. Kết quả cho thấy phương pháp của chúng tôi vượt trội đáng kể so với các phương pháp dựa trên SSM hiện có cho tất cả các điểm chuẩn và đạt được hiệu suất cạnh tranh với các cách tiếp cận dựa trên CNN và Transformer. Hơn nữa, với tinh chỉnh LoRA [30], GrootL thể hiện những cải thiện nhất quán cho mô hình ngôn ngữ lớn được đào tạo trước với chi phí huấn luyện tối thiểu.

2 Nghiên cứu liên quan

2.1 Mô hình Thị giác Cơ bản Thông thường

Sự phát triển của mạng nơ-ron sâu đã là chất xúc tác quan trọng trong nhận thức thị giác máy. Các mô hình dựa trên CNN [27,47,32,24,56,65,35,51,66] đầu tiên xuất hiện như những cột mốc quan trọng, với ResNet [27] đặc biệt nổi bật nhờ mô-đun kết nối dư sáng tạo, được áp dụng rộng rãi trên các lĩnh vực nhận dạng thị giác đa dạng. Hơn nữa, các hoạt động tích chập hiệu quả hơn được công thức hóa, chẳng hạn như tích chập theo chiều sâu được giới thiệu bởi MobileNet [29], mở đường cho các mô hình nhẹ. Ngoài ra, tích chập biến dạng [10] đã được đề xuất để tăng cường trường tiếp nhận. Sau đó, ViT [15] đã cải thiện đáng kể mô hình nhận dạng thị giác. Nó tái công thức hóa thiết kế kiến trúc và cơ chế huấn luyện bằng cách kết hợp kiến trúc transformer trong xử lý ngôn ngữ tự nhiên, nhằm cải thiện hiệu quả tính toán và mở rộng phạm vi ứng dụng. Sau đó, nghiên cứu tập trung vào ViT phân cấp [40,39,11,58,14,52,5] thiết kế mạng bằng cách giảm độ phân giải đặc trưng qua xương sống dần dần. Hơn nữa, nghiên cứu gần đây được xây dựng trên CNN phục vụ để nhấn mạnh lại khả năng của mạng tích chập. Ví dụ, InternImage [57] trình bày một mô hình lớn dựa trên CNN biến dạng, trong khi UniRepLKNet [13] thể hiện hiệu suất đáng kể thông qua tích chập kernel lớn.

2.2 Khám phá về Mô hình Không gian Trạng thái

Các mô hình không gian trạng thái (SSM) đã nổi lên như một lớp mô hình mới trong mô hình học sâu, cho thấy tiềm năng đáng kể cho việc biến đổi chuỗi [22,21,48]. Các phương pháp này đã thu hút sự chú ý đáng kể do khả năng mở rộng tuyến tính với độ dài chuỗi. Phương pháp ban đầu, LSSL [22], lấy cảm hứng từ các mô hình không gian trạng thái liên tục trong hệ thống điều khiển và cố gắng

--- TRANG 2 ---
giải quyết vấn đề phụ thuộc tầm xa thông qua sự kết hợp với khởi tạo HIPPO [19]. S4 [21] đề xuất chuẩn hóa các tham số thành ma trận chéo, thúc đẩy một loạt nghiên cứu tiếp theo về SSM có cấu trúc [23,20,25,18]. Gần đây, Mô hình Không gian Trạng thái Chọn lọc [18], được biết đến với tên Mamba, tạo ra sự cân bằng giữa hiệu quả và hiệu suất thông qua thiết kế chiến lược khởi tạo tham số phụ thuộc đầu vào, đã nổi lên như một đối thủ mạnh mẽ cho cả cấu trúc transformer và CNN. Ngoài việc thể hiện kết quả vượt trội trong mô hình hóa chuỗi, Mamba đã được tích hợp liền mạch vào lĩnh vực thị giác [70,38,31,62]. Những nghiên cứu này thường dựa vào các cơ chế quét cố định thủ công để giảm thiểu sai lệch thực thi của mô hình không gian trạng thái chọn lọc trên hình ảnh 2D không nhân quả. Tuy nhiên, những cách tiếp cận đơn giản như vậy không thể nắm bắt hiệu quả các mối quan hệ không gian trong mô hình phụ thuộc đầu vào. Để giải quyết hạn chế này, chúng tôi đề xuất một khung hiệu quả GrootVL trong công trình này để tăng cường mô hình tầm xa cho cả nhiệm vụ thị giác và ngôn ngữ bằng cách giới thiệu cấu trúc cấu trúc dựa trên cây nhận biết đầu vào.

3 Phương pháp

Trong phần này, chúng tôi đầu tiên xem lại mô hình không gian trạng thái chọn lọc [18] và sau đó trình bày chi tiết thuật toán quét cấu trúc nhận biết đầu vào của chúng tôi cho mô hình không gian trạng thái. Với thuật toán vượt trội này, chúng tôi phát triển một SSM cây và đề xuất một khung mới có tên GrootVL, bao gồm hai mạng con: GrootV cho nhiệm vụ thị giác và GrootL để tinh chỉnh mô hình ngôn ngữ được đào tạo trước [18].

3.1 Xem lại Mô hình Không gian Trạng thái Chọn lọc

Các Mô hình Không gian Trạng thái (SSM) thường được coi là các hệ thống tuyến tính bất biến theo thời gian liên tục [59] ánh xạ kích thích đầu vào x(t) trong R1×D thành tín hiệu đầu ra y(t) trong R1×D thông qua vector trạng thái h(t) trong R1×N, trong đó t, D và N biểu thị bước thời gian, số kênh của tín hiệu và kích thước trạng thái, tương ứng. Các mô hình này có thể được công thức hóa như các phương trình vi phân thường tuyến tính sau:

h′(t) = Ah(t) + Bx(t), y(t) = Ch(t) + Dx(t), (1)

trong đó A trong RN×N, B trong RN×D, C trong RN×D và hệ số feedthrough D trong RD.

Rời rạc hóa. Mặc dù SSM phục vụ như một công cụ mạnh mẽ trong hệ thống và kỹ thuật điều khiển, bản chất liên tục theo thời gian của nó đặt ra thách thức cho việc tích hợp vào kiến trúc học sâu. Để giảm thiểu vấn đề này, hầu hết các phương pháp sử dụng quy tắc giữ bậc không [18] để rời rạc hóa hệ thống liên tục được mô tả bởi Eq. (1) và chuyển đổi các biến liên tục (A,B,C,D) thành các tham số rời rạc tương ứng (Ā,B̄,C̄,D̄) trên thang thời gian lấy mẫu được chỉ định Δ trong RD:

Ā = e^(ΔA), B̄ = (e^(ΔA) - I)/A^(-1) B, C̄ = C, D̄ = D (2)

--- TRANG 3 ---
Ngoài ra, nhiều phương pháp cải tiến [38,18] sử dụng một xấp xỉ của B̄ dựa trên Chuỗi Taylor bậc nhất:

B̄ = (e^(ΔA) - I)/A^(-1) B ≈ (ΔA)(ΔA)^(-1) ΔB = ΔB (3)

Cơ chế Chọn lọc. Các SSM trước đây lưu trữ thông tin thông qua các trạng thái hữu hạn và tính bất biến theo thời gian vốn có, điều này hạn chế hiệu quả của chúng. Do đó, Mamba [18] giới thiệu cơ chế động để lọc chọn lọc đầu vào thành một trạng thái tuần tự. Cụ thể, nó sử dụng Phép chiếu Tuyến tính để tính toán các tham số {Bi}^L_{i=1}, {Ci}^L_{i=1} và {Δi}^L_{i=1} từ chuỗi đầu vào {xi}^L_{i=1} với xi trong R1×D trực tiếp để cải thiện khả năng nhận biết ngữ cảnh. Sau đó, chuỗi đầu ra {yi}^L_{i=1} có thể được tính toán với những tham số rời rạc hóa thích ứng đầu vào như sau:

hi = Āi hi-1 + B̄i xi, yi = Ci hi + Dxi (4)

3.2 Mô hình Không gian Trạng thái Cây

Mamba [18] đã thể hiện hiệu suất đáng chú ý trong việc mô hình hóa các phụ thuộc của các từ liên tiếp trong một chuỗi. Tuy nhiên, khả năng áp dụng của nó trong các nhiệm vụ ngữ cảnh dài, đặc biệt là mô hình thị giác, vẫn đặt ra một số thách thức. Đối với các nhiệm vụ thị giác, nhiều phương pháp cố gắng giải quyết vấn đề này bằng cách sử dụng các chiến lược quét cố định, chẳng hạn như quét raster đa hướng [38,70], quét cục bộ [31], và quét liên tục [62]. Tuy nhiên, các phương pháp quét thủ công này không thể bảo tồn hiệu quả thông tin cấu trúc 2D của hình ảnh.

Theo thiết kế trong Mamba [18], chúng tôi xây dựng một khối biến đổi như một mô hình không gian trạng thái cây, được trình bày trong Hình 2. Sự khác biệt duy nhất giữa khối của chúng tôi và Mamba nằm ở việc thay thế khối không gian trạng thái có cấu trúc bằng thuật toán quét cây được đề xuất. Trong thuật toán quét cây, chúng tôi tạo ra một cấu trúc cây và sau đó truyền trạng thái của mỗi đỉnh dọc theo đường cấu trúc để thu được biểu diễn đặc trưng mạnh mẽ. Ngoài ra, thuật toán của chúng tôi có thể tăng cường hiệu quả biểu diễn ngôn ngữ bằng cách kết hợp cấu trúc cây như vậy trong quá trình xử lý văn bản, vượt qua các ràng buộc hình học của chuỗi văn bản. Trong phần sau, chúng tôi trình bày chi tiết thuật toán quét cây được đề xuất và các ứng dụng của nó cho các nhiệm vụ đa phương thức.

Thuật toán Quét Cây. Với đặc trưng đầu vào X = {xi}^L_{i=1} trong đó L là độ dài chuỗi (hoặc số pixel đầu vào), chúng tôi xây dựng đồ thị không hướng kết nối m G = (V, E) cho đặc trưng. m là một siêu tham số biểu thị số lượng token liền kề. Theo [64,50], chúng tôi đặt m = 4 cho các nhiệm vụ thị giác, có nghĩa là mỗi pixel được kết nối với bốn pixel lân cận. Đối với các nhiệm vụ ngôn ngữ, chúng tôi đặt m = 3 theo mặc định, có nghĩa là mỗi token được kết nối với ba token trước đó. Ngoài ra, các đỉnh V đại diện cho các embedding pixel (hoặc token), và E biểu thị

--- TRANG 4 ---
các cạnh của đồ thị. Trọng số cạnh được tính toán bởi sự khác biệt đặc trưng giữa các đỉnh liền kề. Bên cạnh đó, chỉ số đo sự khác biệt sử dụng khoảng cách cosine theo mặc định, và so sánh với các chỉ số khác tham khảo Bảng 5.

Chúng tôi sử dụng thuật toán Contractive Boruvka [2] để cắt tỉa các cạnh có sự khác biệt đáng kể, tạo ra cây khung tối thiểu (MST) GT có tổng trọng số sự khác biệt là tối thiểu trong tất cả các cây khung. Trong quá trình truyền, chúng tôi lặp qua từng đỉnh, coi nó là gốc, và tổng hợp các đặc trưng của các đỉnh còn lại. Một cách trực quan, việc áp dụng truyền trạng thái trong cấu hình hình học như vậy tạo ra các tương tác ưu tiên giữa các đỉnh có khoảng cách không gian và đặc trưng nhỏ. Theo Mamba, chúng tôi sử dụng ma trận chuyển phụ thuộc dữ liệu cho việc truyền trạng thái. Đối với đỉnh k, chúng tôi ký hiệu ma trận chuyển với cha mẹ của nó là Āk. Hơn nữa, theo Eq. (4), quá trình tổng hợp trạng thái cho đỉnh thứ i có thể được công thức hóa như:

hi = Σ_{for all j in Ω} S(Eij) B̄j xj, S(Eij) = Π_{k in Nij} Āk, (5)

trong đó Ω biểu thị tập chỉ số của tất cả các đỉnh trong cây. S(Eij) đại diện cho trọng số đường dẫn của siêu cạnh Eij được truy từ đỉnh thứ j đến đỉnh thứ i trong cây GT, và Nij biểu thị tập chỉ số của tất cả các đỉnh trên siêu cạnh này. Đối với các nhiệm vụ thị giác, chúng tôi lặp qua từng đỉnh, coi nó là gốc của cây khung GT, và tổng hợp các trạng thái từ các đỉnh khác, từ đó thu được các trạng thái được biến đổi {hi}^L_{i=1}. Đối với các nhiệm vụ văn bản, vì cách dự đoán nhân quả trong các mô hình ngôn ngữ lớn, chúng tôi chỉ lấy token cuối cùng làm gốc và tổng hợp từ các token khác. Để đạt được huấn luyện đầu cuối, chúng tôi rút ra đạo hàm của trạng thái ẩn đầu ra hi đối với các biến đầu vào Āk, B̄j và xj như sau:

∂hi/∂xj = S(Eij) B̄j, ∂hi/∂B̄j = S(Eij) xj (6)

∂hi/∂Āk = Σ_{for all j in C^i_k} B̄j xj S(Ekj) S(Ein), (7)

trong đó C^i_k biểu thị các con của đỉnh k trong cây GT có gốc là đỉnh i, và n biểu thị cha mẹ của đỉnh k trong Eq. (7). Cuối cùng, đặc trưng đầu ra Y có thể được công thức hóa như:

Y = C ⊙ Norm(H) + D ⊙ X, (8)

trong đó Y, H và X biểu thị ngăn xếp của {yi}^L_{i=1}, {hi}^L_{i=1} và {x}^L_{i=1} tương ứng. ⊙ biểu thị phép nhân từng phần tử.

Triển khai Hiệu quả cho Đa phương thức. Đối với các nhiệm vụ thị giác, thuật toán quét cây yêu cầu hai cấp độ duyệt qua toàn bộ tập pixel, dẫn đến độ phức tạp bậc hai không thể chấp nhận được so với số lượng pixel O(L²). Để giảm thiểu vấn đề này, chúng tôi sử dụng quy trình quy hoạch động để tăng tốc các quá trình suy luận và huấn luyện như được trình bày chi tiết trong Thuật toán 1, dẫn đến độ phức tạp tuyến tính O(L). Đối với các nhiệm vụ văn bản, chúng tôi thực hiện cách tiếp cận tổng hợp một hướng (được hiển thị trong Thuật toán 2 của Phụ lục B) tuân thủ tính chất nhân quả của ngôn ngữ. Hơn nữa, chúng tôi cung cấp quá trình lan truyền ngược cho cả quá trình Quét Cây Thị giác và Quét Cây Ngôn ngữ, có bằng chứng chi tiết tham khảo Phụ lục C.

--- TRANG 5 ---
Thuật toán 1 Quét Cây Thị giác
Đầu vào: Đặc trưng đầu vào {xi}^L_{i=1}; Ma trận đầu vào {B̄i}^L_{i=1}; Ma trận trạng thái {Āi}^L_{i=1}; Gradient của loss đối với trạng thái ẩn {∂Loss/∂hi}^L_{i=1}; Cây Khung Tối thiểu GT.

Đường dẫn Duyệt: Gốc, ..., Lá ← BFS(GT) ▷ Thứ tự cấu trúc breadth-first của GT

Tiến:
Khởi tạo: {x^i_i}^L_{i=1} ← {xi}^L_{i=1}
for i ← Lá to Gốc do
    x^i_i = B̄i xi + Σ_{for all j in {t|Par(t)=i}} x^i_j Āj
end for
for i ← Gốc to Lá do
    if i is Gốc then
        hi = x^i_i
    else
        hi = Āi(h_{Par(i)} - Āi x^i_i) + x^i_i = (1 - Ā²i) x^i_i + Āi h_{Par(i)}
    end if
end for

Lùi:
Khởi tạo: {eta_i}^L_{i=1} ← {∂Loss/∂hi}^L_{i=1}
for i ← Lá to Gốc do
    eta_i = B̄i ∂Loss/∂hi + Σ_{for all j in {t|Par(t)=i}} eta_j Āj
end for
for i ← Gốc to Lá do
    if i is Gốc then
        ∂Loss/∂xi = eta_i B̄i, ∂Loss/∂B̄i = eta_i xi, ∂Loss/∂Āi = 0
    else
        ∂Loss/∂xi = (1 - Ā²i) eta_i B̄i + Āi ∂Loss/∂x_{Par(i)} B̄i, ∂Loss/∂B̄i = (1 - Ā²i) eta_i xi + Āi ∂Loss/∂B̄_{Par(i)} xi
        ∂Loss/∂Āi = eta_i * (hi - Āi x^i_i) + x^i_i * (∂Loss/∂xi - Āi eta_i) = eta_i hi + x^i_i ∂Loss/∂xi - 2 eta_i x^i_i Āi
    end if
end for

Đầu ra: Trạng thái ẩn {hi}^L_{i=1}; Grad. của loss đối với đặc trưng đầu vào {∂Loss/∂xi}^L_{i=1}; Grad. của loss đối với ma trận đầu vào {∂Loss/∂B̄i}^L_{i=1}; Grad. của loss đối với ma trận trạng thái {∂Loss/∂Āi}^L_{i=1}.

3.3 Ứng dụng cho Thị giác và Ngôn ngữ

GrootV Với một hình ảnh có hình dạng H×W×3, mục tiêu của chúng tôi là thu được các đặc trưng thị giác chất lượng cao cho các nhiệm vụ hạ nguồn. Để đạt được điều này, chúng tôi đề xuất một kiến trúc thị giác hiệu quả GrootV bao gồm một mô-đun stem, một số khối cơ bản và các lớp downsampling để tạo ra các biểu diễn phân cấp được minh họa trong Hình 3. Nhìn chung, GrootV của chúng tôi bao gồm bốn giai đoạn tương tự như các xương sống thị giác chung trước đây [41,40,57,38]. Chúng tôi tích hợp mô-đun stem trước giai đoạn đầu tiên để giảm độ phân giải của tín hiệu hình ảnh đầu vào với hệ số 4, dẫn đến bản đồ đặc trưng có hình dạng H/4 × W/4 × C. Nó bao gồm hai tích chập, hai lớp Layer Normalization (LN) và một hàm kích hoạt GELU. Kích thước kernel cho cả hai tích chập là 3 với stride 2 và padding 1. Tương tự, một lớp downsampling bao gồm một tích chập 3×3 với stride 2 và padding 1 và một lớp LN. Được đặt giữa hai giai đoạn, nó phục vụ để downsample bản đồ đặc trưng đầu vào với hệ số 2. Được thúc đẩy bởi [57,38], chúng tôi thiết kế một khối residual với các kết nối skip để tích hợp Mô hình Không gian Trạng thái Cây cơ bản của chúng tôi trong Sec. 3.2. Chi tiết, chúng tôi đầu tiên chuẩn hóa các đặc trưng đầu vào với lớp LN. Các prior không gian và phụ thuộc tầm xa sau đó được thu được thông qua thuật toán quét cây của chúng tôi với các kết nối residual được thiết lập cùng với các đặc trưng đầu vào. Cuối cùng, một mạng nơ-ron feedforward được sử dụng để chiếu các đặc trưng được chuẩn hóa thành tín hiệu đầu ra như được hiển thị trong Hình 3. Dựa trên các thành phần gốc trên, chúng tôi phát triển GrootV của chúng tôi trong ba quy mô, tức là GrootV-Tiny, GrootV-Small và GrootV-Base.

GrootL Các mạng nơ-ron đệ quy dựa vào bộ nhớ cố định để bảo tồn thông tin quá khứ, điều này đặt ra các hạn chế khi xử lý ngữ cảnh dài nơi các từ liên quan cách xa thời điểm hiện tại. Trong khi Mamba [18] sử dụng cơ chế lựa chọn để tăng cường nhận thức ngữ cảnh, kích thước bộ nhớ cố định của nó không thể mở rộng theo thời gian, dẫn đến không gian trạng thái hạn chế. Do đó, khả năng ngoại suy giảm trong quá trình cuộn khi prompt mở rộng. Để giảm thiểu vấn đề này, chúng tôi đề xuất một mô hình tinh chỉnh hiệu quả. Cụ thể, nhánh cấu trúc dựa trên cây được xây dựng trên cuộn một chiều với hệ số tỷ lệ, cho phép chuyển trạng thái trong cấu trúc như vậy. Sự sắp xếp này tạo điều kiện cho sự tương tác ưu tiên của các token có liên quan về mặt ngữ nghĩa. Đáng chú ý là mô hình này không giới thiệu bất kỳ tham số huấn luyện bổ sung nào. Thay vào đó, nó sử dụng các tham số biến đổi trạng thái được đào tạo trước để tiến hành tổng hợp ngữ nghĩa bằng cách kết hợp các cấu trúc cấu trúc. Kết quả thí nghiệm chứng minh hiệu quả của cách tiếp cận của chúng tôi.

4 Thí nghiệm

Chúng tôi tiến hành các thí nghiệm mở rộng để đánh giá hiệu quả của GrootV và so sánh nó với các mô hình tiên tiến dựa trên CNN, Transformer và SSM bao phủ các nhiệm vụ hạ nguồn khác nhau, bao gồm phân loại hình ảnh, phát hiện đối tượng và phân đoạn ngữ nghĩa. Hơn nữa, chúng tôi xác thực khả năng của GrootL trong lĩnh vực hiểu ngôn ngữ tự nhiên.

4.1 Phân loại Hình ảnh

Cài đặt. Chúng tôi đánh giá hiệu suất phân loại của GrootV trên tập dữ liệu ImageNet-1k [12]. Theo các thực hành trước đây [40,41,57,38], tất cả các mô hình GrootV được huấn luyện trong 300 epoch từ đầu sử dụng trình tối ưu AdamW với chiến lược warm-up 20 epoch. Trong quá trình huấn luyện, chúng tôi sử dụng Cosine Scheduler với tốc độ học ban đầu 1×10^{-3} và weight decay 0.05. Ngoài ra, exponential moving average (EMA) cũng được áp dụng.

Kết quả. Kết quả so sánh được tóm tắt trong Bảng 1 cho thấy GrootV dẫn đầu tất cả các mô hình dựa trên SSM và có tính cạnh tranh với CNN và Transformer tiên tiến qua các quy mô tiny, small và base. Cụ thể, GrootV-T đạt được 83.4% Top-1 Acc. tăng ViM-S 2.9%, LocalVim-S 2.2%, PlainMamba-L2 1.8% và VMamba-T 0.9% với FLOPs tương tự. Ngoài ra, nó vượt trội ConvNeXt-T 1.3% và Swin-T 2.2%, chứng minh hiệu quả của phương pháp chúng tôi.

4.2 Phát hiện Đối tượng

Cài đặt. Chúng tôi xác minh hiệu suất phát hiện của GrootV trên tập dữ liệu MSCOCO 2017 [36] với thư viện MMDetection [3]. Chúng tôi theo các công trình trước đây [38,57,40,31,49,51,67,63,6] để xác thực các nhiệm vụ phát hiện đối tượng và phân đoạn thể hiện với Mask-RCNN [26]. Cụ thể, chúng tôi áp dụng

--- TRANG 7 ---
trình tối ưu AdamW với tốc độ học 1×10^{-4} và batch size 16 để tối ưu hóa mô hình được xây dựng trên các xương sống phân loại được đào tạo trước của chúng tôi trên ImageNet-1K. Các lịch trình huấn luyện bao gồm 1× (12 epoch) và 3× (36 epoch) với tăng cường dữ liệu đa tỷ lệ.

Kết quả. Như được mô tả trong Bảng 7 (trong Phụ lục A.), phương pháp của chúng tôi vượt trội so với các phương pháp hiện có trên hầu hết các chỉ số đánh giá, đặc biệt cho phân đoạn thể hiện. Dưới lịch trình 1×, GrootV-T đạt được 47.0 trong box mAP (APb), cao hơn 1.1 điểm so với ViM-S và 0.5 điểm so với VMamba-T. Đáng chú ý là GrootV-T vượt trội ViM-S 1.7 điểm với lịch trình 1× và LocalVMamba-T 0.4 điểm với lịch trình 3× trong mask mAP (APm). Hơn nữa, APb 50.1 và APm 44.6 tốt nhất được đạt bởi GrootV-S trong lịch trình 3× với huấn luyện đa tỷ lệ.

4.3 Phân đoạn Ngữ nghĩa

Cài đặt. Để đánh giá hiệu suất phân đoạn ngữ nghĩa của chuỗi GrootV, chúng tôi huấn luyện các mô hình với UperNet [60] được khởi tạo bởi trọng số phân loại được đào tạo trước trên ADE20K [68] trong 160k lần lặp, theo các thực hành chung không có tăng cường bổ sung để so sánh công bằng.

Kết quả. Phương pháp của chúng tôi hoạt động đặc biệt tốt trên các nhiệm vụ phân đoạn được hiển thị trong Bảng 2. GrootV-T tạo ra cải thiện rõ ràng +3.6 trong mIoU tỷ lệ đơn so với ViM-S và +1.9 trong mIoU đa tỷ lệ so với LocalViM-S. Hơn nữa, GrootV-S tăng InterImage-S 0.6 và 0.8 trong tỷ lệ đơn và đa tỷ lệ tương ứng. Chúng tôi coi việc bảo tồn các chi tiết cấu trúc phức tạp thông qua quét cấu trúc cây đặc biệt có lợi cho các nhiệm vụ phân đoạn yêu cầu nhận thức cấp pixel.

4.4 Hiểu Ngôn ngữ

Chúng tôi coi Mamba [18] với 130M tham số là mô hình cơ sở. Để xác minh hiệu quả của GrootL trong hiểu ngôn ngữ tự nhiên, chúng tôi đầu tiên tinh chỉnh Mamba được đào tạo trước thông qua LoRA [30] và GrootL dưới cùng cài đặt với dữ liệu Alpaca [53], chứa 52000 dữ liệu điều chỉnh hướng dẫn cho tinh chỉnh có giám sát. Sau đó, chúng tôi sử dụng các điểm chuẩn ngôn ngữ phổ biến được cung cấp trong dự án mã nguồn mở lm-evaluation-harness [17] để đánh giá, bao gồm PIQA [1], AI2-ARC [8], SST [55], WinoGrande, LAMBADA [45], Race [33] và Openbookqa [43]. Kết quả trong Bảng 3 chứng minh rằng GrootL của chúng tôi cung cấp lợi ích +1.1% trong Acc. trung bình so với LoRA. Do độ dài prompt ngắn của tập dữ liệu WinoGrande, hiệu suất giảm với khoảng cách biên nhỏ.

4.5 Nghiên cứu Phân tích & Kết quả Định tính

Trong phần này, chúng tôi tiến hành các thí nghiệm phân tích trên tập dữ liệu ImageNet-1K và trình bày một số kết quả trực quan để minh họa hiệu quả của thuật toán chúng tôi.

Chiến lược Quét. Chúng tôi tiến hành so sánh trực tiếp các chiến lược quét khác nhau, như được hiển thị trong Bảng 4. Quét cấu trúc cây vượt trội so với các chiến lược trước đây 0.8% và 0.3%, làm nổi bật tính ưu việt của thuật toán chúng tôi trong nhận dạng thị giác.

Chỉ số Khoảng cách. Trước khi tạo cây khung tối thiểu từ đồ thị kết nối, việc đo trọng số cạnh giữa các đỉnh là quan trọng. Do đó, chúng tôi xác thực một số chỉ số khoảng cách như được minh họa trong Bảng 5. Kết quả cho thấy khoảng cách Cosine đại diện hiệu quả nhất mối quan hệ giữa các đỉnh, hoạt động tốt hơn 0.5% so với Manhattan và 0.2% so với Euclidean.

Cài đặt Gốc. Chúng tôi duyệt tất cả các đỉnh, coi mỗi đỉnh là gốc, và thực hiện chuyển trạng thái dọc theo đường cấu trúc từ các đỉnh khác hướng về gốc. Việc duyệt này đảm bảo rằng mỗi đỉnh nắm bắt được các phụ thuộc tầm xa. Để xác minh hiệu quả của hoạt động này, chúng tôi chỉ xem xét đỉnh đầu tiên và cuối cùng làm gốc trong Bảng 6. Kết quả cho thấy giảm 0.5% và 0.4% tương ứng.

Kết quả Định tính. Để minh họa tốt hơn tính ưu việt của chiến lược quét của chúng tôi, chúng tôi trực quan hóa các bản đồ ái lực của các vị trí khác nhau được đánh dấu bằng dấu thập đỏ trong mỗi hình ảnh đầu vào. Ví dụ, chúng tôi đặt điểm neo ở góc trên bên trái của bầu trời như được hiển thị trong hàng thứ hai của Hình 4(a). Phương pháp của chúng tôi có thể dễ dàng xác định những ngôi nhà trắng, cột cờ và bầu trời, điều mà quét raster không thể đạt được. Điều này chứng minh khả năng của thuật toán chúng tôi trong việc bảo tồn thông tin cấu trúc chi tiết. Nhiều so sánh hơn có thể được xem trong Hình 6 (trong Phụ lục D.)

5 Kết luận & Hạn chế

Trong bài báo này, chúng tôi đề xuất một mô hình không gian trạng thái cây để thực hiện truyền đặc trưng trên cấu trúc nhận biết đầu vào. Bên cạnh đó, chúng tôi giới thiệu thuật toán quy hoạch động có độ phức tạp tuyến tính để tăng cường các tương tác tầm xa mà không tăng chi phí tính toán. Với các kỹ thuật được đề xuất, chúng tôi thiết lập các mạng đa phương thức chung để phá vỡ các ràng buộc chuỗi ban đầu và đạt được khả năng biểu diễn mạnh mẽ hơn. Các thí nghiệm mở rộng chứng minh hiệu quả của phương pháp chúng tôi trong cả nhiệm vụ thị giác và ngôn ngữ. Hạn chế của phương pháp chúng tôi là cấu trúc cây không phải là mô hình chung, và nó cần được tối ưu hóa cụ thể theo thiết bị phần cứng.

--- TRANG 9 ---
Tài liệu tham khảo
[1] Bisk, Y., Zellers, R., Gao, J., Choi, Y., et al.: Piqa: Lý luận về kiến thức thông thường vật lý trong ngôn ngữ tự nhiên. Trong: AAAI. tr. 7432-7439 (2020) 8
[2] Borůvka, O.: O jistém problému minimálním (1926) 5
[3] Chen, K., Wang, J., Pang, J., Cao, Y., Xiong, Y., Li, X., Sun, S., Feng, W., Liu, Z., Xu, J., et al.: Mmdetection: Hộp công cụ phát hiện mmlab mở và điểm chuẩn. arXiv preprint arXiv:1906.07155 (2019) 7
[4] Chen, Z., Duan, Y., Wang, W., He, J., Lu, T., Dai, J., Qiao, Y.: Bộ điều hợp vision transformer cho dự đoán dày đặc. arXiv preprint arXiv:2205.08534 (2022) 15
[5] Cheng, C., Song, L., Xue, R., Wang, H., Sun, H., Ge, Y., Shan, Y.: Meta-adapter: Người học vài shot trực tuyến cho mô hình thị giác-ngôn ngữ. arXiv preprint arXiv:2311.03774 (2023) 2
[6] Cheng, T., Song, L., Ge, Y., Liu, W., Wang, X., Shan, Y.: Yolo-world: Phát hiện đối tượng từ vựng mở thời gian thực. arXiv preprint arXiv:2401.17270 (2024) 7
[7] Chung, J., Gulcehre, C., Cho, K., Bengio, Y.: Đánh giá thực nghiệm các mạng nơ-ron đệ quy có cổng trong mô hình chuỗi. arXiv preprint arXiv:1412.3555 (2014) 1
[8] Clark, P., Cowhey, I., Etzioni, O., Khot, T., Sabharwal, A., Schoenick, C., Tafjord, O.: Nghĩ rằng bạn đã giải quyết được việc trả lời câu hỏi? thử arc, thách thức lý luận ai2. arXiv preprint arXiv:1803.05457 (2018) 8, 9
[9] Cubuk, E.D., Zoph, B., Mane, D., Vasudevan, V., Le, Q.V.: Autoaugment: Học các chiến lược tăng cường từ dữ liệu. Trong: CVPR. tr. 113-123 (2019) 14
[10] Dai, J., Qi, H., Xiong, Y., Li, Y., Zhang, G., Hu, H., Wei, Y.: Mạng tích chập biến dạng. Trong: ICCV. tr. 764-773 (2017) 2
[11] Dai, Z., Liu, H., Le, Q.V., Tan, M.: Coatnet: Kết hôn tích chập và attention cho tất cả kích cỡ dữ liệu. NeurIPS 34, 3965-3977 (2021) 2, 7
[12] Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L.: Imagenet: Cơ sở dữ liệu hình ảnh phân cấp quy mô lớn. Trong: CVPR. tr. 248-255. Ieee (2009) 2, 7
[13] Ding, X., Zhang, Y., Ge, Y., Zhao, S., Song, L., Yue, X., Shan, Y.: Unireplknet: Convnet kernel lớn nhận thức phổ quát cho âm thanh, video, đám điểm, chuỗi thời gian và nhận dạng hình ảnh. CVPR (2023) 1, 2, 7, 8
[14] Dong, X., Bao, J., Chen, D., Zhang, W., Yu, N., Yuan, L., Chen, D., Guo, B.: Cswin transformer: Xương sống vision transformer chung với cửa sổ hình chữ thập. Trong: CVPR. tr. 12124-12134 (2022) 1, 2, 15
[15] Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., Uszkoreit, J., Houlsby, N.: Một hình ảnh đáng giá 16x16 từ: Transformer cho nhận dạng hình ảnh ở quy mô. Trong: ICLR (2021) 1, 2
[16] Fu, D., Arora, S., Grogan, J., Johnson, I., Eyuboglu, E.S., Thomas, A., Spector, B., Poli, M., Rudra, A., Ré, C.: Monarch mixer: Kiến trúc dựa trên gemm phụ bậc hai đơn giản. NeurIPS 36(2023) 7
[17] Gao, L., Tow, J., Abbasi, B., Biderman, S., Black, S., DiPofi, A., Foster, C., Golding, L., Hsu, J., Le Noac'h, A., Li, H., McDonell, K., Muennighoff, N., Ociepa, C., Phang, J., Reynolds, L., Schoelkopf, H., Skowron, A., Sutawika, L., Tang, E., Thite, A., Wang, B., Wang, K., Zou, A.: Khung đánh giá mô hình ngôn ngữ vài shot (12 2023) 8
[18] Gu, A., Dao, T.: Mamba: Mô hình chuỗi thời gian tuyến tính với không gian trạng thái chọn lọc. arXiv preprint arXiv:2312.00752 (2023) 1, 2, 3, 4, 6, 8, 9
[19] Gu, A., Dao, T., Ermon, S., Rudra, A., Ré, C.: Hippo: Bộ nhớ đệ quy với phép chiếu đa thức tối ưu. NeurIPS 33, 1474-1487 (2020) 3

--- TRANG 10 ---
[20] Gu, A., Goel, K., Gupta, A., Ré, C.: Về tham số hóa và khởi tạo các mô hình không gian trạng thái chéo. NeurIPS 35, 35971-35983 (2022) 3
[21] Gu, A., Goel, K., Ré, C.: Mô hình hiệu quả các chuỗi dài với không gian trạng thái có cấu trúc. Trong: ICLR (2022) 1, 2, 3
[22] Gu, A., Johnson, I., Goel, K., Saab, K., Dao, T., Rudra, A., Ré, C.: Kết hợp các mô hình đệ quy, tích chập và thời gian liên tục với các lớp không gian trạng thái tuyến tính. NeurIPS 34, 572-585 (2021) 2
[23] Gupta, A., Gu, A., Berant, J.: Không gian trạng thái chéo hiệu quả như không gian trạng thái có cấu trúc. NeurIPS 35, 22982-22994 (2022) 1, 3
[24] Han, K., Wang, Y., Xu, C., Guo, J., Xu, C., Wu, E., Tian, Q.: Ghostnets trên các thiết bị không đồng nhất thông qua các hoạt động rẻ. IJCV 130(4), 1050-1069 (2022) 2
[25] Hasani, R., Lechner, M., Wang, T.H., Chahine, M., Amini, A., Rus, D.: Mô hình không gian trạng thái cấu trúc lỏng. arXiv preprint arXiv:2209.12951 (2022) 3
[26] He, K., Gkioxari, G., Dollár, P., Girshick, R.: Mask r-cnn. Trong: ICCV. tr. 2961-2969 (2017) 7
[27] He, K., Zhang, X., Ren, S., Sun, J.: Học residual sâu cho nhận dạng hình ảnh. Trong: CVPR. tr. 770-778 (2016) 1, 2
[28] Hochreiter, S., Schmidhuber, J.: Bộ nhớ ngắn hạn dài. Neural computation 9(8), 1735-1780 (1997) 1
[29] Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H.: Mobilenets: Mạng nơ-ron tích chập hiệu quả cho ứng dụng thị giác di động. arXiv preprint arXiv:1704.04861 (2017) 1, 2
[30] Hu, E.J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L., Chen, W.: Lora: Điều chỉnh rank thấp của các mô hình ngôn ngữ lớn. Trong: ICLR (2022) 2, 8, 9
[31] Huang, T., Pei, X., You, S., Wang, F., Qian, C., Xu, C.: Localmamba: Mô hình không gian trạng thái thị giác với quét chọn lọc cửa sổ. arXiv preprint arXiv:2403.09338 (2024) 1, 3, 4, 7, 8, 14, 15
[32] Krizhevsky, A., Sutskever, I., Hinton, G.E.: Phân loại imagenet với mạng nơ-ron tích chập sâu. NeurIPS 25(2012) 2
[33] Lai, G., Xie, Q., Liu, H., Yang, Y., Hovy, E.H.: RACE: tập dữ liệu hiểu đọc quy mô lớn từ các kỳ thi. Trong: EMNLP. tr. 785-794. Association for Computational Linguistics (2017) 9
[34] Li, S., Singh, H., Grover, A.: Mamba-nd: Mô hình không gian trạng thái chọn lọc cho dữ liệu đa chiều. arXiv preprint arXiv:2402.05892 (2024) 7
[35] Li, Y., Song, L., Chen, Y., Li, Z., Zhang, X., Wang, X., Sun, J.: Học định tuyến động cho phân đoạn ngữ nghĩa. Trong: CVPR (2020) 2
[36] Lin, T.Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollár, P., Zitnick, C.L.: Microsoft coco: Các đối tượng phổ biến trong ngữ cảnh. Trong: ECCV. tr. 740-755. Springer (2014) 2, 7
[37] Liu, S., Chen, T., Chen, X., Chen, X., Xiao, Q., Wu, B., Kärkkäinen, T., Pechenizkiy, M., Mocanu, D., Wang, Z.: Nhiều convnet hơn trong những năm 2020: Mở rộng kernel vượt 51x51 sử dụng tính thưa. arXiv preprint arXiv:2207.03620 (2022) 7, 8
[38] Liu, Y., Tian, Y., Zhao, Y., Yu, H., Xie, L., Wang, Y., Ye, Q., Liu, Y.: Vmamba: Mô hình không gian trạng thái thị giác. arXiv preprint arXiv:2401.10166 (2024) 1, 3, 4, 6, 7, 8, 14, 15
[39] Liu, Z., Hu, H., Lin, Y., Yao, Z., Xie, Z., Wei, Y., Ning, J., Cao, Y., Zhang, Z., Dong, L., et al.: Swin transformer v2: Mở rộng dung lượng và độ phân giải. Trong: CVPR. tr. 12009-12019 (2022) 1, 2

--- TRANG 11 ---
[40] Liu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., Lin, S., Guo, B.: Swin transformer: Vision transformer phân cấp sử dụng cửa sổ dịch chuyển. Trong: ICCV. tr. 10012-10022 (2021) 1, 2, 6, 7, 8, 14, 15
[41] Liu, Z., Mao, H., Wu, C.Y, Feichtenhofer, C., Darrell, T., Xie, S.: Một convnet cho những năm 2020. Trong: CVPR. tr. 11976-11986 (2022) 1, 6, 7, 8, 15
[42] Loshchilov, I., Hutter, F.: Điều chuẩn decay trọng số tách rời. arXiv preprint arXiv:1711.05101 (2017) 14
[43] Mihaylov, T., Clark, P., Khot, T., Sabharwal, A.: Bộ áo giáp có thể dẫn điện không? Tập dữ liệu mới cho việc trả lời câu hỏi sách mở. Trong: EMNLP. tr. 2381-2391. Association for Computational Linguistics (2018) 9
[44] Nguyen, E., Goel, K., Gu, A., Downs, G.W., Shah, P., Dao, T., Baccus, S.A., Ré, C.: S4nd: Mô hình hình ảnh và video như tín hiệu đa chiều sử dụng không gian trạng thái. arXiv preprint arXiv:2210.06583 (2022) 7
[45] Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et al.: Mô hình ngôn ngữ là người học đa nhiệm không giám sát. OpenAI blog 1(8), 9 (2019) 9, 18
[46] Ren, S., Yang, X., Liu, S., Wang, X.: Sg-former: Transformer tự hướng dẫn với tái phân bổ token tiến hóa. Trong: ICCV. tr. 6003-6014 (2023) 7
[47] Simonyan, K., Zisserman, A.: Mạng tích chập rất sâu cho nhận dạng hình ảnh quy mô lớn. Trong: Bengio, Y., LeCun, Y. (eds.) ICLR (2015) 2
[48] Smith, J.T., Warrington, A., Linderman, S.W.: Các lớp không gian trạng thái đơn giản hóa cho mô hình chuỗi. arXiv preprint arXiv:2208.04933 (2022) 1, 2
[49] Song, L., Li, Y., Jiang, Z., Li, Z., Sun, H., Sun, J., Zheng, N.: Đầu động tỉ mỉ cho phát hiện đối tượng. NIPS (2020) 7
[50] Song, L., Li, Y., Li, Z., Yu, G., Sun, H., Sun, J., Zheng, N.: Bộ lọc cây có thể học cho biến đổi đặc trưng bảo tồn cấu trúc. NeurIPS 32(2019) 2, 4
[51] Song, L., Zhang, S., Yu, G., Sun, H.: Tacnet: Mạng ngữ cảnh nhận biết chuyển tiếp cho phát hiện hành động không gian-thời gian. Trong: CVPR (2019) 2, 7
[52] Song, L., Zhang, S., Liu, S., Li, Z., He, X., Sun, H., Sun, J., Zheng, N.: Bộ mã hóa phân hạt động cho vision transformer. NIPS (2021) 2
[53] Taori, R., Gulrajani, I., Zhang, T., Dubois, Y., Li, X., Guestrin, C., Liang, P., Hashimoto, T.B.: Stanford alpaca: Mô hình llama theo hướng dẫn (2023) 8
[54] Touvron, H., Cord, M., Douze, M., Massa, F., Sablayrolles, A., Jégou, H.: Huấn luyện transformer hình ảnh hiệu quả dữ liệu & chưng cất thông qua attention. Trong: ICML. tr. 10347-10357. PMLR (2021) 1, 7
[55] Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., Bowman, S.R.: GLUE: Nền tảng điểm chuẩn và phân tích đa nhiệm cho hiểu ngôn ngữ tự nhiên. Trong: ICLR (2019) 9
[56] Wang, J., Song, L., Li, Z., Sun, H., Sun, J., Zheng, N.: Phát hiện đối tượng đầu cuối với mạng tích chập hoàn toàn. Trong: CVPR (2021) 2
[57] Wang, W., Dai, J., Chen, Z., Huang, Z., Li, Z., Zhu, X., Hu, X., Lu, T., Lu, L., Li, H., et al.: Internimage: Khám phá các mô hình cơ bản thị giác quy mô lớn với tích chập biến dạng. Trong: CVPR. tr. 14408-14419 (2023) 1, 2, 6, 7, 8, 14, 15
[58] Wang, W., Xie, E., Li, X., Fan, D.P., Song, K., Liang, D., Lu, T., Luo, P., Shao, L.: Pyramid vision transformer: Xương sống đa năng cho dự đoán dày đặc không có tích chập. Trong: ICCV. tr. 568-578 (2021) 2
[59] Williams, R.L., Lawrence, D.A., et al.: Hệ thống điều khiển không gian trạng thái tuyến tính. John Wiley & Sons (2007) 3

--- TRANG 12 ---
[60] Xiao, T., Liu, Y., Zhou, B., Jiang, Y., Sun, J.: Phân tích nhận thức thống nhất cho hiểu cảnh. Trong: ECCV. tr. 418-434 (2018) 8
[61] Xiao, Y., Luo, Z., Liu, Y., Ma, Y., Bian, H., Ji, Y., Yang, Y., Li, X.: Lấp đầy khoảng cách: Khung hiểu video thống nhất cho truy xuất khoảnh khắc và phát hiện điểm nổi bật. CVPR (2024) 14
[62] Yang, C., Chen, Z., Espinosa, M., Ericsson, L., Wang, Z., Liu, J., Crowley, E.J.: Plainmamba: Cải thiện mamba không phân cấp trong nhận dạng thị giác. arXiv preprint arXiv:2403.17695 (2024) 2, 3, 4, 7, 8
[63] Yang, J., Song, L., Liu, S., Li, Z., Li, X., Sun, H., Sun, J., Zheng, N.: Dbq-ssd: Truy vấn bóng động cho phát hiện đối tượng 3d hiệu quả. arXiv preprint arXiv:2207.10909 (2022) 7
[64] Yang, Q.: Khớp stereo sử dụng lọc cây. IEEE TPAMI 37(4), 834-846 (2014) 2, 4
[65] Yang, R., Song, L., Ge, Y., Li, X.: Boxsnake: Phân đoạn thể hiện đa giác với giám sát hộp. Trong: Proceedings of the IEEE/CVF International Conference on Computer Vision (2023) 2
[66] Zhang, S., Song, L., Gao, C., Sang, N.: Glnet: Mạng cục bộ toàn cầu cho định vị hành động giám sát yếu. IEEE Transactions on Multimedia 22(10), 2610-2622 (2019) 2
[67] Zhang, S., Song, L., Liu, S., Ge, Z., Li, Z., He, X., Sun, J.: Hội thảo về lái xe tự động tại cvpr 2021: Báo cáo kỹ thuật cho thách thức nhận thức luồng. arXiv preprint arXiv:2108.04230 (2021) 7
[68] Zhou, B., Zhao, H., Puig, X., Fidler, S., Barriuso, A., Torralba, A.: Phân tích cảnh thông qua tập dữ liệu ade20k. Trong: CVPR. tr. 633-641 (2017) 2, 8
[69] Zhou, H., Yang, R., Zhang, Y., Duan, H., Huang, Y., Hu, R., Li, X., Zheng, Y.: Unihead: Thống nhất đa nhận thức cho đầu phát hiện. TNNLS (2023) 14
[70] Zhu, L., Liao, B., Zhang, Q., Wang, X., Liu, W., Wang, X.: Vision mamba: Học biểu diễn thị giác hiệu quả với mô hình không gian trạng thái hai chiều. arXiv preprint arXiv:2401.09417 (2024) 1, 3, 4, 7, 8, 15

--- TRANG 13 ---
Phụ lục

A Cài đặt và Kết quả Huấn luyện Chi tiết

A.1 Phân loại Hình ảnh.
Chúng tôi theo các công trình trước đây [57,38,40] để tiến hành các thí nghiệm. Các mô hình được huấn luyện với ba mươi hai GPU V100 32GB theo mặc định. Chúng tôi đặt beta và momentum của trình tối ưu AdamW [42,69,61] với (0.9,0.999) và 0.9, tương ứng. Trong quá trình huấn luyện, chúng tôi sử dụng Cosine Scheduler với tốc độ học ban đầu 1×10^{-3} và weight decay 0.05. Chúng tôi áp dụng các chiến lược tăng cường dữ liệu huấn luyện phổ biến theo [31,57], bao gồm AutoAugment [9] với rand -m9-mstd 0.5-inc1. Chiến lược MixUp với tỷ lệ 0.8 cũng được áp dụng trong mỗi batch. Lật ngang và chiến lược cắt resize ngẫu nhiên đều được sử dụng trong quá trình huấn luyện.

So sánh Hiệu suất. Chúng tôi so sánh các mô hình cơ bản thị giác dựa trên SSM khác nhau như được hiển thị trong Hình 5, với các màu khác nhau đại diện cho các mô hình khác nhau và các hình dạng khác nhau biểu thị các quy mô mô hình khác nhau. Kích thước của mỗi hình dạng biểu thị số lượng tham số mô hình. Trục hoành biểu thị FLOPs và trục tung đại diện cho độ chính xác Top-1 của phương pháp tương ứng trên tập dữ liệu val ImageNet-1K. Hình 5 chứng minh rằng GrootV là lựa chọn tốt nhất về hiệu quả và hiệu suất.

A.2 Phát hiện Đối tượng.
Để so sánh công bằng, chúng tôi tiến hành đánh giá theo thực hành chung [57,38,40]. Các mô hình được huấn luyện với tám GPU V100 32GB theo mặc định. Hình ảnh đầu vào được resize sao cho cạnh ngắn hơn là 800 pixel, trong khi cạnh dài hơn không vượt quá 1333 pixel trong lịch trình 1×. Số bước khởi động được đặt thành 500 trong lịch trình 1×. Đối với lịch trình 3×, cạnh ngắn hơn được resize thành 480-800 pixel và cạnh dài hơn không vượt quá 1333 pixel. Số bước khởi động được đặt thành 1000 trong lịch trình 3×. Kết quả được hiển thị trong Bảng 7 chứng minh hiệu quả của GrootV trong phát hiện đối tượng và phân đoạn thể hiện trên COCO val2017.

A.3 Phân đoạn Ngữ nghĩa.
Chúng tôi tối ưu GrootV-T/S của chúng tôi sử dụng trình tối ưu AdamW với tốc độ học ban đầu 6×10^{-5} được giảm với tỷ lệ 1.0 với lịch trình giảm đa thức theo [57]. Số lần lặp khởi động được đặt thành 1600 với tốc độ học ban đầu 1×10^{-6}. Độ phân giải đầu vào mặc định là 512×512 cũng như FLOPs được tính toán với kích thước đầu vào 512×2048. Các mô hình được huấn luyện với tám GPU V100 32GB theo mặc định.

--- TRANG 14 ---
[Bảng 7 với kết quả phát hiện đối tượng và phân đoạn thể hiện]

B Toán tử Quét Cấu trúc Cây Ngôn ngữ

[Thuật toán 2 Quét Cây Ngôn ngữ]

C Chứng minh Thuật toán

Trong phần này, chúng tôi trình bày các chứng minh chi tiết cho thuật toán quét cây của chúng tôi. Các định nghĩa ký hiệu nhất quán với những gì trong bài báo chính.

C.1 Chứng minh cho Thuật toán 1.
[Chi tiết chứng minh toán học]

C.2 Chứng minh cho Thuật toán 2.
[Chi tiết chứng minh cho thuật toán ngôn ngữ]

D Thêm Kết quả Định tính

Hình 6 hiển thị các so sánh định tính bổ sung giữa thuật toán của chúng tôi và các chiến lược quét trước đây (ví dụ, quét chéo và quét raster), cho thấy khả năng tiên tiến của chúng tôi trong việc nhận thức thông tin cấu trúc chi tiết và nắm bắt các phụ thuộc tầm xa.

E Ý nghĩa Thống kê

[Bảng 8 với sai số chuẩn trên các điểm chuẩn mô hình ngôn ngữ]

Chúng tôi tính toán độ lệch chuẩn của GrootL trên các điểm chuẩn mô hình ngôn ngữ trong dự án mã nguồn mở lm-evaluation-harness như được hiển thị trong Bảng 8.

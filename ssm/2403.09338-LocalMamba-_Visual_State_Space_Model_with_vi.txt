# LocalMamba: Mô hình Không gian Trạng thái Thị giác với
Quét Chọn lọc Cửa sổ
Tao Huang1, Xiaohuan Pei1,
Shan You2, Fei Wang3, Chen Qian2, và Chang Xu1
1Khoa Khoa học Máy tính, Khoa Kỹ thuật, Đại học Sydney
2SenseTime Research
3Đại học Khoa học và Công nghệ Trung Quốc
Tóm tắt. Những tiến bộ gần đây trong các mô hình không gian trạng thái, đặc biệt là Mamba,
đã thể hiện tiến bộ đáng kể trong việc mô hình hóa các chuỗi dài cho
các tác vụ như hiểu ngôn ngữ. Tuy nhiên, ứng dụng của chúng trong các tác vụ thị giác
vẫn chưa vượt trội hơn hiệu suất của các Mạng Nơ-ron Tích chập
Truyền thống (CNN) và Vision Transformers (ViT). Bài báo này
cho rằng chìa khóa để nâng cao Vision Mamba (ViM) nằm ở việc tối ưu
hóa các hướng quét cho việc mô hình hóa chuỗi. Các phương pháp ViM truyền thống,
làm phẳng các token không gian, bỏ qua việc bảo tồn các phụ thuộc 2D cục bộ,
từ đó kéo dài khoảng cách giữa các token liền kề.
Chúng tôi giới thiệu một chiến lược quét cục bộ mới chia ảnh thành
các cửa sổ riêng biệt, hiệu quả nắm bắt các phụ thuộc cục bộ đồng thời duy
trì quan điểm toàn cục. Ngoài ra, thừa nhận các sở thích khác nhau
cho các mẫu quét qua các lớp mạng khác nhau, chúng tôi đề
xuất một phương pháp động để độc lập tìm kiếm các lựa chọn quét tối ưu
cho mỗi lớp, cải thiện hiệu suất đáng kể. Các thí nghiệm rộng rãi
qua cả mô hình phẳng và phân cấp nhấn mạnh tính ưu việt của phương pháp
chúng tôi trong việc nắm bắt hiệu quả các biểu diễn ảnh.
Ví dụ, mô hình của chúng tôi vượt trội hơn Vim-Ti 3.1% trên
ImageNet với cùng 1.5G FLOPs. Mã nguồn có sẵn tại: https:
//github.com/hunto/LocalMamba .
Từ khóa: Mô hình thị giác tổng quát · Nhận dạng ảnh · Mô hình không gian trạng thái

1 Giới thiệu
Các Mô hình Không gian Trạng thái Có cấu trúc (SSM) gần đây đã trở nên nổi bật như một
kiến trúc đa năng trong mô hình hóa chuỗi, báo hiệu một kỷ nguyên mới của việc cân bằng
hiệu quả tính toán và tính đa dụng của mô hình [9,12,13,35]. Những mô hình này tổng
hợp các thuộc tính tốt nhất của Mạng Nơ-ron Hồi quy (RNN) và Mạng
Nơ-ron Tích chập (CNN), lấy cảm hứng từ các nguyên tắc nền tảng
của các mô hình không gian trạng thái cổ điển [23]. Được đặc trưng bởi hiệu quả tính toán,
SSM thể hiện độ phức tạp mở rộng tuyến tính hoặc gần tuyến tính với chuỗi

Liên hệ: Tao Huang <thua7590@uni.sydney.edu.au>, Shan You
<youshan@sensetime.com>, Chang Xu <c.xu@sydney.edu.au>arXiv:2403.09338v1 [cs.CV] 14 Mar 2024

độ dài, làm cho chúng đặc biệt phù hợp để xử lý các chuỗi dài. Theo sau
thành công của Mamba [9], một biến thể mới kết hợp quét chọn lọc
(S6), đã có một làn sóng áp dụng SSM cho một loạt các tác vụ thị giác.
Những ứng dụng này mở rộng từ việc phát triển các mô hình nền tảng tổng quát [32,60] đến
việc thúc đẩy các lĩnh vực phân đoạn ảnh [30,34,40,54] và tổng hợp [14], thể
hiện khả năng thích ứng và tiềm năng của mô hình trong lĩnh vực thị giác.

Thông thường các nghiên cứu thị giác này cần biến đổi
ảnh 2D thành chuỗi 1D để xử lý dựa trên SSM,
và sau đó tích hợp cấu trúc SSM gốc của Mamba
vào các mô hình nền tảng của chúng cho các tác vụ cụ thể.
Tuy nhiên, chúng chỉ thể hiện những cải thiện khiêm tốn
so với CNN truyền thống [20,24,39,41,42,52] và Vision
Transformers (ViT) [3,7,33,46]. Tiến bộ khiêm tốn này
nhấn mạnh một thách thức đáng kể: bản chất không nhân
quả của mẫu không gian 2D trong ảnh về cơ bản mâu
thuẫn với khung xử lý nhân quả của SSM. Như được minh
họa trong Hình 1, các phương pháp truyền thống làm phẳng
dữ liệu không gian thành token 1D phá vỡ các phụ thuộc
2D cục bộ tự nhiên, làm yếu khả năng của mô hình diễn
giải chính xác các mối quan hệ không gian. Mặc dù VMamba [32] giới thiệu một
kỹ thuật quét 2D để giải quyết điều này bằng cách quét ảnh theo cả hướng
ngang và dọc, nó vẫn gặp khó khăn trong việc duy trì sự gần gũi của các
token liền kề ban đầu trong các chuỗi được quét, điều quan trọng để mô hình
hóa biểu diễn cục bộ hiệu quả.

Trong công trình này, chúng tôi giới thiệu một phương pháp mới để cải thiện biểu diễn cục bộ
trong Vision Mamba (ViM) bằng cách phân đoạn ảnh thành nhiều cửa sổ cục bộ
riêng biệt. Mỗi cửa sổ được quét riêng lẻ trước khi thực hiện một lượt duyệt

qua các cửa sổ, đảm bảo rằng các token trong cùng một vùng ngữ nghĩa 2D được
xử lý gần nhau. Phương pháp này tăng cường đáng kể khả năng của mô hình
nắm bắt chi tiết giữa các vùng cục bộ, với kết quả thực nghiệm được xác nhận
trong Hình 2. Chúng tôi thiết kế khối nền tảng của mình bằng cách tích hợp cả
các hướng quét toàn cục truyền thống và kỹ thuật quét cục bộ mới của chúng tôi,
trao quyền cho mô hình tiếp thu thông tin toàn cục toàn diện và thông tin cục bộ
tinh tế.
Hơn nữa, để tổng hợp tốt hơn các đặc trưng từ những quy trình quét đa dạng
này, chúng tôi đề xuất một mô-đun chú ý không gian và kênh, SCAttn, được thiết
kế để phân biệt và nhấn mạnh thông tin có giá trị đồng thời lọc bỏ sự dư thừa.

Thừa nhận tác động khác biệt của các hướng quét đối với biểu diễn đặc trưng
(ví dụ, một lần quét cục bộ với kích thước cửa sổ 3 xuất sắc trong việc nắm bắt
các đối tượng hoặc chi tiết nhỏ hơn, trong khi kích thước cửa sổ 7 phù hợp hơn
cho các đối tượng lớn hơn), chúng tôi giới thiệu một phương pháp tìm kiếm hướng
để chọn các hướng quét tối ưu. Sự biến thiên này đặc biệt rõ rệt qua các lớp
khác nhau và độ sâu mạng. Lấy cảm hứng từ DARTS [29], chúng tôi tiến hành từ
lựa chọn rời rạc đến một miền liên tục, được biểu diễn bằng một hệ số có thể
học, để kết hợp nhiều hướng quét trong một mạng duy nhất. Sau khi huấn luyện
mạng này, các hướng quét hiệu quả nhất được xác định bằng cách nhận diện
những hướng có xác suất được gán cao nhất.

Các mô hình phát triển của chúng tôi, LocalVim và LocalVMamba, kết hợp cả
cấu trúc phẳng và phân cấp, dẫn đến những cải tiến đáng chú ý so với các
phương pháp trước đó. Những đóng góp chính của nghiên cứu này bao gồm:
1. Chúng tôi giới thiệu một phương pháp quét mới cho SSM bao gồm quét
cục bộ hóa trong các cửa sổ riêng biệt, tăng cường đáng kể khả năng của
mô hình nắm bắt thông tin cục bộ chi tiết kết hợp với ngữ cảnh toàn cục.
2. Chúng tôi phát triển một phương pháp tìm kiếm các hướng quét qua các lớp
mạng khác nhau, cho phép chúng tôi nhận diện và áp dụng các kết hợp quét
hiệu quả nhất, từ đó cải thiện hiệu suất mạng.
3. Chúng tôi trình bày hai biến thể mô hình, được thiết kế với cấu trúc phẳng
và phân cấp. Thông qua thí nghiệm rộng rãi về phân loại ảnh, phát hiện
đối tượng và các tác vụ phân đoạn ngữ nghĩa, chúng tôi chứng minh rằng
các mô hình của chúng tôi đạt được những cải thiện đáng kể so với các
công trình trước đó. Ví dụ, trên tác vụ phân đoạn ngữ nghĩa, với một
lượng tham số tương tự, LocalVim-S của chúng tôi vượt trội hơn Vim-S
một khoảng cách lớn 1.5 về mIoU (SS).

2 Công trình Liên quan

2.1 Thiết kế Backbone Thị giác Tổng quát
Thập kỷ qua đã chứng kiến những tiến bộ mang tính biến đổi trong thị giác máy tính,
chủ yếu được thúc đẩy bởi sự phát triển của các mạng nơ-ron sâu và sự xuất
hiện của các mô hình nền tảng tổng quát. Ban đầu, Mạng Nơ-ron Tích chập
(CNN) [17,20,24,39,41,42,50,52] đánh dấu một cột mốc quan trọng trong kiến
trúc mô hình thị giác, tạo nền tảng cho các tác vụ nhận dạng và phân tích ảnh phức tạp.

Trong số những công trình này, ResNet [20], với kỹ thuật kết nối dư nền tảng,
là một trong những mô hình phổ biến nhất được sử dụng rộng rãi trong lĩnh vực
tác vụ thị giác; dòng MobileNet [21,41] dẫn dắt thiết kế các mô hình nhẹ với
việc sử dụng các tích chập theo chiều sâu. Tuy nhiên, việc giới thiệu Vision
Transformer (ViT) [7] đánh dấu một sự chuyển đổi mô hình, thách thức sự thống
trị của CNN trong lĩnh vực này. ViT cách mạng hóa phương pháp xử lý ảnh bằng
cách phân đoạn ảnh thành một loạt các patch tuần tự và tận dụng cơ chế tự
chú ý, một thành phần cốt lõi của kiến trúc Transformer [48], để trích xuất
đặc trưng. Phương pháp mới này làm nổi bật tiềm năng chưa được khai thác
của Transformer trong các tác vụ thị giác, khơi dậy một làn sóng nghiên cứu
nhằm tinh chỉnh thiết kế kiến trúc [45] và phương pháp huấn luyện [18,31,46,47,53],
thúc đẩy hiệu quả tính toán [3,22,33,49], và mở rộng phạm vi ứng dụng
[8,25,26,38,44,56,58]. Dựa trên thành công của mô hình hóa chuỗi dài với
Mamba [9], một biến thể của Mô hình Không gian Trạng thái (SSM), một số
mô hình sáng tạo như Vim [60] và VMamba [32] đã được giới thiệu trong các
tác vụ thị giác, được gọi là Vision Mamba. Những mô hình này điều chỉnh
khung Mamba để phục vụ như một backbone đa năng cho các ứng dụng thị giác,
thể hiện hiệu quả và độ chính xác vượt trội so với CNN và ViT truyền thống
trong ảnh độ phân giải cao.

2.2 Mô hình Không gian Trạng thái
Mô hình Không gian Trạng thái (SSM) [11,13,16,27,37], đại diện cho một mô
hình trong kiến trúc được thiết kế cho biến đổi chuỗi-thành-chuỗi, thành thạo
trong việc quản lý các token phụ thuộc dài. Mặc dù có những thách thức ban đầu
trong huấn luyện, do cường độ tính toán và bộ nhớ của chúng, những tiến bộ
gần đây [9-11,16,43] đã cải thiện đáng kể những vấn đề này, định vị SSM sâu
như những đối thủ mạnh mẽ chống lại CNN và Transformer. Đặc biệt, S4 [11]
giới thiệu một biểu diễn Bình thường Cộng Hạng Thấp (NPLR) hiệu quả, tận
dụng đồng nhất Woodbury để nghịch đảo ma trận nhanh chóng, từ đó tinh gọn
việc tính toán kernel tích chập. Dựa trên điều này, Mamba [9] tiếp tục tinh chỉnh
SSM bằng cách kết hợp một tham số hóa cụ thể đầu vào cùng với một phương pháp
tính toán có thể mở rộng, được tối ưu hóa phần cứng, đạt được hiệu quả và
đơn giản chưa từng có trong xử lý các chuỗi rộng lớn qua ngôn ngữ và gen học.

Sự ra đời của S4ND [36] đánh dấu cuộc tấn công đầu tiên của các khối SSM
vào các tác vụ thị giác, khéo léo xử lý dữ liệu thị giác như các tín hiệu liên
tục qua các miền 1D, 2D và 3D. Tiếp theo, lấy cảm hứng từ thành công của
các mô hình Mamba, Vmamba [32] và Vim [60] mở rộng vào các tác vụ thị giác
tổng quát, giải quyết thách thức nhạy cảm hướng trong SSM bằng cách đề xuất
các cơ chế quét hai chiều và quét chéo. Tận dụng nền tảng của Mamba trong
các mô hình tổng quát, các phương pháp mới đã được phát triển cho các tác vụ
thị giác, như phân đoạn ảnh [30,34,40,54] và tổng hợp ảnh [14], thể hiện khả
năng thích ứng và hiệu quả của các mô hình Mamba thị giác trong việc giải
quyết các thách thức thị giác phức tạp.

3 Kiến thức Cơ bản

3.1 Mô hình Không gian Trạng thái
Mô hình Không gian Trạng thái Có cấu trúc (SSM) đại diện cho một lớp mô hình
chuỗi trong học sâu, được đặc trưng bởi khả năng ánh xạ một chuỗi một chiều
x(t) trong R^L thành y(t) trong R^L thông qua một trạng thái ẩn trung gian h(t) trong R^N:
h'(t) = Ah(t) + Bx(t),
y(t) = Ch(t),(1)
trong đó các ma trận hệ thống A trong R^(N×N), B trong R^(N×1), và C trong R^(N×1) điều
khiển động lực học và ánh xạ đầu ra, tương ứng.

Rời rạc hóa. Để triển khai thực tế, hệ thống liên tục được mô tả bởi Phương
trình 1 được rời rạc hóa sử dụng giả định giữ bậc không⁴, hiệu quả chuyển đổi
các tham số thời gian liên tục (A,B) thành các đối tác rời rạc (Ā,B̄) của chúng
trong một thang thời gian lấy mẫu cụ thể Δ trong R>0:
Ā = e^(ΔA)
B̄ = (ΔA)^(-1)(e^(ΔA) - I) · ΔB.(2)

Điều này dẫn đến một công thức mô hình rời rạc như sau:
h_t = Āh_(t-1) + B̄x_t,
y_t = Ch_t.(3)

Để hiệu quả tính toán, quy trình lặp được mô tả trong Phương trình 3 có thể
được đẩy nhanh thông qua tính toán song song, sử dụng một phép tích chập
toàn cục:
y = x ⊛ K
với K = (CB̄, CĀB̄, ..., CĀ^(L-1)B̄),(4)
trong đó ⊛ đại diện cho phép tích chập, và K trong R^L phục vụ như kernel
của SSM. Phương pháp này tận dụng tích chập để tổng hợp các đầu ra qua
chuỗi đồng thời, tăng cường hiệu quả và khả năng mở rộng tính toán.

3.2 Mô hình Không gian Trạng thái Chọn lọc
Mô hình Không gian Trạng thái truyền thống (SSM), thường được gọi là S4,
đã đạt được độ phức tạp thời gian tuyến tính. Tuy nhiên, khả năng nắm bắt
ngữ cảnh chuỗi của chúng về cơ bản bị hạn chế bởi tham số hóa tĩnh. Để giải
quyết hạn chế này,

⁴Giả định này giữ giá trị của x không đổi trong một khoảng mẫu Δ.

Mô hình Không gian Trạng thái Chọn lọc (được gọi là Mamba) [9] giới thiệu
một cơ chế động và chọn lọc cho các tương tác giữa các trạng thái tuần tự.
Không giống như SSM thông thường sử dụng các tham số chuyển đổi không đổi
(A,B), các mô hình Mamba sử dụng các tham số phụ thuộc đầu vào, cho phép
một tham số hóa phong phú hơn, nhận thức chuỗi. Cụ thể, các mô hình Mamba
tính toán các tham số B trong R^(B×L×N), C trong R^(B×L×N), và Δ trong R^(B×L×D)
trực tiếp từ chuỗi đầu vào x trong R^(B×L×D).

Các mô hình Mamba, tận dụng SSM chọn lọc, không chỉ đạt được khả năng
mở rộng tuyến tính theo độ dài chuỗi mà còn mang lại hiệu suất cạnh tranh
trong các tác vụ mô hình hóa ngôn ngữ. Thành công này đã truyền cảm hứng
cho các ứng dụng tiếp theo trong các tác vụ thị giác, với các nghiên cứu đề
xuất việc tích hợp Mamba vào các mô hình thị giác nền tảng. Vim [60], áp
dụng một kiến trúc giống ViT, kết hợp các khối Mamba hai chiều thay cho
các khối transformer truyền thống. VMamba [32] giới thiệu một kỹ thuật quét
chọn lọc 2D mới để quét ảnh theo cả hướng ngang và dọc, và xây dựng một
mô hình phân cấp tương tự Swin Transformer [33]. Nghiên cứu của chúng tôi
mở rộng những khám phá ban đầu này, tập trung vào tối ưu hóa việc thích
ứng S6 cho các tác vụ thị giác, nơi chúng tôi đạt được kết quả hiệu suất cải thiện.

4 Phương pháp
Phần này mô tả các thành phần cốt lõi của LocalMamba của chúng tôi, bắt đầu
với cơ chế quét cục bộ được thiết kế để tăng cường khả năng của mô hình khai
thác chi tiết tỉ mỉ từ ảnh. Tiếp theo, chúng tôi giới thiệu thuật toán tìm kiếm
hướng quét, một phương pháp sáng tạo nhận diện các chuỗi quét tối ưu qua
các lớp khác nhau, từ đó đảm bảo sự tích hợp hài hòa của các tín hiệu thị
giác toàn cục và cục bộ. Phần cuối của phần này minh họa việc triển khai
khung LocalMamba trong cả kiến trúc phẳng đơn giản và kiến trúc phân cấp
phức tạp, thể hiện tính linh hoạt và hiệu quả của nó trong các thiết lập đa dạng.

4.1 Quét Cục bộ cho Biểu diễn Thị giác
Phương pháp của chúng tôi sử dụng cơ chế quét chọn lọc, S6, đã thể hiện hiệu
suất đặc biệt trong việc xử lý dữ liệu chuỗi nhân quả 1D. Cơ chế này xử lý
đầu vào theo cách nhân quả, hiệu quả nắm bắt thông tin quan trọng trong các
phân đoạn được quét, tương tự như mô hình hóa ngôn ngữ nơi việc hiểu các
phụ thuộc giữa các từ tuần tự là thiết yếu. Tuy nhiên, bản chất không nhân
quả vốn có của dữ liệu không gian 2D trong ảnh đặt ra một thách thức đáng
kể cho phương pháp xử lý nhân quả này. Các chiến lược truyền thống làm
phẳng các token không gian làm tổn hại tính toàn vẹn của các phụ thuộc 2D
cục bộ, từ đó giảm khả năng của mô hình phân biệt hiệu quả các mối quan hệ
không gian. Ví dụ, như được mô tả trong Hình 1 (a) và (b), phương pháp làm
phẳng được sử dụng trong Vim [60] phá vỡ những phụ thuộc cục bộ này, tăng
đáng kể khoảng cách giữa các token liền kề theo chiều dọc và cản trở khả
năng của mô hình nắm bắt các sắc thái cục bộ. Trong khi VMamba [32] cố gắng
giải quyết điều này bằng cách quét ảnh theo cả hướng ngang và dọc, nó vẫn
không đạt được việc xử lý toàn diện các vùng không gian trong một lần quét.

Để giải quyết hạn chế này, chúng tôi giới thiệu một phương pháp mới để quét
ảnh cục bộ. Bằng cách chia ảnh thành nhiều cửa sổ cục bộ riêng biệt, phương
pháp của chúng tôi đảm bảo sự sắp xếp gần gũi hơn của các token cục bộ liên
quan, tăng cường việc nắm bắt các phụ thuộc cục bộ. Kỹ thuật này được mô
tả trong Hình 1 (c), đối lập phương pháp của chúng tôi với các phương pháp
trước đó không bảo tồn tính mạch lạc không gian.

Trong khi phương pháp của chúng tôi xuất sắc trong việc nắm bắt các phụ thuộc
cục bộ hiệu quả trong mỗi vùng, nó cũng thừa nhận tầm quan trọng của ngữ
cảnh toàn cục. Để đạt được mục đích này, chúng tôi xây dựng khối nền tảng
của mình bằng cách tích hợp cơ chế quét chọn lọc qua bốn hướng: các hướng
gốc (a) và (c), cùng với các đối tác lật của chúng tạo điều kiện quét từ đuôi
đến đầu (các hướng lật được áp dụng trong cả Vim và VMamba để mô hình hóa
tốt hơn các token ảnh không nhân quả). Phương pháp đa mặt này đảm bảo
một phân tích toàn diện trong mỗi khối quét chọn lọc, tạo ra sự cân bằng
giữa chi tiết cục bộ và quan điểm toàn cục.

Như được minh họa trong Hình 3, khối của chúng tôi xử lý mỗi đặc trưng
ảnh đầu vào thông qua bốn nhánh quét chọn lọc riêng biệt. Những nhánh này
độc lập nắm bắt thông tin liên quan, sau đó được hợp nhất thành một đầu ra
đặc trưng thống nhất. Để tăng cường việc tích hợp các đặc trưng đa dạng và
loại bỏ thông tin không liên quan, chúng tôi giới thiệu một mô-đun chú ý không
gian và kênh trước khi hợp nhất. Như được thể hiện trong Hình 3b, mô-đun
này có trọng số thích ứng các kênh và token trong các đặc trưng của mỗi nhánh,
bao gồm hai thành phần chính: một nhánh chú ý kênh và một nhánh chú ý không
gian. Nhánh chú ý kênh tổng hợp các biểu diễn toàn cục bằng cách tính trung
bình các đặc trưng đầu vào qua chiều không gian, tiếp theo áp dụng một biến
đổi tuyến tính để xác định trọng số kênh. Ngược lại, cơ chế chú ý không gian
đánh giá tầm quan trọng theo token bằng cách tăng cường đặc trưng của mỗi
token với các biểu diễn toàn cục, cho phép trích xuất đặc trưng có trọng số
quan trọng tinh tế.

Nhận xét. Trong khi một số biến thể ViT, như Swin Transformer [33], đề
xuất việc chia ảnh thành các cửa sổ nhỏ hơn, việc quét cục bộ trong Local-

Mamba của chúng tôi là khác biệt cả về mục đích và hiệu ứng. Tự chú ý cửa
sổ trong ViT chủ yếu giải quyết hiệu quả tính toán của tự chú ý toàn cục,
mặc dù phải trả giá bằng một số khả năng chú ý toàn cục. Ngược lại, cơ chế
quét cục bộ của chúng tôi nhằm sắp xếp lại vị trí token để tăng cường việc
mô hình hóa các phụ thuộc vùng cục bộ trong Mamba thị giác, trong khi khả
năng hiểu toàn cục được giữ lại vì toàn bộ ảnh vẫn được tổng hợp và xử lý
bởi SSM.

4.2 Tìm kiếm cho Quét Thích ứng
Hiệu quả của Mô hình Không gian Trạng thái Có cấu trúc (SSM) trong việc
nắm bắt biểu diễn ảnh thay đổi qua các hướng quét khác nhau. Đạt được hiệu
suất tối ưu một cách trực quan gợi ý việc sử dụng nhiều lần quét qua các
hướng khác nhau, tương tự như khối quét chọn lọc cục bộ 4 nhánh được thảo
luận trước đó. Tuy nhiên, phương pháp này tăng đáng kể nhu cầu tính toán.
Để giải quyết điều này, chúng tôi giới thiệu một chiến lược để lựa chọn hiệu
quả các hướng quét phù hợp nhất cho mỗi lớp, từ đó tối ưu hóa hiệu suất
mà không phải chịu chi phí tính toán quá mức. Phương pháp này bao gồm tìm
kiếm các cấu hình quét tối ưu cho mỗi lớp, đảm bảo mô hình hóa biểu diễn
được thiết kế riêng và hiệu quả.

Không gian tìm kiếm. Để điều chỉnh quy trình quét cho mỗi lớp, chúng tôi
giới thiệu một tập hợp đa dạng S gồm 8 hướng quét ứng viên. Những hướng
này bao gồm quét ngang và dọc (cả tiêu chuẩn và lật), cùng với quét cục bộ
với kích thước cửa sổ 2 và 7 (cũng cả tiêu chuẩn và lật). Để có ngân sách
tính toán nhất quán như các mô hình trước đó, chúng tôi chọn 4 trong số 8
hướng này cho mỗi lớp. Phương pháp này dẫn đến một không gian tìm kiếm
đáng kể là (C⁴₈)^K, với K đại diện cho tổng số khối.

Dựa trên các nguyên tắc của DARTS [29], phương pháp của chúng tôi áp dụng
một cơ chế tìm kiếm có thể vi phân cho các hướng quét, sử dụng relax liên
tục để điều hướng các lựa chọn phân loại. Phương pháp này biến đổi quy trình
lựa chọn rời rạc

thành một miền liên tục, cho phép sử dụng xác suất softmax để biểu diễn việc
lựa chọn các hướng quét:
y^(l) = Σ_{s∈S} exp(α_s^(l)) / Σ_{s'∈S} exp(α_{s'}^(l)) SSM_s(x^(l)), (5)
trong đó α^(l) biểu thị một tập hợp các tham số có thể học cho mỗi lớp l, phản
ánh xác suất softmax trên tất cả các hướng quét tiềm năng.

Chúng tôi xây dựng toàn bộ không gian tìm kiếm như một mạng quá tham số
hóa, cho phép chúng tôi đồng thời tối ưu hóa các tham số mạng và các biến
kiến trúc α, theo các giao thức huấn luyện tiêu chuẩn. Khi hoàn thành việc
huấn luyện, chúng tôi rút ra các tùy chọn hướng tối ưu bằng cách chọn bốn
hướng có xác suất softmax cao nhất. Chúng tôi trực quan hóa các hướng được
tìm kiếm của các mô hình trong Hình 4. Để phân tích chi tiết các kết quả tìm
kiếm, xem Phần 5.5.

Khả năng mở rộng của tìm kiếm hướng. Phương pháp hiện tại của chúng tôi
tổng hợp tất cả các hướng quét để lựa chọn trong huấn luyện, phù hợp phục
vụ các mô hình với một dải tùy chọn vừa phải. Ví dụ, một mô hình có 20 khối
và 128 hướng mỗi khối yêu cầu 28GB bộ nhớ GPU, cho thấy giới hạn khả năng
mở rộng cho các lựa chọn rộng lớn. Để giảm tiêu thụ bộ nhớ trong các tình
huống với một mảng lựa chọn rộng lớn, các kỹ thuật như lấy mẫu đường duy
nhất [15,57], xấp xỉ nhị phân [1], và sử dụng kênh một phần [55] trình bày
các giải pháp khả thi. Chúng tôi để lại việc nghiên cứu các chiến lược hướng
thích ứng hơn và các kỹ thuật tìm kiếm tiên tiến cho các nỗ lực tương lai.

4.3 Biến thể Kiến trúc
Để đánh giá kỹ lưỡng hiệu quả của phương pháp, chúng tôi giới thiệu các biến
thể kiến trúc dựa trên cả cấu trúc phẳng [60] và phân cấp [32], được đặt tên
là LocalVim và LocalVMamba, tương ứng. Các cấu hình của những kiến trúc
này được chi tiết trong Bảng 1. Cụ thể, trong LocalVim, khối SSM tiêu chuẩn
được thay thế bằng khối LocalVim của chúng tôi, như được mô tả trong Hình
3. Xem xét khối Vim gốc bao gồm hai hướng quét (ngang và ngang lật), và
LocalVim của chúng tôi giới thiệu bốn hướng quét, từ đó tăng chi phí tính
toán. Để duy trì ngân sách tính toán tương tự, chúng tôi điều chỉnh số lượng
khối Vim từ 24 xuống 20. Đối với LocalVMamba, vốn có bốn hướng quét tương
tự như mô hình của chúng tôi, chúng tôi trực tiếp thay thế các khối mà không
thay đổi cấu hình cấu trúc.

Phân tích chi phí tính toán. Khối LocalMamba của chúng tôi hiệu quả và
hiệu quả, chỉ với sự gia tăng nhỏ về chi phí tính toán. Cơ chế quét, chỉ bao
gồm việc định vị lại token, không phát sinh thêm chi phí tính toán theo FLOPs.
Hơn nữa, mô-đun SCAttn, được thiết kế để tổng hợp hiệu quả thông tin khác
nhau qua các lần quét, được thiết kế cực kỳ hợp lý. Nó tận dụng các lớp tuyến
tính để giảm chiều token bằng hệ số 1/r, sau đó tạo ra trọng số chú ý qua cả
chiều không gian và kênh, với r được đặt thành 8 cho tất cả các mô hình. Ví
dụ, mô hình LocalVMamba-T của chúng tôi, thay thế khối VMamba bằng khối
LocalMamba của chúng tôi, chỉ tăng FLOPs của VMamva-T từ 5.6G lên 5.7G.

5 Thí nghiệm
Phần này trình bày đánh giá thực nghiệm của chúng tôi, bắt đầu với tác vụ
phân loại ImageNet, tiếp theo chuyển giao các mô hình đã huấn luyện sang
các tác vụ downstream khác nhau, bao gồm phát hiện đối tượng và phân đoạn
ngữ nghĩa.

5.1 Phân loại ImageNet
Chiến lược huấn luyện. Chúng tôi huấn luyện các mô hình trên bộ dữ liệu
ImageNet-1K [6] và đánh giá hiệu suất trên tập validation ImageNet-1K. Theo
các công trình trước đó [32,33,46,60], chúng tôi huấn luyện các mô hình trong
300 epoch với kích thước batch cơ sở 1024 và bộ tối ưu AdamW, một lịch trình
tỷ lệ học cosine được áp dụng với giá trị ban đầu 10⁻³ và warmup 20 epoch.
Để tăng cường dữ liệu huấn luyện, chúng tôi sử dụng cắt ngẫu nhiên, AutoAugment
[5] với chính sách rand-m9-mstd0.5, và xóa ngẫu nhiên pixel với xác suất 0.25
trên mỗi ảnh, sau đó một chiến lược MixUp với tỷ lệ 0.2 được áp dụng trong
mỗi batch. Một trung bình động mũ trên mô hình được áp dụng với tỷ lệ suy
giảm 0.9999.

Tìm kiếm hướng quét. Để huấn luyện supernet, chúng tôi rút ngắn số epoch
xuống 100 trong khi duy trì các siêu tham số khác nhất quán với huấn luyện
ImageNet tiêu chuẩn. Chiều nhúng cho supernet trong các biến thể LocalVim
được đặt thành 128, với các phép toán tìm kiếm được thực hiện giống hệt trên
LocalVim-T và LocalVim-S do cấu trúc lớp đồng nhất của chúng. Đối với các
biến thể LocalVMamba, bao gồm LocalVMamba-T và LocalVMamba-S, chiều
nhúng ban đầu được tối thiểu hóa xuống 32 để tạo điều kiện cho quy trình
tìm kiếm.

Kết quả. Kết quả của chúng tôi, được tóm tắt trong Bảng 2, minh họa những
cải thiện độ chính xác đáng kể so với các phương pháp CNN và ViT truyền
thống. Đáng chú ý, LocalVim-T đạt được tỷ lệ chính xác 76.2% với 1.5G FLOPs,
vượt trội hơn DeiT-Ti, ghi nhận 72.2% độ chính xác. Trong các cấu trúc phân
cấp, độ chính xác 82.7% của LocalVMamba-T vượt trội hơn Swin-T 1.4%. Hơn
nữa, so với

những đóng góp ban đầu của chúng tôi, Vim và VMamba, phương pháp của
chúng tôi ghi nhận những tiến bộ đáng kể; ví dụ, LocalVim-T và LocalVMamba-T
vượt trội hơn Vim-Ti và VMamba-T lần lượt 2.7% và 0.5% về độ chính xác.
Ngoài ra, để xác thực hiệu quả của quét cục bộ, chúng tôi đã thực hiện các
thí nghiệm bổ sung trên các mô hình không có tìm kiếm hướng quét, được mô
tả trong Phần 4.1, được đánh dấu bằng * trong bảng. Chỉ kết hợp việc quét
cục bộ của chúng tôi vào khung Vim gốc, LocalVim-T* vượt trội hơn Vim-Ti
2.7%, trong khi phương pháp hoàn chỉnh tiếp tục nâng cao độ chính xác thêm
0.4%. Những phát hiện này khẳng định vai trò then chốt của các hướng quét
trong SSM thị giác, chứng minh khả năng của phương pháp quét cục bộ chúng
tôi trong việc tăng cường nắm bắt phụ thuộc cục bộ hiệu quả.

5.2 Phát hiện Đối tượng
Chiến lược huấn luyện. Chúng tôi xác thực hiệu suất trên phát hiện đối tượng
sử dụng bộ dữ liệu MSCOCO 2017 [28] và thư viện MMDetection [2]. Đối với
dòng LocalVMamba, chúng tôi theo các công trình trước đó [32,33] để huấn
luyện các tác vụ phát hiện đối tượng và phân đoạn instance với detector
Mask-RCNN [19]. Các chiến lược huấn luyện bao gồm thiết lập 1× với 12
epoch huấn luyện và thiết lập 3× với 36 epoch huấn luyện

và tăng cường dữ liệu đa thang. Trong khi đối với LocalVim, chúng tôi theo
Vim [60] để sử dụng Cascade Mask R-CNN với ViTDet [26] làm detector.

Kết quả. Chúng tôi tóm tắt kết quả của LocalVMamba trong so sánh với các
backbone khác trong Bảng 3. Chúng ta có thể thấy rằng, LocalVMamba của
chúng tôi vượt trội hơn VMamba một cách nhất quán trên tất cả các biến thể
mô hình. Và so với các kiến trúc khác, CNN và ViT, chúng tôi đạt được sự
ưu việt đáng kể. Ví dụ, LocalVMamba-T của chúng tôi đạt được 46.7 box AP
và 42.2 mask AP, cải thiện Swin-T với khoảng cách lớn lần lượt 4.0 và 2.9.
Để so sánh định lượng với Vim, vui lòng tham khảo tài liệu bổ sung.

5.3 Phân đoạn Ngữ nghĩa
Chiến lược huấn luyện. Theo [32,33,60], chúng tôi huấn luyện UperNet [51]
với các backbone của chúng tôi trên bộ dữ liệu ADE20K [59]. Các mô hình được
huấn luyện với tổng kích thước batch 16 với đầu vào 512×512, bộ tối ưu AdamW
được áp dụng với weight decay 0.01. Chúng tôi sử dụng lịch trình tỷ lệ học
Poly, suy giảm 160K lần lặp với tỷ lệ học ban đầu 6×10⁻⁵. Lưu ý rằng Vim
không báo cáo FLOPs và mIoU (MS) và phát hành mã cho phân đoạn, vì vậy
chúng tôi triển khai LocalVim của mình theo cấu hình ví dụ ViT trong MMSegmentation [4].

Kết quả. Chúng tôi báo cáo kết quả của cả LocalVim và LocalVMamba trong
Bảng 4. Trên LocalVim, chúng tôi đạt được những cải thiện đáng kể so với
đường cơ sở Vim-Ti. Ví dụ, với một lượng tham số tương tự, LocalVim-S của
chúng tôi vượt trội hơn Vim-S 1.5 về mIoU (SS). Trong khi trên LocalVMamba,
chúng tôi đạt được những cải thiện đáng kể so với đường cơ sở VMamba; ví
dụ, LocalVMamba-T của chúng tôi đạt được mIoU (MS) đáng chú ý là 49.1,
vượt trội hơn VMamba-T 0.8. So với CNN và ViT, những cải thiện của chúng
tôi rõ rệt hơn. Kết quả chứng minh hiệu quả của biểu diễn toàn cục của SSM
trong các tác vụ dự đoán dày đặc.

5.4 Nghiên cứu Loại bỏ
Hiệu ứng của quét cục bộ. Tác động của kỹ thuật quét cục bộ của chúng tôi
được đánh giá, với các thí nghiệm được chi tiết trong Bảng 5. Việc thay thế
quét ngang truyền thống của Vim-T bằng quét cục bộ của chúng tôi đã mang
lại sự cải thiện hiệu suất 1% so với đường cơ sở. Sự kết hợp các hướng quét
dưới ngân sách FLOP bị hạn chế trong LocalVim-T* dẫn đến sự gia tăng độ
chính xác bổ sung 1.1%. Những kết quả này nhấn mạnh các tác động khác
nhau của việc quét với các kích thước cửa sổ khác nhau (xem xét quét ngang
như một quét cục bộ với kích thước cửa sổ 14×14) đối với nhận dạng ảnh, và
sự kết hợp của những lần quét này tăng cường hiệu suất hơn nữa.

Hiệu ứng của SCAttn. Trong Bảng 5, việc kết hợp SCAttn vào khối LocalVim
cuối cùng tạo điều kiện cho sự cải thiện bổ sung 0.6%, xác thực hiệu quả
của việc kết hợp chiến lược các hướng quét khác nhau. Điều này nhấn mạnh
vai trò của SCAttn trong việc tăng cường hiệu suất bằng cách hợp nhất thích
ứng các hướng quét.

Hiệu ứng của tìm kiếm hướng quét. Đánh giá thực nghiệm của chúng tôi, như
được mô tả trong Bảng 2, xác nhận những lợi ích đáng kể thu được từ chiến
lược tìm kiếm hướng quét trong các mô hình LocalVim cuối cùng. Những mô
hình này thể hiện những cải thiện rõ rệt so với các phiên bản chỉ kết hợp
quét ngang, quét cục bộ với kích thước cửa sổ 2×2, và các đối tác phản chiếu
của chúng. Ví dụ, LocalVim-T thể hiện cải thiện 0.4% so với LocalVim-T*.
Tiến bộ hiệu suất này có thể được quy cho việc lựa chọn có phương pháp các
kết hợp quét tại mỗi lớp, cung cấp một tập hợp tùy chọn đa dạng để tối ưu
hóa hiệu quả mô hình.

5.5 Trực quan hóa Các Hướng Quét Được Tìm kiếm
Hình 4 trình bày các trực quan hóa của các hướng quét được tìm thấy trong
các mô hình của chúng tôi. Các quan sát gợi ý rằng trong kiến trúc phẳng
của LocalVim, có một xu hướng sử dụng quét cục bộ ở cả phân đoạn đầu và
cuối, với các lớp trung gian ưa thích quét ngang và dọc toàn cục. Đáng chú
ý, các lần quét cục bộ 2×2 có xu hướng tập trung về phía đuôi mạng, trong
khi các lần quét 7×7 lớn hơn nổi bật về phía khởi đầu mạng. Ngược lại, cấu
trúc phân cấp của LocalVMamba thể hiện xu hướng nghiêng về quét cục bộ
lớn hơn so với LocalVim, với sở thích cho quét 7×7 hơn quét 2×2.

6 Kết luận
Trong bài báo này, chúng tôi giới thiệu LocalMamba, một phương pháp sáng
tạo cho các mô hình không gian trạng thái thị giác tăng cường đáng kể việc
nắm bắt các phụ thuộc cục bộ trong ảnh đồng thời duy trì hiểu biết ngữ cảnh
toàn cục. Phương pháp của chúng tôi tận dụng quét chọn lọc cửa sổ và tìm
kiếm hướng quét để cải thiện đáng kể so với các mô hình hiện có. Các thí
nghiệm rộng rãi qua các bộ dữ liệu và tác vụ khác nhau đã chứng minh sự
ưu việt của LocalMamba so với CNN và ViT truyền thống, thiết lập các tiêu
chuẩn mới cho phân loại ảnh, phát hiện đối tượng và phân đoạn ngữ nghĩa.
Các phát hiện của chúng tôi nhấn mạnh tầm quan trọng của các cơ chế quét
trong mô hình không gian trạng thái thị giác và mở ra các hướng nghiên cứu
mới trong mô hình hóa không gian trạng thái hiệu quả và hiệu quả. Công việc
tương lai sẽ khám phá khả năng mở rộng của phương pháp chúng tôi đến các
tác vụ thị giác phức tạp và đa dạng hơn, cũng như tiềm năng tích hợp các
chiến lược quét tiên tiến hơn.

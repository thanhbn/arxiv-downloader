MambaMixer: Mô hình Không gian Trạng thái Chọn lọc Hiệu quả với Lựa chọn Kép Token và Kênh

Ali Behrouz
Đại học Cornell
ab2947@cornell.edu

Michele Santacatterina
Trường Y NYU Grossman
santam13@nyu.edu

Ramin Zabih
Đại học Cornell
rdz@cs.cornell.edu

Trang dự án (Mã nguồn & Mô hình)

Tóm tắt

Những tiến bộ gần đây trong học sâu chủ yếu dựa vào Transformers do khả năng phụ thuộc dữ liệu và học ở quy mô lớn. Tuy nhiên, mô-đun attention trong các kiến trúc này có độ phức tạp thời gian và không gian bậc hai theo kích thước đầu vào, hạn chế khả năng mở rộng cho việc mô hình hóa chuỗi dài. Mặc dù có những nỗ lực gần đây để thiết kế kiến trúc backbone hiệu quả và hiệu quả cho dữ liệu đa chiều, như hình ảnh và chuỗi thời gian đa biến, các mô hình hiện tại hoặc độc lập với dữ liệu, hoặc không cho phép giao tiếp liên chiều và nội chiều. Gần đây, Mô hình Không gian Trạng thái (SSMs), và cụ thể hơn là Mô hình Không gian Trạng thái Chọn lọc (S6), với việc triển khai hiệu quả nhận biết phần cứng, đã cho thấy tiềm năng đầy hứa hẹn cho việc mô hình hóa chuỗi dài. Được thúc đẩy bởi thành công gần đây của SSMs, chúng tôi trình bày khối MambaMixer, một kiến trúc mới với trọng số phụ thuộc dữ liệu sử dụng cơ chế lựa chọn kép qua tokens và channels - được gọi là Selective Token và Channel Mixer. MambaMixer tiếp tục kết nối các mixer chọn lọc tuần tự bằng cơ chế trung bình có trọng số, cho phép các lớp có quyền truy cập trực tiếp vào đầu vào và đầu ra của các lớp khác nhau. Như một bằng chứng về khái niệm, chúng tôi thiết kế kiến trúc Vision MambaMixer (ViM2) và Time Series MambaMixer (TSM2) dựa trên khối MambaMixer và khám phá hiệu suất của chúng trong các nhiệm vụ thị giác và dự báo chuỗi thời gian khác nhau. Kết quả của chúng tôi nhấn mạnh tầm quan trọng của việc mixing chọn lọc qua cả tokens và channels. Trong phân loại ImageNet, phát hiện đối tượng và phân đoạn ngữ nghĩa, ViM2 đạt hiệu suất cạnh tranh với các mô hình thị giác được thiết lập tốt, tức là ViT, MLP-Mixer, ConvMixer, và vượt trội hơn các mô hình thị giác dựa trên SSM, tức là ViM và VMamba. Trong dự báo chuỗi thời gian, TSM2, một kiến trúc không có attention và MLP, đạt hiệu suất xuất sắc so với các phương pháp tối tân trong khi thể hiện chi phí tính toán được cải thiện đáng kể. Những kết quả này cho thấy rằng trong khi Transformers, attention cross-channel và MLPs cross-channel là đủ cho hiệu suất tốt trong thực tế, không phương pháp nào là cần thiết.

1 Giới thiệu

Trong những năm gần đây, Transformers (Vaswani et al., 2017) đã là kiến trúc backbone quan trọng đằng sau thành công của học sâu, cho phép một số tiến bộ đột phá trong mô hình hóa ngôn ngữ (Wolf et al., 2019), thị giác (Dosovitskiy et al., 2021), chuỗi thời gian (Zhou et al., 2021), chăm sóc sức khỏe (Tang et al., 2023), và một số lĩnh vực khác (Radford et al., 2023; Behrouz et al., 2023). Các mô-đun attention trong Transformers rất quan trọng cho sự phụ thuộc dữ liệu của chúng và cho phép chúng tổng quát hóa với dữ liệu và nhiệm vụ chưa thấy được cung cấp ngữ cảnh làm đầu vào. Tuy nhiên, chúng khó mở rộng hiệu quả cho các chuỗi dài do độ phức tạp thời gian và không gian bậc hai. Phá vỡ chi phí tính toán bậc hai này là một bước quan trọng hướng tới những khả năng mới cho học sâu như học ngữ cảnh tầm xa (Gu & Dao, 2023), phát hiện đối tượng lớn (Zhu et al., 2024), và dự báo chuỗi thời gian tầm xa (Liu et al., 2021a).

Để giảm bớt nút thắt cổ chai độ phức tạp tính toán này, một số nghiên cứu gần đây đã tập trung vào thiết kế các mô hình chuỗi dưới bậc hai được thúc đẩy bởi nhiều mục tiêu đa dạng: tức là, MLP-Mixer (Tolstikhin et al., 2021) và ConvMixer (Trockman & Kolter, 2023) được thúc đẩy như những lựa chọn thay thế đơn giản hơn cho các mô-đun attention, MonarchMixer (M2) (Fu et al., 2023a) giải quyết hiệu quả mà không mất chất lượng bằng cách sử dụng ma trận Monarch thưa, và các attention hiệu quả (Xiao et al., 2024; Kacham et al., 2023; Ding et al., 2023; Chen et al., 2021) làm thưa hoặc xấp xỉ ma trận attention đầy đủ. Tuy nhiên, các phương pháp này hoặc ¹dựa trên các tham số độc lập với dữ liệu, ²giới thiệu sự đánh đổi giữa tính biểu đạt và tốc độ, hoạt động kém so với Transformers khi có thể mở rộng và hiệu quả, hoặc ³thực tế chậm trong thực tế, do việc sử dụng phần cứng thấp (Dao et al., 2022; Chen et al., 2021).

Gần đây, Mô hình Không gian Trạng thái có cấu trúc (SSMs) đã nổi lên như một lớp kiến trúc đầy hứa hẹn cho việc mô hình hóa chuỗi (Gu et al., 2022b; Fu et al., 2023b; Smith et al., 2023). SSMs có thể được xem như sự kết hợp của Mạng Nơ-ron Hồi quy (RNNs) và Mạng Nơ-ron Tích chập (CNNs), làm cho chúng rất hiệu quả trong đào tạo (như CNN) và suy luận (như RNN) (Gu et al., 2020). Mặc dù hiệu quả, các kiến trúc SSM tổng quát chính, ví dụ S4 (Gu et al., 2022b), S4D (Gu et al., 2022a), dựa trên các tham số độc lập với dữ liệu, hạn chế hiệu quả của chúng trong việc nén ngữ cảnh thành trạng thái nhỏ hơn (Gu & Dao, 2023). Để giảm bớt hạn chế này, gần đây, Gu & Dao (2023) trình bày Mamba, một SSMs chọn lọc (S6) hiệu quả lựa chọn ngữ cảnh liên quan bằng cách làm cho trọng số SSM thay đổi theo thời gian (tức là phụ thuộc dữ liệu). Mamba đạt hiệu suất ngang bằng với các phương pháp tối tân dựa trên Transformer trong mô hình hóa ngôn ngữ trong khi có ít tham số hơn và mở rộng gần tuyến tính theo độ dài chuỗi (Gu & Dao, 2023), giải quyết tất cả ba hạn chế nêu trên. Thành công của Mamba thúc đẩy một số nghiên cứu để điều chỉnh thiết kế của nó cho các lĩnh vực và phương thức khác nhau, ví dụ thị giác (Zhu et al., 2024; Liu et al., 2024), đồ thị (Behrouz & Hashemi, 2024), video (Li et al., 2024), mô hình hóa DNA (Schiff et al., 2024), v.v.

Đáng ngạc nhiên, Mamba và các biến thể của nó áp dụng độc lập khối S6 cho từng kênh, bỏ qua luồng thông tin qua các kênh (còn được gọi là Channel Mixing). Việc thiếu channel mixing trong Mamba không chỉ dẫn đến các vấn đề ổn định khi mở rộng lên các mạng kích thước lớn (Patro & Agneeswaran, 2024), mà còn gây ra việc bỏ sót các mối quan hệ giữa các feature maps, hạn chế khả năng của Mamba trong việc mô hình hóa thông tin toàn cục trong dữ liệu đa chiều như hình ảnh và chuỗi thời gian đa biến. Tuy nhiên, việc sử dụng các khối channel mixing bổ sung cho các khối S6 có thể gây thách thức trong các mạng quy mô lớn vì do bản chất hồi quy của chúng, việc tăng số lượng khối cho cả token và channel mixing có thể làm hỏng luồng thông tin, hạn chế khả năng sử dụng các đặc trưng sớm của chúng.

Trong bài báo này, chúng tôi trình bày MambaMixer, một mô hình không gian trạng thái chọn lọc hiệu quả với lựa chọn kép qua cả channels và tokens. MambaMixer tuần tự sử dụng Selective Token Mixer và Selective Channel Mixer, mỗi cái bao gồm một khối S6 hai chiều (Gu & Dao, 2023), để hiệu quả lựa chọn và trộn (tương ứng lọc) các tokens và channels có thông tin (tương ứng không liên quan). Trái ngược với khối Mamba gốc sử dụng kết nối skip đơn giản giữa các khối liên tiếp, được lấy cảm hứng từ DenseNet (Huang et al., 2017) và DenseFormer (Pagliardini et al., 2024), khối MambaMixer cho phép các lớp có quyền truy cập trực tiếp vào các đặc trưng sớm hơn (tức là đầu vào và đầu ra của các lớp sớm hơn) và tiếp tục tăng cường luồng thông tin giữa các khối selective channel và token mixer cũng như các lớp khác nhau bằng cơ chế trung bình có trọng số, cho phép các mô hình dựa trên MambaMixer sử dụng số lượng lớp lớn và làm cho việc đào tạo ổn định hơn cho các mạng lớn.

Như một bằng chứng về khái niệm, chúng tôi sử dụng khối MambaMixer để thiết kế Vision Mamba Mixer (ViM2) và TimeSeries Mamba Mixer (TSM2) cho các nhiệm vụ thị giác và dự báo chuỗi thời gian, tương ứng. ViM2 đầu tiên tokenize các hình ảnh và sử dụng Cross-Scan Module (CSM) (Liu et al., 2024) để quét hình ảnh theo chiều dọc và ngang, xác định thứ tự của các tokens. Sau đó, nó sử dụng khối MambaMixer để chọn lọc trộn tokens và channels. Trong khi TSM2 chia sẻ kiến trúc rất tương tự với ViM2, trái ngược với ViM2, nó sử dụng các khối S6 một chiều cho chiều thời gian do bản chất nhân quả của nó và được lấy cảm hứng từ (Chen et al., 2023), nó sử dụng thêm một khối MambaMixer để chọn lọc trộn thông tin phụ trợ của chuỗi thời gian (bất cứ khi nào có sẵn) cũng như một chuẩn hóa 2 chiều qua cả chiều thời gian và biến. Chúng tôi tiếp tục khám phá hiệu suất của các mô hình được đề xuất trong các nhiệm vụ thị giác và dự báo chuỗi thời gian khác nhau. Trong phân loại ImageNet, phát hiện đối tượng và phân đoạn ngữ nghĩa, ViM2 đạt hiệu suất cạnh tranh với các mô hình thị giác được thiết lập tốt, và vượt trội hơn các mô hình thị giác dựa trên SSM. Trong dự báo chuỗi thời gian, TSM2 đạt hiệu suất xuất sắc so với các phương pháp tối tân trên các bộ dữ liệu khác nhau với các lĩnh vực đa dạng.

Bảng 1: So sánh thiết kế kiến trúc của MambaMixer và các mô hình hiện có.

Backbone | Token Mixing | Channel Mixing | Mô hình
---|---|---|---
Phụ thuộc dữ liệu | Mô-đun | Phụ thuộc dữ liệu | Mô-đun | Độ phức tạp
MLP-Mixer | - | MLP | - | MLP | O(L²) | MLP-Mixer (Tolstikhin et al., 2021) DynaMixer (Wang et al., 2022b)
ConvMixer | - | Conv | - | Conv | O(L) | ConvMixer (Trockman & Kolter, 2023)
Convolution | - | ConvNet | - | MLP | O(L) | AlexNet (Krizhevsky et al., 2012) ResNet (He et al., 2016)
Transformers | ✓ | Attention | - | MLP | O(L²) | ViT (Dosovitskiy et al., 2021) DeIT (Touvron et al., 2021)
 | ✓ | Attention + Conv | - | MLP |  | SwinTransformer (Liu et al., 2021b)
SSMs | - | SSM | - | - | O(L) | Hyena (Poli et al., 2023) H3 (Fu et al., 2023b)
 | ✓ | Selective SSM | - | - |  | Mamba (Gu & Dao, 2023) Vim (Zhu et al., 2024)
 | ✓ | Selective SSM | ✓ | Selective SSM |  | MambaMixer (Của chúng tôi)

Đóng góp. Tóm lại, đóng góp của chúng tôi là: ¹Trình bày khối MambaMixer, một kiến trúc mới dựa trên SSM với lựa chọn kép hiệu quả và hiệu quả lựa chọn và trộn (tương ứng lọc) các tokens và channels có thông tin (tương ứng không liên quan) theo cách phụ thuộc dữ liệu, cho phép kết nối qua cả chiều channel và token. ²Chứng minh khả năng và hiệu quả của các khối S6 hai chiều để tập trung vào hoặc bỏ qua các kênh cụ thể bằng các nghiên cứu loại bỏ. ³Tăng cường luồng thông tin trong các kiến trúc đa lớp dựa trên MambaMixer bằng cách cho phép truy cập trực tiếp vào các đặc trưng sớm hơn bằng cơ chế trung bình có trọng số. ⁴Trình bày các mô hình ViM2 và TSM2 dựa trên MambaMixer cho các nhiệm vụ thị giác và dự báo chuỗi thời gian, với hiệu suất xuất sắc so với các baseline.

2 Nghiên cứu liên quan

Để đặt đóng góp của chúng tôi trong bối cảnh rộng hơn, chúng tôi thảo luận các nghiên cứu liên quan trong ba nhóm:

2.1 Mô hình hóa Chuỗi

Transformers (Vaswani et al., 2017) đã là kiến trúc backbone quan trọng đằng sau thành công của học sâu. Mặc dù thành công xuất sắc của chúng trong các lĩnh vực khác nhau, mô-đun attention của chúng có độ phức tạp không gian và thời gian bậc hai, hạn chế khả năng mở rộng của chúng. Về mục đích này, gần đây, một số nghiên cứu nhằm thiết kế các mô hình không có attention với hiệu suất cạnh tranh với Transformers (Karami & Ghodsi, 2024; De et al., 2024). Về mục đích này, Mô hình không gian trạng thái (SSMs) gần đây đã nổi lên như một công cụ mạnh mẽ và không có attention để mô hình hóa các chuỗi đầu vào dài (Poli et al., 2023; Fu et al., 2023b). Cụ thể hơn, gần đây, Gu & Dao (2023) trình bày Mamba, một mô hình không gian trạng thái chọn lọc sử dụng trọng số phụ thuộc đầu vào có thể tập trung hoặc bỏ qua hiệu quả một số tokens cụ thể. Trong khi các mô hình chuỗi này cho thấy hiệu suất đầy hứa hẹn trên dữ liệu 1D, chúng bỏ qua các phụ thuộc theo kênh trong chuỗi. Mặc dù các phụ thuộc theo kênh này trong một số nhiệm vụ trên dữ liệu đầu vào 1D như mô hình hóa ngôn ngữ có thể không làm hỏng đáng kể hiệu suất, việc thiếu nó làm cho việc thích ứng các mô hình chuỗi này cho dữ liệu đa chiều trở nên thách thức. Khối MambaMixer của chúng tôi sử dụng các mô hình không gian trạng thái chọn lọc (Gu & Dao, 2023) qua cả channel và tokens để chọn lọc trộn và hợp nhất thông tin qua các chiều này.

2.2 Kiến trúc cho Backbone Thị giác Tổng quát

Mạng Nơ-ron Tích chập và Kiến trúc Mixer. CNNs đã phục vụ như tiêu chuẩn de-facto backbone trong thị giác máy tính kể từ khi mô hình AlexNet (Krizhevsky et al., 2012) vượt trội hơn các mô hình thị giác được thiết kế dựa trên các đặc trưng hình ảnh thủ công (Pinz et al., 2006). Một số nghiên cứu đã tập trung vào cải thiện thiết kế của CNNs: He et al. (2016) trình bày mạng dư sử dụng kết nối skip và Ioffe & Szegedy (2015) giới thiệu chuẩn hóa batch, cả hai đều cho phép thiết kế CNNs rất sâu. Một số nghiên cứu đã tập trung vào sử dụng tích chập thưa (Xie et al., 2017; Liu et al., 2015), ví dụ tích chập theo chiều sâu (Guo et al., 2019). Sử dụng ý tưởng tích chập trong trường hợp cực đoan của kernel nhỏ, (Tolstikhin et al., 2021) trình bày MLP-Mixer sử dụng MLP qua cả hướng patch và channel để hợp nhất thông tin trong cả hướng không gian và đặc trưng. Thành công của MLP-Mixer thúc đẩy một số nghiên cứu sử dụng phép nhân ma trận với các ma trận hiệu quả và thưa qua hướng không gian và channel (Wang et al., 2022b; Tang et al., 2022; Fu et al., 2023a). Tuy nhiên, tất cả các kiến trúc này đều dựa trên trọng số độc lập với dữ liệu, hạn chế khả năng tổng quát hóa và khả năng học trong ngữ cảnh của chúng.

Vision Transformers. Được thúc đẩy bởi thành công của Transformers (Vaswani et al., 2017) trong các lĩnh vực khác nhau, Vision Transformers (ViT) (Dosovitskiy et al., 2021) được thiết kế hoàn toàn dựa trên Transformers. Kiến trúc backbone mới này đã truyền cảm hứng cho một mô hình mới của các kiến trúc "đồng hướng", là các kiến trúc sử dụng patch embeddings cho lớp đầu tiên và có kích thước và hình dạng bằng nhau trong toàn bộ mạng. ViTs do khả năng học ở quy mô lớn đã trở thành các mô hình phổ biến theo thời gian và nhiều biến thể khác nhau của chúng được thiết kế cho một loạt rộng các nhiệm vụ thị giác (Liu et al., 2021b, 2022a, 2021c; Touvron et al., 2021). Trong khi nhiều kiến trúc ViT sử dụng MLPs cho channel mixing, gần đây, một số nghiên cứu gợi ý rằng MLP đơn giản không thể lọc hiệu quả các đặc trưng không liên quan và thảo luận về nhu cầu của attention theo kênh (Zamir et al., 2022; Zhang et al., 2022). Mặc dù hiệu suất xuất sắc, thời gian và bộ nhớ của Transformers tăng bậc hai so với đầu vào, làm cho việc sử dụng chúng trở nên thách thức cho hình ảnh độ phân giải cao. Điều này thậm chí còn thách thức hơn, đặc biệt cho attention theo kênh trong các mạng lớn, nơi số lượng kênh lớn. Thời gian của mô hình ViM2 của chúng tôi tăng tuyến tính so với đầu vào và cho thấy cùng một mô hình cho việc sử dụng bộ nhớ của nó (xem Phần 6.1). Nó tiếp tục sử dụng các mô hình không gian trạng thái chọn lọc qua cả chiều channel và token, cho phép lựa chọn hiệu quả (tương ứng lọc) các tokens hoặc channels có thông tin (tương ứng không liên quan).

Mô hình Thị giác Tổng quát dựa trên SSM. S4ND (Nguyen et al., 2022) là nghiên cứu tiên phong sử dụng các khối SSM cho các nhiệm vụ thị giác, xử lý dữ liệu thị giác như tín hiệu liên tục qua các lĩnh vực 1D, 2D và 3D. Gần đây, được thúc đẩy bởi thành công của Mamba (Gu & Dao, 2023), Vmamba (Liu et al., 2024) và Vim (Zhu et al., 2024) điều chỉnh khối Mamba cho các nhiệm vụ thị giác tổng quát bằng cách giải quyết thách thức nhạy cảm hướng trong SSMs dựa trên các cơ chế hai chiều và cross-scan. Sau đó, một số nghiên cứu đề xuất các cơ chế quét tinh vi hơn để cải thiện hiệu suất của các mô hình này (Li et al., 2024; Huang et al., 2024; Hu et al., 2024). Đáng ngạc nhiên, các thích ứng hiện có chủ yếu tập trung vào các chiến lược quét khác nhau và xử lý từng kênh riêng biệt, bỏ sót phụ thuộc cross-channel. Mô hình ViM2 của chúng tôi, sử dụng các khối MambaMixer, có thể hợp nhất thông tin hiệu quả và chọn lọc qua cả hai chiều.

2.3 Kiến trúc cho Backbone Chuỗi thời gian Tổng quát

Không ngạc nhiên, các mô hình dựa trên Transformer đã là lựa chọn phổ biến cho dự báo chuỗi thời gian, khi cần mô hình hóa các mối quan hệ phức tạp của các biến (Zhou et al., 2021; Liu et al., 2021a; Wu et al., 2021; Ilbert et al., 2024; Nie et al., 2023). Một số nghiên cứu đã tập trung vào làm cho thiết kế Transformers cho chuỗi thời gian hiệu quả hơn (Zhou et al., 2021; Wu et al., 2021). Một số nghiên cứu khác đã tập trung vào trích xuất thông tin dài hạn để dự báo tốt hơn (Nie et al., 2023; Zhou et al., 2022a). Về mục đích này, Zhou et al. (2022a) và Zhou et al. (2022b) đề xuất phân rã các chuỗi bằng Biến đổi Fourier Nhanh, cho phép trích xuất thông tin dài hạn tốt hơn. Gần đây, Chen et al. (2023) trình bày TSMixer, một kiến trúc toàn MLP cho dự báo chuỗi thời gian, với hiệu suất tối tân và cho thấy rằng để đạt hiệu suất cạnh tranh trong thực tế, Transformers không cần thiết. TSM2 của chúng tôi là một kiến trúc thay thế không có MLP và attention được thiết kế dựa trên khối MambaMixer. Trong thiết kế này, các khối S6, trong cả hai hướng của biến và thời gian, được sử dụng để lựa chọn (tương ứng lọc) các biến quan trọng (tương ứng không liên quan) cũng như dấu thời gian.

3 Mô hình: MambaMixer

Trong phần này, đầu tiên chúng tôi thảo luận các khái niệm sơ bộ về SSMs và sau đó giới thiệu chi tiết khối MambaMixer.

3.1 Kiến thức Sơ bộ

SSMs được biết đến như các hệ thống tuyến tính bất biến thời gian ánh xạ chuỗi đầu vào x(t) ∈ R^L thành chuỗi phản hồi y(t) ∈ R^L (Aoki, 2013). Về mục đích này, SSMs sử dụng trạng thái tiềm ẩn h(t) ∈ R^(N×L), tham số A ∈ R^(N×N), và các tham số chiếu B ∈ R^(N×1), C ∈ R^(1×N) sao cho:

h'(t) = Ah(t) + Bx(t),
y(t) = Ch(t). (1)

Tuy nhiên, phương trình vi phân trên trong các cài đặt học sâu khó giải và vì vậy các mô hình không gian trạng thái rời rạc (Gu et al., 2020; Zhang et al., 2023) đề xuất rời rạc hóa hệ thống trên bằng tham số Δ, tức là:

h_t = Āh_(t-1) + B̄x_t,
y_t = Ch_t, (2)

trong đó

Ā = exp(ΔA),
B̄ = (ΔA)^(-1)(exp(ΔA) - I)ΔB. (3)

SSMs rời rạc có thể được hiểu như sự kết hợp của CNNs và RNNs và tương đương với tích chập sau (Gu et al., 2020):

K̄ = (CB̄, CĀB̄, ..., CĀ^(L-1)B̄),
y = x * K̄, (4)

điều này làm cho chúng rất hiệu quả trong cả đào tạo, như CNN, và suy luận, như RNN.

Mặc dù hiệu quả của SSMs rời rạc, chúng dựa trên các tham số độc lập với dữ liệu, có nghĩa là các tham số Ā, B̄, và C bất biến thời gian và giống nhau cho bất kỳ đầu vào nào, hạn chế hiệu quả của chúng trong việc nén ngữ cảnh thành trạng thái nhỏ hơn (Gu & Dao, 2023). Để giảm bớt hạn chế này, gần đây, Gu & Dao (2023) trình bày Mamba, một SSMs chọn lọc (S6) hiệu quả lựa chọn ngữ cảnh liên quan bằng cách cho phép phụ thuộc của các tham số B̄, C̄, và Δ vào đầu vào x_t, tức là:

B̄_t = Linear_B(x_t), C̄_t = Linear_C(x_t), và Δ_t = Softplus(Linear_Δ(x_t)), (5)

trong đó Linear(.) là phép chiếu tuyến tính và Softplus(.) = log(1 + exp(.)). Sự lựa chọn này (hoặc phụ thuộc dữ liệu) đi kèm với chi phí mô hình không thể được đào tạo như CNN (Phương trình 4), gây ra thách thức cho hiệu quả và khả năng mở rộng của mô hình. Để vượt qua thách thức này, (Gu & Dao, 2023) cho thấy rằng hồi quy tuyến tính trong Phương trình 2 có thể được công thức hóa như một phép quét kết hợp (Martin & Cundy, 2018), chấp nhận các thuật toán song song hiệu quả, dẫn đến độ phức tạp logarit theo độ dài chuỗi.

3.2 MambaMixer

Như đã thảo luận trước đó, mặc dù thành công của S6 trong mô hình hóa ngôn ngữ (Gu & Dao, 2023), việc sử dụng chúng cho dữ liệu không nhân quả và/hoặc đa chiều là thách thức. Mặc dù có những nỗ lực gần đây để điều chỉnh khối S6 và mô hình Mamba cho dữ liệu không nhân quả và/hoặc đa chiều (Li et al., 2024; Zhu et al., 2024), đáng ngạc nhiên, các thích ứng hiện có chủ yếu tập trung vào các chiến lược quét khác nhau và xử lý từng kênh riêng biệt, bỏ sót phụ thuộc cross-channel. Để vượt qua thách thức này và cho phép khối S6 lựa chọn cross channels và tokens, chúng tôi trình bày khối MambaMixer có ba mô-đun chính (Xem Hình 1): Selective Token Mixer, Selective Channel Mixer, và Weighted Averaging of Earlier Features.

Selective Token Mixer. Mô-đun đầu tiên của MambaMixer là selective token mixer, nhằm trộn và hợp nhất thông tin qua tokens trong khi có khả năng tập trung vào hoặc bỏ qua các tokens cụ thể. Đặt x ∈ R^(B×L×D) đại diện cho đầu vào, trong đó B là kích thước batch, L là độ dài chuỗi và D là số lượng kênh. Được lấy cảm hứng từ kiến trúc Mamba, chúng tôi sử dụng khối S6 với gated MLP cũng như lớp tích chập. Trong khi Mamba được thiết kế cho dữ liệu 1D và vì vậy sử dụng tích chập 1D, chúng tôi sau này thảo luận cách lựa chọn tích chập nên phụ thuộc vào dữ liệu đầu vào, tức là tích chập theo chiều sâu (Chollet, 2017) cho hình ảnh và tích chập 1D cho chuỗi thời gian. Do đó, mô-đun Selective Token Mixer một chiều có thể được tóm tắt như sau:

x̄ = sigma(Conv(Linear(x))), (6)
x̄_MLP = MLP(x), (7)
B̄_x = Linear_B(x), (8)
C̄_x = Linear_C(x) (9)
Δ_x = Softplus(Linear_Δ(x)) (10)
y_Token = SSM_{Ā,B̄_x,C_x,Δ_x}(x̄) ⊗ x̄_MLP (Sử dụng Phương trình 2), (11)

trong đó Conv(.) là tích chập và ⊗ là phi tuyến. Trường hợp đặc biệt của mô-đun selective token mixer có thể được xem như khối Mamba (Gu & Dao, 2023), khi chúng ta sử dụng tích chập 1D như Conv(.). Thiết kế này cho phép mô hình không chỉ trộn và hợp nhất thông tin qua tokens, mà còn tập trung vào hoặc bỏ qua các tokens cụ thể trong quá trình này. Tuy nhiên, đối với dữ liệu đa chiều (ví dụ hình ảnh, video, v.v.), tokens không nhân quả và yêu cầu quá trình trộn đa hướng với nhiều lần quét để cho phép luồng thông tin giữa từng cặp tokens. Trong những trường hợp này, với d lần quét có thể, chúng ta đơn giản mở rộng khối trên thành selective token mixer d-hướng bằng cách sử dụng d khối S6 một chiều (thay vì một) mỗi khối nhận chuỗi đầu vào dựa trên quét khác nhau, và sau đó cộng các đầu ra tương ứng của chúng lại với nhau. Chúng tôi tiếp tục thảo luận điều này trong Phần 4, khi chúng tôi điều chỉnh MambaMixer cho các nhiệm vụ thị giác.

Selective Channel Mixer. Trong dữ liệu đa chiều, việc học các phụ thuộc của các đặc trưng là một bước quan trọng hướng tới đào tạo một mô hình hiệu quả và mạnh mẽ. Ví dụ, người ta biết rằng hình ảnh trong các lĩnh vực khác nhau chia sẻ tương quan cross-channel trong khi có tương quan không gian đặc trưng theo lĩnh vực (Guo et al., 2019). Trong xử lý hình ảnh độ phân giải cao, để tránh chi phí tính toán cao, thay vì mô hình hóa rõ ràng các tương tác pixel theo cặp, người ta có thể hợp nhất thông tin qua các kênh đặc trưng (Zamir et al., 2022). Trong chuỗi thời gian đa biến, các đặc trưng là các biến khác nhau và để tận dụng thông tin bổ sung được cung cấp bởi các biến khác nhau, việc học các phụ thuộc của chúng là cần thiết.

Tuy nhiên, việc học các phụ thuộc của các đặc trưng (channel mixing) đi kèm với một số thách thức lớn: Nó ¹yêu cầu các tham số bổ sung, có thể hạn chế khả năng mở rộng của mô hình, ²cần phải chọn lọc và phụ thuộc dữ liệu để lựa chọn (tương ứng lọc) các đặc trưng có thông tin (tương ứng không có thông tin), và ³yêu cầu chú ý bổ sung đến tính ổn định đào tạo và truy cập vào các đặc trưng sớm, do độ sâu mô hình bổ sung. Để vượt qua ¹ và ² chúng tôi sử dụng khối selective channel mixer chọn lọc tập trung vào hoặc bỏ qua một số đặc trưng cụ thể, tùy thuộc vào các nhiệm vụ hạ nguồn. Trong phần tiếp theo, chúng tôi tiếp tục thảo luận cách giải quyết ³.

Thiết kế kiến trúc tương tự như mô-đun selective token mixer với một số khác biệt nhỏ. Đầu tiên, do bản chất không nhân quả của các đặc trưng, chúng tôi sử dụng phương pháp hai chiều để tăng cường luồng thông tin giữa từng cặp đặc trưng. Thứ hai, vì mô-đun này là mô hình chuỗi và được áp dụng qua chiều kênh, chúng tôi sử dụng 1D-Conv như mô-đun tích chập. Đó là:

x̃_forward = sigma(1D-Conv(Linear(x^T))), (12)
B̃_x^T = Linear_B(x^T), C̄_x^T = Linear_C(x^T), và Δ_x^T = Softplus(Linear_Δ(x^T)), (13)
z = Flip(x), (14)
x̃_backward = sigma(1D-Conv(Linear(z^T))), (15)
B̃_z^T = Linear_B(z^T), C̄_z^T = Linear_C(z^T), và Δ_z^T = Softplus(Linear_Δ(z^T)), (16)
x̃_MLP = MLP(x^T), (17)
y_Channel = SSM_{Ā,B̄_x^T,C_x^T,Δ_x^T}(x̃_forward) ⊗ x̃_MLP + Flip(SSM_{Ā,B̄_z^T,C_z^T,Δ_z^T}(x̃_backward)) ⊗ x̃_MLP. (18)

Thiết kế này tương tự như Mamba (Gu & Dao, 2023), khi chúng ta làm cho Mamba hai chiều bằng cách sử dụng hai mô-đun chịu trách nhiệm cho quét chọn lọc tiến và lùi và thay vì áp dụng nó qua tokens, chúng ta áp dụng nó qua channels. Channel mixing này tăng cường luồng thông tin giữa từng cặp đặc trưng và có thể mô phỏng chức năng giống attention, trong khi giữ độ phức tạp tuyến tính. Ví dụ, trong các nhiệm vụ thị giác, trong khi các mô hình thị giác dựa trên selective SSM hiện có (ví dụ ViM (Zhu et al., 2024) và VMamba (Liu et al., 2024)) có thể lựa chọn các patch hình ảnh có thông tin, chúng không thể tập trung vào một phần cụ thể của một patch duy nhất. Sử dụng selective channel mixer bằng cách lựa chọn các đặc trưng có thông tin, MambaMixer có thể tập trung vào một phần cụ thể của một patch duy nhất, cho phép tính linh hoạt hơn và tăng cường khả năng tổng quát hóa.

Weighted Averaging of Earlier Features. Được lấy cảm hứng từ DenseNet (Huang et al., 2017) và DenseFormer (Pagliardini et al., 2024), cho tất cả các lớp MambaMixer cũng như các khối Selective Token và Channel Mixer, chúng tôi kết nối trực tiếp các đầu ra của các khối sớm hơn với đầu vào của chúng bằng cơ chế trung bình có trọng số. Cơ chế này cho phép tái sử dụng trực tiếp các đặc trưng sớm, nắm bắt động lực phức tạp và làm cho đào tạo ổn định hơn. Cho ℓ ∈ {1, ..., L}, trong khối MambaMixer thứ ℓ, đặt y_Token^(ℓ) và y_Channel^(ℓ) là đầu ra của các khối selective token và channel mixer, tương ứng. Chúng tôi tính đầu vào của khối selective token mixer thứ ℓ, x_Token^(ℓ) như:

x_Token^(ℓ) = Σ_{i=0}^{ℓ-1} α_{ℓ,i} y_Token^(i) + Σ_{i=0}^{ℓ-1} β_{ℓ,i} y_Channel^(i). (19)

Tương tự, cho đầu vào của khối selective channel mixer thứ ℓ, x_Channel^(ℓ), chúng ta có:

x_Channel^(ℓ) = Σ_{i=0}^{ℓ} θ_{ℓ,i} y_Token^(i) + Σ_{i=0}^{ℓ-1} γ_{ℓ,i} y_Channel^(i). (20)

Lưu ý rằng trong công thức trên, α_{i,j}, β_{i,j}, θ_{i,j}, và γ_{i,j} là các tham số có thể học được và y_Token^(0) = y_Channel^(0) = x, trong đó x là đầu vào của mô hình.

3.3 Độ Phức tạp Tính toán

Để hiểu độ phức tạp tính toán (không gian và thời gian) của MambaMixer, chúng tôi thảo luận từng selective mixer của nó riêng biệt.

Hardware-aware Implementation. Thách thức chính của việc làm cho trọng số của SSMs phụ thuộc đầu vào là Phương trình 4 trong đào tạo không còn hợp lệ nữa, làm cho việc đào tạo hồi quy và chậm. Nhờ việc triển khai nhận biết phần cứng của khối S6 bởi Gu & Dao (2023), MambaMixer sử dụng thuật toán song song nhận biết phần cứng của họ ở chế độ hồi quy cho các khối S6 của nó trong cả khối Selective Channel và Token Mixer. Theo đó, không có hạn chế cho việc song song hóa hiệu quả phần cứng của đào tạo MambaMixer.

Time Complexity. Đặt B là kích thước batch, L là độ dài chuỗi, D là chiều trạng thái ẩn, E là chiều trạng thái mở rộng, và N là chiều kênh. Sử dụng việc triển khai nhận biết phần cứng của khối S6, độ phức tạp thời gian của nó cho token mixing là O(BLE + EN). Tương tự, độ phức tạp thời gian của nó cho channel mixing là O(BNE + EL). Tổng thể, độ phức tạp thời gian của MambaMixer là O(EB(N + L)), tuyến tính so với cả độ dài chuỗi và số lượng kênh của nó.

Space Complexity. Một trong những hạn chế chính của Transformers (Vaswani et al., 2017), và các mô-đun attention của chúng là độ phức tạp không gian bậc hai so với độ dài chuỗi. Đó là, cho E = 2D, độ phức tạp không gian của khối self-attention là O(LD² + L²D). Đối với khối Mamba thuần túy cho thị giác, bỏ sót các phụ thuộc của kênh, độ phức tạp này là O(LDN) (Zhu et al., 2024). MambaMixer của chúng tôi tương tự yêu cầu O(2LDN + L(2L + 3)) không gian (L là số lượng lớp), dẫn đến độ phức tạp không gian tuyến tính so với độ dài chuỗi và số lượng kênh. Lưu ý rằng L(2L + 3) là bộ nhớ cần thiết cho mô-đun weighted averaging của chúng tôi. Trong các trường hợp cực đoan, thậm chí sử dụng 50 khối MambaMixer, bộ nhớ overhead là không đáng kể.

4 Vision MambaMixer (ViM2)

Trong khi trong phần trước chúng tôi tập trung vào thiết kế MambaMixer như một backbone tổng quát có thể chọn lọc trộn cả tokens và channels, trong phần này, chúng tôi sửa đổi và sử dụng nó để thiết kế một mô hình thị giác.

4.1 Kiến trúc ViM2

Như đã thảo luận trước đó trong Phần 3.2, thiết kế gốc của Selective Token Mixer phù hợp cho các tokens nhân quả, trong khi hình ảnh là dữ liệu không nhân quả và yêu cầu sửa đổi mô hình. Trong phần này, đầu tiên chúng tôi mô tả các sửa đổi của khối MambaMixer để điều chỉnh nó cho các nhiệm vụ thị giác, và sau đó trình bày kiến trúc tổng thể của nó.

Scanning. Để điều chỉnh thiết kế chính của MambaMixer cho hình ảnh, chúng tôi sử dụng cross-scan được trình bày bởi Liu et al. (2024). Trong quét này, chúng tôi quét mỗi hình ảnh theo bốn hướng: trái trên xuống phải dưới, phải dưới lên trái trên, phải trên xuống trái dưới, và trái dưới lên phải trên. Sau đó, mỗi lần quét được chuyển đến khối S6 (selective SSM) và các đầu ra được hợp nhất để tạo thành embeddings mới.

Depth-wise Convolution. Do bản chất 2 chiều của hình ảnh, để bảo tồn cấu trúc của nó, trong Selective Token Mixer, chúng tôi không làm phẳng các patch thành chuỗi 1D. Theo đó, mỗi patch có hình dạng 2D và vì vậy chúng tôi áp dụng tích chập theo chiều sâu (Guo et al., 2019) như lựa chọn mô-đun tích chập trong kiến trúc của Selective Token Mixer.

Selective Channel Mixing. Trong Selective Channel Mixer, thay vì thiết kế hai chiều chính của nó, chúng tôi sử dụng cùng các lần quét như Selective Token Mixer, nhưng chuyển chúng đến các khối S6 qua các kênh của chúng và cuối cùng hợp nhất chúng để tạo thành các đặc trưng mới.

Overall Architecture. Kiến trúc tổng thể của ViM2 được minh họa trong Hình 2. Sử dụng pipeline tương tự như Liu et al. (2024), đầu tiên, chúng tôi patchify các hình ảnh đầu vào bằng mô-đun stem, và giữ nó ở hình dạng 2D mà không làm phẳng thành chuỗi 1D cho token mixing. Trong khối selective channel mixer, đầu tiên chúng tôi làm phẳng mỗi token và cuối cùng reshape nó thành hình dạng 2D. Để học biểu diễn phân cấp của mỗi hình ảnh, sau đó chúng tôi xếp chồng nhiều khối MambaMixer đã sửa đổi (được mô tả ở trên) với down sampling trong bốn giai đoạn chính. Thực tế, mỗi giai đoạn (trừ giai đoạn đầu tiên) bao gồm down sampling ở đầu, dẫn đến việc chia kích thước hình ảnh cho hai trong mỗi giai đoạn, tiếp theo là các stack của các khối MambaMixer với các mô-đun weighted averaging. Chúng tôi giới hạn các kết nối dư có trọng số này cho từng giai đoạn riêng lẻ. Sử dụng thiết kế này, không chỉ ViM2 có thể học biểu diễn phân cấp của hình ảnh, mà nó cũng có thể chọn lọc trộn và hợp nhất thông tin qua cả tokens và channels.

4.2 Kết nối với MLP-Mixer và VMamba

Trong trường hợp cực đoan của việc sử dụng SSMs với chiều không, tức là loại bỏ các khối S6 khỏi cả mô-đun selective token và channel mixer, cũng như loại bỏ tích chập theo chiều sâu, ViM2 tương đương với kiến trúc MLP-Mixer, trong đó MLP(.) được sử dụng để hợp nhất thông tin qua cả channels và tokens. Khi đóng băng tất cả β_{i,j} = 0, α_{i,j} = 0 cho j <= i-2, và α_{i,i-1} = 1, và/hoặc loại bỏ khối selective channel mixer, ViM2 tương đương với kiến trúc VMamba. Do đó, người ta có thể hiểu ViM2 như sự tổng quát hóa của VMamba và MLP-Mixer sao cho nó chọn lọc hợp nhất thông tin qua cả channels và tokens và cho phép truy cập trực tiếp vào các đặc trưng sớm, làm cho mô hình mạnh mẽ và ổn định hơn.

5 Time Series MambaMixer (TSM2)

Trong việc học các mô hình thời gian phức tạp trong chuỗi thời gian đa biến, việc nắm bắt các phụ thuộc của các biến là một bước quan trọng. Về mục đích này, một số nghiên cứu đề xuất tăng cường luồng thông tin cross-variate bằng cách sử dụng mô-đun feature mixer (Chen et al., 2023; Behrouz & Hashemi, 2023). Tuy nhiên, các phương pháp hiện có xử lý tất cả các biến giống nhau trong giai đoạn feature mixing, bao gồm các biến không quan trọng và/hoặc nhiễu. Điều này trở thành một thách thức đáng kể khi các biến khác nhau đến từ các nguồn khác nhau và có thể có nhiễu (ví dụ hồ sơ sức khỏe y tế), hoặc khi một số biến không liên quan đến nhiệm vụ dự báo (ví dụ dự báo giao thông). Để vượt qua thách thức này, chúng tôi điều chỉnh khối MambaMixer của chúng tôi cho dự báo chuỗi thời gian đa biến. Selective Token Mixer (ở đây cũng được gọi là Selective Time Mixer), có thể trộn và hợp nhất thông tin hiệu quả qua chiều thời gian với khả năng tập trung vào hoặc bỏ qua các dấu thời gian cụ thể. Hơn nữa, khối Selective Channel Mixer (ở đây cũng được gọi là Selective Variate Mixer) có thể lựa chọn hiệu quả (tương ứng lọc) các biến có thông tin (tương ứng không liên quan).

Tiếp theo, chúng tôi thảo luận chi tiết về kiến trúc TSM2.

5.1 Kiến trúc TSM2

Kiến trúc tổng thể của TSM2 được minh họa trong Hình 3. TSM2 đầu tiên patchify từng biến của chuỗi thời gian riêng biệt, và sau đó sử dụng khối MambaMixer với Selective Token (Time) Mixer một chiều và Selective Channel (Variate) Mixer hai chiều để chọn lọc luồng thông tin và trộn qua cả thời gian và channels. Lý do chính cho những lựa chọn này là bản chất nhân quả của chiều thời gian và bản chất không nhân quả của variates/features. Tương tự như thiết kế chính của MambaMixer, chúng tôi cũng sử dụng weighted averaging để cho phép mô hình truy cập trực tiếp vào các đặc trưng sớm, cải thiện tính ổn định và cho phép mô hình hiệu quả bỏ qua các hoạt động time và channel mixing không cần thiết. Chúng tôi áp dụng chuẩn hóa 2D trên cả chiều thời gian và đặc trưng và cuối cùng, cho lựa chọn tích chập trong Selective Token (Time) Mixer, chúng tôi sử dụng tích chập 1D, do bản chất nhân quả của dữ liệu.

Auxiliary Information. Chen et al. (2023) cho thấy tầm quan trọng của việc sử dụng thông tin phụ trợ trong dự báo chuỗi thời gian, bất cứ khi nào nó có sẵn. Đó là, ngoài các quan sát lịch sử (chuỗi thời gian đa biến), một số tình huống thực tế cung cấp cho chúng ta các đặc trưng tĩnh S ∈ R^(M×C_S) và các đặc trưng thay đổi theo thời gian trong tương lai Z ∈ R^(M×T_Z×C_Z), trong đó M là số lượng biến, T_Z là chiều thời gian của các đặc trưng tương lai, và C_S và C_Z là kích thước kênh cho các đặc trưng tĩnh và tương lai, tương ứng. Ví dụ, các đặc trưng tĩnh có thể là vị trí của đường phố trong dự báo giao thông, chức năng của các vùng não trong phân tích hoạt động não, meta-data trong hồ sơ y tế cho phân tích sống sót, v.v. Tương tự, các đặc trưng thay đổi theo thời gian trong tương lai có thể là khuyến mãi trong các tuần tiếp theo, dự báo thời tiết cho dự đoán giao thông, các triệu chứng ẩn trong thời gian ủ bệnh lâm sàng, v.v.

Những thách thức chính để kết hợp thông tin này trong các nhiệm vụ dự báo là ¹cách căn chỉnh chúng với các quan sát lịch sử, và ²cách mã hóa chúng hiệu quả để nắm bắt các mô hình động phức tạp của chúng trong các nhiệm vụ dự báo. Trong mô hình TSM2 của chúng tôi, chúng tôi theo pipeline Chen et al. (2023) để căn chỉnh các đặc trưng lịch sử, tương lai và tĩnh. Đó là, cho dữ liệu chuỗi thời gian đa biến lịch sử x ∈ R^(M×T) và các đặc trưng tĩnh S ∈ R^(M×C_S) và các đặc trưng thay đổi theo thời gian trong tương lai Z ∈ R^(M×T_Z×C_Z) tương ứng, đầu tiên chúng tôi sử dụng Selective Channel Mixer trên Z và chiếu nó thành kích thước M×T, cùng kích thước với quan sát lịch sử. Tương tự, chúng tôi chiếu S thành cùng kích thước và nối tất cả ba ma trận để sử dụng như đầu vào của TSM2. Đó là:

S_proj = Linear_stat(S) ∈ R^(M×T), (21)
Z_proj = Linear_future(SelectiveChannelMixer(Z)) ∈ R^(M×T), (22)
x_input = x||Z_proj||S_proj ∈ R^(M×3T) (23)
y = TSM2(x_input). (24)

Một lần nữa, do bản chất nhân quả của các đặc trưng phụ trợ tương lai thay đổi theo thời gian, chúng tôi sử dụng Selective Token Mixer một chiều và Selective Channel Mixer hai chiều.

6 Thí nghiệm

Trong phần này, chúng tôi đánh giá hiệu suất của MambaMixer, ViM2, và TSM2 trong các nhiệm vụ khác nhau của phân loại ImageNet, phát hiện đối tượng, phân đoạn ngữ nghĩa, và các nhiệm vụ dự báo chuỗi thời gian.

Mô hình ViM2 và TSM2. Trong các đánh giá thí nghiệm của chúng tôi, chúng tôi sử dụng các biến thể khác nhau của mô hình. Trong khi chúng tôi điều chỉnh các siêu tham số của TSM2 bằng tìm kiếm lưới để có được hiệu suất tốt nhất, đối với ViM2 chúng tôi theo các nghiên cứu hiện có và sử dụng ba quy mô của mô hình: tức là ViM2-Tiny, ViM2-Small, và ViM2-Base, được gọi là ViM2-T, ViM2-S, và ViM2-B. Chi tiết của các kiến trúc này được báo cáo trong Bảng 8. Cho các nghiên cứu loại bỏ, chúng tôi tiếp tục thay thế selective channel mixer của chúng tôi bằng MLP mà không có weighted averaging, và gọi nó là ViM2-MLP và TSM2-MLP.

Bảng 2: So sánh độ chính xác qua các mô hình khác nhau trên ImageNet-1K†.

Phương pháp | Kích thước Hình ảnh | #Tham số (M) | Độ chính xác Top-1 ImageNet

ConvNets
ResNet-18 (He et al., 2016) | 224 | 12 | 69.8
ResNet-50 (He et al., 2016) | 224 | 25 | 76.2
ResNet-101 (He et al., 2016) | 224 | 45 | 77.4
ResNet-152 (He et al., 2016) | 224 | 60 | 78.3
RegNetY-4G (Radosavovic et al., 2020) | 224 | 21 | 80.0
RegNetY-8G (Radosavovic et al., 2020) | 224 | 39 | 81.7
RegNetY-16G (Radosavovic et al., 2020) | 224 | 84 | 82.9
EffNet-B3 (Tan & Le, 2019) | 300 | 12 | 81.6
EffNet-B4 (Tan & Le, 2019) | 380 | 19 | 82.9
EffNet-B5 (Tan & Le, 2019) | 456 | 30 | 83.6
EffNet-B6 (Tan & Le, 2019) | 528 | 43 | 84.0

Mixer
Mixer-B/16 (Tolstikhin et al., 2021) | 224 | 59 | 76.4
Mixer-L/16 (Tolstikhin et al., 2021) | 224 | 207 | 71.8
ConvMixer-768/32 (Trockman & Kolter, 2023) | 224 | 21 | 80.2
ConvMixer-1536/20 (Trockman & Kolter, 2023) | 224 | 52 | 81.4
M2-ViT-b (Fu et al., 2023a) | 224 | 45 | 79.5

Transformers
ViT-b+Monarch (Fu et al., 2023a) | 224 | 33 | 78.9
ViT-B/16 (Dosovitskiy et al., 2021) | 384 | 86 | 77.9
ViT-L/16 (Dosovitskiy et al., 2021) | 384 | 307 | 76.5
DeiT-S (Touvron et al., 2021) | 224 | 22 | 79.8
DeiT-B (Touvron et al., 2021) | 224 | 86 | 81.8
DeiT-B (Touvron et al., 2021) | 384 | 86 | 83.1
Swin-T (Liu et al., 2021b) | 224 | 29 | 81.3
Swin-S (Liu et al., 2021b) | 224 | 50 | 83.0
Swin-B (Liu et al., 2021b) | 224 | 88 | 83.5

SSMs
S4ND-ConvNeXt-T (Nguyen et al., 2022) | 224 | 30 | 82.2
S4ND-ViT-B (Nguyen et al., 2022) | 224 | 89 | 80.4
VMamba-T (Liu et al., 2024) | 224 | 22 | 82.2
VMamba-S (Liu et al., 2024) | 224 | 44 | 83.5
VMamba-B (Liu et al., 2024) | 224 | 75 | 83.2
ViM-T (Zhu et al., 2024) | 224 | 7 | 76.1
ViM-S (Zhu et al., 2024) | 224 | 26 | 80.5
ViM2-MLP | 224 | 40 | 79.1
ViM2-T | 224 | 20 | 82.7
ViM2-S | 224 | 43 | 83.7
ViM2-B | 224 | 74 | 83.9

†Kết quả báo cáo là kết quả sơ bộ và có thể thay đổi trong các phiên bản tiếp theo.

6.1 Phân loại Hình ảnh trên ImageNet

Setup. Trong thí nghiệm này, chúng tôi đánh giá và so sánh hiệu suất phân loại ViM2 trên ImageNet-1K (Deng et al., 2009) với các baseline khác. Theo Liu et al. (2024), chúng tôi sử dụng pipeline của Liu et al. (2022a) và đào tạo các mô hình của chúng tôi trong 300 epochs (với 20 epochs đầu tiên để warm-up), với kích thước batch 1024 và sử dụng optimizer AdamW (Loshchilov & Hutter, 2019) với momentum 0.9, learning rate 0.001, và weight decay 0.05.

Results. Bảng 2 báo cáo kết quả phân loại ImageNet cho ViM2 và các baseline khác nhau dựa trên ConvNets (tức là ResNet (He et al., 2016), RegNetY (Radosavovic et al., 2020), và EffNet (Tan & Le, 2019)), lớp Mixer (tức là MLP-Mixer (Tolstikhin et al., 2021), ConvMixer (Trockman & Kolter, 2023), và M2-ViT (Fu et al., 2023a)), dựa trên Transformer (tức là ViT (Dosovitskiy et al., 2021), DeiT-S (Touvron et al., 2021), và Swin (Liu et al., 2021b)), và cuối cùng các baseline dựa trên SSM (tức là VMamba (Liu et al., 2024) và ViM (Zhu et al., 2024)). ViM2-T, ViM2-S, và ViM2-B đạt 82.7%, 83.7%, và 83.9% độ chính xác phân loại, tương ứng. Những kết quả này cho thấy rằng với quy mô và kích thước tương tự, ViM2 vượt trội hơn tất cả các mô hình thị giác được thiết lập tốt, trừ EffNet (Tan & Le, 2019). Cụ thể hơn, nó vượt trội hơn ViM-T 6.6%, ViM-S 2.2%, Vmamba-T 0.5%, Swin-T 1.4%, MLP-Mixer-B/16 6.5%, và ResNet-50 6.5%. Mô hình này tiếp tục qua các quy mô khác nhau: tức là ViM2-B vượt trội hơn VMamba-B 0.7%, Swin-B 0.4%, DeiT-B 0.8%, ResNet-152 5.6%, và EffNet-B5 0.3%.

Cuối cùng, so sánh ViM2-MLP với ViM2 tiêu chuẩn, kết quả cho thấy rằng mặc dù sử dụng 100% tham số hơn, ViM2-T vượt trội hơn ViM2-MLP 3.6%. Điều này cho thấy tầm quan trọng của mô-đun selective channel mixer vì việc thay thế nó bằng MLP đơn giản làm hỏng hiệu suất đáng kể.

Input Scaling Evaluation và #Parameters. Chúng tôi tiếp tục đánh giá ViM2 về input scaling và so sánh nó với các baseline. Chúng tôi theo Liu et al. (2024) và đánh giá hiệu suất suy luận của ViM2, được đào tạo với kích thước đầu vào 224×224. Kết quả được báo cáo trong Hình 4. ViM2 và VMamba là những mô hình duy nhất cho thấy cải thiện khi chúng tôi tăng độ phân giải hình ảnh từ 224 lên 384. So với các mô hình khác, ViM2 cho thấy hiệu suất ổn định nhất và ít sụt giảm hiệu suất nhất khi sử dụng độ phân giải hình ảnh 1024. Chúng tôi tiếp tục báo cáo hiệu suất của các mô hình trên ImageNet-1K so với số lượng tham số của chúng. Kết quả được báo cáo trong Hình 5. ViM2 cho thấy hiệu suất tốt nhất với ít tham số hơn. Có hai lý do chính cho hiệu suất vượt trội của ViM2. Đầu tiên, kiến trúc phân cấp của nó cho phép hiểu hình ảnh ở các mức độ chi tiết khác nhau. Thứ hai, khối selective channel mixer cũng như mô-đun weighted averaging của nó, cho phép truy cập trực tiếp vào các đặc trưng sớm, tăng cường luồng thông tin, dẫn đến các mô hình hiệu quả hơn.

6.2 Phân đoạn Ngữ nghĩa

Setup. Trong thí nghiệm này, chúng tôi đánh giá hiệu suất của mô hình ViM2 trên bộ dữ liệu ADE20K (Zhou et al., 2019) và so sánh nó với các baseline tối tân. Theo Liu et al. (2024), chúng tôi xây dựng UperHead (Xiao et al., 2018b) trên đỉnh mô hình được đào tạo trước. Chúng tôi sử dụng crop size 512×512. Trong khi một lần nữa sử dụng optimizer AdamW (Loshchilov & Hutter, 2019), chúng tôi đặt learning rate là 0.00006, và sử dụng batch size 16 trong fine-tuning.

Results. Kết quả so sánh hiệu suất của ViM2 với các baseline được báo cáo trong Bảng 3. Kết quả cho thấy rằng với quy mô và kích thước tương tự, ViM2 vượt trội hơn tất cả các baseline: tức là ViM2-T vượt trội hơn VMamba-T với 1.3, ViM-S với 3.7, Swin-T với 4.2, và ResNet-50 với 6.5 mIoU (single-scale) improvement. Xu hướng tương tự có thể được thấy cho mô hình ViM-S cũng như thước đo mIoU (multi-scale).

Bảng 3: Kết quả phân đoạn ngữ nghĩa trên ADE20K sử dụng UperNet (Xiao et al., 2018a)†.

Phương pháp | Crop size | mIoU (Single-scale) | mIoU (Multi-scale) | #Tham số (M)
---|---|---|---|---
ResNet-50 (He et al., 2016) | 512 | 42.1 | 42.8 | 67
ResNet-101 (He et al., 2016) | 512 | 42.9 | 44.0 | 85
DeiT-S+MLN (Touvron et al., 2021) | 512 | 43.8 | 45.1 | 58
DeiT-B+MLN (Touvron et al., 2021) | 512 | 45.5 | 47.2 | 144
Swin-T (Liu et al., 2021b) | 512 | 44.4 | 45.8 | 60
Swin-S (Liu et al., 2021b) | 512 | 47.6 | 49.5 | 81
Swin-B (Liu et al., 2021b) | 512 | 48.1 | 49.7 | 121
ConvNeXt-T (Liu et al., 2022b) | 512 | 46.0 | 46.7 | 60
ConvNeXt-S (Liu et al., 2022b) | 512 | 48.7 | 49.6 | 82
ConvNeXt-B (Liu et al., 2022b) | 512 | 49.1 | 49.9 | 122
ViM-T (Zhu et al., 2024) | 512 | 41.0 | - | 13
ViM-S (Zhu et al., 2024) | 512 | 44.9 | - | 46
VMamba-T (Liu et al., 2024) | 512 | 47.3 | 48.3 | 55
VMamba-S (Liu et al., 2024) | 512 | 49.5 | 50.5 | 76
VMamba-B (Liu et al., 2024) | 512 | 50.0 | 51.3 | 110
ViM2-T | 512 | 48.6 | 49.9 | 51
ViM2-S | 512 | 50.2 | 51.4 | 75

†Kết quả báo cáo là kết quả sơ bộ và có thể thay đổi trong các phiên bản tiếp theo.

6.3 Phát hiện Đối tượng trên COCO

Setup. Trong thí nghiệm này, chúng tôi đánh giá và so sánh hiệu suất của ViM2 với các baseline về phát hiện đối tượng sử dụng bộ dữ liệu MSCOCO 2017 (Lin et al., 2014). Theo thiết lập thí nghiệm của Liu et al. (2024), chúng tôi sử dụng framework đào tạo trên thư viện mmdetection (Chen et al., 2019). Chúng tôi fine-tune các mô hình phân loại được đào tạo trước trên ImageNet-1K cho cả 12 và 36 epochs. Một lần nữa, chúng tôi sử dụng optimizer AdamW với learning rate 0.0001.

Results. Kết quả so sánh hiệu suất của ViM2 và các baseline trong phát hiện đối tượng được báo cáo trong Bảng 4. Chúng tôi thấy rằng khả năng của khối S6 trong việc nắm bắt ngữ cảnh tầm xa dẫn đến hiệu suất vượt trội của ViM2 vì nó cho phép ViM2 nắm bắt các đối tượng lớn mà các phương pháp dựa trên transformer khác không thể nắm bắt. ViM2-S đạt hiệu suất ngang bằng với VMamba-B trong khi có gần 30% (34 M) ít tham số hơn. Một lần nữa, với quy mô và kích thước tương tự, ViM2 vượt trội hơn hiệu suất baseline bao gồm Swin-B, ViM-T, ViT, và ResNet-101.

Bảng 4: Kết quả phát hiện đối tượng và phân đoạn instance trên bộ dữ liệu COCO†. Ở đây, AP^b và AP^m biểu thị box AP và mask AP, tương ứng.

Phương pháp | AP^b | AP^b_50 | AP^b_75 | AP^m | AP^m_50 | AP^m_75 | #Tham số (M)
---|---|---|---|---|---|---|---
ResNet-50 (He et al., 2016) | 38.2 | 58.8 | 41.4 | 34.7 | 55.7 | 37.2 | 44
ResNet-101 (He et al., 2016) | 38.2 | 58.8 | 41.4 | 34.7 | 55.7 | 37.2 | 63
Swin-T (Liu et al., 2021b) | 42.7 | 65.2 | 46.8 | 39.3 | 62.2 | 42.2 | 48
Swin-S (Liu et al., 2021b) | 44.8 | 66.6 | 48.9 | 40.9 | 63.2 | 44.2 | 69
Swin-B (Liu et al., 2021b) | 46.9 | - | - | 42.3 | - | - | 107
ConvNeXt-T (Liu et al., 2022b) | 44.2 | 66.6 | 48.3 | 40.1 | 63.3 | 42.8 | 48
ConvNeXt-S (Liu et al., 2022b) | 45.4 | 67.9 | 50.0 | 41.8 | 65.2 | 45.1 | 70
ConvNeXt-B (Liu et al., 2022b) | 47.0 | 69.4 | 51.7 | 42.7 | 66.3 | 46.0 | 108
PVTv2-B2 (Wang et al., 2022a) | 45.3 | 67.1 | 49.6 | 41.2 | 64.2 | 44.4 | 45
PVTv2-B3 (Wang et al., 2022a) | 47.0 | 68.1 | 51.7 | 42.5 | 65.7 | 45.7 | 65
PVTv2-B5 (Wang et al., 2022a) | 47.4 | 68.6 | 51.9 | 42.5 | 65.7 | 46.0 | 102
ViT-Adapter-S (Dosovitskiy et al., 2021) | 44.7 | 65.8 | 48.3 | 39.9 | 62.5 | 42.8 | 48
ViT-Adapter-B (Dosovitskiy et al., 2021) | 47.0 | 68.2 | 51.4 | 41.8 | 65.1 | 44.9 | 102
ViM-T (Zhu et al., 2024) | 45.7 | 63.9 | 49.6 | 26.1 | 49.0 | 63.2 | -*
VMamba-T (Liu et al., 2024) | 46.5 | 68.5 | 50.7 | 42.1 | 65.5 | 45.3 | 42
VMamba-S (Liu et al., 2024) | 48.2 | 69.7 | 52.5 | 43.0 | 66.6 | 46.4 | 64
VMamba-B (Liu et al., 2024) | 48.5 | 69.6 | 53.0 | 43.1 | 67.0 | 46.4 | 96
ViM2-T | 47.1 | 68.7 | 50.9 | 42.4 | 65.6 | 45.5 | 39
ViM2-S | 48.5 | 69.9 | 52.8 | 43.1 | 66.8 | 46.5 | 62

*Số lượng tham số không được báo cáo (Zhu et al., 2024).
†Kết quả báo cáo là kết quả sơ bộ và có thể thay đổi trong các phiên bản tiếp theo.

6.4 Dự báo Dài hạn Đa biến

Setup. Chúng tôi thực hiện thí nghiệm trên 8 bộ dữ liệu chuỗi thời gian đa biến thực tế có sẵn công khai, thường được sử dụng trong các nghiên cứu về dự báo dài hạn (Ilbert et al., 2024; Chen et al., 2023; Nie et al., 2023). Chúng tôi so sánh hiệu suất của TSM2 với các mô hình tối tân về dự báo chuỗi thời gian đa biến: tức là SAMFormer (Ilbert et al., 2024), cross-variate Transformer đơn giản (Ilbert et al., 2024), TSMixer (Chen et al., 2023), Informer (Zhou et al., 2021), Autoformer (Wu et al., 2021), FEDFormer (Zhou et al., 2022b), Pyraformer (Liu et al., 2021a), và LogTransformer (Li et al., 2019). Tất cả chuỗi thời gian được phân đoạn với độ dài đầu vào L=512, horizon dự báo H∈{96,192,336,720}, và stride 1.

Results. Chúng tôi so sánh kết quả MSE của TSM2 với các baseline trong Bảng 5. TSM2 vượt trội hơn tất cả các baseline trong hầu hết các trường hợp (26 trên 32 trường hợp như mô hình tốt nhất và 5 như mô hình tốt thứ hai). Lý do cho hiệu suất vượt trội của TSM2 là hai mặt: ¹Trong khi một số baseline đã tập trung nhiều hơn vào các phụ thuộc cross-time (Zhou et al., 2021, 2022b), một số khác được thiết kế để tập trung nhiều hơn vào các phụ thuộc cross-variate (Ilbert et al., 2024). Tuy nhiên, lựa chọn này phụ thuộc vào bản chất của bộ dữ liệu. TSM2 sử dụng mô-đun weighted averaging có thể học liệu nó cần tập trung nhiều hơn vào các phụ thuộc cross-variate hay cross-time theo cách dữ liệu-driven. ²Cơ chế lựa chọn kép trong MambaMixer không chỉ cho phép TSM2 nắm bắt các phụ thuộc tầm xa mà nó cũng sử dụng trọng số phụ thuộc dữ liệu, làm cho mô hình tổng quát hóa hơn; trong khi một số baseline như TSMixer (Chen et al., 2023) sử dụng MLPs đơn giản độc lập với dữ liệu để hợp nhất thông tin, thiếu khả năng lựa chọn.

Bảng 5: So sánh hiệu suất giữa MambaMixer của chúng tôi và các baseline cho dự báo dài hạn đa biến với các horizon H khác nhau. Kết quả của các baseline được lấy từ Ilbert et al. (2024). Chúng tôi hiển thị MSE của các phương pháp. Kết quả tốt nhất được in đậm và tô màu xanh, tốt thứ hai được tô màu xám†.

[Bảng dữ liệu chi tiết với các bộ dữ liệu ETTh1, ETTh2, ETTm1, ETTm2, Electricity, Exchange, Traffic, Weather và các horizon khác nhau, so sánh TSMambaMixer với các phương pháp khác]

†Kết quả báo cáo là kết quả sơ bộ và có thể thay đổi trong các phiên bản tiếp theo.

Dự báo với Thông tin Phụ trợ. Chen et al. (2023) thảo luận về tầm quan trọng của thông tin phụ trợ trong dự báo chuỗi thời gian. Để cho thấy khả năng của TSM2 trong việc sử dụng các đặc trưng phụ trợ, chúng tôi theo Chen et al. (2023) và thực hiện thí nghiệm trên bộ dữ liệu M5 (Makridakis et al., 2022). Chúng tôi sử dụng hai baseline bổ sung có khả năng sử dụng các đặc trưng phụ trợ: tức là DeepAR (Salinas et al., 2020) và TFT (Lim et al., 2021). Kết quả được báo cáo trong Bảng 6. TSM2 vượt trội đáng kể hơn các baseline với 7.43% cải thiện so với mô hình tốt thứ hai, tức là TSMixer (Chen et al., 2023).

Bảng 6: Đánh giá TSM2 và các baseline trên bộ dữ liệu M5 với thông tin phụ trợ.

Thước đo | TSMambaMixer (Của chúng tôi) | TSMixer (Chen et al., 2023) | DeepAR (Salinas et al., 2020) | TFT (Lim et al., 2021)
---|---|---|---|---
Test WRMSSE | 0.591 | 0.640 | 0.789 | 0.670
Val WRMSSE | 0.527 | 0.568 | 0.611 | 0.579

6.5 Tầm quan trọng của Lựa chọn Kép

Chúng tôi tiếp tục đánh giá tầm quan trọng của lựa chọn kép và thiết kế kiến trúc của khối MambaMixer trong TSM2. Về mục đích này, chúng tôi sử dụng hai biến thể của TSM2: ¹TSM2-MLP thay thế khối selective channel mixer bằng MLP. ²Mamba + Linear Time: sử dụng Mamba một chiều (Gu & Dao, 2023) như channel mixer và lớp tuyến tính như token mixer (tương tự kiến trúc TSMixer (Chen et al., 2023)). Kết quả được báo cáo trong Bảng 7. So với TSM2-MLP, hiệu suất vượt trội của TSM2 cho thấy tầm quan trọng của khối selective channel mixer trong TSM2. So với baseline thứ hai, hiệu suất vượt trội của TSM2 cho thấy tầm quan trọng của tính hai chiều trong thiết kế selective channel mixer cũng như tầm quan trọng của khối selective token mixer.

Bảng 7: Nghiên cứu loại bỏ về kiến trúc của TSM2 trên các bộ dữ liệu ETTh1, ETTm1, Exchange, và Electricity.

Mô hình | ETTh1 | ETTm1 | Exchange | Electricity
---|---|---|---|---
TSM2 | 0.375 | 0.322 | 0.163 | 0.142
TSM2-MLP | 0.386 | 0.339 | 0.197 | 0.173
Mamba + Linear Time | 0.388 | 0.334 | 0.220 | 0.151

7 Kết luận

Chúng tôi trình bày MambaMixer, một mô hình không gian trạng thái chọn lọc hiệu quả với lựa chọn kép token và channel. MambaMixer sử dụng các mô hình không gian trạng thái chọn lọc (khối S6) trong cả hướng token và channel, cho phép mô hình hợp nhất thông tin hiệu quả và chọn lọc qua cả hai chiều này. Để tăng cường luồng thông tin và nắm bắt động lực phức tạp của các đặc trưng, MambaMixer sử dụng cơ chế weighted averaging có thể học được trên các đặc trưng sớm, cho phép mỗi khối truy cập trực tiếp vào các đặc trưng sớm. Như bằng chứng về khái niệm, chúng tôi tiếp tục trình bày các mô hình ViM2 và TSM2 dựa trên khối MambaMixer cho các nhiệm vụ thị giác và dự báo chuỗi thời gian. Các đánh giá thí nghiệm của chúng tôi cho thấy rằng trong phân loại ImageNet, phát hiện đối tượng và phân đoạn ngữ nghĩa, ViM2 đạt hiệu suất cạnh tranh với các mô hình thị giác được thiết lập tốt, tức là ViT, MLP-Mixer, ConvMixer, và vượt trội hơn các mô hình thị giác dựa trên SSM, tức là ViM và VMamba. Trong dự báo chuỗi thời gian, TSM2 vượt trội hơn tất cả các baseline trong hầu hết các bộ dữ liệu và đạt hiệu suất tối tân trong khi thể hiện chi phí tính toán được cải thiện đáng kể.

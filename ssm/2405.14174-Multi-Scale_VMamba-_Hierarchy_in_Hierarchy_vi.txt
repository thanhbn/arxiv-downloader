# Multi-Scale VMamba: Hệ thống Phân cấp trong Phân cấp
Mô hình Không gian Trạng thái Thị giác

Yuheng Shi
Đại học Thành phố Hồng Kông
yuhengshi99@gmail.comMinjing Dong
Đại học Thành phố Hồng Kông
minjdong@cityu.edu.hkChang Xu
Đại học Sydney
c.xu@sydney.edu.au

Tóm tắt
Bất chấp những thành tựu đáng kể của Vision Transformers (ViTs) trong các tác vụ thị giác khác nhau, chúng bị hạn chế bởi độ phức tạp bậc hai. Gần đây, các Mô hình Không gian Trạng thái (SSMs) đã thu hút sự chú ý rộng rãi do trường tiếp nhận toàn cục và độ phức tạp tuyến tính theo độ dài đầu vào, thể hiện tiềm năng đáng kể trong các lĩnh vực bao gồm xử lý ngôn ngữ tự nhiên và thị giác máy tính. Để cải thiện hiệu suất của SSMs trong các tác vụ thị giác, một chiến lược quét đa hướng được áp dụng rộng rãi, dẫn đến sự dư thừa đáng kể của SSMs. Để có sự cân bằng tốt hơn giữa hiệu quả và hiệu suất, chúng tôi phân tích các lý do cơ bản đằng sau thành công của chiến lược quét đa hướng, trong đó phụ thuộc tầm xa đóng vai trò quan trọng. Dựa trên phân tích này, chúng tôi giới thiệu Multi-Scale Vision Mamba (MSVMamba) để bảo toàn ưu thế của SSMs trong các tác vụ thị giác với tham số hạn chế. Nó sử dụng kỹ thuật quét 2D đa tỷ lệ trên cả bản đồ đặc trưng gốc và được lấy mẫu xuống, không chỉ có lợi cho việc học phụ thuộc tầm xa mà còn giảm chi phí tính toán. Ngoài ra, chúng tôi tích hợp Mạng Feed-Forward Tích chập (ConvFFN) để giải quyết việc thiếu trộn kênh. Các thí nghiệm của chúng tôi chứng minh rằng MSVMamba có tính cạnh tranh cao, với mô hình MSVMamba-Tiny đạt độ chính xác top-1 82.8% trên ImageNet, 46.9% box mAP, và 42.2% instance mAP với khung Mask R-CNN, lịch huấn luyện 1x trên COCO, và 47.6% mIoU với kiểm tra đơn tỷ lệ trên ADE20K. Mã nguồn có sẵn tại https://github.com/YuHengsss/MSVMamba .

1 Giới thiệu
Trong lĩnh vực thị giác máy tính, việc trích xuất đặc trưng đóng vai trò then chốt trong hiệu suất của các tác vụ khác nhau, từ phân loại hình ảnh đến các ứng dụng phức tạp hơn như phát hiện và phân đoạn. Theo truyền thống, Mạng Nơ-ron Tích chập (CNNs) đã là xương sống của các phương pháp trích xuất đặc trưng, được đánh giá cao về độ phức tạp tỷ lệ tuyến tính và khả năng nắm bắt các mẫu cục bộ. Tuy nhiên, CNNs thường không đạt được việc bao quát bối cảnh toàn cục, một hạn chế trở nên ngày càng rõ ràng trong các tác vụ đòi hỏi hiểu biết toàn diện về toàn bộ trường thị giác. Ngược lại, Vision Transformers (ViTs) đã nổi lên như một lựa chọn thay thế hấp dẫn, tự hào có trường tiếp nhận toàn cục vốn có cho phép nắm bắt trực tiếp các phụ thuộc tầm xa trong một hình ảnh. Mặc dù có những ưu điểm, ViTs bị cản trở bởi độ phức tạp tỷ lệ bậc hai liên quan đến kích thước đầu vào, điều này hạn chế đáng kể khả năng áp dụng của chúng vào các tác vụ downstream như phát hiện đối tượng và phân đoạn, nơi hiệu quả là tối quan trọng. Gần đây, các phương pháp dựa trên Mô hình Không gian Trạng thái (SSM) đã thu hút sự chú ý vì khả năng kết hợp tốt nhất của cả hai thế giới: trường tiếp nhận toàn cục và độ phức tạp tỷ lệ tuyến tính. Đáng chú ý, Mamba giới thiệu một thuật toán nhận thức phần cứng và phụ thuộc đầu vào giúp nâng cao đáng kể hiệu suất và hiệu quả của SSMs. Được truyền cảm hứng bởi thành công của Mamba, một lượng lớn công trình đã tìm cách tận dụng những ưu điểm của nó cho các tác vụ thị giác, những nỗ lực tiên phong như ViM và VMamba.

Khối S6, được phát triển bởi Mamba, ban đầu được thiết kế cho các tác vụ NLP. Để điều chỉnh S6 cho các tác vụ thị giác, hình ảnh trước tiên được chia thành các patch và sau đó được làm phẳng thành một chuỗi patch dọc theo đường quét. Để phù hợp với tính chất không nhân quả của dữ liệu hình ảnh, chiến lược quét đa hướng được áp dụng rộng rãi cho các tác vụ thị giác, chẳng hạn như ViM nâng cao chuỗi bằng cách cộng nó theo cả hướng tiến và ngược, và VMamba tích hợp quét ngang và dọc. Tuy nhiên, không giống như các mô hình NLP, có thể có tới hàng tỷ tham số, các backbone thị giác hiện tại luôn xem xét chi phí tính toán, tức là sự cân bằng giữa độ chính xác và hiệu quả. Ràng buộc về kích thước mô hình này vốn dĩ hạn chế khả năng mô hình hóa tầm xa của SSMs trong các tác vụ thị giác. Lấy ViM-Tiny làm ví dụ, việc đặt cls token ở giữa chuỗi cho kết quả tốt hơn đáng kể so với việc đặt nó ở các đầu. Điều này cho thấy việc đặt ở trung tâm bù đắp cho khả năng hạn chế của mô hình trong việc tích hợp thông tin xa, làm nổi bật những khó khăn trong việc xử lý các phụ thuộc tầm xa trong các mô hình thị giác có tham số hạn chế. Chúng tôi gọi đây là vấn đề quên tầm xa.

Trong công trình này, chúng tôi phân tích cách chiến lược quét đa hướng trong giúp giảm bớt vấn đề này. So với chiến lược quét đơn hướng, chiến lược quét đa hướng cho phép suy giảm tầm xa thể hiện trong các hướng khác nhau trong hình ảnh 2D. Tuy nhiên, việc tăng các tuyến quét mang lại nhiều lần tính toán, tăng đáng kể sự dư thừa và hạn chế hiệu quả. Do đó, chúng tôi nhằm mục đích theo đuổi sự cân bằng tốt hơn giữa hiệu suất và hiệu quả của Mamba trong các tác vụ thị giác.

Phương pháp trực tiếp và hiệu quả nhất để giải quyết vấn đề quên tầm xa là rút ngắn độ dài chuỗi, có thể đạt được bằng cách lấy mẫu xuống bản đồ đặc trưng. Tuy nhiên, việc đặt tất cả các tuyến quét trên bản đồ đặc trưng được lấy mẫu xuống có thể dẫn đến mất các đặc trưng tinh tế và hiệu suất tác vụ downstream. Thông qua việc trực quan hóa các quét khác nhau, chúng tôi cho thấy tốc độ suy giảm có thể khác nhau cho các tuyến quét khác nhau, điều này thúc đẩy chúng tôi phát triển một thiết kế phân cấp của quét đa hướng. Trong công trình này, chúng tôi đề xuất chiến lược quét 2D Đa Tỷ lệ (MS2D) để giảm bớt vấn đề quên tầm xa với chi phí tính toán hạn chế. Cụ thể, chúng tôi chia các hướng quét của SS2D thành hai nhóm: một nhóm giữ nguyên độ phân giải gốc và được xử lý bởi khối S6, trong khi các nhóm khác được lấy mẫu xuống, xử lý bởi khối S6, và sau đó được lấy mẫu lên, không chỉ rút ngắn độ dài chuỗi cho việc học phụ thuộc tầm xa mà còn giảm bớt sự dư thừa. Xây dựng trên VMamba với kiến trúc phân cấp của nó, chúng tôi kết hợp thêm một thiết kế phân cấp khác trong khối, tạo ra một hệ thống phân cấp trong phân cấp. Hơn nữa, chúng tôi giới thiệu Mạng Feed-Forward Tích chập (ConvFFN) trong mỗi khối để củng cố khả năng trao đổi thông tin theo kênh và nắm bắt đặc trưng cục bộ của mô hình.

Chúng tôi tiến hành các thí nghiệm mở rộng để xác thực hiệu quả của MSVmamba trên một loạt các tác vụ, bao gồm phân loại hình ảnh, phát hiện đối tượng và phân đoạn ngữ nghĩa. Các so sánh chi tiết trên bộ dữ liệu ImageNet-1K được minh họa trong Hình 1. Cụ thể, MSVMamba-Tiny đạt được cải thiện đáng chú ý so với VMamba-Tiny, nâng cao độ chính xác Top-1 lên 0.6% trong khi đồng thời giảm nhu cầu tính toán 17% về GFLOPs. Hơn nữa, mô hình MSVMamba của chúng tôi cũng vượt trội hơn các mô hình dựa trên SSM SOTA về hiệu suất trên các bộ dữ liệu COCO và ADE20K cho các tác vụ phát hiện đối tượng và phân đoạn ngữ nghĩa, tương ứng.

2 Công trình liên quan

2.1 Backbone Thị giác Tổng quát
Sự phát triển của các backbone thị giác tổng quát đã định hình đáng kể cảnh quan thị giác máy tính, chuyển đổi từ CNNs sang ViTs. CNNs đã là nền tảng của các mô hình dựa trên thị giác, thống trị các tác vụ thị giác trong kỷ nguyên đầu của deep learning. Các CNN cổ điển như AlexNet, VGG, và ResNet, đã mở đường cho nhiều đổi mới tiếp theo. Những thiết kế này đã cải thiện đáng kể hiệu suất trên một loạt rộng các tác vụ thị giác bằng cách nâng cao khả năng nắm bắt các mẫu và đặc trưng phức tạp từ dữ liệu thị giác của mạng. Vision Transformer, lấy cảm hứng từ thành công của transformers trong xử lý ngôn ngữ tự nhiên, đã nổi lên như một đối thủ đáng gờm với CNNs thông thường cho các tác vụ liên quan đến thị giác. ViT tái tưởng tượng xử lý hình ảnh bằng cách phân đoạn một hình ảnh thành các patch và sử dụng cơ chế self-attention để xử lý các phân đoạn này. Phương pháp đổi mới này cho phép mô hình phân biệt các phụ thuộc toàn cục trên toàn bộ hình ảnh, một bước tiến đáng kể trong việc hiểu dữ liệu thị giác phức tạp. Tuy nhiên, kiến trúc ViT đòi hỏi tài nguyên tính toán đáng kể và bộ dữ liệu mở rộng để huấn luyện hiệu quả. Hơn nữa, hiệu suất của nó gắn liền phức tạp với độ dài chuỗi đầu vào, thể hiện độ phức tạp bậc hai có thể làm tăng chi phí xử lý. Để ứng phó, nghiên cứu tiếp theo đã tập trung vào việc phát triển các chiến lược huấn luyện hiệu quả hơn, cấu trúc mạng phân cấp, cơ chế attention không gian tinh tế và thiết kế dựa trên convolution để giải quyết những vấn đề này.

2.2 Mô hình Không gian Trạng thái
Mô hình Không gian Trạng thái (SSMs) đã thu hút sự chú ý ngày càng tăng từ các nhà nghiên cứu do độ phức tạp tính toán của chúng tăng tuyến tính với độ dài của chuỗi đầu vào và các tính chất nhận thức toàn cục vốn có. Để giảm tiêu thụ tài nguyên tính toán của SSMs, S4 đã giới thiệu cấu trúc đường chéo và kết hợp nó với phương pháp đường chéo cộng low-rank để xây dựng SSMs có cấu trúc. Tiếp theo, S5 và H3 đã nâng cao hơn nữa hiệu quả của các mô hình dựa trên SSM bằng cách giới thiệu các kỹ thuật quét song song và cải thiện việc sử dụng phần cứng. Mamba sau đó đã giới thiệu khối S6, kết hợp các tham số phụ thuộc dữ liệu để sửa đổi các đặc tính Linear Time Invariant (LTI) của các mô hình SSM trước đó, thể hiện hiệu suất vượt trội so với transformers trên các bộ dữ liệu quy mô lớn. Trong lĩnh vực các tác vụ thị giác, S4ND đã tiên phong trong việc áp dụng các mô hình SSM trong các tác vụ thị giác bằng cách xử lý dữ liệu thị giác như tín hiệu 1D, 2D và 3D. U-Mamba đã kết hợp CNNs với SSMs cho phân đoạn hình ảnh y tế. ViM và VMamba đã tích hợp khối S6 vào thiết kế backbone thị giác, sử dụng nhiều hướng quét để phù hợp với tính chất không nhân quả của dữ liệu hình ảnh, đạt được kết quả cạnh tranh với ViTs và CNNs. Được thúc đẩy bởi thành công của ViM và VMamba, một loạt các công trình dựa trên Mamba đã xuất hiện trên các tác vụ thị giác khác nhau, bao gồm thiết kế backbone thị giác, phân đoạn hình ảnh y tế và phân loại video, thể hiện tiềm năng của các phương pháp dựa trên SSM trong việc thúc đẩy lĩnh vực thị giác máy tính.

3 Phương pháp
Trong phần này, trước tiên chúng tôi tóm tắt mô hình không gian trạng thái trong Phần 3.1. Tiếp theo, trong Phần 3.2, chúng tôi cung cấp phân tích sâu về chiến lược quét đa hướng trong các mô hình vision Mamba hiện có. Theo sau phân tích, Phần 3.3 giải quyết vấn đề dư thừa và phụ thuộc tầm xa bằng cách giới thiệu chiến lược quét 2D Đa Tỷ lệ (MS2D). Cuối cùng, Phần 3.4 chi tiết việc tích hợp khối Không gian Trạng thái Đa Tỷ lệ (MS3), kết hợp kỹ thuật MS2D cùng với ConvFFN. Xây dựng trên khối MS3, các cấu hình mô hình khác nhau được phát triển trên các tỷ lệ khác nhau, minh họa khả năng thích ứng và mở rộng của phương pháp được đề xuất.

3.1 Kiến thức cơ bản
Mô hình Không gian Trạng thái. Mô hình Không gian Trạng thái (SSMs) cổ điển đại diện cho một hệ thống liên tục ánh xạ một chuỗi đầu vào x(t) ∈ R^L sang một biểu diễn không gian tiềm ẩn h(t) ∈ R^N và sau đó dự đoán một chuỗi đầu ra y(t) ∈ R^L dựa trên biểu diễn này. Về mặt toán học, một SSM có thể được mô tả như sau:

h'(t) = Ah(t) + Bx(t), y(t) = Ch(t), (1)

trong đó A ∈ R^(N×N), B ∈ R^(N×1) và C ∈ R^(1×N) là các tham số có thể học.

Rời rạc hóa. Để điều chỉnh Mô hình Không gian Trạng thái liên tục (SSMs) để sử dụng trong các khung deep learning, việc thực hiện các phép toán rời rạc hóa là rất quan trọng. Bằng cách kết hợp tham số thang thời gian Δ ∈ R và sử dụng zero-order hold (ZOH) được sử dụng rộng rãi làm quy tắc rời rạc hóa, các phiên bản rời rạc của A và B (ký hiệu là Ā và B̄, tương ứng) có thể được rút ra, với chúng, Phương trình 1 có thể được tái công thức thành dạng rời rạc như:

h(t) = Āh(t-1) + B̄x(t), y(t) = Ch(t),
trong đó Ā = e^(ΔA), B̄ = (ΔA)^(-1)(e^(ΔA) - I)ΔB ≈ ΔB, (2)

trong đó I biểu thị ma trận đơn vị. Sau đó, quá trình của Phương trình 2 có thể được thực hiện theo cách convolution toàn cục như:

y = x ⊙ K, K = [C̄B̄, C̄ĀB̄, ..., C̄Ā^(L-1)B̄], (3)

trong đó K ∈ R^L là kernel convolution.

Mô hình Không gian Trạng thái Chọn lọc. Cơ chế Selective State Space (S6), được giới thiệu bởi Mamba, làm cho các tham số B, C và Δ phụ thuộc vào đầu vào, từ đó nâng cao hiệu suất của các mô hình dựa trên SSM. Sau khi làm cho B, C và Δ phụ thuộc vào đầu vào, kernel convolution toàn cục trong Phương trình 3 có thể được viết lại như:

K = [C_L B_L, C_L Ā_(L-1) B_(L-1), ..., C_L ∏_(i=1)^(L-1) Ā_i B_1]. (4)

3.2 Phân tích Chiến lược Quét Đa hướng
Khi xử lý dữ liệu hình ảnh bằng khối S6, bản đồ đặc trưng 2D Z ∈ R^(H×W×D) được làm phẳng thành chuỗi 1D các token hình ảnh, ký hiệu là X ∈ R^(L×D). Theo Phương trình 4 và Phương trình 2, đóng góp của token thứ m vào việc xây dựng token thứ n (m < n) trong S6 có thể được biểu diễn như:

C_n ∏_(i=m) Ā_i B_m = C_n Ā^(m→n) B_m, trong đó Ā^(m→n) = e^(∑_(i=m)^n Δ_i A). (5)

Thông thường, Δ_i A đã học được là âm, điều này làm mô hình thiên về ưu tiên thông tin của các token gần đây. Do đó, khi độ dài chuỗi tăng, số hạng mũ e^(∑_(i=m)^n Δ_i A) trong Phương trình 5 suy giảm đáng kể, dẫn đến đóng góp tối thiểu từ các token xa. Chúng tôi gọi đây là vấn đề quên tầm xa, điều này cũng đã được quan sát thấy trong các nghiên cứu gần đây áp dụng S6 cho các tác vụ thị giác. Mặc dù vấn đề này có thể được giảm bớt bằng cách tăng số lượng tham số và độ sâu của mô hình, những điều chỉnh như vậy sẽ mang lại chi phí tính toán bổ sung. Hơn nữa, tính chất nhân quả của khối S6 đảm bảo rằng thông tin chỉ có thể lan truyền theo cách một chiều giữa các token, ngăn cản các token trước đó truy cập thông tin từ các token tiếp theo.

Tính chất không nhân quả vốn có của hình ảnh làm cho việc áp dụng trực tiếp khối S6 vào các tác vụ liên quan đến thị giác trở nên kém tối ưu, như đã được xác định bởi ViM. Để giảm thiểu hạn chế này, ViM và VMamba đã giới thiệu các phương pháp bao gồm việc quét các đặc trưng hình ảnh theo các hướng khác nhau và sau đó tích hợp các đặc trưng này. Nói chung, token được cập nhật dọc theo một trong các tuyến quét, ký hiệu là Scan(Z_(p,q)), trong đó (p, q) chỉ tọa độ, có thể được thu được bằng:

Scan(Z_(p,q)) = C_α ∑_(i=1)^α Ā^(i→α) B_i σ(Z)_i. (6)

Trong Phương trình 6, σ đại diện cho phép biến đổi chuyển đổi bản đồ đặc trưng 2D thành chuỗi 1D, và α biểu thị chỉ số tương ứng của Z_(p,q) trong chuỗi 1D đã biến đổi. Sau đó, kết quả từ các tuyến quét đa hướng được cộng lại với nhau để tạo ra đặc trưng nâng cao Z'_(p,q), có thể được ký hiệu là:

Z'_(p,q) = ∑_k Scan_k(Z_(p,q)) = ∑_k C_α_k ∑_(i=1)^α_k Ā^(i→α_k) B_i σ_k(Z)_i. (7)

Chiến lược quét đa hướng này cho phép các token truy cập thông tin từ nhau. Trong ViM, hai tuyến quét riêng biệt tương ứng với hai phép biến đổi khác nhau trong Phương trình 6, cụ thể là phép biến đổi flatten và flatten với flip. Tương tự, VMamba mở rộng quét hai chiều cơ bản bằng cách kết hợp cả hướng quét ngang và dọc, tạo ra bốn tuyến quét riêng biệt. Ngoài ra, chiến lược quét đa hướng cũng giảm bớt vấn đề quên tầm xa bằng cách giảm thiểu khoảng cách hiệu quả giữa các token. Đối với các token tại tọa độ (p1, q1) và (p2, q2), chiến lược sử dụng nhiều tuyến quét, mỗi tuyến có thể thay đổi vị trí tương đối của chúng. Khoảng cách tối thiểu trên các tuyến này được cho bởi min_k d_k((p1, q1) → (p2, q2)), trong đó d_k đại diện cho khoảng cách giữa các token trong chuỗi được tạo bởi quét thứ k. Bằng cách giảm khoảng cách này, chiến lược quét đa hướng giảm sự suy giảm ảnh hưởng giữa các token xa, từ đó nâng cao khả năng duy trì và sử dụng thông tin tầm xa của mô hình.

Để minh họa trực quan hơn mối quan hệ giữa chiến lược quét đa hướng và suy giảm tầm xa, chúng tôi trực quan hóa số hạng mũ e^(∑_(i=1)^α Δ_i A) dọc theo các hướng quét ngang và dọc trong VMamba-Tiny đối với token trung tâm trong Hình 2a và Hình 2b. Cụ thể, chúng tôi chọn ngẫu nhiên 50 hình ảnh từ tập xác thực ImageNet và tính toán suy giảm trung bình dọc theo các tuyến quét tại lớp cuối của giai đoạn cuối trên các hình ảnh và chiều đặc trưng này. Chúng tôi sử dụng độ phân giải đầu vào cao hơn để nâng cao chất lượng trực quan hóa.

Theo những quan sát này, thành công của chiến lược quét đa hướng trong VMamba có thể được quy cho việc giảm thiểu các tính chất không nhân quả của dữ liệu hình ảnh và giảm bớt vấn đề quên tầm xa. Tuy nhiên, khi số lượng tuyến quét tăng, chi phí tính toán cũng tăng tuyến tính, mang lại sự dư thừa tính toán. Trong Hình 2c, chúng tôi minh họa tỷ lệ tối đa của Hình 2a so với Hình 2b và ngược lại. Trong khi trong Hình 2d, chúng tôi trình bày phiên bản nhị phân của Hình 2c, áp dụng ngưỡng 10, bao phủ hơn 40% toàn bộ hình. Hiện tượng này cho thấy các tốc độ suy giảm khác nhau trên các tuyến quét khác nhau dẫn đến một số tuyến thống trị động lực suy giảm, điều này cũng có thể được quy cho vấn đề quên tầm xa. Sự tồn tại của các tuyến quét thống trị ngụ ý rằng một số quét đóng góp nhiều hơn đáng kể vào việc giữ lại thông tin so với những quét khác, dẫn đến sự dư thừa tính toán trong chiến lược quét đa hướng.

3.3 Quét 2D Đa Tỷ lệ
Như đã thảo luận trong phần phụ cuối, đóng góp của các token suy giảm với khoảng cách quét tăng. Cách hiệu quả và trực tiếp nhất để giảm bớt vấn đề quên tầm xa là giảm số lượng token. Đồng thời, vì độ phức tạp tính toán của khối S6 phụ thuộc tuyến tính vào số lượng token, việc giảm số lượng token cũng nâng cao hiệu quả. Do đó, một phương pháp thay thế để giải quyết vấn đề nêu trên là áp dụng chiến lược quét đa hướng trên bản đồ đặc trưng được lấy mẫu xuống. Tuy nhiên, việc đặt tất cả các quét trên bản đồ đặc trưng được lấy mẫu xuống sẽ bỏ qua các đặc trưng tinh tế và dẫn đến mất thông tin không thể tránh khỏi. Do đó, việc quét dọc theo bản đồ đặc trưng độ phân giải đầy đủ cũng rất cần thiết.

Được thúc đẩy bởi những cân nhắc này, chúng tôi giới thiệu chiến lược quét 2D Đa Tỷ lệ (MS2D) đơn giản nhưng hiệu quả, như được mô tả trong Hình 3. Phương pháp của chúng tôi bắt đầu với việc tạo ra các bản đồ đặc trưng phân cấp ở các tỷ lệ khác nhau, đạt được thông qua việc áp dụng Depthwise Convolution (DWConv) với các giá trị stride riêng biệt. Các bản đồ đặc trưng đa tỷ lệ này sau đó được xử lý thông qua bốn tuyến quét riêng biệt trong VMamba. Cụ thể, chúng tôi sử dụng DWConvs với stride 1 và s để thu được bản đồ đặc trưng Z1 ∈ R^(H×W×D) và Z2 ∈ R^(H/s×W/s×D), tương ứng. Sau đó, Z1 và Z2 được xử lý bởi hai khối S6 như:

Y1 = S6(σ1(Z1)), (8)
[Y2, Y3, Y4] = S6([σ2(Z2), σ3(Z2), σ4(Z2)]), (9)

trong đó σ là phép biến đổi chuyển đổi bản đồ đặc trưng 2D thành chuỗi 1D được sử dụng trong SS2D, và Y là chuỗi đã xử lý. Các chuỗi đã xử lý này được chuyển đổi trở lại thành bản đồ đặc trưng 2D, và các bản đồ đặc trưng được lấy mẫu xuống được nội suy để hợp nhất:

Z'_i = γ_i(Y_i), i ∈ {1,2,3,4}, (10)
Z' = Z'_1 + Interpolate(∑(Z'_j)), j ∈ {2,3,4}, (11)

trong đó γ là phép biến đổi nghịch đảo của σ và Z' là bản đồ đặc trưng được nâng cao bởi MS2D.

Hoạt động lấy mẫu xuống giảm độ dài chuỗi bằng hệ số s², điều này cũng rút ngắn khoảng cách giữa các token trong Phương trình 5 bằng hệ số s², từ đó giảm bớt vấn đề quên tầm xa. Vì độ phức tạp tính toán của một khối S6 đơn lẻ là O(9LDN), trong đó N biểu thị chiều SSM, việc thay thế SS2D bằng MS2D giảm tổng độ dài chuỗi trên bốn quét từ 4L xuống (1 + 3/s²)L, từ đó cải thiện hiệu quả. Thực tế, tỷ lệ lấy mẫu xuống được đặt là 2. Đáng chú ý rằng các chuỗi từ Z2 được xử lý bởi cùng một khối S6. Phương pháp này duy trì độ chính xác giống như sử dụng nhiều khối S6 cho các tuyến quét khác nhau trong khi hiệu quả giảm số lượng tham số.

Để minh họa tốt hơn việc giảm bớt vấn đề quên tầm xa, chúng tôi cũng cung cấp bằng chứng thực nghiệm, như được hiển thị trong Hình 4. Chúng tôi so sánh sự suy giảm dọc theo các tuyến quét trong SS2D của VMamba và MS2D của chúng tôi, tập trung vào token cuối cùng với cấu hình giống như Hình 2. Các bản đồ suy giảm trong các đặc trưng được lấy mẫu xuống được nội suy trở lại. Như quan sát thấy, tốc độ suy giảm dọc theo các tuyến quét trong các bản đồ được lấy mẫu xuống được giảm bớt đáng kể, nâng cao khả năng nắm bắt thông tin toàn cục.

3.4 Kiến trúc Mô hình Tổng thể
Trong nghiên cứu này, chúng tôi mở rộng khả năng của khung VMamba bằng cách thay thế khối VSS của nó bằng khối Multi-Scale State Space (MS3) của chúng tôi. Khung kiến trúc của khối MS3 được vạch ra trong Hình 5, bao gồm một thành phần Multi-Scale Vision Space State (MSVSS) và một Mạng Feed-Forward Tích chập (ConvFFN). Thành phần MSVSS được thiết kế bằng cách điều chỉnh khung không gian trạng thái thị giác trong VMamba, thay thế SS2D bằng MS2D để giới thiệu thêm thiết kế phân cấp trong một lớp đơn. Ngoài ra, một khối Squeeze-Excitation (SE) được tích hợp sau quét 2D đa tỷ lệ, như được thông báo bởi tài liệu liên quan. Khác với trọng tâm thông thường về trộn token trong các kiến trúc vision Mamba trước đó, thiết kế của chúng tôi giới thiệu một bộ trộn kênh để tăng cường luồng thông tin qua các kênh khác nhau, phù hợp với các mô hình cấu trúc của các vision transformers điển hình. Phù hợp với các nghiên cứu trước đó, ConvFFN bao gồm một convolution theo độ sâu và hai lớp kết nối đầy đủ được sử dụng làm bộ trộn kênh. Để đảm bảo rằng ConvFFN và khối MSVSS tiêu thụ khoảng cùng FLOPs theo LeViT, chúng tôi áp dụng tỷ lệ mở rộng kênh khiêm tốn là 2. Sau khi kết hợp MSVSS và ConvFFN trong khối MS3, các điều chỉnh tỉ mỉ được thực hiện đối với số lượng khối để đảm bảo ngân sách tính toán tương đương, tạo điều kiện cho so sánh công bằng.

Để xác thực thực nghiệm hiệu quả của các sửa đổi được đề xuất, chúng tôi giới thiệu các biến thể mô hình ở các tỷ lệ khác nhau, các thông số kỹ thuật được chi tiết trong phụ lục 6 của chúng tôi. Các biến thể này, cụ thể là Nano, Micro và Tiny, được đặc trưng bởi số lượng tham số tương ứng là 6.9M, 11.9M và 33.0M. Về chi phí tính toán, các mô hình này yêu cầu 0.9, 1.5 và 4.6 GFLOPs tương ứng, thể hiện phương pháp thiết kế mô hình có thể mở rộng phù hợp với các ràng buộc tính toán khác nhau.

4 Xác thực Thực nghiệm

4.1 Phân loại ImageNet
Cài đặt. Các mô hình của chúng tôi được huấn luyện và kiểm tra trên bộ dữ liệu ImageNet-1K. Phù hợp với các công trình trước đó, tất cả các mô hình trải qua huấn luyện 300 epoch, với 20 epoch đầu dành cho làm nóng. Quá trình huấn luyện sử dụng kích thước batch 1024 trên 8 GPU. Chúng tôi sử dụng bộ tối ưu hóa AdamW, đặt betas thành (0.9, 0.999) và momentum thành 0.9. Tốc độ học được quản lý thông qua bộ lập lịch cosine decay, bắt đầu từ tốc độ ban đầu 0.001, kết hợp với weight decay 0.05. Ngoài ra, chúng tôi tận dụng exponential moving average (EMA) và thực hiện label smoothing với hệ số 0.1 để nâng cao hiệu suất và khả năng tổng quát hóa của mô hình. Trong quá trình kiểm tra, hình ảnh được cắt trung tâm với kích thước 224×224. Khi xử lý các tuyến cho quét đa tỷ lệ, chúng tôi chọn thực nghiệm từ trên-trái đến dưới-phải để xử lý bản đồ đặc trưng độ phân giải đầy đủ trong khi ba quét khác chịu trách nhiệm quét bản đồ đặc trưng được lấy mẫu xuống.

Kết quả. Bảng 1 trình bày các mô hình MSVMamba của chúng tôi so với các CNN, ViTs và mô hình dựa trên SSM đã được thiết lập trên ImageNet-1K. MSVMamba-N, với 7M tham số và 0.9G FLOPs, đạt độ chính xác top-1 77.3%, vượt trội hơn RegNetY-800M dựa trên Conv có chi phí tương tự và EfficientVMamba-T dựa trên SSM. MSVMamba-M, với 12M tham số và 1.5G FLOPs, đạt độ chính xác 79.8%, vượt trội ViM-T 3.7%. Mô hình MSVMamba-T đạt độ chính xác 82.8% với 33M tham số và 4.6G FLOPs, vượt VMamba-T 0.6% với chi phí tính toán ít hơn nhiều. Những kết quả này làm nổi bật hiệu quả và khả năng mở rộng của MSVMamba, cung cấp một lựa chọn mạnh mẽ cho thiết kế mô hình có độ chính xác cao và hiệu quả tài nguyên.

4.2 Phát hiện Đối tượng
Cài đặt. Chúng tôi đánh giá MSVMamba của chúng tôi trên bộ dữ liệu MSCOCO sử dụng khung Mask R-CNN cho các tác vụ phát hiện đối tượng và phân đoạn instance. Theo các công trình trước đó, chúng tôi sử dụng các backbone được pre-train trên ImageNet-1K để khởi tạo. Chúng tôi sử dụng các chiến lược huấn luyện tiêu chuẩn của 1× (12 epochs) và 3× (36 epochs) với huấn luyện Multi-Scale (MS) để so sánh công bằng.

Kết quả. Bảng 2 trình bày so sánh hiệu suất của phương pháp chúng tôi so với CNNs, ViTs và các mô hình dựa trên SSM. Mô hình của chúng tôi luôn vượt trội hơn các mô hình khác trên các biến thể và cài đặt huấn luyện khác nhau. Cụ thể, MSVMamba-T vượt trội Swin-T +4.2 box AP và +2.9 mask AP dưới lịch trình 1× và cũng cho thấy cải thiện trong cả box AP và mask AP dưới lịch trình 3×.

4.3 Phân đoạn Ngữ nghĩa
Cài đặt. Phù hợp với các phương pháp được sử dụng trong Swin và VMamba, chúng tôi sử dụng khung UperHead trên backbone MSVMamba được pre-train trên ImageNet. Quá trình huấn luyện được tiến hành qua 160K vòng lặp với kích thước batch 16. Chúng tôi sử dụng bộ tối ưu hóa AdamW với tốc độ học được đặt ở 6×10^(-5). Các thí nghiệm của chúng tôi chủ yếu được tiến hành sử dụng độ phân giải đầu vào mặc định 512×512. Ngoài ra, chúng tôi cũng kết hợp kiểm tra Multi-Scale (MS) để đánh giá các biến động hiệu suất.

Kết quả. Chúng tôi trình bày kết quả chi tiết của mô hình và các đối thủ cạnh tranh khác trong Bảng 3, bao gồm cả kiểm tra đơn tỷ lệ và đa tỷ lệ. MSVMamba của chúng tôi luôn vượt trội hơn các mô hình Swin, ConNeXt và VMamba trong biến thể tiny với biên độ +2.2, +1.6 và +0.3 mIoU, tương ứng.

4.4 Nghiên cứu Ablation
Để xác thực hiệu quả của các module được đề xuất, chúng tôi đã tiến hành nghiên cứu ablation toàn diện. Cụ thể, chúng tôi thu nhỏ mô hình VMamba-Tiny bằng cách đặt chiều embedding d thành 48, chiều không gian trạng thái N thành 8, và số lượng khối trong bốn giai đoạn khác nhau thành [1,2,4,2]. Mô hình được thu nhỏ, được gọi là VMamba-Nano, có tham số và chi phí tính toán lần lượt là 4.4M và 0.87GFLOPs. Mô hình này phục vụ như baseline cho các thí nghiệm ablation của chúng tôi. Các mô hình trong nghiên cứu ablation được tiến hành qua lịch trình huấn luyện 100 epochs, trừ trường hợp được ghi chú khác, để giảm thời gian huấn luyện.

Về Quét 2D Đa Tỷ lệ. Sau khi thay thế SS2D trong VMamba bằng MS2D của chúng tôi, trong khi duy trì số lượng FLOP tương đương, độ chính xác tăng từ 69.6% lên 71.9%, như được chứng minh trong Bảng 4. Hơn nữa, chúng tôi đã tiến hành ablation về số lượng quét trong quét đa tỷ lệ, xem xét cả nhánh độ phân giải đầy đủ và nửa độ phân giải. Kết quả được hiển thị trong Bảng 5. Việc đặt tất cả các quét trong nhánh nửa độ phân giải dẫn đến mất đáng kể các đặc trưng tinh tế, dẫn đến giảm đáng kể độ chính xác của mô hình. Việc đặt hai hoặc ba quét trong nhánh độ phân giải đầy đủ, so với chỉ một, dẫn đến cải thiện độ chính xác 0.1% và 0.6%, nhưng mang lại chi phí tính toán bổ sung khoảng 12% và 25%. Việc phân bổ bốn quét cho nhánh độ phân giải đầy đủ, thực sự quay trở lại phương pháp SS2D, tăng chi phí tính toán 34% trong khi chỉ cải thiện độ chính xác 0.4%. Để có sự cân bằng tối ưu giữa chi phí tính toán và độ chính xác, chúng tôi chọn một quét trong nhánh độ phân giải đầy đủ làm cài đặt mặc định. Xây dựng trên nền tảng MS2D, chúng tôi giới thiệu khối SE theo EfficientVMamba, điều này nâng cao thêm độ chính xác 0.5% với chi phí tính toán bổ sung tối thiểu.

Về ConvFFN. Sau khi thay thế SS2D bằng MS2D và kết hợp khối SE, chúng tôi xây dựng một mô hình sử dụng ConvFFN làm bộ trộn kênh. Khi chỉ sử dụng SSM, mô hình thể hiện trao đổi thông tin không đầy đủ giữa các kênh. Việc tích hợp ConvFFN làm bộ trộn kênh đã nâng cao đáng kể khả năng tương tác thông tin liên kênh của mô hình. Như được chỉ ra trong Bảng 4, việc bổ sung ConvFFN dẫn đến cải thiện độ chính xác bổ sung 2.0%. Để duy trì chi phí tính toán tương đương, chúng tôi điều chỉnh số lượng khối trong mô hình. Ngoài ra, chúng tôi đặt chiều không gian trạng thái N = 1 và xếp chồng thêm một khối nữa để nâng cao hơn nữa khả năng nắm bắt thông tin tầm xa trong khi duy trì chi phí tính toán gần như không đổi. Hoạt động này dẫn đến cải thiện độ chính xác bổ sung 0.7%, như được hiển thị trong Bảng 4.

5 Hạn chế
Thiết kế của multi-scale VMamba nhằm giải quyết vấn đề quên tầm xa của các mô hình Mamba với tham số hạn chế trên các tác vụ thị giác. Mặc dù mô hình được đề xuất đã chứng minh là hiệu quả, khả năng mở rộng của nó vẫn còn phải khám phá vì vấn đề này cũng có thể được giảm bớt bằng cách tăng kích thước mô hình. Trong những trường hợp như vậy, thiết kế đa tỷ lệ có thể chỉ có cải thiện nhỏ.

6 Kết luận
Trong bài báo này, chúng tôi đã giới thiệu Multi-Scale VMamba (MSVMamba), một backbone thị giác dựa trên SSM tận dụng các ưu điểm của độ phức tạp tuyến tính và trường tiếp nhận toàn cục. Chúng tôi phát triển kỹ thuật quét 2D Đa Tỷ lệ (MS2D) để giảm thiểu sự dư thừa tính toán và giảm bớt vấn đề quên tầm xa trong các mô hình thị giác có tham số hạn chế. Ngoài ra, chúng tôi kết hợp Mạng Feed-Forward Tích chập (ConvFFN) để nâng cao việc trao đổi thông tin giữa các kênh, từ đó cải thiện đáng kể hiệu suất của mô hình. Các thí nghiệm của chúng tôi chứng minh rằng MSVMamba luôn vượt trội hơn các mô hình phổ biến từ các kiến trúc khác nhau, bao gồm ConvNeXt, Swin Transformer và VMamba, trong phân loại hình ảnh và các tác vụ downstream.

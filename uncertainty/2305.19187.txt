# 2305.19187.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/uncertainty/2305.19187.pdf
# File size: 1132026 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
Published in Transactions on Machine Learning Research (05/2024)
Generating with Confidence: Uncertainty Quantification for
Black-box Large Language Models
Zhen Lin1
zhenlin4@illinois.edu
Shubhendu Trivedi
shubhendu@csail.mit.edu
Jimeng Sun1,2
jimeng@illinois.edu
1University of Illinois at Urbana-Champaign
2Carle’s Illinois College of Medicine, University of Illinois at Urbana-Champaign
Reviewed on OpenReview: https: // openreview. net/ forum? id= DWkJCSxKU5
Abstract
Large language models (LLMs) specializing in natural language generation (NLG) have
recently started exhibiting promising capabilities across a variety of domains. However,
gauging the trustworthiness of responses generated by LLMs remains an open challenge,
with limited research on uncertainty quantification (UQ) for NLG. Furthermore, existing
literature typically assumes white-box access to language models, which is becoming unreal-
istic either due to the closed-source nature of the latest LLMs or computational constraints.
In this work, we investigate UQ in NLG for black-box LLMs. We first differentiate uncer-
taintyvsconfidence : the former refers to the “dispersion” of the potential predictions for a
fixed input, and the latter refers to the confidence on a particular prediction/generation. We
then propose and compare several confidence/uncertainty measures, applying them to selec-
tive NLG where unreliable results could either be ignored or yielded for further assessment.
Experiments were carried out with several popular LLMs on question-answering datasets
(for evaluation purposes). Results reveal that a simple measure for the semantic dispersion
can be a reliable predictor of the quality of LLM responses, providing valuable insights for
practitioners on uncertainty management when adopting LLMs. The code to replicateour
experiments is available at https://github.com/zlin7/UQ-NLG .
1 Introduction
Large language models (LLMs) have recently gained significant attention in natural language generation
(NLG) (Touvron et al., 2023a; Katz et al., 2023; OpenAI, 2023; Chowdhery et al., 2022). Trained on vast
amounts of data, they exhibit impressive abilities in generating human-like responses. As such advances
invariably lead to wider adoption of LLM for language generation tasks, such as question-answering (QA),
it is crucial to quantify their uncertainty.
Uncertainty quantification (UQ) is well-studied within machine learning. A reliable measure of uncertainty is
important to decide when to trust a model. When a model shows high uncertainty or returns low-confidence
predictions1, the input should either be rejected or yielded to further evaluation (Gal & Ghahramani, 2016).
1See Section 3.2 for a discussion of uncertainty vs. confidence.
1arXiv:2305.19187v3  [cs.CL]  20 May 2024

--- PAGE 2 ---
Published in Transactions on Machine Learning Research (05/2024)
This is an area of active research typically called selective classification (Chow, 1970; Lin et al., 2022b;
Geifman & El-Yaniv, 2017). Similarly, in NLG, one might refuse the generation sby the LLM to the
inputxwith high uncertainty/low confidence. Selective generation basing on uncertainty estimates could
potentially improve the decision making process, especially for high-stakes applications such as medical or
legal question-answering.
While UQ has been an important topic for classical machine learning tasks like classification or regres-
sion (Lakshminarayanan et al., 2017; Gal & Ghahramani, 2016; Hernández-Lobato & Adams, 2015; Abdar
et al., 2021a), it bears specific challenges for NLG and has attracted limited attention until recently (Lin
et al., 2022a; Kuhn et al., 2023; Malinin & Gales, 2021). Numerous challenges hinder the direct application
of UQ methods from classification or regression. First, the output space has forbiddingly high dimensional-
ity, rendering most measures, such as the exact entropy of predicted probabilities, unfeasible. Furthermore,
distinct token sequences may convey identical meanings, necessitating an effective uncertainty measure to
operate in the semantic meaning space (Kuhn et al., 2023). Lastly, many existing LLMs are black-boxes
served via APIs, implying that end-users typically lack white-box access. Even when such access is available,
many LLMs are too large to run for most. Note that such considerations are orthogonal to the problem of
overconfidence: We need a ranking-wise informative confidence/uncertainty measure before the problem of
overconfidence even appears (see discussion in Section 2).
Inthisstudy, weexploretheproblemofuncertaintyquantificationinNLGwithblack-boxLLMs. Unlikesome
prior research (Mielke et al., 2020; Lin et al., 2022a; Kadavath et al., 2022; Kuhn et al., 2023), we focus on the
more realistic scenario where we only possess access to the generated text, rather than the numerical outputs
such as token-level logits. We first introduce a set of measures designed to assess the uncertainty of the input
and the confidence of each generation - The main idea entails estimating the uncertainty/confidence from
multiple generations from the LLM. Then, we demonstrate the application of these uncertainty estimates in
the context of free-form QA. QA datasets are used for the simplicity of evaluation, as completely open-ended
NLG tasks require expensive human evaluation. The main contributions of this paper are summarized as
follows:
•We investigate uncertainty quantification for black-box LLMs, a previously under-explored topic, and
assess its value in the downstream task of selective natural language generation.
•We put forward several simple yet effective techniques for estimating uncertainty associated with input
data and determining the confidence level of each individual generated response.
•Through extensive experiments on several popular LLMs and question-answering datasets, we observe
that proposed measures demonstrate a high level of effectiveness in pinpointing challenging (uncertain)
questions and predicting the quality of their corresponding answers.
2 Related Works
Thequantificationofuncertaintyhasemergedasasignificantareaofresearchacrossvariousmachinelearning
domains, including natural language processing (NLP). However, previous NLP studies have predominantly
addressed the associated UQ challenges similarly to classification or regression methodologies (Desai &
Durrett, 2020; Jiang et al., 2021; Kamath et al., 2020; Wang et al., 2022; Xiong et al., 2023). For instance,
Kamath et al. (2020) examines the selective question-answering task as a multiple-choice problem, reducing
it to a de facto classification task rather than directly engaging with free-form generation. As recently argued
in Kuhn et al. (2023), such approaches enable the application of UQ measures akin to those employed in
more extensively researched classification or regression contexts, but overlook the generative aspects and
distinct challenges of NLG.
Recently, some research started to study uncertainty quantification for NLG. One line of research involves
asking the LLM itself for its confidence, with or without additional fine-tuning (Kadavath et al., 2022; Lin
et al., 2022a; Mielke et al., 2020; Chen & Mueller, 2023). Apart from being expensive, such approaches can
be hard to generalize due to opaque training details or differences between LLMs (Kuhn et al., 2023). The
work most relevant to ours is Kuhn et al. (2023), which proposes to compute the “semantic entropy” by
2

--- PAGE 3 ---
Published in Transactions on Machine Learning Research (05/2024)
considering the equivalence relationships amongst generated answers, and requires no training. Nonetheless,
it still requires access to the token-level numerical output of the LLM, which is not always available.
As discussed, one of the most pertinent applications of uncertainty quantification in NLG involves the de-
velopment of methods for selective NLG (or, NLG with rejection). This emerging field has limited research
to date, but shares close ties with classification with rejection . Both tasks can be viewed as determining
when to trust a model, whether it is a classifier or an LLM. Numerous classification with rejection methods
emphasize the identification of a reliable confidence score (some of which are jointly trained with the classi-
fier) (Corbière et al., 2019; Fumera et al., 2000; Geifman & El-Yaniv, 2017; Jiang et al., 2018), which is often
not only dependent on the input but also on the prediction. As existing uncertainty quantification research
for NLG primarily focuses on input uncertainty (Kuhn et al., 2023; Malinin & Gales, 2021), it overlooks the
crucial aspect of confidence, which is essential in deciding when to trust an LLM’s response (see Section 3.2
for more discussion). Recent works have explored selective classification in NLP tasks (Varshney et al.,
2022a;b). However, the distinct generative nature of NLG precludes the direct adaptation of confidence
measures from the classification with rejection literature. This paper serves as a step to bridge this gap and
enhance the effectiveness of uncertainty quantification in NLG.
It is worth noting that the issue of LLMs being overconfident (Mielke et al., 2022; Si et al., 2022; Xiong
et al., 2023) is orthogonal to our work, as we evaluate measures basing how they rankdifferent samples -
such measures may then be calibrated by distribution-free uncertainty quantification methods like in Schus-
ter et al. (2022)2. Giulianelli et al. (2023) also provides an interesting exploration of the inherent uncertainty
in human responses for many NLG tasks, in a black-box manner. Finally, carefully designed prompts have
been proposed to improve the quality of the generated responses in general (Zhou et al., 2023; Si et al.,
2023; Wei et al., 2022). Orthogonal to UQ but related to selective NLG, Varshney & Baral (2023) focuses on
reattempting rejected samples, with the help of an auxiliary model trained on an additional dataset that pre-
dicts the correctness of the generation. This paper focuses on providing quantitative uncertainty/confidence
measures, which can be used to identify high-quality generations.
3 Background
In this section, we describe the specific type of uncertainty under examination in the context of Natural
Language Generation (NLG), while introducing terminologies used in the rest of the paper.
3.1 Predictive Uncertainty in NLG
Predictiveuncertaintyisaprevalentsubjectinprobabilisticmodeling, especiallyBayesianliterature(Malinin
& Gales, 2018; Gal & Ghahramani, 2016). It quantifies the degree of dispersion in the predicted distribution
ofY, conditioned on the input X=x. As it is generally a characteristic of the predicted distribution , we
denote it as U(x), dependent only on x. For example, when Y|X=xadheres to a Gaussian distribution,
the variance serves as an indicator of the uncertainty.
NLG can be viewed as a classification problem characterized by an exceedingly high dimension. In classifica-
tion, the uncertainty is frequently measured by the entropy of the prediction (e.g. Abdar et al. (2021b); Kuhn
et al. (2023); Sun et al. (2019); Wellmann & Regenauer-Lieb (2012)). The predictive entropy is formally
defined asH(Y|x) =−/integraltext
p(y|x) log (p(y|x))dy, which becomes the following uncertainty score in NLG:
U(x) =H(S|x) =−/summationdisplay
sp(s|x) log (p(s|x)). (1)
Here,xrepresents the input, and the summation is taken over all potential sequences (responses).
Predictive uncertainty is occasionally characterized as total uncertainty, encompassing both epistemic and
aleatoric uncertainty. Epistemic uncertainty (model uncertainty) can potentially be reduced with additional
information, such as the use of a better model and/or additional training data (Hüllermeier & Waegeman,
2See Appendix for results on calibrated confidence measures.
3

--- PAGE 4 ---
Published in Transactions on Machine Learning Research (05/2024)
2021; Lahlou et al., 2023). For example, an enhanced LLM trained on more math problems could po-
tentially generate better proofs with lower epistemic uncertainty. In contrast, aleatoric uncertainty (data
uncertainty) pertains to the irreducible component of uncertainty inherently associated with the data gener-
ation process (Senge et al., 2014). In a sense, this is related to the “open-endedness” in NLG. For instance,
for the question “when did the Philadelphia Eagles win their latest Super Bowl” (as of 2023), the answer
could be either 2017 or 2018, as the game took place in February 2018 but belongs to the 2017 season.
Some questions ( x) intrinsically allow for markedly different answers ( s). Decomposing aleatoric vs epis-
temic uncertainty is, however, often complex and typically not required for learning algorithms in real-world
predictive applications (Hüllermeier & Waegeman, 2021).
Like most existing literature, we focus on quantifying the total uncertainty3. We would like to emphasize
again that like Kuhn et al. (2023), we adopt QA datasets due to the simplicity of evaluation. Methods
proposed in this paper could still potentially be applied to more open-ended tasks with no reference answers,
but the question then becomes: First, can we evaluate the quality of the UQ in a scalable fashion, given
that extensive human evaluation might be necessitated? Second, how do we formulate the task and what
does uncertainty entail in practice, when the questions are intrinsically open-ended? These are interesting
but arguably much harder and less well-defined questions that could be explored in future work.
3.2 Uncertainty vs. Confidence
Uncertainty and confidence are sometimes deemed antonyms. However, confidence scores typically bear
a slightly different meaning, especially outside the Bayesian literature. Specifically, while U, as discussed
in Section 3.1, only depends on xand is a property of the predicted distribution , the confidence scores are
generally associated with both the input and the prediction and can be expressed as C(x,y)(Chow, 1970;
Corbière et al., 2019; Jiang et al., 2018; Lin et al., 2022b). As a concrete example, for P(Y|x) =N(µ,σ2),
the variance σ2is an uncertainty measure. For a particular prediction Y=y, the negative z-score −|y−µ|
σ
could be a confidence measure. Notice the use of a lower-case yin the notation, instead of a upper-case
Ythat represents a random variable. In the context of classification, one of the simplest and most used
confidence measures is just the predicted probability ˆp(Y=y|x)(Geifman & El-Yaniv, 2017; Hendrycks &
Gimpel, 2017). The corresponding confidence score in NLG is the joint probability:
C(x,s) = ˆp(s|x) =/productdisplay
iˆp(si|s<i,x). (2)
Obviously, Eq. (2) requires access to the original LLM4. In Section 4, we will elaborate some alternatives
that do not require such white-box access.
Existing literature sometimes uses uncertainty estimate U(x)to predict the correctness of a particular
response s(Kuhn et al., 2023; Malinin & Gales, 2021), ignoring the distinction between uncertainty and
confidence. Section 5 shows that this is problematic, and confidence is a more reliable indicator of the
correctness of a given response.
4 Quantifying the Uncertainty for NLG
In this section, we discuss several uncertainty quantification methods that can be applied to black-box LLMs.
Some of these methods are sourced from the existing literature, while the majority are simple proposals of
our own. The discussed methods can be structured as taking the following steps:
1. For a given input x, generatemresponse samples s1,..., sm.
2. Calculate the pairwise similarity scores a(sj1,sj2)for thesemresponses.
3. Compute an uncertainty estimate U(x)or a confidence score C(x,sj)using the similarity values.
3In fact, when the level of “open-endedness” of an input distribution is similar, the ranking of total uncertainty should still be
indicative of that of the epistemic uncertainty.
4Here, we assume a auto-regressive LLM. For other models, computing such a quantify might require a different approach, if
possible.
4

--- PAGE 5 ---
Published in Transactions on Machine Learning Research (05/2024)
4.1 Measuring Response Similarities
We mainly focus on two ways to compare the similarity between a pair of responses.
Jaccard Similarity : The Jaccard similarity is a widely employed metric for determining the similarity
between two sets. It is calculated by dividing the cardinality of the intersection of the two sets by the
cardinality of their union. A rule-based metric that is easy to implement, the Jaccard index has been
extensively utilized in Natural Language Processing (NLP) tasks (Cronin et al., 2017; Pilehvar et al., 2013;
Qurashi et al., 2020), where sentences or documents are treated as sets of words. Specifically, the Jaccard
similarity between two responses sj1andsj2(considered as sets of words) where j1,j2∈[m]is computed as:
aJaccard (sj1,sj2) =|sj1∩sj2|/|sj1∪sj2|∈[0,1]. (3)
Despite the computation efficiency, Jaccard similarity has certain limitations, including the lack of consid-
eration for word order and the inability to capture crucial expressions such as negation.
Natural Language Inference (NLI) : As noted above, rule-based similarity may not effectively capture
the nuances present in generated responses. A potential alternative approach involves utilizing a Natural
Language Inference (NLI) classifier for this task. Numerous NLI datasets are available for training such
classifiers (Williams et al., 2018; Bowman et al., 2015; Poliak, 2020). In Section 5, we will adopt the
methodology outlined by Kuhn et al. (2023) and employ an off-the-shelf DeBERTa-large model (He et al.,
2021) as the classifier. A NLI classifier typically predicts scores (logits) for three distinct classes: entailment,
neutral, andcontradiction. Wecanusethepredictedprobabilitiesasthesimilarity, denotedas aNLI(sj1,sj2).
To obtain a continuous value ranging from 0 to 1, we apply the softmax function to the predicted logits,
resulting in ˆpcontra (sj1,sj2)andˆpentail (sj1,sj2)(both depend on x). We then define the following:
aNLI,entail (sj1,sj2) = ˆpentail (sj1,sj2)aNLI,contra (sj1,sj2) = 1−ˆpcontra (sj1,sj2).(4)
It should be emphasized that obtaining ˆpentailand ˆpcontrais not in conflict with our primary objective of
quantifying the uncertainty of a black-box LLM, for two key reasons. Firstly, the NLI model can be (and is)
substantially smaller than the LLM, because NLI is a considerably simpler task, and the NLI model is not
required to have the same “knowledge” as the LLM. Secondly, the LLM’s function in NLG is to generate
responses (sequences of tokens); thus, any additional information, such as token-level logits or embeddings,
is not part of the standard output and may not be accessible to users. In contrast, the NLI model’s outputs
arethe probabilities we utilize.
4.2 Estimating Uncertainty and Confidence from Similarities
In this section, we aim to convert similarities from Section 4.1 into uncertainty/confidence measures.
Number of Semantic Sets was first proposed in Kuhn et al. (2023). The original paper proposed to use
a NLI classifier to group responses into several “semantic equivalence” subsets (which form a partition of
all responses). They use such “semantic equivalence” classes as well as the numerical output of the base
LLM to compute the “semantic entropy”5. While such a method cannot be applied to a black-box LLM, in
their experiments they also used the numberof “semantic sets” (equivalence classes), which is an uncertainty
measure applicable to black-box LLMs6. We denote this uncertainty measure as UNumSet7. For example, for
the question “What city was Zeus the patron god of?”, the three responses “Olympia”, “Zeus was the patron
god of Olympia, Greece”, and “Corinth” form two semantic sets (with the first two responses in one set).
Intuitively, if in the mresponses, the LLM generates more semantically different answers, then the total
uncertainty is high.
5This is an improved version of Eq. (1), where/summationtext
sis replaced with/summationtext
cwherecdenotes a semantic concept instead of a
response.p(s|x)is replaced with p(c|x) =/summationtext
s∈cp(c|x)correspondingly.
6https://github.com/lorenzkuhn/semantic_uncertainty
7We follow the bi-directional entailment algorithm in Kuhn et al. (2023) to construct such semantic sets using aNLI,entail and
aNLI,contra and assuming transitivity of semantic equivalence. Specifically, we iterate over j1< j 2, and merge sj2into the
same semantic set of sj1ifˆpentail (sj1,sj2)>ˆpcontra (sj1,sj2)andˆpentail (sj2,sj1)>ˆpcontra (sj2,sj1).
5

--- PAGE 6 ---
Published in Transactions on Machine Learning Research (05/2024)
SumofEigenvaluesoftheGraphLaplacian Inreality, whethertworesponsessharethesamemeaningis
not black-and-white. In the example of Zeus above, potential responses “Olympia” and “Greece” are neither
exactly the same nor completely different. Moreover, there is no guarantee that the semantic equivalence
judged by the NLI model (or any other measure) is transitive. As a result, a more nuanced and “continuous”
way to measure the number of meanings is preferable.
Since we only know the pairwise similarities aj1,j2between response sj1andsj2, but not the embeddings of
the generated responses, a natural choice for the clustering responses is spectral clustering. Fixing an input
x, we first treat each generated response as one node and define the symmetric weighted adjacency matrix
asW= (wj1,j2)j1,j2=1,...,mwherewj1,j2= (aj1,j2+aj2,j1)/2. The symmetric normalized graph Laplacian is
then given by
L:=I−D−1
2WD−1
2 (5)
Dj1,j2=/braceleftigg/summationtext
j′∈[m]wj1,j′(j1=j2)
0 ( j1̸=j2)(6)
A continuous version of UNumSetcould be defined with λ1<···<λm, the eigenvalues of L:
UEigV=m/summationdisplay
k=1max(0,1−λk). (7)
To see the connection, between UEigVandUNumSet, we recall the classical theorem:
Theorem 1. (Von Luxburg, 2007) The multiplicity of the eigenvalue 0ofLis equal to the number of
connected components in the graph represented by W.
In other words, with a binary W(two responses are either connected or not at all), the multiplicity of the
zero eigenvalue coincides with the number of semantic sets ( UNumSet). With a weighted Wwhose entries are
continuous, thereistypicallyonlyoneconnectedcomponent. However, inspectralclustering, thedistribution
of the eigenvalues is typically used to determine the number of clusters (Von Luxburg, 2007)8. An illustration
is provided in Fig. 1, with UEigVroughly corresponding to the “number of semantic meanings”. In Eq. (7)
we ignore eigenvalues larger than 1 as only the smallest few eigenvalues carry important information about
the clusters (Von Luxburg, 2007).
2 4 6 8 10
k-th eigenvalue0.00.51.0
UeigV=2.139
Pink Floyd
Pink Floyd in Edinburgh
Pink Floyd
Shambles
Pink Floyd
Pink Floyd
Pink Floyd
Pink Floyd
Pink Floyd
Pink Floyd
2 4 6 8 10
k-th eigenvalue0.00.51.0
UeigV=5.984Leukemia
Low Blood Pressure
Cervical cancer
Cancer in 1953 at 41
Breast cancer
Tuberculosis
Cancer
Leukaemia
Cancer (in 1953 at age 41)
Throat cancer
Figure 1: The distribution of the eigenvalues of the graph Laplacian generated by aNLI,entail , for two
questions from trivia, as well as the 10 generated responses. On the left, the question and reference answer
are “Q: Dave Gilmore and Roger Waters were in which rock group? A: Pink Floyd”. We have somewhere
between two and three meanings, and UEigVis slightly above 2. The question on the right is “Q: What
claimed the life of singer Kathleen Ferrier? A: Cancer”, and we observe more diverse responses. As a result,
we see a higher UEigV(almost 6).
The Degree Matrix The previous two methods helped us define the uncertainty U(x)but cannot assign
a confidence score to each generated response. We utilize the degree matrix Din Eq. (6) to define both
metrics, as Dalready contains relevant information: A node with high degree is well-connected to other
nodes, suggesting that it lies in a confident region of the LLM. We thus define uncertainty estimate UDeg(x)
8In particular, a “gap” between a small eigenvalue λkto a large one λk+1indicates that there are kclusters.
6

--- PAGE 7 ---
Published in Transactions on Machine Learning Research (05/2024)
and confidence score CDeg(x,sj)as
UDeg(x) =trace (mI−D)/m2CDeg(x,sj) =Dj,j/m. (8)
Here, we assume Wj1,j2∈[0,1].UDegcan also be interpreted as the average pairwise distance.
Eccentricity Recall that one challenge from earlier is that we only have the similarity (or distance) between
different responses, but do not know their actual embedding space. The graph Laplacian, however, can
provide us with coordinates for the responses. Denote u1,..., uk∈Rmas the smallest keigenvectors of L,
then an informative embedding of sjis simply vj= [u1,j,...,uk,j](Ng et al., 2001; Von Luxburg, 2007).
As a result, we could use the average distance from center as the uncertainty measure, and each response’s
distance from the center as the (negative) confidence. Formally, the “eccentricity” estimates are:
UEcc(x) =∥[v′⊤
1,..., v′⊤
m]∥2 CEcc(x,sj) =−∥v′
j∥2 (9)
where v′
j=vj−1
m/summationtextm
j′=1vj′represents the offset from the average embedding. Ren et al. (2023) uses a
similar idea for OOD detection for LLMs, which however requires white-box access to the original language
model. Fig. 2 illustrates a sample embedding (from coqa).
Remark: The confidence scores CEccandCDegin the current form are hardly interpretable. For example,
CEcccould have a value of 10 or 0.4. In practice, they could easily be calibrated to match the probability
of whether the answer is correct. In Appendix C.5 we show that with simple calibration these confidence
scores could faithfully reflect the probability of correct answer.
5 Experiments
Figure 2: An example of the 2D UMAP (McInnes
et al., 2018) projection of the embeddings used in Ecc
for 20 responses. The question and answer are “Q:
What is the bakery’s name? A:the Dominique Ansel
Bakery”. Similar answers tend to live closely together,
justifying the use of distance-based uncertainty and
confidence measures ( UEccandCEcc).In this section, we evaluate the quality of uncer-
tainty and confidence measures proposed in Sec-
tion 4.
5.1 Setup for experiments
Datasets Following Kuhn et al. (2023), we use
the open-book conversational question answering
dataset, CoQA ( coqa) (Reddy et al., 2019), and the
closed-book QA dataset, TriviaQA ( trivia) (Joshi
et al., 2017). In addition, we also use the more chal-
lenging closed-book QA dataset, Natural Questions
(nq) (Kwiatkowski et al., 2019). We use the devel-
opment split of coqawith 7,983 questions, the vali-
dation split of nqwith 3,610 questions, and the val-
idation split of the rc.nocontext subset of trivia
with 9,960 (de-duplicated) questions. We repeat
all experiments 10 times, each time with a random
subset of 1,000 questions as the calibration set for
hyper-parametersof UandCmeasures, andtestthe
performance on the remaining data. We report the mean and standard deviation of all evaluation metrics
(see Section 5.2).
LLMsWe followed Kuhn et al. (2023) and include OPT (Zhang et al., 2022) in our experiments. We also test
three more recent models that have demonstrated superior performance: LLaMA (Touvron et al., 2023a),
LLaMA2 (Touvron et al., 2023b) and the black-box gpt-3.5-turbo served by OpenAI via an API9. For
both LLaMA and OPT, we use the 13B versions. We use the default generation configs for all models.
Baselines We compare all uncertainty and confidence measures listed in Section 4, including NumSet,Deg,
EccandEigV.Deg,EccandEigVare constructed with three versions using aJaccard,aNLI,entail ,aNLI,contra
9Allgpt-3.5-turbo used in this paper are the 0301version.
7

--- PAGE 8 ---
Published in Transactions on Machine Learning Research (05/2024)
(with suffix J/E/C, respectively). We also include “lexical similarity” ( ULexiSim) from Kuhn et al. (2023)
which measures the average rougeL between responses. Note that only UNumSetandULexiSimhave appeared in
literature before (Kuhn et al., 2023). To benchmark these methods with the existing literature, we include
twowhite-box baselines for non-GPT LLMs:
•Semantic Entropy ( SE) (Kuhn et al., 2023): This uncertainty estimate ( USE) groups answers like NumSet,
and then computes the entropy over the aggregated semantic sets. This requires access to the token-level
logits from the base LLM.
•P(true) (Kadavath et al., 2022): This confidence measure CP(true)estimates the probability that a
model’s generation is correct by asking the model itself10. We follow the prompts provided in Kuhn et al.
(2023); Kadavath et al. (2022), and convert CP(true)to an uncertainty estimate UP(true)by taking the
average over all responses.
5.2 Evaluation
Evaluation Metrics : Effective uncertainty measures must reflect the reliability of LLM responses, with
higher uncertainty and lower confidence more likely leading to incorrect generations. Following prior
works (Kuhn et al., 2023; Band et al., 2022), we evaluate the quality of the proposed UQ measures by using
them to predict whether a generation is correct or not, and compute the Area Under Receiver Operating
Characteristic( AUROC )forsuchprediction. Specifically, ifwedenote acci,j= 1{si,jcorrectly answers xi},
we compute average AUROC using C(x·,s·,j)to predictacc·,jforj∈[m]. Unless otherwise noted, m= 20.
AUROC however bears two limitations: it can only be applied on binary labels, and its value is hard to
interpret. Thus, we use Area Under Accuracy-Rejection Curve ( AUARC ) (Nadeem et al., 2009), as an
alternative evaluation metric11. Illustrated in Fig. 3, Accuracy-Rejection Curve (ARC) is computed as the
averagetarget(i.e. accuracy) when we reject a subset of the samples basing on predictor (i.e.UorC). As
we reject more high-uncertainty samples, the remaining samples should have higher accuracy. The “Oracle”
(max) AUARC is achieved by directly using the targetas thepredictor , while the AUARC of a random
predictor equals to the base accuracy without rejection.
Correctness of Generations : We assess the correctness of the generated responses automatically using
gpt-3.5-turbo from the OpenAI API. This model is provided with the question, reference answer, and
LLM-generated response, and it assigns a correctness score between 0 and 1. Responses with scores above
0.7 are deemed correct. Like Kuhn et al. (2023) (which used rougeL score as a heuristic to evaluate the
correctness of generated responses), we also perform human verification on the correctness of the auto-
generated judgment by gpt-3.5-turbo and found that the accuracy is about 0.95 (see the Appendix for
more details).
5.3 Results
Uncertainty Measures : We first evaluate the uncertainty measures by using them as the predictor to
predictexpected accuracy (shorthanded as U+EA), estimated with ˆE[acci] =1
m/summationtextm
j=1acci,j(m=20). The
AUARCs are shown in Table 1 (AUROC is skipped as expected accuracy is not binary). For readability, we
include only aNLI,entail which empirically performs the best, with full experiment results in the Appendix.
We hypothesize that aNLI,entail outperforms aNLI,contra because even if generations do not contradict each
other, they could be still mostly meaningless, whereas generations that actually align could indicate low
uncertainty. A such example could be found in Fig. 5 (see more discussion in Appendix B.6). Deg,Ecc, and
EigVperform similarly as an uncertainty measure. In some cases, such as trivia(llama) , the AUARC (for
Deg) is close to the upper-bound (Oracle). In general, we found that the choice of similarity (E-entailment,
C-contra, J-Jaccard) matters more than the choice of Deg,Ecc,EigV.
10Note that P(true) may not require white-box access if one is willing to sample a lot of responses from the LLM, which is
however computationally expensive.
11While originally AUARC was defined with a binary accuracy label, one could generalize it to any continuous label, such as
the expected accuracy (using a Monte Carlo estimate).
8

--- PAGE 9 ---
Published in Transactions on Machine Learning Research (05/2024)
0.0 0.2 0.4 0.6 0.8 1.0
False Positive Rate0.00.20.40.60.81.0True Positive RateROC
0.0 0.2 0.4 0.6 0.8 1.0
Rejection Rate0.60.70.80.91.0Average AccuracyARC
NumSet
EigV(E)
Ecc(E)
Deg(E)
SE
P(true)
Oracle
Base Accuracy
Figure 3: The ROC (left) computed using the accuracy of the 1st generated response and the corresponding
confidenceC(when available, otherwise U), for LLaMA on trivia. ARC (right) is computed using Uand
expected accuracy. (For ARC, average accuracy is noisy at high rejection rate due to small sample size.)
The suffix (E) denotes for aNLI,entail . Different ways to construct UorCfromaNLI,entail make a relatively
small difference, but are all noticeably better than the baselines (including the white-box baselines). The
ARC suggests that if we select only the top 50% samples using, for example, Deg(E), we could improve the
accuracy from 62% to around 90%.
1 3 5 10 20
Number of Generations (m)0.600.650.700.750.800.850.90AUARC (Confidence)
1 3 5 10 20
Number of Generations (m)0.600.650.700.750.800.850.90AUARC (Uncertainty)Base Accuracy
Deg(E)
Ecc(E)
EigV(E)
NumSet
P(true)
SE
Figure 4: AUARC for confidence (left) and uncertainty (right), with different number of sampled responses.
A smallmlike 3 already greatly improves the accuracy in selective generation, compared with no rejection
or rejection based on random noise (Base Accuracy). In general, confidence-based measures ( DegandEcc)
achieve better performance in the C+IA setting, confirming the intuition that response-dependent confidence
measures predict the quality of individual responses better.
Confidence Measures : To evaluate confidence measures, we compute AUROC and AUARC, and take
the average across all mgenerations. We refer to this as the "C+IA" (C onfidence + I ndividual A ccuracy)
setting. The results are reported in Table 2 (with AUROCs deferred to the Appendix). Note that Eccand
Degare actual confidence measures and EigVis an uncertainty measure (not response-specific). As a result,
able to further distinguish the quality of each response, Degand Ecctypically observe higher performance
in Table 2 compared with Table 1, while the uncertainty-only measures like EigVstay the same, echoing the
discussion in Section 3.2.
VaryingtheNumberofGenerations : InFig.4,wereportresultswhenwevarythenumberofgenerations
m, for triviaand LLaMA. It is observed that even with m= 3, the confidence or uncertainty measures
already achieve good performance. As mincreases, the quality of CandUtypically increases. Note that
for AUARC(C+IA), only the confidence measure ( CDegandCEcc) improves, and the other measures, being
response-agnostic uncertainty measures, stay the same. NumSetseemingly deteriorates as mincreases in this
plot, because it seems to predict the quality of the first few responses (for LLaMA+ triviaonly) better. As
a result, as we take the average of more samples, the higher performance flattens out. The trend is different
for other settings, and is flat in general when considering all data and LLMs. A full presentation of the
results varying the number of generations could be found in Appendix C.1. In practice, one could choose
the quality-computation trade-off by picking a number of generations that is appropriate.
9

--- PAGE 10 ---
Published in Transactions on Machine Learning Research (05/2024)
Q: why was the plague that struck athens so devastating
A: close quarters and poor hygiene
10 Generations:
There’s no cure
a large flock of birds
because the plague was unknown at the time
The plague was devastating then because the diseases were unknown and a mystery to the \
ancient world and the there where numerous diseases spread
it was so short and caused so much quaratic
Athens was located within a part of Greece that was full of fleas
The plague of Athens was a pandemic that hit the Greek city of Athens and surrounding \
areas in 429-428 BC
Soldiers returning from battle
because they were
because it happened just as farming season began
Figure 5: An example where contradiction-based UEigVindicates low uncertainty, yet the generated responses
are mostly low-quality. Entailment-based similarity suggests high uncertainty.
Table 1: AUARC when using U(x)to predict expected accuracy. The best black-box methods are in bold
and the best overall is underscored . In general, our proposed uncertainty measures perform significantly
better than the baselines, sometimes outperforming the white-box methods.
trivia(llama) trivia(llama2) trivia(opt) trivia(gpt) coqa(llama) coqa(llama2) coqa(opt) coqa(gpt) nq(llama) nq(llama2) nq(opt) nq(gpt)
Random 61.18±0.07 76.24 ±0.11 25.75 ±0.12 87.42 ±0.0862.46±0.11 78.71 ±0.13 53.81 ±0.18 79.76 ±0.1423.63±0.36 44.13 ±0.68 8.60 ±0.18 62.72 ±0.39
Oracle 87.03±0.05 96.50 ±0.03 54.72 ±0.19 99.09 ±0.0186.29±0.06 96.92 ±0.03 79.41 ±0.14 97.45 ±0.0347.67±0.55 77.62 ±0.63 23.28 ±0.43 90.65 ±0.21
BaselinesNumSet 78.78±0.17 91.37 ±0.12 39.46 ±0.29 93.18 ±0.1167.58±0.17 83.66 ±0.17 60.41 ±0.27 80.69 ±0.2228.18±0.55 57.55 ±0.98 10.36 ±0.27 68.92 ±0.74
LexiSim 80.32±0.06 91.73 ±0.13 45.68 ±0.24 94.69 ±0.1578.17±0.15 89.29 ±0.16 71.46 ±0.21 86.60 ±0.1340.15±0.70 61.88 ±1.14 15.92 ±0.55 73.40 ±0.74
OursEigV(E)85.01±0.08 93.07±0.1751.54±0.21 95.16±0.2181.27±0.12 90.21±0.2473.46±0.20 88.80±0.10 40.42±0.67 63.58±0.9618.20±0.44 75.17±0.80
Ecc(E)84.66±0.06 93.12±0.1251.42±0.22 95.21±0.2280.55±0.14 90.02±0.2272.73±0.20 88.67 ±0.1340.38±0.68 63.41±0.92 18.82±0.46 75.40±0.49
Deg(E)85.27±0.06 93.05±0.14 52.06 ±0.21 95.00±0.23 81.50±0.15 90.18±0.22 73.91±0.1988.63±0.23 41.07±0.69 63.41±1.03 18.43±0.4874.35±0.78
White-boxSE79.15±0.08 93.99 ±0.0651.11±0.20 – 78.83±0.16 89.29 ±0.17 70.75 ±0.21 – 36.03±0.54 62.40 ±0.98 18.40 ±0.44 –
P(true) 64.98±0.10 82.53 ±0.09 20.25 ±0.11 – 64.04±0.18 79.92 ±0.17 50.23 ±0.23 – 24.72±0.42 44.25 ±0.65 7.63 ±0.22 –
Table 2: AUARC when using C(x,s)to predict individual accuracy. The best black-box methods are in
boldand the best overall is underscored . Compared with Table 1, the AUARC for confidence measures ( Deg
andEcc) generally improve, as they could discriminate the quality of each response.
trivia(llama) trivia(llama2) trivia(opt) trivia(gpt) coqa(llama) coqa(llama2) coqa(opt) coqa(gpt) nq(llama) nq(llama2) nq(opt) nq(gpt)
Random 61.18±0.07 76.24 ±0.11 25.75 ±0.12 87.42 ±0.0862.46±0.11 78.71 ±0.13 53.81 ±0.18 79.76 ±0.1423.63±0.36 44.13 ±0.68 8.60 ±0.18 62.72 ±0.39
Oracle 91.24±0.03 96.92 ±0.03 60.68 ±0.16 99.17 ±0.0191.85±0.05 97.55 ±0.03 87.15 ±0.11 97.80 ±0.0357.69±0.53 80.22 ±0.56 29.65 ±0.45 91.97 ±0.18
BaselinesNumSet 78.78±0.17 91.37 ±0.12 39.46 ±0.29 93.18 ±0.1167.58±0.17 83.66 ±0.17 60.41 ±0.27 80.69 ±0.2228.18±0.55 57.55 ±0.98 10.36 ±0.27 68.92 ±0.74
LexiSim 80.32±0.06 91.73 ±0.13 45.68 ±0.24 94.69 ±0.1578.17±0.15 89.29 ±0.16 71.46 ±0.21 86.60 ±0.1340.15±0.70 61.88 ±1.14 15.92 ±0.55 73.40 ±0.74
OursEigV(E)85.01±0.08 93.07 ±0.17 51.54 ±0.21 95.16±0.2181.27±0.12 90.21±0.2473.46±0.20 88.80±0.1040.42±0.67 63.58±0.9618.20±0.44 75.17±0.80
Ecc(E)88.17±0.11 93.21±0.0755.82±0.21 95.11±0.18 84.62±0.13 90.21±0.25 78.14±0.2088.42±0.1945.78±0.69 63.89±1.08 21.00±0.49 75.43±0.67
Deg(E)88.86±0.05 93.19±0.11 56.11 ±0.1994.94±0.16 84.60±0.1589.75±0.19 77.83 ±0.20 88.02 ±0.31 46.54±0.69 63.55±1.01 21.30±0.5074.67±0.64
White-boxSE79.15±0.08 93.99 ±0.0651.11±0.20 – 78.83±0.16 89.29 ±0.17 70.75 ±0.21 – 36.03±0.54 62.40 ±0.98 18.40 ±0.44 –
P(true) 67.27±0.11 82.18 ±0.08 20.89 ±0.12 – 66.23±0.19 79.55 ±0.16 49.84 ±0.23 – 27.62±0.46 44.34 ±0.64 8.07 ±0.21 –
6 Conclusion and Discussion
In this paper, we studied the problem of uncertainty quantification in black-box LLMs, with an emphasis
on assessing the quality of generated responses to a diverse set of questions. We developed and tested a
range of easily implementable uncertainty and confidence measures. Our results demonstrated that using
similarityasdeterminedbyanNLImodel, alongwithsimplemeasuresthatmeasuredispersionbasedonthese
similarities, can effectively identify difficult questions and confident answers, often outperforming existing
white-box benchmarks. The objective of this paper is to provide practitioners with simple and effective
methods to manage uncertainty, reduce incorrect answers (possibly by excluding them), and apply LLMs
with confidence.
To conclude, we also note some limitations of our work and challenges remaining to be addressed. Currently,
the evaluation of uncertainty/confidence measures is restricted to question-answering tasks, because it is
10

--- PAGE 11 ---
Published in Transactions on Machine Learning Research (05/2024)
generally difficult to acquire labels on whether a response is “reliable” or not for open-ended conversations.
Even for the datasets used in our paper, while our use of GPT as the judge improves upon previous heuristics
(of using rougeL), the evaluation can be improved if human labels are used. Moreover, we currently evaluate
uncertainty and confidence separately. Methods that consider both have the potential to predict the quality
of generations better. Finally, the uncertainty and confidence measures in this work (and those mentioned
in Section 2) reflect those in the “posterior” represented by the LLM. This has two implications: When the
sampling temperature is 0 (i.e. greedy decoding), all methods will give degenerate results, and one might
resort to white-box methods or external information to quantify the uncertainty. Also, our methods may not
identify factual errors propagated from the training corpus or identify when the LLM is being overconfident
(which is related to calibration , an orthogonal research topic). We hope this work could serve as a foundation
for future research in these directions.
Acknowledgements
This work was supported by NSF award SCH-2205289, SCH-2014438, IIS-1838042, NIH award R01
1R01NS107291-01.
References
Moloud Abdar, Farhad Pourpanah, Sadiq Hussain, Dana Rezazadegan, Li Liu, Mohammad Ghavamzadeh,
Paul Fieguth, Xiaochun Cao, Abbas Khosravi, U. Rajendra Acharya, Vladimir Makarenkov, and Saeid Na-
havandi. A review of uncertainty quantification in deep learning: Techniques, applications and challenges.
Information Fusion ,76:243–297,2021a. ISSN1566-2535. doi: https://doi.org/10.1016/j.inffus.2021.05.008.
URL https://www.sciencedirect.com/science/article/pii/S1566253521001081 .
Moloud Abdar, Farhad Pourpanah, Sadiq Hussain, Dana Rezazadegan, Li Liu, Mohammad Ghavamzadeh,
Paul Fieguth, Xiaochun Cao, Abbas Khosravi, U Rajendra Acharya, et al. A review of uncertainty
quantification in deep learning: Techniques, applications and challenges. Information Fusion , 76:243–297,
2021b.
Neil Band, Tim G. J. Rudner, Qixuan Feng, Angelos Filos, Zachary Nado, Michael W. Dusenberry, Ghassen
Jerfel, DustinTran, andYarinGal. Benchmarkingbayesiandeeplearningondiabeticretinopathydetection
tasks.ArXiv, abs/2211.12717, 2022. URL https://api.semanticscholar.org/CorpusID:244906451 .
Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. A large annotated cor-
pus for learning natural language inference. In Proceedings of the 2015 Conference on Empirical Methods
in Natural Language Processing , pp. 632–642, Lisbon, Portugal, September 2015. Association for Compu-
tational Linguistics. doi: 10.18653/v1/D15-1075. URL https://aclanthology.org/D15-1075 .
Jiuhai Chen and Jonas Mueller. Quantifying uncertainty in answers from any language model via intrinsic
and extrinsic confidence assessment. arXiv preprint arXiv:2308.16175 , 2023.
C. K. Chow. On Optimum Recognition Error and Reject Tradeoff. IEEE Transactions on Information
Theory, 1970. ISSN 15579654. doi: 10.1109/TIT.1970.1054406.
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts,
Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi,
Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar
Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael
Isard, GuyGur-Ari, PengchengYin, TojuDuke, AnselmLevskaya, SanjayGhemawat, SunipaDev, Henryk
Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito,
David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani
Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor
Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang,
Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas
Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. Palm: Scaling language modeling with pathways, 2022.
11

--- PAGE 12 ---
Published in Transactions on Machine Learning Research (05/2024)
Charles Corbière, Nicolas THOME, Avner Bar-Hen, Matthieu Cord, and Patrick Pérez. Address-
ing failure prediction by learning model confidence. In H. Wallach, H. Larochelle, A. Beygelzimer,
F. d 'Alché-Buc, E. Fox, and R. Garnett (eds.), Advances in Neural Information Processing Systems ,
volume 32. Curran Associates, Inc., 2019. URL https://proceedings.neurips.cc/paper/2019/file/
757f843a169cc678064d9530d12a1881-Paper.pdf .
Robert M Cronin, Daniel Fabbri, Joshua C Denny, S Trent Rosenbloom, and Gretchen Purcell Jackson.
A comparison of rule-based and machine learning approaches for classifying patient portal messages.
International journal of medical informatics , 105:110–120, 2017.
Shrey Desai and Greg Durrett. Calibration of pre-trained transformers. In Proceedings of the 2020 Confer-
ence on Empirical Methods in Natural Language Processing (EMNLP) , pp. 295–302, Online, Novem-
ber 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.21. URL
https://aclanthology.org/2020.emnlp-main.21 .
Giorgio Fumera, Fabio Roli, and Giorgio Giacinto. Reject option with multiple thresholds. Pattern Recog-
nition, 2000. ISSN 00313203. doi: 10.1016/S0031-3203(00)00059-5.
Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing model uncertainty
in deep learning. In Maria Florina Balcan and Kilian Q. Weinberger (eds.), Proceedings of The 33rd
International Conference on Machine Learning , volume 48 of Proceedings of Machine Learning Research ,
pp. 1050–1059, New York, New York, USA, 20–22 Jun 2016. PMLR. URL https://proceedings.mlr.
press/v48/gal16.html .
Yonatan Geifman and Ran El-Yaniv. Selective classification for deep neural networks. In Advances in Neural
Information Processing Systems , 2017.
Mario Giulianelli, Joris Baan, Wilker Aziz, Raquel Fernández, and Barbara Plank. What comes next?
evaluating uncertainty in neural text generators against human production variability, 2023.
Pengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen. Deberta: Decoding-enhanced bert with
disentangled attention. In International Conference on Learning Representations , 2021. URL https:
//openreview.net/forum?id=XPZIaotutsD .
Dan Hendrycks and Kevin Gimpel. A baseline for detecting misclassified and out-of-distribution examples
in neural networks. In International Conference on Learning Representations , 2017. URL https://
openreview.net/forum?id=Hkg4TI9xl .
José Miguel Hernández-Lobato and Ryan P. Adams. Probabilistic backpropagation for scalable learn-
ing of bayesian neural networks. In Francis R. Bach and David M. Blei (eds.), Proceedings of the
32nd International Conference on Machine Learning, ICML 2015, Lille, France, 6-11 July 2015 , vol-
ume 37 of JMLR Workshop and Conference Proceedings , pp. 1861–1869. JMLR.org, 2015. URL http:
//proceedings.mlr.press/v37/hernandez-lobatoc15.html .
Eyke Hüllermeier and Willem Waegeman. Aleatoric and epistemic uncertainty in machine learning: An
introduction to concepts and methods. Machine Learning , 110:457–506, 2021.
Heinrich Jiang, Been Kim, Maya Gupta, and Melody Y. Guan. To trust or not to trust a classifier. In
Advances in Neural Information Processing Systems , 2018.
Zhengbao Jiang, Jun Araki, Haibo Ding, and Graham Neubig. How can we know when language models
know? on the calibration of language models for question answering. Transactions of the Association for
Computational Linguistics , 9:962–977, 2021. doi: 10.1162/tacl_a_00407. URL https://aclanthology.
org/2021.tacl-1.57 .
MandarJoshi, EunsolChoi, DanielWeld, andLukeZettlemoyer. TriviaQA:Alargescaledistantlysupervised
challenge dataset for reading comprehension. In Proceedings of the 55th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers) , pp. 1601–1611, Vancouver, Canada, July 2017.
Association for Computational Linguistics. doi: 10.18653/v1/P17-1147. URL https://aclanthology.
org/P17-1147 .
12

--- PAGE 13 ---
Published in Transactions on Machine Learning Research (05/2024)
Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas
Schiefer, Zac Hatfield Dodds, Nova DasSarma, Eli Tran-Johnson, et al. Language models (mostly) know
what they know. arXiv preprint arXiv:2207.05221 , 2022.
Amita Kamath, Robin Jia, and Percy Liang. Selective question answering under domain shift. In Proceedings
of the 58th Annual Meeting of the Association for Computational Linguistics , pp. 5684–5696, Online,
July 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.503. URL https:
//aclanthology.org/2020.acl-main.503 .
Daniel Martin Katz, Michael James Bommarito, Shang Gao, and Pablo Arredondo. Gpt-4 passes the bar
exam.Available at SSRN 4389233 , 2023.
Lorenz Kuhn, Yarin Gal, and Sebastian Farquhar. Semantic uncertainty: Linguistic invariances for uncer-
tainty estimation in natural language generation. In The Eleventh International Conference on Learning
Representations , 2023. URL https://openreview.net/forum?id=VD-AYtP0dve .
Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti,
Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew
Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. Natural ques-
tions: A benchmark for question answering research. Transactions of the Association for Computational
Linguistics , 7:452–466, 2019. doi: 10.1162/tacl_a_00276. URL https://aclanthology.org/Q19-1026 .
Salem Lahlou, Moksh Jain, Hadi Nekoei, Victor I Butoi, Paul Bertin, Jarrid Rector-Brooks, Maksym Ko-
rablyov, and Yoshua Bengio. DEUP: Direct epistemic uncertainty prediction. Transactions on Machine
Learning Research , 2023. ISSN 2835-8856. URL https://openreview.net/forum?id=eGLdVRvvfQ .
Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive uncer-
tainty estimation using deep ensembles. In Advances in Neural Information Processing Systems , 2017.
Stephanie C. Lin, Jacob Hilton, and Owain Evans. Teaching models to express their uncertainty in words.
ArXiv, abs/2205.14334, 2022a.
Zhen Lin, Lucas Glass, M Brandon Westover, Cao Xiao, and Jimeng Sun. Scrib: set-classifier with class-
specific risk bounds for blackbox models. In Proceedings of the AAAI Conference on Artificial Intelligence ,
volume 36, pp. 7497–7505, 2022b.
Andrey Malinin and Mark Gales. Predictive uncertainty estimation via prior networks. In S. Bengio,
H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett (eds.), Advances in Neural
Information Processing Systems , volume 31. Curran Associates, Inc., 2018. URL https://proceedings.
neurips.cc/paper_files/paper/2018/file/3ea2db50e62ceefceaf70a9d9a56a6f4-Paper.pdf .
Andrey Malinin and Mark Gales. Uncertainty estimation in autoregressive structured prediction. In In-
ternational Conference on Learning Representations , 2021. URL https://openreview.net/forum?id=
jN5y-zb5Q7m .
L. McInnes, J. Healy, and J. Melville. UMAP: Uniform Manifold Approximation and Projection for Dimen-
sion Reduction. ArXiv e-prints , February 2018.
Sabrina J. Mielke, Arthur Szlam, Y-Lan Boureau, and Emily Dinan. Linguistic calibration through metacog-
nition: aligning dialogue agent responses with expected correctness. CoRR, abs/2012.14983, 2020. URL
https://arxiv.org/abs/2012.14983 .
Sabrina J. Mielke, Arthur Szlam, Emily Dinan, and Y-Lan Boureau. Reducing conversational agents’ over-
confidence through linguistic calibration. Transactions of the Association for Computational Linguistics ,
10:857–872, 2022. doi: 10.1162/tacl_a_00494. URL https://aclanthology.org/2022.tacl-1.50 .
Malik Sajjad Ahmed Nadeem, Jean-Daniel Zucker, and Blaise Hanczar. Accuracy-rejection curves (arcs)
for comparing classification methods with a reject option. In Sašo Džeroski, Pierre Guerts, and Juho
Rousu (eds.), Proceedings of the third International Workshop on Machine Learning in Systems Biology ,
13

--- PAGE 14 ---
Published in Transactions on Machine Learning Research (05/2024)
volume 8 of Proceedings of Machine Learning Research , pp. 65–81, Ljubljana, Slovenia, 05–06 Sep 2009.
PMLR. URL https://proceedings.mlr.press/v8/nadeem10a.html .
Andrew Ng, Michael Jordan, and Yair Weiss. On spectral clustering: Analysis and an algorithm. In
T. Dietterich, S. Becker, and Z. Ghahramani (eds.), Advances in Neural Information Processing Systems ,
volume 14. MIT Press, 2001. URL https://proceedings.neurips.cc/paper_files/paper/2001/file/
801272ee79cfde7fa5960571fee36b9b-Paper.pdf .
Jeremy Nixon, Michael W. Dusenberry, Linchuan Zhang, Ghassen Jerfel, and Dustin Tran. Measuring
calibrationindeeplearning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR) Workshops , June 2019.
OpenAI. Gpt-4 technical report, 2023.
Mohammad Taher Pilehvar, David Jurgens, and Roberto Navigli. Align, disambiguate and walk: A unified
approach for measuring semantic similarity. In Proceedings of the 51st Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers) , pp. 1341–1351, Sofia, Bulgaria, August 2013.
Association for Computational Linguistics. URL https://aclanthology.org/P13-1132 .
Adam Poliak. A survey on recognizing textual entailment as an NLP evaluation. In Proceedings of
the First Workshop on Evaluation and Comparison of NLP Systems , pp. 92–109, Online, November
2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.eval4nlp-1.10. URL https:
//aclanthology.org/2020.eval4nlp-1.10 .
Abdul Wahab Qurashi, Violeta Holmes, and Anju P. Johnson. Document processing: Methods for semantic
text similarity analysis. In 2020 International Conference on INnovations in Intelligent SysTems and
Applications (INISTA) , pp. 1–6, 2020. doi: 10.1109/INISTA49547.2020.9194665.
Siva Reddy, Danqi Chen, and Christopher D. Manning. CoQA: A conversational question answer-
ing challenge. Transactions of the Association for Computational Linguistics , 7:249–266, 2019. doi:
10.1162/tacl_a_00266. URL https://aclanthology.org/Q19-1016 .
Jie Ren, JiamingLuo, Yao Zhao, Kundan Krishna, MohammadSaleh, Balaji Lakshminarayanan, and PeterJ
Liu. Out-of-distribution detection and selective generation for conditional language models. In The
Eleventh International Conference on Learning Representations , 2023. URL https://openreview.net/
forum?id=kJUS5nD0vPB .
Tal Schuster, Adam Fisch, Jai Gupta, Mostafa Dehghani, Dara Bahri, Vinh Q. Tran, Yi Tay, and Donald
Metzler. Confident adaptive language modeling. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave,
and Kyunghyun Cho (eds.), Advances in Neural Information Processing Systems , 2022. URL https:
//openreview.net/forum?id=uLYc4L3C81A .
Robin Senge, Stefan Bösner, Krzysztof Dembczyński, Jörg Haasenritter, Oliver Hirsch, Norbert Donner-
Banzhoff, and Eyke Hüllermeier. Reliable classification: Learning classifiers that distinguish aleatoric and
epistemic uncertainty. Inf. Sci., 255:16–29, jan 2014. ISSN 0020-0255. doi: 10.1016/j.ins.2013.07.030.
URL https://doi.org/10.1016/j.ins.2013.07.030 .
Chenglei Si, Chen Zhao, Sewon Min, and Jordan Boyd-Graber. Re-examining calibration: The case of
question answering. In Findings of the Association for Computational Linguistics: EMNLP 2022 , pp.
2814–2829, AbuDhabi, UnitedArabEmirates, December2022.AssociationforComputationalLinguistics.
URL https://aclanthology.org/2022.findings-emnlp.204 .
Chenglei Si, Zhe Gan, Zhengyuan Yang, Shuohang Wang, Jianfeng Wang, Jordan Lee Boyd-Graber, and
Lijuan Wang. Prompting GPT-3 to be reliable. In The Eleventh International Conference on Learning
Representations , 2023. URL https://openreview.net/forum?id=98p5x51L5af .
Lin Sun, Xiaoyu Zhang, Yuhua Qian, Jiucheng Xu, and Shiguang Zhang. Feature selection using neighbor-
hood entropy-based uncertainty measures for gene expression data classification. Information Sciences ,
502:18–41, 2019.
14

--- PAGE 15 ---
Published in Transactions on Machine Learning Research (05/2024)
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix,
Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation
language models. arXiv preprint arXiv:2302.13971 , 2023a.
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bash-
lykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Fer-
rer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,
Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan
Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh
Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao,
Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy
Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subra-
manian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng
Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez,
Robert Stojnic, Sergey Edunov, and Thomas Scialom. Llama 2: Open foundation and fine-tuned chat
models, 2023b.
Neeraj Varshney and Chitta Baral. Post-abstention: Towards reliably re-attempting the abstained instances
inQA. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume
1: Long Papers) , pp. 967–982, Toronto, Canada, July 2023. Association for Computational Linguistics.
doi: 10.18653/v1/2023.acl-long.55. URL https://aclanthology.org/2023.acl-long.55 .
NeerajVarshney, SwaroopMishra, andChittaBaral. Investigatingselectivepredictionapproachesacrosssev-
eraltasksinIID,OOD,andadversarialsettings. In Findings of the Association for Computational Linguis-
tics: ACL 2022 , pp. 1995–2002, Dublin, Ireland, May 2022a. Association for Computational Linguistics.
doi: 10.18653/v1/2022.findings-acl.158. URL https://aclanthology.org/2022.findings-acl.158 .
Neeraj Varshney, Swaroop Mishra, and Chitta Baral. Towards improving selective prediction ability of NLP
systems. In Proceedings of the 7th Workshop on Representation Learning for NLP , pp. 221–226, Dublin,
Ireland, May 2022b. Association for Computational Linguistics. doi: 10.18653/v1/2022.repl4nlp-1.23.
URL https://aclanthology.org/2022.repl4nlp-1.23 .
Ulrike Von Luxburg. A tutorial on spectral clustering. Statistics and computing , 17:395–416, 2007.
Yuxia Wang, Daniel Beck, Timothy Baldwin, and Karin Verspoor. Uncertainty estimation and reduction of
pre-trained models for text regression. Transactions of the Association for Computational Linguistics , 10:
680–696, 2022. doi: 10.1162/tacl_a_00483. URL https://aclanthology.org/2022.tacl-1.39 .
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed H. Chi, Quoc V Le,
and Denny Zhou. Chain of thought prompting elicits reasoning in large language models. In Alice H. Oh,
Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho (eds.), Advances in Neural Information Processing
Systems, 2022. URL https://openreview.net/forum?id=_VjQlMeSB_J .
J Florian Wellmann and Klaus Regenauer-Lieb. Uncertainties have a meaning: Information entropy as a
quality measure for 3-d geological models. Tectonophysics , 526:207–216, 2012.
Adina Williams, Nikita Nangia, and Samuel Bowman. A broad-coverage challenge corpus for sentence
understanding through inference. In Proceedings of the 2018 Conference of the North American Chapter
of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers) ,
pp. 1112–1122, New Orleans, Louisiana, June 2018. Association for Computational Linguistics. doi: 10.
18653/v1/N18-1101. URL https://aclanthology.org/N18-1101 .
Miao Xiong, Zhiyuan Hu, Xinyang Lu, Yifei Li, Jie Fu, Junxian He, and Bryan Hooi. Can llms express their
uncertainty? an empirical evaluation of confidence elicitation in llms, 2023.
Bianca Zadrozny and Charles Elkan. Learning and making decisions when costs and probabilities are both
unknown. In Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery
and Data Mining , KDD ’01, pp. 204–213, New York, NY, USA, 2001. Association for Computing Machin-
ery. ISBN 158113391X. doi: 10.1145/502512.502540. URL https://doi.org/10.1145/502512.502540 .
15

--- PAGE 16 ---
Published in Transactions on Machine Learning Research (05/2024)
Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan,
Mona Diab, Xian Li, Xi Victoria Lin, et al. Opt: Open pre-trained transformer language models. arXiv
preprint arXiv:2205.01068 , 2022.
Kaitlyn Zhou, Dan Jurafsky, and Tatsunori Hashimoto. Navigating the grey area: Expressions of overconfi-
dence and uncertainty in language models. ArXiv, abs/2302.13439, 2023.
16

--- PAGE 17 ---
Published in Transactions on Machine Learning Research (05/2024)
A Proof for Theorem 1
Theorem1isthesameasProposition4inVonLuxburg(2007)(Notethe LdefinedinTheorem1isequivalent
toLsymin Von Luxburg (2007)). We briefly recover the proof below, beginning with a proposition:
Proposition 1. Von Luxburg (2007) For every f∈Rm
f⊤Lf=1
2m/summationdisplay
i,j=1wi,j/parenleftigfi√di−fj/radicalbig
dj/parenrightig2
(10)
Proposition 1 can be verified by simple algebra. Now, suppose the graph has kconnected components. We
first findkorthonormal eigenvectors. This can be done by letting v1,...,vkbekvectors such that
vl(j) =

√
dj/radicalig/summationtext
j′∈Sldj′j∈Sl
0 j̸∈Sl(11)
It is easy to verify that ∀l= 1,...,k,∥vl∥= 1. Forl1̸=l2,⟨vl1,vl2⟩= 0becauseSl2andSl1are disjoint.
Finally, the i-th entry of/radicalig/summationtext
j′∈Sldj′Lvlis 0 ifi̸∈Sl, and
/radicalbig
di−1√di/summationdisplay
jwij1√di/radicalbig
di= 0 (12)
ifi∈Sl(becauseL=I−D−1
2WD−1
2).
Now, we argue that we cannot find another vector vthat is a zero eigenvector. By Proposition 1 vmust be
be a scaled version of vlon component Sl. w.l.o.g., assume v(j)̸= 0, withj∈Sl. Then, by Proposition 1, ∃c
suchthat∀j′∈Sl,v(j′) =cvl(j′). Thismeans⟨v,vl⟩̸= 0. Thus, wecannotfindanotherzeroeigenvector.
B Additional Experiment Details and Ablations
B.1 Prompts for Response Generation
TriviaQA : We use the exact prompt in Touvron et al. (2023a) for TriviaQA, which is reproduced below:
Answer these questions:
Q: In Scotland a bothy/bothie is a?
A: House
Q: [Provided question]
A:
Natural Questions is a much harder dataset than TriviaQA, so we use the same 5-shot prompt version of
the prompt in Touvron et al. (2023a) (with 5 questions randomly picked from the training set).
CoQA: For CoQA, we use the code provided by Kuhn et al. (2023) to prepare the data12. We provide the
prompts below for convenience:
[The provided context paragraph]
[additional question-answer pairs]
Q: [Provided question]
A:
where additional question-answer pairs are preceding turns of the conversation about the paragraph consist-
ing of questions and reference answers.
12https://github.com/lorenzkuhn/semantic_uncertainty/blob/main/code/parse_coqa.py
17

--- PAGE 18 ---
Published in Transactions on Machine Learning Research (05/2024)
B.2 Prompts for NLI similarity
Similar to Kuhn et al. (2023), we feed both the question and answer to DeBERTa-large13with the following
prompt for any pair of answers to the same question in order to get the entailment/contradiction scores:
[question] [answer_1] [SEP] [question] [answer_2]
B.3 Automatic accuracy evaluation
We use gpt-3.5-turbo to evaluate the similarity between each response and the reference answer. The
prompts for coqa,triviaand nqare shown below. The few-shot examples are chosen from the training
split.
CoQA:
Rate the level of consistency between the answer to the question and the reference answer, from 0 to 100.
Question: When was the Vat formally opened?
Reference: It was formally established in 1475
Answer: In 1475
Rating: 100.
Question: what is the library for?
Reference: research
Answer: tourism
Rating: 0.
Question: [question]
Reference: [reference answer]
Answer: [generated response]
Rating:
TriviaQA :
Rate the level of consistency between the answer to the question and the reference answer, from 0 to 100.
Question: In Scotland a bothy/bothie is a?
Reference: House
Answer: House
Rating: 100.
Question: Where in England was Dame Judi Dench born?
Reference: York
Answer: London
Rating: 0.
Question: [question]
Reference: [reference answer]
Answer: [generated response]
Rating:
Natural Questions :
Rate the level of consistency between the answer to the question and the reference answer, from 0 to 100.
Question: who makes up the state council in russia
Reference: governors and presidents
Answer: governors and presidents
Rating: 100.
Question: when does real time with bill maher come back
Reference: November 9, 2018
Answer: September 8, 2000
Rating: 0.
Question: [question]
Reference: [reference answer]
Answer: [generated response]
Rating:
99.34% of the judgements by GPT can be parsed as an integer between 0 and 100 in the first attempt with
a simple str.split in Python. We skipped the remaining samples for the experiments in this paper, but if
necessary one could devise a better parsing algorithm as well as improved prompts to elicit judgement with
higher coverage.
13https://huggingface.co/microsoft/deberta-large-mnli
18

--- PAGE 19 ---
Published in Transactions on Machine Learning Research (05/2024)
Verifying the correctness of GPT evaluations We sample 33 samples per dataset and model (OPT,
LLaMA, GPT) and perform a human evaluation of the quality of the GPT judgement. That is, we compare
the human judgement on whether a generated response is correct or not with the GPT’s judgement, like in
Kuhn et al. (2023). In Table 3, we show the breakdown of the accuracy by datasets.
Table 3: The accuracy of the GPT evaluation on the correctness of the responses, measured by the authors.
For example, for trivia, the human evaluations and the GPT evaluations are aligned on 97 out of the 99
question/answer pairs, leading to an accuracy of 98.0.
coqa trivia nq
Accuracy of GPT evaluation 90.9 98.0 95.9
We also include a few typical examples where the GPT evaluation is more reliable than the rougeL evaluation
used in Kuhn et al. (2023)
•“Q: Were they nice to the other critters? A: no”. GPT correctly identifies that “They were mean to the
other animals” is a correct answer, but the rougeL metric does not capture this logic.
•“Q: Who created the immunity plan? A: the Gulf Cooperation Council”. GPT correctly identities that
“GCC” is a correct answer (an abbreviation of the Gulf Coorperation Councol”, but rougeL cannot
identify this mechanically).
•“Q: when was the last bear killed in the uk A: c. 1000 AD”. GPT classifies the response “The last bear
in the UK was killed over a thousand years ago, in the 9th century, so there is no specific date available”
as correct, but rougeL fails to do so.
The GPT evaluation also introduces its own problems, though. For example, when it is used to evaluate
its own response to the question “when did it become law to stand for the national anthem” with reference
answer “6/22/1942”, it rates “There is no federal law that mandates standing for the national anthem in
the United States” as 100. However, we believe it is using its own knowledge here and largely ignores the
reference answer. Such problems could potentially be improved with better prompts.
B.4 Hyper-parameters for Uncertainty/Confidence Measures
For allUandCmeasures involving aNLI,entail andaNLI,contra , we need to choose a temperature for the
NLI model. The temperature is chosen from 0.1, 0.25, 0.5, 1, 3, 5, and 7. For UEccandCEcc, we also need to
choose a cutoff for eigenvalues. For simplicity we use the same threshold for each experiment/dataset, and
the threshold is chosen from 0.4, 0.5, 0.6, 0.7, 0.8, and 0.9.
B.5 Computational Requirements
We perform all experiments on a machine with 2x AMD EPYC Milan 7513 CPU, 512 GB RAM, 8x A6000
GPUs. Generating 20 responses with OPT/LLaMA for coqa,nq,triviatakes from 2.5 to 15 hours, or
from 2 to 11 seconds per question. CoQA takes the longest due to the story input. Running the NLI model
for 20 responses (assuming the worst case that no two responses are exactly the same, which means 380
comparisons) takes about 0.8 seconds.
B.6 Full Experiment Results
19

--- PAGE 20 ---
Published in Transactions on Machine Learning Research (05/2024)
In the main text, we present only results for aNLI,entail . We show results for aJaccardandaNLI,contra
in Tables 4 to 6. We observe that with the default generation configs, the choice of similarity measure
(aNLI,contra,aNLI,entail,aJaccard) seems to play a bigger role than the construction of UandCmeasures.
aNLI,entail consistently performs the best, especially on nq. This is likely due to the nature of the questions.
For example, for questions starting with “why”, for a collection of low-quality random answers, aNLI,contra
does not consider them as high-uncertainty because they don’t actually contradict each other, but aNLI,entail
capturessuchhigh-uncertaintycase,asillustratedbyFig.5. Ontheotherhand,forthemorefactualquestions
like in Fig. 6, both all similarity measures agree on high-uncertainty cases, as there are few other ways to
state the correct answer. It will be interesting to see more future research on the choice of the appropriate
similarityfordifferenttasks(whichcouldinvolvedifferenttypesofquestions). Fig.7alsoprovidesanexample
showing why semantic-based similarities are preferred over lexical-based ones.
Table 4: AUARC, U(x)+ Expected Accuracy, with m= 20(similar to Table 1). The best black-box
methods are in boldand the best overall is underscored .
Baselines Ours White-box
Random Oracle NumSet LexiSim EigV(C) Ecc(C) Deg(C) EigV(E) Ecc(E) Deg(E) EigV(J) Ecc(J) Deg(J) SE P(true)
m= 20
trivia(llama) 61.18±0.07 87.03 ±0.0578.78±0.17 80.32 ±0.0684.97±0.06 84.48 ±0.07 85.04 ±0.0685.01±0.08 84.66 ±0.06 85.27±0.0683.94±0.07 83.74 ±0.07 84.29 ±0.0679.15±0.08 64.98 ±0.10
trivia(llama2) 76.24±0.11 96.50 ±0.0391.37±0.12 91.73 ±0.1393.07±0.16 93.12 ±0.06 93.23±0.0893.07±0.17 93.12 ±0.12 93.05 ±0.1492.74±0.06 92.62 ±0.09 92.60 ±0.1093.99±0.0682.53±0.09
trivia(opt) 25.75±0.12 54.72 ±0.1939.46±0.29 45.68 ±0.2450.16±0.23 50.37 ±0.24 50.52 ±0.2251.54±0.21 51.42 ±0.22 52.06±0.2150.60±0.21 50.85 ±0.20 51.49 ±0.2051.11±0.20 20.25 ±0.11
trivia(gpt) 87.42±0.08 99.09 ±0.0193.18±0.11 94.69 ±0.1594.82±0.23 94.82 ±0.19 94.92 ±0.13 95.16±0.21 95.21±0.22 95.00±0.2394.83±0.15 94.70 ±0.17 94.62 ±0.21 – –
coqa(llama) 62.46±0.11 86.29 ±0.0667.58±0.17 78.17 ±0.1580.85±0.11 78.81 ±0.12 80.86 ±0.1281.27±0.12 80.55 ±0.14 81.50±0.1579.38±0.13 79.60 ±0.13 80.39 ±0.1578.83±0.16 64.04 ±0.18
coqa(llama2) 78.71±0.13 96.92 ±0.0383.66±0.17 89.29 ±0.1689.73±0.31 89.67 ±0.55 89.71 ±0.38 90.21±0.24 90.02±0.22 90.18±0.2289.28±0.24 89.12 ±0.16 89.25 ±0.2289.29±0.17 79.92 ±0.17
coqa(opt) 53.81±0.18 79.41 ±0.1460.41±0.27 71.46 ±0.2172.87±0.20 70.77 ±0.22 72.92 ±0.2073.46±0.20 72.73 ±0.20 73.91±0.1971.60±0.22 71.43 ±0.22 72.25 ±0.2270.75±0.21 50.23 ±0.23
coqa(gpt) 79.76±0.14 97.45 ±0.0380.69±0.22 86.60 ±0.13 88.72±0.1388.11±0.25 88.70±0.17 88.80±0.1088.67±0.13 88.63 ±0.2387.66±0.29 88.13 ±0.19 88.08 ±0.19 – –
nq(llama) 23.63±0.36 47.67 ±0.5528.18±0.55 40.15 ±0.7036.99±0.64 34.29 ±0.60 37.27 ±0.64 40.42±0.6740.38±0.68 41.07±0.6940.07±0.70 39.78 ±0.67 40.17 ±0.6436.03±0.54 24.72 ±0.42
nq(llama2) 44.13±0.68 77.62 ±0.6357.55±0.98 61.88 ±1.14 62.89±1.13 62.99±0.96 63.07±1.13 63.58±0.96 63.41±0.92 63.41±1.0362.21±0.94 61.65 ±0.96 61.97 ±0.9062.40±0.98 44.25 ±0.65
nq(opt) 8.60±0.18 23.28 ±0.4310.36±0.27 15.92 ±0.5515.05±0.46 14.21 ±0.43 15.08 ±0.4718.20±0.44 18.82±0.46 18.43±0.4817.98±0.50 18.38±0.49 18.56±0.4818.40±0.447.63±0.22
nq(gpt) 62.72±0.39 90.65 ±0.2168.92±0.74 73.40 ±0.74 75.49±0.66 75.04±0.70 75.21±0.76 75.17±0.80 75.40±0.4974.35±0.7873.75±0.89 73.11 ±0.77 72.95 ±0.88 – –
Table 5: AUARC, C(x,s)+ Individual Accuracy, with m= 20(similar to Table 2). The best black-box
methods are in boldand the best overall is underscored .
Baselines Ours White-box
Random Oracle NumSet LexiSim EigV(C) Ecc(C) Deg(C) EigV(E) Ecc(E) Deg(E) EigV(J) Ecc(J) Deg(J) SE P(true)
m= 20
trivia(llama) 61.18±0.07 91.24 ±0.0378.78±0.17 80.32 ±0.0684.97±0.06 87.51 ±0.06 88.51 ±0.0685.01±0.08 88.17 ±0.11 88.86±0.0583.94±0.07 86.88 ±0.09 87.65 ±0.0679.15±0.08 67.27 ±0.11
trivia(llama2) 76.24±0.11 96.92 ±0.0391.37±0.12 91.73 ±0.1393.07±0.16 93.23 ±0.07 93.32±0.0793.07±0.17 93.21 ±0.07 93.19 ±0.1192.74±0.06 92.58 ±0.08 92.60 ±0.0893.99±0.0682.18±0.08
trivia(opt) 25.75±0.12 60.68 ±0.1639.46±0.29 45.68 ±0.2450.16±0.23 54.36 ±0.20 54.31 ±0.2151.54±0.21 55.82 ±0.21 56.11±0.1950.60±0.21 54.25 ±0.21 55.01 ±0.1951.11±0.20 20.89 ±0.12
trivia(gpt) 87.42±0.08 99.17 ±0.0193.18±0.11 94.69 ±0.1594.82±0.23 94.79 ±0.20 94.82 ±0.19 95.16±0.21 95.11±0.1894.94±0.1694.83±0.15 94.58 ±0.13 94.52 ±0.16 – –
coqa(llama) 62.46±0.11 91.85 ±0.0567.58±0.17 78.17 ±0.1580.85±0.11 80.07 ±0.11 84.56±0.1381.27±0.12 84.62±0.13 84.60±0.1579.38±0.13 83.18 ±0.14 84.03 ±0.1378.83±0.16 66.23 ±0.19
coqa(llama2) 78.71±0.13 97.55 ±0.0383.66±0.17 89.29 ±0.1689.73±0.31 89.82 ±0.25 89.94 ±0.19 90.21±0.24 90.21±0.2589.75±0.1989.28±0.24 89.11 ±0.17 89.38 ±0.2089.29±0.17 79.55 ±0.16
coqa(opt) 53.81±0.18 87.15 ±0.1160.41±0.27 71.46 ±0.2172.87±0.20 72.70 ±0.18 77.23 ±0.2073.46±0.20 78.14±0.2077.83±0.2071.60±0.22 75.96 ±0.22 76.98 ±0.2170.75±0.21 49.84 ±0.23
coqa(gpt) 79.76±0.14 97.80 ±0.0380.69±0.22 86.60 ±0.13 88.72±0.1387.83±0.12 88.37 ±0.14 88.80±0.1088.42±0.19 88.02 ±0.3187.66±0.29 87.54 ±0.13 87.88 ±0.14 – –
nq(llama) 23.63±0.36 57.69 ±0.5328.18±0.55 40.15 ±0.7036.99±0.64 35.20 ±0.62 39.66 ±0.7140.42±0.67 45.78 ±0.69 46.54±0.6940.07±0.70 44.41 ±0.68 45.24 ±0.6936.03±0.54 27.62 ±0.46
nq(llama2) 44.13±0.68 80.22 ±0.5657.55±0.98 61.88 ±1.14 62.89±1.13 63.23±0.93 63.17±1.06 63.58±0.96 63.89±1.08 63.55±1.0162.21±0.94 61.92 ±1.01 62.16 ±1.0962.40±0.98 44.34 ±0.64
nq(opt) 8.60±0.18 29.65 ±0.4510.36±0.27 15.92 ±0.5515.05±0.46 15.15 ±0.47 16.55 ±0.4718.20±0.44 21.00±0.49 21.30±0.5017.98±0.50 20.15 ±0.54 20.99±0.5118.40±0.44 8.07 ±0.21
nq(gpt) 62.72±0.39 91.97 ±0.1868.92±0.74 73.40 ±0.74 75.49±0.66 75.10±0.68 74.99±0.60 75.17±0.80 75.43±0.6774.67±0.6473.75±0.89 72.53 ±0.82 72.58 ±0.75 – –
Table 6: AUROC, C(x,s)+ Individual Accuracy, with m= 20. The best black-box methods are in bold
and the best overall is underscored . The conclusions are similar to Table 8, with confidence measures based
onaNLI,entail (E) performing the best.
Baselines Ours White-box
NumSet LexiSim EigV(C) Ecc(C) Deg(C) EigV(E) Ecc(E) Deg(E) EigV(J) Ecc(J) Deg(J) SE P(true)
m= 20
trivia(llama) 78.79±0.13 75.92 ±0.0486.29±0.07 92.61 ±0.06 93.69 ±0.0686.47±0.14 93.51 ±0.35 94.60±0.0584.58±0.08 90.14 ±0.22 91.45 ±0.0776.61±0.10 59.21 ±0.09
trivia(llama2) 86.02±0.11 82.77 ±0.1089.28±0.16 89.79 ±0.14 89.97±0.0989.18±0.19 89.78 ±0.08 89.38 ±0.1687.60±0.05 87.07 ±0.32 86.93 ±0.0989.75±0.07 65.05 ±0.14
trivia(opt) 75.02±0.16 74.49 ±0.1883.14±0.12 91.55 ±0.07 89.64 ±0.0986.09±0.10 92.71 ±0.30 92.83±0.0885.16±0.10 89.38 ±0.07 90.60 ±0.0686.19±0.09 41.76 ±0.11
trivia(gpt) 74.69±0.24 78.18 ±0.1780.90±0.50 80.92 ±0.54 80.88 ±0.49 81.78±0.25 81.80±0.2280.50±0.2279.37±0.18 77.58 ±0.24 77.42 ±0.19 – –
coqa(llama) 59.34±0.14 71.09 ±0.1776.78±0.11 76.24 ±0.17 84.47 ±0.1177.65±0.09 85.07±0.1284.91±0.1574.43±0.12 81.34 ±0.12 83.13 ±0.1173.32±0.16 55.39 ±0.17
coqa(llama2) 63.56±0.25 73.69 ±0.2876.88±0.43 77.19 ±0.25 77.41 ±0.32 77.94±0.31 78.37±0.6076.76±0.3374.49±0.29 73.86 ±0.26 74.97 ±0.2973.02±0.31 50.88 ±0.27
coqa(opt) 59.72±0.08 71.81 ±0.1574.67±0.14 76.24 ±0.13 82.37 ±0.2875.61±0.13 84.25±0.1284.06±0.0973.16±0.13 80.70 ±0.12 82.02 ±0.1071.68±0.13 45.82 ±0.15
coqa(gpt) 52.44±0.08 63.39 ±0.19 72.26±0.2769.29±0.17 70.64 ±0.25 72.17±0.1770.40±0.38 69.36 ±0.8768.18±0.21 67.46 ±0.19 68.57 ±0.19 – –
nq(llama) 60.61±0.31 75.19 ±0.3269.41±0.38 72.30 ±0.35 73.35 ±0.3975.05±0.32 83.37 ±0.31 83.99±0.2975.40±0.36 81.27 ±0.28 82.34 ±0.3469.79±0.26 56.35 ±0.40
nq(llama2) 71.02±0.41 72.41 ±0.4475.26±0.87 76.07 ±0.46 76.27 ±0.5276.50±0.41 77.13±0.4876.57±0.4674.14±0.38 73.46 ±0.46 74.07 ±0.4273.46±0.40 52.12 ±0.30
nq(opt) 60.45±0.47 70.66 ±0.6968.01±0.58 74.78 ±0.43 71.77 ±0.4777.03±0.32 83.61±0.29 83.51±0.3077.55±0.45 79.23 ±0.75 82.25 ±0.4179.16±0.26 46.74 ±0.51
nq(gpt) 62.88±0.51 65.32 ±0.62 69.99±0.66 69.71±0.56 69.34±0.4669.05±0.63 69.44±0.6967.81±0.6066.40±0.69 63.38 ±0.97 63.68 ±0.71 – –
20

--- PAGE 21 ---
Published in Transactions on Machine Learning Research (05/2024)
Q: Who was the lead singer with Stylistics
A: Russell Thompkins
10 Generations:
David McKee
Darius Rucker
Bruce Watson
Billy Jer osteen
Paul Michael McMurray
Jermaine Rogers
Billy Davis
Steve Winwood
Stacy Lattisaw
David Bennett - yeah it was a 60’s,
Figure 6: An example where contradiction-based UEigVindicates high uncertainty. In this case, the
entailment-based and Jaccard-based similarity also indicates high uncertainty.
Q: How was he traveling then?
A: he was walking
by foot
by foot
on foot
walking
walked
Walking
walking
on foot
with his legs
with his own feet
Figure 7: An example where purely lexical similarity performs worse than semantic-based ones. Although
the generations are phrased differently, they all convey the exact same meaning.
21

--- PAGE 22 ---
Published in Transactions on Machine Learning Research (05/2024)
C Additional Results
C.1 Number of Generations
In the main text, we include results with only m= 20. Here, we show the full results with m= 3,5,10, in
Tables 7 to 9. The results are very similar to when m= 20: In general, aNLI,entail seems to provide the best
results, and the choice of similarity seems more important than the choice of construction ( Ecc,Deg,EigV).
Asmincreases, the performance typically increases as well. With three generations ( m= 3) we already see
noticeable performance boost if we perform selective generation (AUARC).
Table 7: AUARC, U(x)+ Expected Accuracy, with m= 3,5,10(similar to Table 1). The best black-box
methods are in boldand the best overall is underscored .
Baselines Ours White-box
Random Oracle NumSet LexiSim EigV(C) Ecc(C) Deg(C) EigV(E) Ecc(E) Deg(E) EigV(J) Ecc(J) Deg(J) SE P(true)
m= 3
trivia(llama) 61.13±0.07 87.00 ±0.0576.51±0.15 77.79 ±0.1379.65±0.15 79.63 ±0.29 79.62 ±0.16 79.84±0.1579.54±0.16 79.86±0.1978.98±0.14 78.15 ±0.23 78.99 ±0.1177.53±0.11 64.32 ±0.08
trivia(llama2) 76.24±0.11 96.50 ±0.0387.49±0.22 88.38 ±0.20 88.89±0.23 88.87 ±0.15 88.89 ±0.30 88.85±0.27 88.69 ±0.20 88.81 ±0.2588.57±0.29 88.29 ±0.33 88.59 ±0.2793.34±0.0782.25±0.09
trivia(opt) 25.45±0.11 54.20 ±0.1839.64±0.29 41.08 ±0.1744.06±0.19 44.95 ±0.21 44.23 ±0.20 45.45±0.2144.97±0.17 45.49±0.2144.02±0.19 43.55 ±0.20 44.11 ±0.1848.87±0.1819.92±0.10
trivia(gpt) 87.42±0.08 99.09 ±0.0191.17±0.11 92.38±0.1292.26±0.27 92.36±0.3192.22±0.34 92.57±0.23 92.58±0.25 92.53±0.1692.28±0.09 92.18 ±0.25 92.28 ±0.12 – –
coqa(llama) 62.46±0.11 86.29 ±0.0667.19±0.16 75.28 ±0.1776.29±0.13 75.90 ±0.20 76.30 ±0.17 76.96±0.1876.21±0.25 77.00±0.1976.05±0.17 75.42 ±0.26 76.11 ±0.2177.68±0.1663.75±0.20
coqa(llama2) 78.71±0.13 96.92 ±0.0382.29±0.16 86.51 ±0.21 86.82±0.3086.57±0.27 86.99±0.23 86.97±0.2986.71±0.26 86.98±0.3186.48±0.23 86.40 ±0.35 86.44 ±0.3088.82±0.1779.82±0.16
coqa(opt) 53.78±0.17 79.39 ±0.1359.44±0.19 66.15 ±0.1766.94±0.28 66.94 ±0.18 66.95 ±0.22 67.82±0.1767.07±0.25 67.78±0.2766.56±0.22 65.72 ±0.36 66.52 ±0.2468.96±0.2050.06±0.23
coqa(gpt) 79.76±0.14 97.45 ±0.0380.22±0.22 85.72 ±0.26 86.46±0.2585.44±0.39 86.41±0.29 86.32±0.3586.08±0.31 86.43±0.2885.87±0.23 86.32±0.2385.98±0.20 – –
nq(llama) 23.54±0.34 47.57 ±0.5227.77±0.35 33.97 ±0.5632.79±0.56 32.98 ±0.42 32.84 ±0.54 35.30±0.4933.98±0.62 35.32±0.5634.68±0.61 33.35 ±0.66 34.74 ±0.5833.49±0.48 24.66 ±0.38
nq(llama2) 44.13±0.68 77.62 ±0.6353.46±0.74 57.74 ±1.15 58.05±1.0057.64±0.86 58.25±1.10 58.61±0.77 57.94 ±0.87 58.40 ±0.7957.74±1.09 57.20 ±1.11 57.71 ±1.0560.65±0.9544.02±0.66
nq(opt) 8.64±0.18 23.32 ±0.4210.34±0.24 12.32 ±0.3712.94±0.38 13.80 ±0.45 13.03 ±0.40 14.90±0.4314.40±0.43 14.96±0.4613.99±0.39 13.61 ±0.47 14.05 ±0.3817.34±0.387.68±0.19
nq(gpt) 62.72±0.39 90.65 ±0.2166.85±0.97 70.02 ±0.85 70.97±0.85 70.83±0.82 71.06±0.87 70.93±0.9170.14±1.14 70.86±0.93 70.36±0.7569.37±0.90 70.13 ±0.80 – –
m= 5
trivia(llama) 61.15±0.07 87.01 ±0.0578.76±0.14 78.86 ±0.0982.20±0.14 82.25 ±0.10 82.32 ±0.10 82.45±0.0982.21±0.12 82.47±0.1281.59±0.08 81.07 ±0.09 81.62 ±0.0778.44±0.08 64.58 ±0.09
trivia(llama2) 76.24±0.11 96.50 ±0.0389.53±0.29 90.15 ±0.14 91.11±0.17 90.96 ±0.13 91.04 ±0.2390.93±0.09 90.98±0.1990.91±0.1690.71±0.15 90.46 ±0.13 90.57 ±0.1993.60±0.0782.35±0.09
trivia(opt) 25.45±0.11 54.20 ±0.1841.52±0.31 41.96 ±0.2746.59±0.20 47.64 ±0.26 46.87 ±0.2048.07±0.24 48.11 ±0.16 48.33±0.1947.37±0.18 46.95 ±0.20 47.59 ±0.1949.92±0.1819.95±0.11
trivia(gpt) 87.42±0.08 99.09 ±0.0192.04±0.11 93.47 ±0.1793.62±0.25 93.49 ±0.34 93.51 ±0.34 93.72±0.1393.48±0.18 93.75±0.1293.57±0.19 93.49 ±0.11 93.53 ±0.12 – –
coqa(llama) 62.46±0.11 86.29 ±0.0668.31±0.16 76.25 ±0.1777.98±0.15 77.59 ±0.11 78.06 ±0.07 78.79±0.1278.18±0.19 78.85±0.1777.74±0.12 77.36 ±0.24 77.93 ±0.1478.25±0.16 63.94 ±0.19
coqa(llama2) 78.71±0.13 96.92 ±0.0383.10±0.14 88.13 ±0.23 88.47±0.11 88.44 ±0.36 88.51 ±0.27 88.52±0.30 88.41 ±0.27 88.57 ±0.1888.04±0.20 87.63 ±0.18 87.99 ±0.2189.08±0.1679.88±0.16
coqa(opt) 53.79±0.17 79.39 ±0.1361.15±0.31 67.85 ±0.2269.18±0.19 68.98 ±0.25 69.34 ±0.24 70.29±0.2269.74±0.26 70.35±0.2368.97±0.21 68.32 ±0.25 69.16 ±0.1870.06±0.21 50.08 ±0.22
coqa(gpt) 79.76±0.14 97.45 ±0.0380.39±0.23 86.58 ±0.21 87.77±0.1686.88±0.23 87.63±0.2887.43±0.16 87.34 ±0.22 87.49 ±0.3186.98±0.20 87.40 ±0.24 87.16 ±0.15 – –
nq(llama) 23.53±0.35 47.56 ±0.5328.23±0.43 36.52 ±0.5534.39±0.55 34.52 ±0.53 34.69 ±0.55 37.87±0.6037.47±0.59 38.14±0.6037.29±0.57 36.13 ±0.61 37.21 ±0.6134.56±0.46 24.74 ±0.42
nq(llama2) 44.13±0.68 77.62 ±0.6355.51±0.77 59.85 ±1.2760.05±1.23 60.15±1.1760.08±0.95 60.93±0.85 60.68±1.01 61.01±0.93 60.39±1.0459.45±1.00 60.11±1.0461.34±0.9744.19±0.66
nq(opt) 8.64±0.18 23.33 ±0.4210.67±0.31 13.67 ±0.5113.66±0.38 14.06 ±0.39 13.87 ±0.39 16.39±0.44 16.28 ±0.49 16.48 ±0.45 16.11±0.4516.00±0.40 16.29±0.4218.08±0.427.64±0.20
nq(gpt) 62.72±0.39 90.65 ±0.2167.94±1.12 71.18 ±0.83 72.59±0.78 72.30±1.07 72.48±0.81 72.74±0.94 72.20±0.82 72.38±0.7071.37±0.87 70.75 ±0.84 71.29 ±0.67 – –
m= 10
trivia(llama) 61.16±0.07 87.02 ±0.0579.26±0.20 79.46 ±0.0583.98±0.08 83.84 ±0.06 84.04 ±0.0884.10±0.05 83.80 ±0.09 84.27±0.0683.32±0.05 82.90 ±0.07 83.44 ±0.0678.99±0.08 64.79 ±0.10
trivia(llama2) 76.24±0.11 96.50 ±0.0390.79±0.23 91.24 ±0.15 92.53±0.10 92.43 ±0.11 92.53 ±0.13 92.47±0.1492.36±0.17 92.40 ±0.1792.13±0.10 91.92 ±0.20 91.98 ±0.0993.86±0.0682.35±0.09
trivia(opt) 25.56±0.11 54.39 ±0.1841.50±0.32 43.28 ±0.2748.79±0.21 49.63 ±0.22 49.17 ±0.2150.23±0.22 50.39 ±0.20 50.70±0.1949.58±0.20 49.48 ±0.18 50.08 ±0.1850.80±0.2020.08±0.11
trivia(gpt) 87.42±0.08 99.09 ±0.0192.81±0.10 94.44 ±0.1794.38±0.25 94.24 ±0.22 94.28 ±0.29 94.65±0.16 94.66±0.15 94.52±0.1794.40±0.15 94.29 ±0.17 94.26 ±0.16 – –
coqa(llama) 62.46±0.11 86.29 ±0.0668.33±0.33 77.47 ±0.1279.72±0.12 78.59 ±0.13 79.81 ±0.12 80.42±0.1579.79±0.17 80.49±0.1478.99±0.11 78.89 ±0.17 79.50 ±0.1378.72±0.16 63.99 ±0.18
coqa(llama2) 78.71±0.13 96.92 ±0.0383.58±0.12 88.85 ±0.1289.29±0.26 89.25 ±0.21 89.20 ±0.52 89.56±0.19 89.53±0.25 89.54±0.2588.86±0.20 88.68 ±0.23 88.86 ±0.1689.17±0.17 79.89 ±0.17
coqa(opt) 53.80±0.18 79.40 ±0.1361.40±0.22 70.13 ±0.1971.73±0.21 70.61 ±0.18 71.86 ±0.1872.58±0.22 71.98 ±0.17 72.85±0.1971.06±0.21 70.67 ±0.18 71.33 ±0.1970.83±0.21 50.16 ±0.22
coqa(gpt) 79.76±0.14 97.45 ±0.0380.65±0.22 86.59 ±0.18 88.41±0.2487.23±0.50 88.42±0.1388.28±0.19 87.91 ±0.32 88.14 ±0.2787.45±0.32 87.84 ±0.30 87.74 ±0.20 – –
nq(llama) 23.58±0.35 47.61 ±0.5328.29±0.51 38.74 ±0.6535.63±0.62 34.96 ±0.58 36.03 ±0.62 39.35±0.64 39.30±0.65 39.82±0.6539.08±0.64 38.33 ±0.62 39.10 ±0.6335.56±0.56 24.66 ±0.40
nq(llama2) 44.13±0.68 77.62 ±0.6356.71±0.95 61.12 ±0.93 62.12±1.12 61.82±0.93 62.09±1.09 62.62±1.03 62.53±0.99 62.60±1.0761.47±1.11 60.82 ±0.96 61.26 ±1.0061.98±0.9744.19±0.63
nq(opt) 8.62±0.18 23.29 ±0.4210.85±0.20 15.16 ±0.4914.47±0.38 14.81 ±0.42 14.77 ±0.4117.67±0.44 18.12±0.44 17.81±0.4817.45±0.47 17.60 ±0.46 17.79±0.4618.49±0.447.59±0.22
nq(gpt) 62.72±0.39 90.65 ±0.2168.85±1.28 72.53 ±0.82 74.26±0.64 74.24±0.59 74.07±0.91 74.12±0.78 73.98±0.70 73.75±0.8172.90±0.79 72.48 ±0.81 72.43 ±0.82 – –
C.2 Uncertainty + Individual Accuracy
We present the result of using uncertainty to predict individual accuracy in Table 10. This is similar to the
practice of Kuhn et al. (2023); Malinin & Gales (2021). Formally, this setting is U(x)+ Individual Accuracy:
We use the uncertainty estimated on msamples for each of the msamples to predict each answer’s accuracy.
For AUROC, this means
AUROC U+IA =m/summationdisplay
j=1AUROC ([−U(x1),...,−U(xN)],[acc1,j,...,accN,j]). (13)
C.3 Effects of Sampling Temperature of LLM
In the main text, we use the default generation config from hugginface or OpenAI’s API for the LLMs. In
Tables 7 to 9, the temperature is 1 for all models except for LLaMA2 (which uses 0.6) and top_pis 1 for
all models except for LLaMA2 (which uses 0.9). Being sampling-based uncertainty quantification methods,
our proposed measures obviously are affected by the temperature of the base LLM, and as we noted in the
main paper, when very low temperature we do not expect such sampling-based black-box methods to work
at all. Thus, in Tables 11 to 13, we lower the temperature to 0.5 and observe the effects.
Lower temperature leads to a less divergent posterior, which makes it more difficult for sampling based
methods to get an estimate of uncertainty or confidence. As a result, compared with results at higher
22

--- PAGE 23 ---
Published in Transactions on Machine Learning Research (05/2024)
Table 8: AUARC, C(x,s)+ Individual Accuracy, with m= 3,5,10(similar to Table 2). The best black-box
methods are in boldand the best overall is underscored .
Baselines Ours White-box
Random Oracle NumSet LexiSim EigV(C) Ecc(C) Deg(C) EigV(E) Ecc(E) Deg(E) EigV(J) Ecc(J) Deg(J) SE P(true)
m= 3
trivia(llama) 61.21±0.07 91.25 ±0.0381.00±0.17 82.84 ±0.1184.98±0.14 85.59 ±0.09 85.93±0.0885.19±0.17 85.83 ±0.12 85.76 ±0.3483.98±0.10 84.02 ±0.10 84.78 ±0.1480.15±0.10 67.51 ±0.09
trivia(llama2) 76.26±0.13 96.93 ±0.0488.30±0.23 89.28 ±0.21 89.77±0.30 89.79 ±0.17 89.78 ±0.30 89.76±0.20 89.65 ±0.21 89.68 ±0.2589.40±0.27 89.22 ±0.18 89.33 ±0.1793.58±0.0882.19±0.12
trivia(opt) 25.73±0.13 60.65 ±0.1743.64±0.36 45.80 ±0.2149.01±0.18 49.94 ±0.35 50.40 ±0.1950.55±0.25 50.79 ±0.22 51.10±0.2048.94±0.20 48.54 ±0.32 49.45 ±0.1652.77±0.1720.46±0.11
trivia(gpt) 87.45±0.08 99.18 ±0.0191.46±0.12 92.61±0.1392.51±0.22 92.69±0.17 92.61±0.23 92.81±0.23 92.78±0.25 92.62±0.1592.50±0.10 92.29 ±0.12 92.49 ±0.07 – –
coqa(llama) 62.62±0.14 91.93 ±0.0769.05±0.22 79.80 ±0.2280.70±0.16 80.51 ±0.16 81.57±0.15 81.54±0.22 81.77±0.26 81.57±0.2080.32±0.16 80.37 ±0.26 81.34 ±0.1780.24±0.21 66.24 ±0.20
coqa(llama2) 78.92±0.16 97.60 ±0.0482.74±0.19 87.24 ±0.19 87.60±0.2187.34±0.39 87.70±0.16 87.67±0.18 87.63 ±0.2387.48±0.2587.18±0.23 87.08 ±0.22 87.25 ±0.1889.17±0.1779.76±0.17
coqa(opt) 53.70±0.22 87.09 ±0.1461.60±0.23 71.18 ±0.2271.96±0.35 72.21 ±0.28 73.17 ±0.2573.20±0.28 73.66±0.36 73.31±0.2171.69±0.26 71.63 ±0.27 72.68 ±0.2472.15±0.23 49.55 ±0.26
coqa(gpt) 79.76±0.17 97.80 ±0.0480.21±0.24 85.92 ±0.31 86.69±0.3385.85±0.21 86.52±0.25 86.58±0.3686.07±0.39 86.60±0.3086.09±0.26 86.02 ±0.37 86.35 ±0.22 – –
nq(llama) 23.40±0.31 57.37 ±0.4629.00±0.46 38.30 ±0.6836.28±0.73 36.30 ±0.64 37.06 ±0.67 39.84±0.67 39.93±0.76 40.45±0.6339.03±0.66 38.67 ±0.76 40.46±0.7336.45±0.52 27.15 ±0.44
nq(llama2) 44.11±0.75 80.20 ±0.6154.43±0.86 59.01±1.31 59.22±1.09 59.12 ±1.07 59.48 ±1.05 59.78±0.84 59.24 ±1.12 59.32 ±0.9558.91±1.14 58.02 ±1.08 58.53 ±1.0861.22±0.9644.59±0.71
nq(opt) 8.94±0.24 30.49 ±0.5911.35±0.28 14.44 ±0.4315.00±0.43 14.60 ±0.38 15.85 ±0.40 17.76±0.3417.13±0.55 18.11±0.4416.81±0.37 16.81 ±0.47 17.35 ±0.4320.39±0.408.46±0.33
nq(gpt) 62.42±0.46 91.83 ±0.2267.54±0.93 69.96 ±0.93 70.84±0.88 70.89±0.87 70.83±0.75 70.93±0.99 71.11±0.91 70.89±0.8470.20±0.82 69.59 ±0.90 69.90 ±0.88 – –
m= 5
trivia(llama) 61.22±0.08 91.26 ±0.0481.60±0.17 82.01 ±0.1185.60±0.11 86.57 ±0.18 87.42±0.0985.83±0.08 87.33 ±0.10 87.57±0.1784.79±0.09 85.79 ±0.16 86.48 ±0.1080.01±0.09 67.31 ±0.10
trivia(llama2) 76.28±0.12 96.93 ±0.0390.07±0.28 90.61 ±0.16 91.62±0.15 91.55 ±0.13 91.55 ±0.2491.44±0.09 91.59±0.18 91.56 ±0.1491.17±0.15 90.94 ±0.09 91.00 ±0.1693.75±0.0782.07±0.11
trivia(opt) 25.54±0.11 60.40 ±0.1444.00±0.36 44.67 ±0.2749.71±0.18 50.43 ±0.23 52.13 ±0.1751.29±0.16 52.99 ±0.18 53.48±0.1750.44±0.16 51.34 ±0.26 52.09 ±0.1652.16±0.17 20.46 ±0.10
trivia(gpt) 87.44±0.08 99.18 ±0.0192.19±0.11 93.61 ±0.19 93.74±0.3093.55±0.29 93.74±0.23 93.87±0.14 93.76±0.2293.65±0.1893.71±0.18 93.62 ±0.11 93.53 ±0.10 – –
coqa(llama) 62.46±0.12 91.86 ±0.0669.40±0.17 79.16 ±0.1780.70±0.14 80.77 ±0.11 83.00±0.1481.73±0.17 83.02±0.15 83.06±0.1880.49±0.16 81.62 ±0.23 82.68 ±0.1479.69±0.18 66.11 ±0.17
coqa(llama2) 78.85±0.15 97.58 ±0.0483.45±0.15 88.59 ±0.25 88.98±0.1288.84±0.19 89.05±0.16 89.03±0.28 89.08 ±0.1688.80±0.2188.51±0.20 88.26 ±0.19 88.40 ±0.1789.30±0.1879.78±0.16
coqa(opt) 53.63±0.22 87.04 ±0.1462.58±0.43 70.92 ±0.2372.27±0.22 72.60 ±0.26 75.02 ±0.2073.60±0.21 75.63±0.21 75.43±0.2172.21±0.21 73.74 ±0.21 74.81 ±0.2271.82±0.22 49.76 ±0.26
coqa(gpt) 79.78±0.14 97.80 ±0.0380.36±0.23 86.68 ±0.21 87.92±0.1586.75±0.31 87.57 ±0.2287.59±0.16 87.22 ±0.25 87.37 ±0.2087.11±0.19 87.14 ±0.24 87.33 ±0.17 – –
nq(llama) 23.73±0.31 57.84 ±0.4529.05±0.58 39.82 ±0.5637.13±0.60 35.42 ±0.58 38.63 ±0.6241.37±0.58 43.17 ±0.55 44.00±0.5740.69±0.58 41.36 ±0.58 43.13 ±0.5936.43±0.41 27.99 ±0.53
nq(llama2) 44.16±0.66 80.24 ±0.5455.92±0.82 60.59 ±1.3160.61±1.23 60.92±1.13 60.91±1.10 61.54±0.92 61.52±0.92 61.22±0.93 61.01±1.0560.51±1.02 60.70±0.9861.59±0.9744.48±0.63
nq(opt) 8.79±0.20 30.13 ±0.4911.26±0.29 15.15 ±0.5615.00±0.38 14.63 ±0.34 16.46 ±0.4418.49±0.45 18.60 ±0.51 19.78±0.4618.23±0.47 18.97 ±0.45 19.50±0.4619.90±0.418.46±0.27
nq(gpt) 62.42±0.40 91.83 ±0.1968.05±1.08 71.19 ±0.86 72.65±0.79 72.46±0.77 72.44±0.92 72.76±0.99 72.56±0.81 72.34±0.8071.31±0.89 70.78 ±0.87 70.86 ±0.87 – –
m= 10
trivia(llama) 61.03±0.07 91.16 ±0.0480.34±0.24 80.55 ±0.0785.26±0.08 87.18 ±0.06 88.13 ±0.0785.39±0.07 87.87 ±0.06 88.44±0.0684.48±0.07 86.52 ±0.07 87.26 ±0.0779.60±0.08 67.04 ±0.10
trivia(llama2) 76.25±0.12 96.92 ±0.0390.98±0.23 91.37 ±0.1792.66±0.11 92.63 ±0.11 92.76±0.0992.58±0.15 92.60 ±0.14 92.69±0.1192.27±0.11 92.03 ±0.14 91.97 ±0.0993.90±0.0682.03±0.10
trivia(opt) 25.65±0.11 60.54 ±0.1542.34±0.33 44.23 ±0.2749.90±0.21 52.66 ±0.19 53.51 ±0.1951.38±0.21 54.79 ±0.19 55.20±0.1750.72±0.18 53.22 ±0.17 54.00 ±0.1751.64±0.19 20.69 ±0.11
trivia(gpt) 87.45±0.08 99.18 ±0.0192.90±0.11 94.51 ±0.1794.46±0.25 94.34 ±0.20 94.37 ±0.30 94.73±0.16 94.75±0.17 94.60±0.1994.46±0.15 94.23 ±0.15 94.27 ±0.14 – –
coqa(llama) 62.44±0.10 91.85 ±0.0568.64±0.34 78.50 ±0.1480.77±0.13 80.35 ±0.17 83.96 ±0.1481.55±0.16 84.09±0.11 84.06±0.1280.00±0.13 82.59 ±0.22 83.52 ±0.1379.25±0.16 65.98 ±0.17
coqa(llama2) 78.70±0.13 97.55 ±0.0383.62±0.12 88.98 ±0.1289.45±0.27 89.28 ±0.38 89.59±0.18 89.72±0.19 89.77±0.2489.33±0.2389.01±0.21 88.81 ±0.21 88.97 ±0.1689.22±0.17 79.55 ±0.17
coqa(opt) 53.78±0.18 87.14 ±0.1161.93±0.24 71.45 ±0.2072.97±0.20 72.89 ±0.17 76.73 ±0.2073.93±0.24 77.39±0.27 77.30±0.1972.41±0.21 75.59 ±0.24 76.57 ±0.2071.57±0.22 49.96 ±0.24
coqa(gpt) 79.81±0.13 97.81 ±0.0380.73±0.21 86.64 ±0.18 88.51±0.2387.30±0.15 88.06 ±0.15 88.36±0.2087.72±0.23 87.88 ±0.1387.52±0.31 87.48 ±0.17 87.74 ±0.11 – –
nq(llama) 23.67±0.36 57.75 ±0.5228.51±0.54 39.91 ±0.6436.62±0.69 34.97 ±0.68 39.13 ±0.7240.57±0.69 44.78 ±0.74 45.63±0.7140.35±0.66 43.21 ±0.70 44.74 ±0.6736.16±0.55 27.52 ±0.45
nq(llama2) 44.07±0.70 80.16 ±0.5856.70±0.94 61.28 ±0.94 62.24±1.13 62.48±1.08 62.32±1.15 62.67±1.10 63.25±1.13 62.58±1.0061.59±1.13 61.23 ±1.08 61.57 ±1.0762.00±0.98 44.22 ±0.67
nq(opt) 8.66±0.21 29.80 ±0.5111.01±0.24 15.71 ±0.5014.99±0.43 14.75 ±0.45 16.71 ±0.5118.51±0.48 20.08 ±0.49 20.87±0.5318.34±0.47 19.90 ±0.47 20.53±0.4819.18±0.45 8.21 ±0.25
nq(gpt) 62.71±0.39 91.97 ±0.1869.06±1.20 72.59 ±0.81 74.37±0.64 74.18±0.65 74.25±0.71 74.29±0.62 74.40±0.78 73.80±0.7672.93±0.79 71.98 ±0.81 71.99 ±0.84 – –
Table 9: AUROC, C(x,s)+ Individual Accuracy, with m= 3,5,10(similar to Table 9). The best black-box
methods are in boldand the best overall is underscored .
Baselines Ours White-box
NumSet LexiSim EigV(C) Ecc(C) Deg(C) EigV(E) Ecc(E) Deg(E) EigV(J) Ecc(J) Deg(J) SE P(true)
m= 3
trivia(llama) 82.58±0.13 80.78 ±0.1286.44±0.12 88.32 ±0.13 88.91±0.1087.36±0.17 89.01±0.1188.77±0.4884.40±0.12 84.46 ±0.39 86.13 ±0.1077.96±0.14 59.42 ±0.08
trivia(llama2) 79.25±0.15 80.41 ±0.21 82.52±0.43 82.64 ±0.22 82.60 ±0.47 82.45±0.1782.34±0.24 82.14 ±0.4180.84±0.21 80.46 ±0.24 80.52 ±0.2288.43±0.0865.00±0.19
trivia(opt) 78.24±0.09 73.52 ±0.1480.50±0.07 82.63 ±0.33 82.63 ±0.0783.40±0.10 83.69±0.46 83.75 ±0.0880.70±0.06 79.73 ±0.19 80.97 ±0.0787.51±0.0741.12±0.10
trivia(gpt) 66.67±0.21 71.93 ±0.3071.76±1.33 72.24 ±0.35 72.34 ±0.98 73.04±0.3272.60±0.49 72.11 ±0.3371.63±0.29 70.50 ±0.45 71.22 ±0.28 – –
coqa(llama) 62.67±0.12 73.85 ±0.2376.61±0.40 76.94 ±0.22 79.10 ±0.26 79.17±0.23 80.02±0.92 79.26±0.1975.84±0.15 75.90 ±0.32 77.97 ±0.1675.23±0.24 55.11 ±0.16
coqa(llama2) 59.63±0.22 70.89 ±0.26 72.47±0.2471.70±0.73 72.51±0.28 72.76±0.40 72.53±0.5271.88±0.4070.68±0.22 70.21 ±0.29 70.67 ±0.2172.10±0.30 50.97 ±0.31
coqa(opt) 63.48±0.18 71.84 ±0.1773.30±0.41 74.84 ±0.31 76.31 ±0.2576.84±0.26 78.25±0.3877.14±0.1373.73±0.13 73.77 ±0.49 75.56 ±0.1573.62±0.15 45.57 ±0.16
coqa(gpt) 51.46±0.10 64.37 ±0.16 67.41±0.2664.29±0.16 66.56 ±0.22 67.42±0.5365.29±0.64 66.18 ±0.4264.86±0.20 64.40 ±1.06 65.33 ±0.21 – –
nq(llama) 61.30±0.33 70.48 ±0.4066.22±0.60 68.96 ±0.47 68.42 ±0.4573.16±0.66 71.98 ±0.76 73.94±0.4272.44±0.40 70.57 ±0.86 73.78±0.3968.84±0.44 56.55 ±0.60
nq(llama2) 67.70±0.43 70.69 ±0.5572.14±0.56 72.25 ±0.53 72.41 ±0.43 72.92±0.2972.20±0.39 72.26 ±0.3570.86±0.48 69.08 ±1.01 70.34 ±0.4571.15±0.36 52.08 ±0.41
nq(opt) 61.18±0.52 61.07 ±0.6364.25±0.73 65.52 ±0.87 67.02 ±0.66 72.07±0.4269.77±1.65 71.16 ±0.5668.40±0.75 66.83 ±0.63 68.55 ±0.8381.01±0.4447.40±0.80
nq(gpt) 60.05±0.52 62.72 ±0.75 65.27±0.89 64.92±0.73 65.11±0.57 64.82±0.7064.34±0.80 64.30 ±0.7562.66±0.73 61.44 ±0.47 62.19 ±0.73 – –
m= 5
trivia(llama) 82.94±0.09 77.82 ±0.1387.03±0.10 90.09 ±0.21 91.51 ±0.0887.77±0.12 91.56 ±0.22 92.01±0.2685.66±0.08 87.70 ±0.32 89.18 ±0.0777.64±0.10 59.16 ±0.07
trivia(llama2) 83.12±0.13 82.53 ±0.16 86.39±0.19 86.56 ±0.17 86.57 ±0.3386.23±0.17 86.44±0.1986.14±0.1684.52±0.17 84.20 ±0.47 84.01 ±0.1889.00±0.0864.82±0.17
trivia(opt) 79.46±0.11 71.23 ±0.2282.05±0.10 85.45 ±0.10 86.12 ±0.0985.38±0.20 88.11 ±0.37 88.32±0.0984.11±0.07 84.97 ±0.44 85.64 ±0.1087.27±0.05 41.37 ±0.10
trivia(gpt) 69.99±0.22 74.81 ±0.1975.97±0.66 75.60 ±0.76 75.92 ±0.73 76.34±0.2475.84±1.15 75.49 ±0.3675.04±0.21 74.05 ±0.26 74.16 ±0.21 – –
coqa(llama) 62.60±0.09 72.42 ±0.1576.55±0.27 77.01 ±0.09 81.83 ±0.2179.08±0.17 82.22±0.33 82.32±0.1476.31±0.11 78.75 ±0.14 80.75 ±0.1274.61±0.19 55.15 ±0.17
coqa(llama2) 62.01±0.26 73.23 ±0.2975.33±0.29 75.10 ±0.53 75.60±0.26 75.85±0.53 76.03±0.4474.65±0.3273.37±0.25 72.63 ±0.48 73.06 ±0.2572.71±0.33 51.04 ±0.28
coqa(opt) 63.87±0.11 70.68 ±0.1673.79±0.23 75.17 ±0.14 79.24 ±0.0976.89±0.20 81.21±0.1180.73±0.1374.56±0.10 77.39 ±0.26 79.09 ±0.0873.23±0.15 45.90 ±0.12
coqa(gpt) 51.81±0.10 64.88 ±0.15 70.23±0.2466.20±0.21 68.70 ±0.5169.69±0.64 67.96 ±0.60 67.96 ±0.6066.89±0.20 67.01 ±0.53 67.43 ±0.17 – –
nq(llama) 62.01±0.37 72.21 ±0.3767.69±0.42 67.61 ±0.56 70.47 ±0.3674.88±0.40 77.45 ±0.39 78.40±0.2774.49±0.47 74.45 ±0.68 77.51 ±0.2969.09±0.28 57.23 ±0.55
nq(llama2) 69.12±0.38 71.50 ±0.5273.21±0.70 73.77 ±0.58 73.92 ±0.66 74.72±0.49 74.71±0.39 74.32±0.4372.84±0.46 72.26 ±0.44 72.45 ±0.4771.95±0.44 52.16 ±0.32
nq(opt) 62.68±0.48 64.64 ±0.9365.70±0.60 68.68 ±0.68 69.79 ±0.5675.66±0.46 75.24 ±2.49 77.34±0.5174.84±0.47 74.01 ±0.62 75.29 ±0.5681.25±0.3347.77±0.63
nq(gpt) 61.36±0.39 63.80 ±0.82 67.56±0.60 67.25±0.64 67.18±0.7166.55±0.72 66.58 ±0.78 65.86 ±0.6664.19±0.88 62.78 ±0.90 62.83 ±0.84 – –
m= 10
trivia(llama) 81.26±0.15 75.14 ±0.0786.66±0.13 91.69 ±0.08 93.02 ±0.0887.07±0.08 92.88 ±0.16 93.85±0.0585.40±0.07 89.29 ±0.12 90.76 ±0.0677.37±0.10 59.02 ±0.07
trivia(llama2) 85.16±0.11 82.79 ±0.1188.43±0.14 88.67 ±0.15 88.94±0.1288.31±0.22 88.68 ±0.32 88.31 ±0.1586.63±0.09 85.99 ±0.53 85.96 ±0.1189.46±0.0864.88±0.16
trivia(opt) 77.90±0.14 70.51 ±0.2682.63±0.11 89.18 ±0.09 88.50 ±0.0885.87±0.13 91.25 ±0.32 91.42±0.0885.16±0.08 87.86 ±0.26 88.94 ±0.0786.72±0.07 41.54 ±0.11
trivia(gpt) 72.69±0.25 77.40 ±0.1879.16±0.62 78.84 ±0.57 78.81 ±0.86 79.81±0.42 79.77±0.4678.76±0.6477.95±0.19 76.27 ±0.67 76.44 ±0.20 – –
coqa(llama) 61.20±0.12 71.19 ±0.1776.63±0.11 76.27 ±0.12 83.50 ±0.1178.25±0.12 84.03±0.20 84.07±0.1275.46±0.12 80.37 ±0.60 82.43 ±0.1073.97±0.16 55.10 ±0.14
coqa(llama2) 62.97±0.26 73.48 ±0.2876.44±0.31 76.33 ±0.33 76.78 ±0.27 77.33±0.27 77.51±0.4475.98±0.2974.19±0.26 73.53 ±0.29 74.15 ±0.2672.85±0.31 50.87 ±0.28
coqa(opt) 62.65±0.10 71.33 ±0.1074.55±0.11 75.70 ±0.14 81.55 ±0.2276.39±0.17 83.36±0.35 83.15±0.1174.25±0.09 79.87 ±0.36 81.33 ±0.1172.70±0.13 46.04 ±0.14
coqa(gpt) 52.24±0.12 63.89 ±0.22 71.46±0.5467.77±0.20 69.97 ±0.40 71.22±0.3269.39±0.38 69.19 ±0.1967.61±0.24 67.41 ±0.57 68.17 ±0.20 – –
nq(llama) 61.47±0.31 74.24 ±0.3868.22±0.40 70.51 ±0.35 72.32 ±0.3674.76±0.40 80.96 ±0.61 82.13±0.3475.27±0.38 78.74 ±0.59 81.23 ±0.2969.43±0.28 56.28 ±0.49
nq(llama2) 70.64±0.37 72.44 ±0.3575.09±0.71 75.45 ±0.51 75.70 ±0.5875.90±0.49 76.44±0.4975.85±0.5173.55±0.35 72.89 ±0.43 73.49 ±0.4172.91±0.39 51.98 ±0.27
nq(opt) 62.39±0.56 68.27 ±0.7167.13±0.66 72.83 ±0.51 71.33 ±0.6076.90±0.42 80.73 ±0.35 81.34±0.4377.47±0.35 77.80 ±0.90 79.43 ±0.3580.46±0.21 46.96 ±0.56
nq(gpt) 62.24±0.52 64.77 ±0.71 68.97±0.66 68.65±0.45 68.64±0.6168.11±0.72 68.19 ±0.76 67.16 ±0.6365.46±0.76 63.21 ±0.92 63.48 ±0.75 – –
temperature, we observe that in general, the white-box method ( SE) performs better than our black-box
methods when mis small. However, as mincreases (≥10), our methods’ performance picks up.
23

--- PAGE 24 ---
Published in Transactions on Machine Learning Research (05/2024)
Table 10: AUROC, U(x)+ Individual Accuracy. Compared with Table 9, the AUROC for confidence
measures ( Eccand Deg) are typically lower, which is consistent to the belief that confidence measures
captures the quality of each responses.
NumSet LexiSim EigV(C) Ecc(C) Deg(C) EigV(E) Ecc(E) Deg(E) EigV(J) Ecc(J) Deg(J) SE P(true)
m= 3
trivia(llama) 82.58±0.13 80.78 ±0.1286.44±0.12 86.86 ±0.11 86.38 ±0.25 87.36±0.1786.36±0.17 87.34±0.1784.40±0.12 82.58 ±0.22 84.30 ±0.1177.96±0.14 56.23 ±0.09
trivia(llama2) 79.25±0.15 80.41 ±0.21 82.52±0.43 82.50 ±0.23 82.55 ±0.39 82.45±0.1782.08±0.18 82.35±0.2280.84±0.21 80.18 ±0.50 80.84 ±0.2188.43±0.0864.83±0.19
trivia(opt) 78.24±0.09 73.52 ±0.1480.50±0.07 82.83 ±0.16 80.89 ±0.0783.40±0.10 82.87 ±0.22 83.52±0.1080.70±0.06 79.57 ±0.32 80.79 ±0.0687.51±0.0740.21±0.09
trivia(gpt) 66.67±0.21 71.93 ±0.3071.76±1.33 71.67 ±1.36 71.60 ±1.57 73.04±0.3272.26±0.57 72.95±0.3371.63±0.29 70.59 ±0.34 71.58 ±0.29 – –
coqa(llama) 62.67±0.12 73.85 ±0.2376.61±0.40 76.46 ±0.39 76.84 ±0.17 79.17±0.2376.93±0.72 79.14±0.2175.84±0.15 74.33 ±0.35 75.93 ±0.1475.23±0.24 52.78 ±0.16
coqa(llama2) 59.63±0.22 70.89 ±0.26 72.47±0.2471.94±0.34 72.51±0.29 72.76±0.4071.74±0.96 72.75±0.3870.68±0.22 69.92 ±0.24 70.66 ±0.2272.10±0.30 51.17 ±0.31
coqa(opt) 63.48±0.18 71.84 ±0.1773.30±0.41 74.35 ±0.30 73.48 ±0.43 76.84±0.2675.52±0.27 76.91±0.1873.73±0.13 72.15 ±0.52 73.68 ±0.1373.62±0.15 45.60 ±0.18
coqa(gpt) 51.46±0.10 64.37 ±0.16 67.41±0.2664.43±0.24 67.38±0.46 67.42±0.5366.22±0.56 67.40±0.5264.86±0.20 66.33 ±0.45 65.19 ±0.20 – –
nq(llama) 61.30±0.33 70.48 ±0.4066.22±0.60 69.69 ±0.71 66.50 ±0.59 73.16±0.6670.47±0.53 73.28±0.6372.44±0.40 69.43 ±0.94 72.45 ±0.4168.84±0.44 53.46 ±0.53
nq(llama2) 67.70±0.43 70.69 ±0.5572.14±0.56 72.08 ±0.50 72.27 ±0.63 72.92±0.2971.80±0.32 72.74±0.4670.86±0.48 69.15 ±0.45 70.76 ±0.4471.15±0.36 51.68 ±0.37
nq(opt) 61.18±0.52 61.07 ±0.6364.25±0.73 69.53 ±0.66 64.58 ±0.81 72.07±0.4270.54±0.79 72.14±0.4368.40±0.75 66.83 ±0.55 68.44 ±0.7581.01±0.4446.56±0.74
nq(gpt) 60.05±0.52 62.72 ±0.75 65.27±0.89 65.23±0.82 65.36±0.77 64.82±0.7063.86±0.82 64.67±0.7662.66±0.73 60.95 ±0.89 62.44 ±0.72 – –
m= 5
trivia(llama) 82.94±0.09 77.82 ±0.1387.03±0.10 87.38 ±0.13 87.19 ±0.1187.77±0.12 87.32 ±0.12 87.98±0.1285.66±0.08 84.51 ±0.08 85.56 ±0.0877.64±0.10 55.14 ±0.06
trivia(llama2) 83.12±0.13 82.53 ±0.16 86.39±0.1985.98±0.26 86.33±0.20 86.23±0.1785.88±0.33 86.06 ±0.2284.52±0.17 84.13 ±0.15 84.42 ±0.1789.00±0.0864.74±0.18
trivia(opt) 79.46±0.11 71.23 ±0.2282.05±0.10 85.11 ±0.10 82.56 ±0.1085.38±0.20 85.69 ±0.17 85.99±0.2484.11±0.07 83.67 ±0.14 84.35 ±0.0787.27±0.0540.33±0.10
trivia(gpt) 69.99±0.22 74.81 ±0.1975.97±0.66 75.32 ±0.80 75.92 ±0.75 76.34±0.2475.49±1.23 76.19±0.2975.04±0.21 74.32 ±0.33 74.64 ±0.21 – –
coqa(llama) 62.60±0.09 72.42 ±0.1576.55±0.27 76.03 ±0.10 76.80 ±0.2379.08±0.17 77.91 ±0.22 79.28±0.1176.31±0.11 75.54 ±0.24 76.63 ±0.1274.61±0.19 52.29 ±0.16
coqa(llama2) 62.01±0.26 73.23 ±0.2975.33±0.29 75.36 ±0.25 74.98 ±1.32 75.85±0.5375.31±0.81 75.87±0.2673.37±0.25 72.55 ±0.40 73.24 ±0.2672.71±0.33 51.27 ±0.29
coqa(opt) 63.87±0.11 70.68 ±0.1673.79±0.23 74.05 ±0.17 74.20 ±0.2276.89±0.20 75.97 ±0.12 77.08±0.1474.56±0.10 73.71 ±0.17 74.65 ±0.1173.23±0.15 45.95 ±0.12
coqa(gpt) 51.81±0.10 64.88 ±0.15 70.23±0.2467.19±0.65 69.93 ±0.6369.69±0.64 68.61 ±0.38 69.73 ±0.3766.89±0.20 68.56 ±0.71 67.64 ±0.20 – –
nq(llama) 62.01±0.37 72.21 ±0.3767.69±0.42 69.83 ±0.37 68.25 ±0.42 74.88±0.4073.61±0.68 75.20±0.4374.49±0.47 72.45 ±0.45 74.33 ±0.4469.09±0.28 53.06 ±0.57
nq(llama2) 69.12±0.38 71.50 ±0.5273.21±0.70 73.27 ±0.57 73.26 ±0.64 74.72±0.4973.85±0.43 74.51±0.4872.84±0.46 71.71 ±0.49 72.36 ±0.5071.95±0.44 51.86 ±0.32
nq(opt) 62.68±0.48 64.64 ±0.9365.70±0.60 70.08 ±0.59 66.28 ±0.61 75.66±0.46 75.73 ±0.64 75.98 ±0.4774.84±0.47 74.08 ±0.57 75.08 ±0.4981.25±0.3346.74±0.57
nq(gpt) 61.36±0.39 63.80 ±0.82 67.56±0.60 67.33±0.80 67.52±0.7666.55±0.72 65.79 ±0.88 66.04 ±0.7464.19±0.88 62.67 ±0.69 63.52 ±0.84 – –
m= 10
trivia(llama) 81.26±0.15 75.14 ±0.0786.66±0.13 86.75 ±0.06 86.80 ±0.1387.07±0.08 86.71 ±0.08 87.59±0.1285.40±0.07 84.61 ±0.07 85.52 ±0.0777.37±0.10 54.54 ±0.05
trivia(llama2) 85.16±0.11 82.79 ±0.11 88.43±0.1488.26±0.14 88.53±0.2288.31±0.22 88.13 ±0.15 88.10 ±0.1986.63±0.09 86.06 ±0.59 86.15 ±0.1089.46±0.0864.85±0.17
trivia(opt) 77.90±0.14 70.51 ±0.2682.63±0.11 85.58 ±0.09 83.26 ±0.1185.87±0.13 86.66 ±0.13 86.90±0.0885.16±0.08 84.94 ±0.19 85.76 ±0.0786.72±0.07 40.20 ±0.10
trivia(gpt) 72.69±0.25 77.40 ±0.1879.16±0.62 78.93 ±0.61 78.92 ±0.67 79.81±0.42 79.60±0.5678.96±0.7977.95±0.19 77.07 ±0.35 77.17 ±0.20 – –
coqa(llama) 61.20±0.12 71.19 ±0.1776.63±0.11 74.56 ±0.16 76.84 ±0.2678.25±0.12 77.18 ±0.13 78.54±0.1375.46±0.12 75.40 ±0.30 76.34 ±0.1273.97±0.16 51.73 ±0.15
coqa(llama2) 62.97±0.26 73.48 ±0.2876.44±0.31 76.31 ±0.44 76.22 ±0.85 77.33±0.2776.81±0.33 77.02 ±0.3574.19±0.26 73.44 ±0.26 74.04 ±0.2672.85±0.31 51.08 ±0.29
coqa(opt) 62.65±0.10 71.33 ±0.1074.55±0.11 72.94 ±0.12 74.86 ±0.2476.39±0.17 75.59 ±0.14 76.94±0.1274.25±0.09 73.92 ±0.08 74.65 ±0.1172.70±0.13 46.02 ±0.14
coqa(gpt) 52.24±0.12 63.89 ±0.22 71.46±0.5468.22±0.21 71.54±0.52 71.22±0.3270.11±0.41 70.71 ±0.4167.61±0.24 69.46 ±1.14 68.83 ±0.23 – –
nq(llama) 61.47±0.31 74.24 ±0.3868.22±0.40 69.86 ±0.38 68.68 ±0.4374.76±0.40 74.55 ±0.45 75.39±0.40 75.27±0.3873.63±0.40 75.09±0.3469.43±0.28 51.37 ±0.50
nq(llama2) 70.64±0.37 72.44 ±0.3575.09±0.71 74.94 ±0.36 75.05 ±0.72 75.90±0.49 75.51±0.41 75.61±0.4473.55±0.35 72.55 ±0.31 73.22 ±0.3872.91±0.39 51.70 ±0.31
nq(opt) 62.39±0.56 68.27 ±0.7167.13±0.66 71.74 ±0.56 67.33 ±0.6876.90±0.42 78.71±0.3977.56±0.3677.47±0.35 77.16 ±0.50 78.00 ±0.3280.46±0.2145.65±0.45
nq(gpt) 62.24±0.52 64.77 ±0.71 68.97±0.66 68.81±0.56 68.93±0.6468.11±0.72 67.89 ±0.70 67.11 ±0.7065.46±0.76 64.40 ±0.81 64.27 ±0.77 – –
m= 20
trivia(llama) 78.79±0.13 75.92 ±0.0486.29±0.07 85.59 ±0.08 86.43 ±0.0786.47±0.14 85.86 ±0.08 87.09±0.0784.58±0.08 84.15 ±0.10 85.19 ±0.0776.61±0.10 54.43 ±0.06
trivia(llama2) 86.02±0.11 82.77 ±0.10 89.28±0.1689.18±0.15 89.47±0.1989.18±0.19 89.11 ±0.20 89.05 ±0.1187.60±0.05 87.23 ±0.33 86.94 ±0.0789.75±0.0765.02±0.15
trivia(opt) 75.02±0.16 74.49 ±0.1883.14±0.12 85.22 ±0.12 83.71 ±0.1286.09±0.10 86.55 ±0.12 87.20±0.1085.16±0.10 85.50 ±0.11 86.31 ±0.0886.19±0.09 40.23 ±0.11
trivia(gpt) 74.69±0.24 78.18 ±0.1780.90±0.50 80.74 ±0.73 81.24 ±0.24 81.78±0.25 81.75±0.3080.73±0.4679.37±0.18 78.64 ±0.22 78.15 ±0.18 – –
coqa(llama) 59.34±0.14 71.09 ±0.1776.78±0.11 72.97 ±0.13 76.89 ±0.2077.65±0.09 76.48 ±0.21 78.17±0.1574.43±0.12 75.04 ±0.11 76.19 ±0.1273.32±0.16 51.69 ±0.19
coqa(llama2) 63.56±0.25 73.69 ±0.2876.88±0.43 76.61 ±0.88 76.93 ±0.71 77.94±0.3177.42±0.30 77.76±0.2774.49±0.29 73.56 ±0.32 74.66 ±0.2873.02±0.31 51.09 ±0.28
coqa(opt) 59.72±0.08 71.81 ±0.1574.67±0.14 71.16 ±0.16 74.85 ±0.2675.61±0.13 74.74 ±0.24 76.49±0.1273.16±0.13 73.28 ±0.16 74.32 ±0.1471.68±0.13 45.77 ±0.14
coqa(gpt) 52.44±0.08 63.39 ±0.19 72.26±0.2770.26±0.30 71.99±0.55 72.17±0.1771.39±0.36 71.53 ±0.3268.18±0.21 69.93 ±0.83 69.46 ±0.22 – –
nq(llama) 60.61±0.31 75.19 ±0.3269.41±0.38 69.08 ±0.33 69.54 ±0.3975.05±0.32 74.94 ±0.38 75.94±0.3575.40±0.36 74.41 ±0.28 75.32 ±0.3169.79±0.26 51.26 ±0.44
nq(llama2) 71.02±0.41 72.41 ±0.4475.26±0.87 75.19 ±0.78 75.66 ±0.65 76.50±0.41 76.18±0.43 76.25±0.4374.14±0.38 73.40 ±0.37 73.85 ±0.4373.46±0.40 51.92 ±0.35
nq(opt) 60.45±0.47 70.66 ±0.6968.01±0.58 70.49 ±0.52 67.43 ±0.5777.03±0.32 79.65±0.3477.85±0.2977.55±0.45 77.59 ±0.51 78.50 ±0.3879.16±0.26 45.22 ±0.50
nq(gpt) 62.88±0.51 65.32 ±0.62 69.99±0.66 69.75±0.51 69.86±0.6269.05±0.63 69.57±0.6667.43±0.6866.40±0.69 65.01 ±0.53 64.40 ±0.72 – –
C.4 Generation without Rejection
Previous results indicate the practical performance of using the proposed UandCfor selective generation,
wheresomehardquestionsareignored. InTable14wesimplypickthemostconfidentresponse. Evenwithout
rejection, most confidence measures can pick better responses and significantly improve the accuracy.
C.5 Confidence vs Calibration
As suggested in Section 2, model calibration is an orthogonal research direction. Once the confidence mea-
sures are given, a calibration method could then be applied to calibrate the confidence scores into something
close to the probability of correct answer. We applied the classical histogram binning method Zadrozny &
Elkan (2001) on all methods, and compute the adaptive calibration error (ACE) Nixon et al. (2019). The
number of bins is set to 15 following the standard practice Nixon et al. (2019), and the confidence measures
are calibrated on the 1st generation of 1000 calibration samples and evaluated on the rest. Confidence
measures are estimated using 20 generations. The results are in Table 16. After calibration, the confidence
scores can faithfully reflect the accuracy. For example, for Ecc(E) on trivia(llama) , the gap between
calibrated probability and the actual accuracy is only 0.026.
24

--- PAGE 25 ---
Published in Transactions on Machine Learning Research (05/2024)
Table11: AUARC, U(x)+ExpectedAccuracy, with m= 3,5,10,20(similartoTable1)andthetemperature
of the LLM set to 0.5. The best black-box methods are in boldand the best overall is underscored .
Baselines Ours White-box
Random Oracle NumSet LexiSim EigV(C) Ecc(C) Deg(C) EigV(E) Ecc(E) Deg(E) EigV(J) Ecc(J) Deg(J) SE P(true)
m= 3
trivia(llama) 74.43±0.10 95.85 ±0.0385.88±0.16 86.87 ±0.15 87.29±0.24 87.32 ±0.14 87.29 ±0.25 87.25±0.1587.16±0.16 87.27±0.1686.95±0.12 86.67 ±0.14 86.96 ±0.1292.20±0.0775.92±0.14
trivia(llama2) 75.92±0.11 96.35 ±0.0386.96±0.16 87.56 ±0.27 88.21±0.28 88.17 ±0.32 88.29 ±0.20 88.17±0.1887.98±0.36 88.14±0.2487.77±0.24 87.55 ±0.24 87.82 ±0.2193.02±0.0582.07±0.10
trivia(opt) 40.53±0.13 75.08 ±0.1358.77±0.23 59.40 ±0.45 60.98±0.30 61.06 ±0.48 60.98 ±0.29 61.26±0.35 61.02 ±0.47 61.33 ±0.4160.25±0.32 60.04 ±0.43 60.35 ±0.3767.52±0.1835.56±0.20
trivia(gpt) 87.79±0.10 99.20 ±0.0189.98±0.13 91.64±0.18 91.49±0.29 91.54±0.26 91.52±0.25 91.62±0.16 91.55±0.19 91.63±0.17 91.60±0.16 91.55±0.16 91.60±0.16 – –
coqa(llama) 76.27±0.08 95.97 ±0.0280.00±0.16 84.72 ±0.30 85.35±0.1785.20±0.43 85.42±0.14 85.28±0.5285.21±0.57 85.33±0.4584.72±0.29 84.39 ±0.28 84.73 ±0.2787.84±0.1774.94±0.17
coqa(llama2) 78.36±0.12 96.77 ±0.0381.86±0.13 85.78±0.1885.68±0.77 85.97±0.3485.70±0.69 86.09±0.27 85.90 ±0.31 86.10 ±0.3285.67±0.28 85.31 ±0.31 85.76 ±0.1888.45±0.1679.65±0.18
coqa(opt) 70.40±0.15 93.70 ±0.0775.31±0.13 78.94 ±0.2279.11±0.77 79.41±0.6379.23±0.70 79.58±0.25 79.34 ±0.36 79.52 ±0.3278.92±0.34 78.68 ±0.35 79.02 ±0.2882.35±0.2068.42±0.26
coqa(gpt) 80.02±0.13 97.74 ±0.0380.27±0.25 85.08 ±0.27 85.40±0.2984.91±0.59 85.37±0.33 85.33±0.54 85.16±0.49 85.37±0.55 85.30±0.26 85.22±0.26 85.27±0.33 – –
nq(llama) 40.72±0.56 73.91 ±0.5150.88±0.66 53.82 ±0.66 54.67±0.80 54.74 ±0.89 54.84 ±0.45 55.00±0.81 54.30 ±0.65 54.89 ±0.7953.71±0.71 52.61 ±0.91 53.42 ±0.6557.22±0.6846.68±0.67
nq(llama2) 44.01±0.64 77.45 ±0.6053.35±0.51 56.62±0.80 57.28±0.88 57.05 ±0.80 57.08 ±0.85 57.39±0.92 56.80 ±0.85 57.26 ±1.09 56.65±0.8556.11±0.98 56.95±0.9560.31±0.8844.58±0.54
nq(opt) 18.06±0.36 45.06 ±0.6524.54±0.66 26.67 ±0.99 28.24±1.00 28.50 ±0.90 28.22 ±0.93 28.88±0.80 28.51 ±0.72 28.96 ±0.8128.05±0.89 27.72 ±0.91 28.12 ±0.7433.34±0.8315.94±0.40
nq(gpt) 62.90±0.45 91.42 ±0.2265.74±0.80 67.77±0.87 67.93±1.29 67.81±1.29 68.07±1.29 68.22±0.94 68.15±0.87 68.20±0.91 67.74±0.91 67.67±0.65 67.75±0.91 – –
m= 5
trivia(llama) 74.43±0.10 95.85 ±0.0387.66±0.12 89.09 ±0.08 89.87±0.25 89.89 ±0.13 89.88 ±0.2889.70±0.17 89.72 ±0.21 89.80±0.1889.53±0.10 89.03 ±0.17 89.49 ±0.1092.50±0.0776.16±0.13
trivia(llama2) 75.92±0.11 96.35 ±0.0388.91±0.16 89.38 ±0.24 90.15±0.26 90.08 ±0.22 90.21 ±0.16 90.14±0.18 90.08 ±0.19 90.18 ±0.1589.91±0.22 89.47 ±0.25 89.85 ±0.3193.28±0.0682.20±0.10
trivia(opt) 40.55±0.13 75.10 ±0.1360.52±0.24 60.31 ±0.30 63.51±0.55 63.41 ±0.3763.13±0.47 63.58±0.35 63.56 ±0.26 63.49 ±0.2862.45±0.23 62.26 ±0.14 62.87 ±0.2067.92±0.1835.62±0.20
trivia(gpt) 87.79±0.10 99.20 ±0.0190.49±0.14 92.07±0.17 92.15±0.19 92.21±0.18 92.11±0.29 92.13±0.20 92.10±0.18 92.10±0.20 92.13±0.18 92.11±0.21 92.07±0.22 – –
coqa(llama) 76.27±0.08 95.97 ±0.0280.51±0.15 85.93 ±0.24 86.80±0.23 86.64 ±0.27 86.94 ±0.10 86.96±0.38 86.75 ±0.39 86.86 ±0.4286.10±0.17 85.83 ±0.18 86.28 ±0.2388.00±0.1674.93±0.18
coqa(llama2) 78.36±0.12 96.77 ±0.0382.54±0.16 86.79 ±0.25 87.56±0.19 87.40 ±0.27 87.60 ±0.23 87.60±0.17 87.58 ±0.21 87.59 ±0.1287.11±0.22 86.74 ±0.31 87.07 ±0.1788.67±0.1679.69±0.18
coqa(opt) 70.40±0.15 93.70 ±0.0776.43±0.22 80.25 ±0.2680.86±0.79 81.00 ±0.50 80.74 ±0.41 81.41±0.37 81.19 ±0.46 81.40 ±0.3380.55±0.20 80.19 ±0.24 80.59 ±0.2682.70±0.2068.41±0.26
coqa(gpt) 80.02±0.13 97.74 ±0.0380.27±0.25 85.94 ±0.16 86.19±0.4985.90±0.48 86.19±0.28 86.28±0.28 86.21±0.51 86.14±0.37 86.03±0.2385.94±0.21 86.11±0.23 – –
nq(llama) 40.71±0.56 73.91 ±0.5152.88±0.80 55.59 ±0.71 56.73±0.74 56.88 ±0.53 56.60 ±0.65 57.21±0.65 57.09 ±0.82 57.25 ±0.7055.93±0.65 54.95 ±0.64 55.63 ±0.7457.91±0.6646.86±0.60
nq(llama2) 44.01±0.64 77.45 ±0.6055.36±0.62 58.71 ±0.91 59.43±0.92 59.46 ±0.80 59.56 ±0.76 59.72±0.66 59.42 ±0.92 59.68 ±1.1858.93±0.83 58.25 ±0.87 58.75 ±0.9860.94±0.8844.62±0.52
nq(opt) 18.08±0.36 45.11 ±0.6526.13±0.78 26.94 ±0.96 30.56±0.93 30.57 ±0.90 30.55 ±0.84 31.21±0.79 31.03 ±1.00 31.00 ±0.8130.05±0.96 30.29 ±0.95 30.14 ±0.7533.89±0.8316.11±0.38
nq(gpt) 62.90±0.45 91.42 ±0.2266.49±0.86 68.62±0.93 69.49±1.00 69.34±0.85 69.46±0.85 69.47±0.58 68.94±0.98 69.26±0.86 68.78±0.8668.27±0.78 68.71±1.12 – –
m= 10
trivia(llama) 74.43±0.10 95.85 ±0.0389.54±0.08 89.84 ±0.13 91.31±0.1991.23±0.16 91.42±0.12 91.39±0.0691.27±0.13 91.35±0.0990.86±0.11 90.67 ±0.26 90.76 ±0.0992.76±0.0676.18±0.14
trivia(llama2) 75.92±0.11 96.35 ±0.0390.76±0.06 90.71 ±0.08 92.27±0.19 92.19 ±0.21 92.21 ±0.18 92.17±0.21 92.13 ±0.14 92.12 ±0.1091.80±0.09 91.70 ±0.11 91.65 ±0.1193.60±0.0682.30±0.10
trivia(opt) 40.59±0.13 75.14 ±0.1362.12±0.32 60.95 ±0.2765.75±0.40 66.01±0.2565.80±0.3565.87±0.26 66.14±0.26 66.21 ±0.2764.90±0.20 64.97 ±0.29 65.23 ±0.2668.27±0.1835.65±0.19
trivia(gpt) 87.79±0.10 99.20 ±0.0191.17±0.13 92.75±0.24 92.73±0.19 92.69±0.28 92.73±0.33 92.81±0.20 92.83±0.18 92.78±0.22 92.72±0.27 92.67±0.26 92.67±0.20 – –
coqa(llama) 76.27±0.08 95.97 ±0.0280.98±0.16 87.32 ±0.2088.16±0.25 88.37±0.3088.12±0.65 88.54±0.27 88.30±0.28 88.51±0.2487.76±0.17 87.48 ±0.19 87.92 ±0.1888.27±0.1675.00±0.18
coqa(llama2) 78.36±0.12 96.77 ±0.0383.20±0.14 87.85 ±0.21 88.70±0.1588.45±0.40 88.58 ±0.19 88.78±0.2288.57±0.20 88.79±0.1988.08±0.21 87.91 ±0.21 88.12 ±0.2488.86±0.1679.70±0.18
coqa(opt) 70.40±0.15 93.70 ±0.0778.18±0.14 81.97 ±0.3082.59±0.58 82.94±0.3882.58±0.44 83.36±0.45 83.09±0.40 83.35±0.2982.30±0.19 81.77 ±0.30 82.17 ±0.2883.23±0.1968.43±0.27
coqa(gpt) 80.02±0.13 97.74 ±0.0380.44±0.24 86.34 ±0.24 87.29±0.3987.00±0.42 87.47±0.21 87.36±0.2687.23±0.34 87.25 ±0.2486.82±0.41 87.16 ±0.36 86.90 ±0.32 – –
nq(llama) 40.72±0.56 73.92 ±0.5153.73±0.66 57.24 ±0.7358.49±0.95 58.96±0.96 58.64±0.74 59.35±0.84 59.31±0.88 58.88±0.7557.70±0.75 56.94 ±0.84 57.26 ±0.7558.71±0.7046.81±0.64
nq(llama2) 44.01±0.64 77.45 ±0.6056.35±0.83 60.30 ±0.89 61.55±1.16 61.42±1.18 61.44±1.04 61.88±0.97 61.77±1.14 61.54±1.06 60.96±1.1560.33±1.03 60.56 ±1.0461.55±0.9444.71±0.55
nq(opt) 18.14±0.36 45.21 ±0.6626.53±0.67 27.49 ±0.5732.09±0.83 32.32±0.87 32.30 ±0.73 33.12±0.94 33.07 ±0.88 32.97 ±0.7331.74±0.90 32.40±0.89 32.25 ±0.7834.13±0.7916.22±0.39
nq(gpt) 62.90±0.45 91.42 ±0.2266.44±0.94 69.00 ±0.95 70.34±1.01 69.98±1.11 70.30±1.05 70.20±0.98 69.97±0.60 70.11±0.64 69.40±0.8969.20±0.83 69.04 ±0.91 – –
m= 20
trivia(llama) 74.43±0.10 95.85 ±0.0390.83±0.11 90.27 ±0.0892.46±0.09 92.45 ±0.08 92.60±0.1292.41±0.13 92.37 ±0.11 92.42 ±0.1591.85±0.09 91.76 ±0.08 91.71 ±0.1092.98±0.0676.13±0.15
trivia(llama2) 75.92±0.11 96.35 ±0.0391.77±0.15 91.21 ±0.09 93.23±0.18 93.14 ±0.21 93.28 ±0.15 93.23±0.15 93.21 ±0.10 93.21 ±0.1292.79±0.11 92.67 ±0.11 92.59 ±0.0893.80±0.0682.31±0.09
trivia(opt) 40.65±0.13 75.21 ±0.1362.91±0.26 61.07 ±0.2967.61±0.25 67.58 ±0.19 67.49 ±0.2867.66±0.30 67.64 ±0.22 67.88±0.2066.27±0.26 66.62 ±0.21 66.73 ±0.2568.58±0.1835.75±0.20
trivia(gpt) 87.79±0.10 99.20 ±0.0191.61±0.15 93.02 ±0.2492.87±0.24 93.04 ±0.32 93.02 ±0.31 93.23±0.25 93.31±0.13 93.25±0.2293.08±0.27 92.95 ±0.19 93.02 ±0.27 – –
coqa(llama) 76.27±0.08 95.97 ±0.0281.17±0.17 87.57 ±0.1988.68±0.20 88.82 ±0.27 88.71 ±0.44 89.18±0.2488.94±0.22 89.27±0.1688.19±0.22 88.02 ±0.36 88.34 ±0.2188.44±0.16 75.03 ±0.18
coqa(llama2) 78.36±0.12 96.77 ±0.0383.34±0.12 88.40 ±0.1289.42±0.21 89.28 ±0.51 89.44 ±0.29 89.83±0.27 89.62±0.30 89.80±0.3088.81±0.29 88.65 ±0.23 88.87 ±0.2189.07±0.16 79.72 ±0.19
coqa(opt) 70.40±0.15 93.70 ±0.0778.67±0.15 82.57 ±0.2383.75±0.37 83.67 ±0.13 83.94 ±0.28 84.23±0.42 84.26±0.25 84.44±0.4083.10±0.29 82.61 ±0.24 82.97 ±0.2683.53±0.18 68.44 ±0.27
coqa(gpt) 80.02±0.13 97.74 ±0.0380.38±0.22 86.74 ±0.27 87.91±0.1787.47±0.57 88.04±0.29 87.83±0.31 87.85±0.2587.66±0.2887.36±0.32 87.39 ±0.35 87.47 ±0.25 – –
nq(llama) 40.72±0.56 73.92 ±0.5153.73±0.73 58.29 ±0.64 60.11±0.9760.04±0.91 60.11±0.91 60.84±0.80 60.51±0.93 60.26±0.7658.97±0.68 58.21 ±0.72 58.23 ±0.7659.23±0.77 46.84 ±0.64
nq(llama2) 44.01±0.64 77.45 ±0.6056.41±0.84 61.19 ±0.80 62.80±0.9862.35±0.83 62.59±1.08 63.24±0.84 62.76±0.95 62.91±0.8862.12±0.95 61.53 ±0.87 61.49 ±1.0261.96±0.95 44.69 ±0.55
nq(opt) 18.18±0.37 45.27 ±0.6726.30±0.70 27.06 ±0.5333.24±0.80 32.87 ±0.79 33.07 ±0.78 34.06±0.83 34.07±0.79 33.78±0.8632.40±0.77 33.24 ±0.82 33.06 ±0.8134.29±0.7916.29±0.42
nq(gpt) 62.90±0.45 91.42 ±0.2266.61±0.74 69.89 ±0.89 71.11±0.86 71.45±0.81 71.33±0.87 71.39±0.77 71.43±0.78 70.67±0.74 70.70±0.8370.21±0.87 69.97 ±0.68 – –
25

--- PAGE 26 ---
Published in Transactions on Machine Learning Research (05/2024)
Table 12: AUARC, C(x,s)+ Individual Accuracy, with m= 3,5,10,20(similar to Table 2) and the
temperature of the LLM set to 0.5. The best black-box methods are in boldand the best overall is
underscored .
Baselines Ours White-box
Random Oracle NumSet LexiSim EigV(C) Ecc(C) Deg(C) EigV(E) Ecc(E) Deg(E) EigV(J) Ecc(J) Deg(J) SE P(true)
m= 3
trivia(llama) 74.25±0.09 96.36 ±0.0386.97±0.15 87.96 ±0.16 88.39±0.22 88.50 ±0.12 88.51 ±0.15 88.37±0.14 88.36 ±0.1488.34±0.2288.01±0.13 87.76 ±0.13 88.01 ±0.1292.52±0.0775.79±0.15
trivia(llama2) 75.95±0.10 96.84 ±0.0388.05±0.16 88.81 ±0.30 89.51±0.32 89.41 ±0.33 89.34 ±0.36 89.44±0.26 89.41 ±0.23 89.35 ±0.2889.00±0.28 88.75 ±0.30 89.04 ±0.1993.37±0.0581.99±0.12
trivia(opt) 40.49±0.14 77.10 ±0.1260.61±0.23 61.19 ±0.4862.89±0.35 63.10±0.4362.97±0.29 63.31±0.23 63.15 ±0.4362.92±0.4062.02±0.35 61.77 ±0.40 62.20 ±0.3968.35±0.1835.51±0.20
trivia(gpt) 87.78±0.10 99.22 ±0.0190.07±0.13 91.70±0.19 91.56±0.26 91.60±0.1891.52±0.34 91.70±0.15 91.66±0.17 91.65±0.14 91.64±0.17 91.58±0.18 91.64±0.17 – –
coqa(llama) 76.27±0.09 96.93 ±0.0380.24±0.18 85.89 ±0.35 86.52±0.15 86.42 ±0.47 86.62 ±0.22 86.53±0.4886.39±0.56 86.29 ±0.6285.83±0.31 85.46 ±0.30 85.85 ±0.2788.32±0.1774.80±0.18
coqa(llama2) 78.31±0.16 97.46 ±0.0482.55±0.13 86.86 ±0.2086.71±0.78 86.93±0.27 87.09 ±0.18 87.17±0.26 87.07 ±0.23 87.03 ±0.1886.67±0.33 86.56 ±0.26 86.73 ±0.1688.86±0.1679.15±0.25
coqa(opt) 70.31±0.21 95.08 ±0.0776.03±0.18 80.12 ±0.2580.25±0.82 80.60±0.5680.52±0.29 80.85±0.30 80.79 ±0.2680.37±0.3280.08±0.37 79.84 ±0.30 80.25 ±0.2682.81±0.2268.11±0.29
coqa(gpt) 80.00±0.13 97.85 ±0.0380.18±0.24 85.15 ±0.27 85.47±0.3085.14±0.28 85.48±0.23 85.41±0.5785.18±0.46 85.16 ±0.86 85.36±0.2785.15±0.25 85.28±0.23 – –
nq(llama) 41.01±0.63 77.54 ±0.5652.59±0.78 55.50 ±0.79 56.57±0.71 56.66 ±0.76 56.79 ±0.83 56.97±0.88 56.63 ±0.93 56.43 ±0.7655.37±0.76 54.04 ±0.80 55.15 ±0.6958.19±0.7147.48±0.62
nq(llama2) 43.84±0.58 79.98 ±0.4853.89±0.47 57.71±0.84 58.27±0.92 58.24 ±0.76 58.55 ±0.84 58.44±0.95 58.16 ±0.92 58.41 ±0.9457.69±0.92 57.16 ±0.84 57.75±1.0160.56±0.8644.59±0.46
nq(opt) 17.83±0.44 48.55 ±0.7625.31±0.78 28.05 ±1.19 29.63±1.20 29.64 ±1.01 29.83 ±1.12 30.30±0.94 30.11 ±0.96 30.50 ±1.0729.42±1.17 29.06 ±1.06 29.42 ±0.9633.64±0.9616.32±0.55
nq(gpt) 62.95±0.45 92.08 ±0.2165.64±0.76 68.04±0.86 68.15±1.35 68.10±1.31 67.93±1.63 68.52±0.90 68.42±0.82 68.24±1.02 68.04±0.84 67.99±0.76 68.03±0.74 – –
m= 5
trivia(llama) 74.35±0.09 96.38 ±0.0388.48±0.13 89.86 ±0.09 90.67±0.22 90.74 ±0.16 90.71 ±0.3690.57±0.14 90.61±0.19 90.59 ±0.1990.29±0.10 90.10 ±0.17 90.21 ±0.1092.75±0.0775.89±0.16
trivia(llama2) 75.97±0.09 96.85 ±0.0389.67±0.15 90.22 ±0.26 91.00±0.25 91.14 ±0.15 91.07 ±0.3290.95±0.17 91.02±0.14 91.03 ±0.2190.77±0.25 90.59 ±0.19 90.65 ±0.2093.51±0.0581.92±0.11
trivia(opt) 40.56±0.15 77.16 ±0.1361.58±0.25 61.31 ±0.3264.65±0.56 64.80 ±0.26 64.92±0.2164.80±0.35 65.09±0.24 65.03 ±0.2363.49±0.21 63.63 ±0.25 64.06 ±0.1868.41±0.1935.66±0.20
trivia(gpt) 87.74±0.11 99.22 ±0.0190.50±0.14 92.09±0.17 92.12±0.20 92.14±0.14 92.09±0.34 92.15±0.20 92.14±0.18 92.10±0.24 92.14±0.17 92.07±0.15 92.05±0.19 – –
coqa(llama) 76.32±0.09 96.94 ±0.0280.82±0.16 86.74 ±0.2387.55±0.27 87.49 ±0.30 87.79±0.15 87.76±0.3887.56±0.41 87.56 ±0.4586.85±0.18 86.75 ±0.19 87.11 ±0.1888.33±0.1674.91±0.17
coqa(llama2) 78.26±0.15 97.44 ±0.0482.92±0.17 87.46 ±0.29 88.27±0.21 88.17 ±0.17 88.28 ±0.19 88.30±0.16 88.28 ±0.3088.00±0.2887.76±0.27 87.43 ±0.25 87.73 ±0.2288.91±0.1679.06±0.22
coqa(opt) 70.31±0.17 95.08 ±0.0676.95±0.19 81.01 ±0.2781.70±0.78 81.76 ±0.58 82.02 ±0.26 82.32±0.42 82.54 ±0.3681.80±0.2681.39±0.18 81.34 ±0.23 81.50 ±0.2283.00±0.1968.16±0.26
coqa(gpt) 80.05±0.13 97.86 ±0.0380.24±0.25 85.95 ±0.15 86.25±0.4785.84±0.53 86.20±0.27 86.34±0.2985.99±0.45 86.13±0.22 86.06±0.2385.88±0.17 86.10±0.25 – –
nq(llama) 40.83±0.60 77.39 ±0.5453.76±0.90 56.77 ±0.7157.91±0.77 58.13 ±0.90 58.26±0.65 58.50±0.69 58.90±0.65 58.55±0.7357.11±0.71 56.61 ±0.65 56.94 ±0.6458.56±0.6447.27±0.59
nq(llama2) 43.95±0.61 80.07 ±0.5056.00±0.63 59.60 ±0.98 60.33±0.93 60.46±0.83 60.76±0.71 60.62±0.74 60.93±0.85 60.71±0.7859.80±0.88 59.35 ±0.93 59.60 ±0.9561.14±0.8444.83±0.50
nq(opt) 17.91±0.45 48.69 ±0.7826.70±0.82 27.84 ±1.13 31.35±1.0630.86±0.92 31.69±0.98 31.89±0.98 31.77 ±1.05 32.00 ±1.0130.77±1.05 30.70 ±0.97 30.99±1.0133.98±0.9316.53±0.50
nq(gpt) 62.95±0.49 92.08 ±0.2366.52±0.94 68.75±0.95 69.61±1.04 69.32±1.18 69.33±1.06 69.56±0.58 69.34±0.81 69.25±0.84 68.90±0.8768.52±0.82 68.72±0.77 – –
m= 10
trivia(llama) 74.41±0.10 96.40 ±0.0389.92±0.09 90.20 ±0.1491.66±0.17 91.92±0.13 91.88 ±0.1791.75±0.06 91.89±0.09 91.83 ±0.1091.20±0.12 91.09 ±0.19 91.12 ±0.0992.88±0.0775.87±0.14
trivia(llama2) 75.93±0.10 96.84 ±0.0391.05±0.07 90.98 ±0.08 92.52±0.21 92.66 ±0.24 92.69 ±0.27 92.46±0.21 92.67 ±0.13 92.54 ±0.1692.08±0.09 92.02 ±0.09 91.95 ±0.0993.70±0.0581.96±0.10
trivia(opt) 40.64±0.13 77.23 ±0.1262.51±0.30 61.33 ±0.2666.06±0.44 67.02±0.22 66.88 ±0.3966.29±0.26 67.09±0.25 67.04 ±0.2265.29±0.20 65.61 ±0.20 66.00 ±0.2168.44±0.1835.75±0.17
trivia(gpt) 87.75±0.10 99.22 ±0.0191.12±0.13 92.76±0.24 92.73±0.19 92.67±0.26 92.68±0.30 92.82±0.20 92.74±0.20 92.71±0.14 92.72±0.2792.61±0.16 92.59 ±0.18 – –
coqa(llama) 76.39±0.09 96.96 ±0.0381.31±0.16 87.70 ±0.2088.57±0.24 88.45 ±0.27 88.90±0.20 88.92±0.27 88.98±0.24 88.77±0.2988.12±0.18 88.03 ±0.21 88.43 ±0.1888.46±0.17 75.13 ±0.18
coqa(llama2) 78.30±0.13 97.45 ±0.0383.32±0.14 88.10 ±0.22 88.97±0.1588.77±0.21 88.97±0.18 89.05±0.23 89.03±0.1788.69±0.2288.34±0.22 88.14 ±0.19 88.45 ±0.2288.93±0.1779.18±0.19
coqa(opt) 70.33±0.15 95.08 ±0.0578.46±0.16 82.30 ±0.2982.96±0.57 83.32 ±0.27 83.22 ±0.55 83.76±0.46 83.95±0.4183.36±0.3182.66±0.19 82.51 ±0.31 82.70 ±0.2183.37±0.19 68.16 ±0.26
coqa(gpt) 80.00±0.14 97.85 ±0.0380.39±0.25 86.36 ±0.24 87.30±0.4086.97±0.34 87.25±0.16 87.39±0.26 87.19±0.2087.09±0.1986.85±0.41 86.69 ±0.26 87.01 ±0.15 – –
nq(llama) 40.85±0.57 77.40 ±0.5154.32±0.78 57.84 ±0.7759.04±0.99 59.71 ±0.86 59.65 ±0.91 60.01±0.85 60.51±0.72 60.06±0.6358.34±0.76 57.87 ±0.79 58.20 ±0.6959.06±0.69 47.21 ±0.64
nq(llama2) 44.10±0.62 80.19 ±0.5156.66±0.86 60.71 ±0.92 61.85±1.05 62.03±0.98 62.39±1.07 62.27±0.98 62.68±0.98 62.22±1.1061.33±1.18 60.94 ±0.98 61.09 ±1.0561.68±0.95 45.12 ±0.49
nq(opt) 18.01±0.37 48.86 ±0.6426.60±0.68 27.88 ±0.5932.38±0.83 32.34 ±0.77 33.21±0.81 33.40±0.96 33.39±0.85 33.88±0.8532.06±0.91 32.70 ±0.86 32.91 ±0.8034.10±0.8016.61±0.42
nq(gpt) 63.06±0.46 92.13 ±0.2166.66±0.98 69.11 ±0.95 70.47±1.01 70.22±0.72 70.39±0.76 70.31±0.97 70.04±0.73 70.14±0.88 69.51±0.8768.97±0.92 69.00 ±0.82 – –
m= 20
trivia(llama) 74.43±0.10 96.41 ±0.0390.83±0.11 90.27 ±0.0892.46±0.09 92.73±0.16 92.73 ±0.0992.41±0.13 92.75±0.0892.66±0.1191.85±0.09 91.89 ±0.08 91.81 ±0.0892.98±0.0675.84±0.15
trivia(llama2) 75.92±0.11 96.83 ±0.0391.77±0.15 91.21 ±0.0993.23±0.18 93.35 ±0.27 93.53±0.0893.23±0.15 93.51±0.1093.40±0.0992.79±0.11 92.81 ±0.09 92.64 ±0.0893.80±0.0681.96±0.10
trivia(opt) 40.65±0.13 77.24 ±0.1262.91±0.26 61.07 ±0.2967.61±0.25 68.42±0.1868.29±0.1767.66±0.30 68.45±0.19 68.51±0.2066.27±0.26 66.69 ±0.21 67.21 ±0.1868.58±0.1835.80±0.18
trivia(gpt) 87.79±0.10 99.22 ±0.0191.61±0.15 93.02 ±0.2492.87±0.24 92.93 ±0.16 93.09±0.33 93.23±0.25 93.27±0.20 93.17±0.15 93.08±0.2792.94±0.25 92.92 ±0.20 – –
coqa(llama) 76.27±0.08 96.93 ±0.0281.17±0.17 87.57 ±0.1988.68±0.20 88.86 ±0.15 89.15±0.21 89.18±0.24 89.30±0.1889.05±0.2388.19±0.22 88.24 ±0.21 88.61 ±0.1988.44±0.16 75.11 ±0.17
coqa(llama2) 78.36±0.12 97.47 ±0.0383.34±0.12 88.40 ±0.1289.42±0.21 89.51 ±0.23 89.65 ±0.16 89.83±0.27 89.97±0.3089.41±0.2088.81±0.29 88.63 ±0.17 88.99 ±0.1789.07±0.16 79.37 ±0.18
coqa(opt) 70.40±0.15 95.11 ±0.0578.67±0.15 82.57 ±0.2383.75±0.37 83.88 ±0.21 84.22 ±0.2284.23±0.42 84.97±0.2684.23±0.2183.10±0.29 83.05 ±0.23 83.23 ±0.2383.53±0.18 68.19 ±0.27
coqa(gpt) 80.02±0.13 97.86 ±0.0380.38±0.22 86.74 ±0.27 87.91±0.1787.59±0.36 87.80±0.21 87.83±0.31 87.84±0.2787.43±0.2187.36±0.32 87.05 ±0.15 87.37 ±0.19 – –
nq(llama) 40.72±0.56 77.29 ±0.5053.73±0.73 58.29 ±0.6460.11±0.97 60.41 ±0.86 60.68±0.76 60.84±0.80 61.40±0.83 60.87±0.7558.97±0.68 58.20 ±0.70 58.72 ±0.7159.23±0.77 46.98 ±0.64
nq(llama2) 44.01±0.64 80.11 ±0.5356.41±0.84 61.19 ±0.80 62.80±0.98 62.87±0.86 63.33±0.92 63.24±0.84 63.49±0.87 63.26±0.9662.12±0.95 61.74 ±0.86 61.81 ±0.9361.96±0.95 45.02 ±0.53
nq(opt) 18.18±0.37 49.14 ±0.6326.30±0.70 27.06 ±0.5333.24±0.80 33.04 ±0.68 33.91 ±0.76 34.06±0.83 34.39±0.79 34.73±0.7632.40±0.77 33.40 ±0.78 33.69 ±0.7534.29±0.7916.71±0.43
nq(gpt) 62.90±0.45 92.06 ±0.2166.61±0.74 69.89 ±0.89 71.11±0.86 71.38±0.73 71.48±0.84 71.39±0.77 71.48±0.78 71.02±0.8170.70±0.83 69.99 ±0.73 69.90 ±0.76 – –
26

--- PAGE 27 ---
Published in Transactions on Machine Learning Research (05/2024)
Table 13: AUROC, C(x,s)+ Individual Accuracy, with m= 3,5,10,20(similar to Table 9) and the
temperature of the LLM set to 0.5. The best black-box methods are in boldand the best overall is
underscored .
Baselines Ours White-box
NumSet LexiSim EigV(C) Ecc(C) Deg(C) EigV(E) Ecc(E) Deg(E) EigV(J) Ecc(J) Deg(J) SE P(true)
m= 3
trivia(llama) 78.71±0.16 79.49 ±0.2081.75±0.26 82.08±0.17 82.12 ±0.1881.72±0.23 81.79 ±0.45 81.58 ±0.3380.04±0.21 79.42 ±0.40 79.98 ±0.1987.51±0.1356.45±0.18
trivia(llama2) 78.62±0.17 79.59 ±0.20 81.84±0.38 81.77 ±0.40 81.82 ±0.53 81.94±0.21 81.83 ±0.2081.47±0.5580.29±0.20 79.38 ±0.87 80.16 ±0.1988.15±0.1064.42±0.17
trivia(opt) 78.24±0.13 76.29 ±0.1380.62±0.19 80.94±0.12 80.93 ±0.36 81.05±0.13 80.93 ±0.3280.81±0.3578.79±0.08 78.38 ±0.34 79.04 ±0.0885.22±0.1245.94±0.17
trivia(gpt) 59.98±0.13 66.28±0.27 66.06±1.46 66.15±0.4465.82±1.73 66.41±0.41 66.20±0.43 66.17±0.70 66.36±0.2665.95±0.26 66.16±0.26 – –
coqa(llama) 60.68±0.19 71.78 ±0.2374.05±0.28 73.93 ±0.37 74.08 ±0.25 74.60±0.33 74.34±0.5073.47±0.5071.72±0.23 70.64 ±0.61 71.93 ±0.2373.90±0.28 48.14 ±0.20
coqa(llama2) 59.83±0.19 70.20 ±0.1971.38±1.53 71.38 ±0.70 72.06±0.27 72.13±0.3871.60±1.00 71.46 ±0.4569.96±0.23 69.43 ±0.18 70.26 ±0.2272.50±0.2751.12±0.26
coqa(opt) 62.34±0.15 68.75 ±0.2369.99±1.10 70.71 ±0.54 70.79 ±0.25 71.40±0.42 71.24±0.7170.29±0.4669.22±0.25 68.75 ±0.53 69.51 ±0.2370.34±0.19 46.62 ±0.33
coqa(gpt) 50.95±0.08 63.01 ±0.29 64.37±0.4462.80±0.87 64.15±0.36 64.35±0.7563.65±0.77 63.37 ±1.3563.01±0.30 62.91 ±0.41 63.09 ±0.29 – –
nq(llama) 68.36±0.44 69.74 ±0.3072.63±0.46 72.75 ±0.16 72.98 ±0.38 73.42±0.4372.67±0.29 72.11 ±0.4370.26±0.32 67.99 ±0.65 69.87 ±0.3471.05±0.35 58.86 ±0.61
nq(llama2) 67.25±0.23 69.53 ±0.4271.63±0.34 71.50 ±0.31 72.03±0.34 72.25±0.3771.55±0.48 71.67 ±0.4570.16±0.49 68.59 ±0.69 69.97 ±0.5170.50±0.43 52.71 ±0.32
nq(opt) 68.42±0.43 66.75 ±0.5271.90±0.65 72.30 ±0.69 73.01 ±0.85 74.50±0.6173.44±0.80 74.58±0.5771.37±0.58 69.97 ±0.70 71.23 ±0.6677.38±0.5546.37±0.84
nq(gpt) 56.18±0.32 58.59 ±0.43 60.48±0.99 60.08±0.80 60.06±1.22 60.45±0.45 59.88±0.55 59.89±0.6558.97±0.47 58.11 ±0.52 58.67 ±0.47 – –
m= 5
trivia(llama) 82.31±0.17 81.59 ±0.17 85.44±0.23 85.77 ±0.52 85.79 ±0.43 85.38±0.20 85.67 ±0.68 85.51 ±0.1883.53±0.18 83.33 ±0.40 83.30 ±0.1688.05±0.1256.41±0.19
trivia(llama2) 82.06±0.13 81.28 ±0.1885.31±0.56 85.80±0.30 85.73 ±0.7685.44±0.22 85.63±0.21 85.55 ±0.3283.66±0.19 83.25 ±0.84 83.39 ±0.1888.57±0.0864.23±0.16
trivia(opt) 80.45±0.12 75.03 ±0.1683.08±0.39 83.78 ±0.24 83.88±0.1983.48±0.11 84.08±0.29 84.06 ±0.1481.22±0.07 81.20 ±0.27 81.95 ±0.0785.28±0.1146.17±0.17
trivia(gpt) 62.19±0.17 68.21 ±0.33 69.00±0.47 68.81±0.2668.36±1.50 68.94±0.44 68.64±0.6068.46±0.6368.42±0.32 67.90 ±0.30 67.88 ±0.32 – –
coqa(llama) 61.93±0.15 72.29 ±0.2075.30±0.31 75.50 ±0.24 75.89 ±0.26 76.18±0.37 76.31±0.3375.76±0.4073.04±0.18 72.74 ±0.28 73.98 ±0.1873.83±0.27 48.18 ±0.19
coqa(llama2) 61.48±0.19 71.68 ±0.2174.55±0.25 74.56 ±0.18 74.81 ±0.28 75.04±0.22 74.91±0.9773.99±0.6372.29±0.25 71.54 ±0.26 72.48 ±0.2572.73±0.27 51.12 ±0.25
coqa(opt) 64.53±0.17 69.76 ±0.2072.22±0.71 72.76 ±0.78 73.21 ±0.2173.67±0.26 74.30±0.2872.91±0.3170.87±0.22 70.94 ±0.30 71.42 ±0.2170.89±0.17 46.75 ±0.28
coqa(gpt) 51.15±0.09 63.90 ±0.30 66.17±0.9464.31±1.13 65.66 ±0.48 66.30±0.4765.05±0.83 65.20 ±0.3564.64±0.31 64.22 ±0.47 64.75 ±0.31 – –
nq(llama) 69.54±0.35 70.63 ±0.2673.64±0.60 74.05 ±0.53 74.53 ±0.2474.69±0.31 75.33±0.3674.54±0.3371.80±0.21 71.26 ±0.24 71.80 ±0.2171.88±0.28 59.02 ±0.58
nq(llama2) 69.18±0.38 70.99 ±0.5673.49±0.44 73.62 ±0.34 74.15 ±0.3174.08±0.57 74.63±0.4674.02±0.3072.18±0.50 71.78 ±0.41 71.96 ±0.5071.42±0.34 52.81 ±0.31
nq(opt) 70.52±0.35 63.81 ±0.4674.60±0.67 74.25 ±0.55 75.54 ±0.52 76.65±0.4575.94±0.60 76.63±0.5473.92±0.42 73.54 ±0.46 74.10 ±0.4577.97±0.5946.36±0.64
nq(gpt) 57.87±0.39 59.48 ±0.49 62.54±0.62 62.02±0.87 62.02±0.7161.54±0.42 61.52 ±0.46 61.02 ±0.4760.08±0.59 59.10 ±0.54 59.11 ±0.58 – –
m= 10
trivia(llama) 84.62±0.14 81.17 ±0.1787.45±0.26 88.32±0.15 88.38±0.2087.53±0.21 88.26±0.1587.84±0.1785.40±0.14 85.01 ±0.72 85.16 ±0.1188.40±0.1056.26±0.18
trivia(llama2) 85.18±0.12 81.61 ±0.0988.12±0.42 88.80±0.28 88.92 ±0.3688.06±0.38 88.81±0.2888.31±0.3786.28±0.11 86.21 ±0.12 85.88 ±0.1289.20±0.0864.40±0.14
trivia(opt) 81.18±0.11 72.45 ±0.1883.93±0.68 85.76±0.1985.45±0.3684.60±0.18 85.86±0.13 85.77±0.1582.37±0.09 82.88 ±0.09 83.63 ±0.0985.24±0.11 46.22 ±0.17
trivia(gpt) 64.47±0.15 70.65 ±0.3371.44±0.87 71.12 ±0.88 71.04 ±1.29 71.82±0.3871.30±0.57 71.01 ±0.3770.82±0.31 70.02 ±0.43 69.91 ±0.30 – –
coqa(llama) 62.88±0.20 72.52 ±0.2876.53±0.26 77.10 ±0.31 77.63 ±0.3377.73±0.27 78.22±0.4577.60±0.2874.58±0.26 74.45 ±0.33 75.78 ±0.2474.01±0.28 48.40 ±0.19
coqa(llama2) 62.90±0.20 71.76 ±0.2075.71±0.29 75.94 ±0.28 76.38±0.20 76.41±0.28 76.61±0.4075.38±0.3573.27±0.24 72.73 ±0.29 73.76 ±0.2472.73±0.29 51.29 ±0.24
coqa(opt) 66.42±0.20 70.49 ±0.2573.94±0.63 75.08 ±0.25 75.09 ±0.7675.28±0.23 76.24±0.4975.00±0.2572.31±0.22 72.48 ±0.36 72.89 ±0.2071.63±0.21 46.79 ±0.28
coqa(gpt) 51.57±0.12 64.60 ±0.24 68.45±0.7567.22±0.80 67.77 ±0.48 68.68±0.3767.45±0.83 66.94 ±0.3266.39±0.26 65.34 ±0.54 66.38 ±0.26 – –
nq(llama) 70.61±0.47 71.31 ±0.4274.50±1.32 75.64 ±0.38 75.88 ±0.6875.96±0.42 77.01±0.3376.20±0.3573.10±0.32 72.46 ±0.41 73.03 ±0.2972.77±0.34 58.89 ±0.64
nq(llama2) 69.63±0.49 71.31 ±0.4674.47±0.80 74.85 ±0.51 75.55 ±0.4775.39±0.44 76.06±0.3875.33±0.5273.30±0.46 72.80 ±0.45 73.13 ±0.4872.28±0.44 52.99 ±0.36
nq(opt) 70.22±0.31 61.49 ±0.6075.79±0.58 76.37 ±0.26 77.36 ±0.3378.20±0.38 78.23 ±0.38 78.83±0.3775.36±0.41 75.86 ±0.41 76.50 ±0.3978.09±0.48 46.62 ±0.65
nq(gpt) 58.24±0.35 59.80 ±0.58 63.76±0.62 63.36±0.46 63.61±0.5962.80±0.59 62.34 ±0.48 62.09 ±0.5260.74±0.66 59.39 ±0.72 59.58 ±0.64 – –
m= 20
trivia(llama) 85.55±0.12 79.81 ±0.1388.62±0.31 89.67±0.22 89.75±0.1488.50±0.20 89.65±0.2989.24±0.1286.34±0.09 86.44 ±0.22 86.30 ±0.1088.64±0.08 56.25 ±0.18
trivia(llama2) 86.29±0.12 80.39 ±0.1189.18±0.36 89.95±0.31 90.22±0.2889.04±0.40 90.20±0.2189.75±0.2887.20±0.08 87.36 ±0.21 86.92 ±0.0989.45±0.09 64.40 ±0.16
trivia(opt) 81.53±0.12 70.38 ±0.1885.10±0.13 86.99±0.1086.65±0.0985.41±0.27 86.93±0.15 86.96±0.1282.97±0.09 83.68 ±0.14 84.63 ±0.0885.45±0.11 46.31 ±0.17
trivia(gpt) 66.44±0.23 72.10 ±0.3272.83±0.85 72.74 ±0.84 72.88 ±1.19 73.67±0.31 73.53±0.6472.66±0.3672.68±0.29 71.62 ±0.54 71.46 ±0.28 – –
coqa(llama) 62.96±0.24 71.79 ±0.3476.89±0.77 77.58 ±0.26 78.22 ±0.6677.99±0.33 78.60±0.3178.19±0.2174.37±0.30 74.98 ±0.31 76.47 ±0.2574.10±0.27 48.56 ±0.18
coqa(llama2) 63.36±0.24 71.76 ±0.2276.50±0.66 77.06 ±0.44 77.54 ±0.4177.55±0.26 78.38±0.5576.75±0.3273.72±0.25 73.33 ±0.22 74.80 ±0.2572.98±0.28 51.59 ±0.24
coqa(opt) 66.40±0.14 70.18 ±0.2074.60±0.70 75.66 ±0.40 76.34 ±0.5075.70±0.38 77.39±0.5776.12±0.2272.46±0.23 72.75 ±0.36 73.58 ±0.1971.73±0.19 46.82 ±0.26
coqa(gpt) 51.70±0.10 64.35 ±0.24 69.68±0.3468.18±1.18 68.87 ±0.56 69.80±0.2869.04±0.89 67.50 ±0.3166.95±0.26 65.67 ±0.33 67.11 ±0.25 – –
nq(llama) 70.08±0.46 71.34 ±0.4075.49±1.09 76.13 ±0.35 76.63 ±0.3176.51±0.43 77.80±0.3876.89±0.3973.47±0.32 72.36 ±0.28 73.29 ±0.2873.30±0.41 58.78 ±0.60
nq(llama2) 69.52±0.46 71.09 ±0.4375.44±0.70 75.70 ±0.39 76.39±0.4176.07±0.41 76.65±0.3576.22±0.4474.01±0.45 73.22 ±0.52 73.66 ±0.4272.97±0.47 53.07 ±0.30
nq(opt) 69.62±0.37 59.19 ±0.6176.51±0.34 77.25 ±0.26 78.02 ±0.2578.58±0.34 79.20 ±0.35 79.80±0.3675.45±0.36 76.84 ±0.30 77.38 ±0.2778.17±0.45 46.50 ±0.63
nq(gpt) 59.23±0.45 61.05 ±0.57 65.38±0.71 65.25±0.62 65.02±0.5864.28±0.51 64.32 ±0.45 63.08 ±0.5962.06±0.72 60.79 ±0.62 60.39 ±0.69 – –
Table 14: Accuracy achieved by picking the most confident answer among m= 20generations.
Base Accuracy Ecc(C) Deg(C) Ecc(E) Deg(E) Ecc(J) Deg(J) P(true)
trivia(llama) 61.18±0.07 68.27±0.12 71.78 ±0.1174.04±0.32 75.75 ±0.1574.25±0.06 76.19±0.1055.19±0.15
trivia(llama2) 76.24±0.11 78.22±0.42 78.85±0.1478.68±0.20 78.96±0.2378.41±0.32 78.81±0.1673.36±0.13
trivia(opt) 25.75±0.12 31.86±0.38 31.91 ±0.1539.10±0.28 40.25 ±0.3839.98±0.22 41.63±0.1717.89±0.13
trivia(gpt) 87.42±0.08 87.74±0.16 87.91 ±0.2088.08±0.15 88.36±0.1187.96±0.12 88.15 ±0.11 –
coqa(llama) 62.46±0.11 63.02±0.25 73.48 ±0.1473.96±0.68 76.53 ±0.3374.73±0.17 77.41±0.1256.97±0.21
coqa(llama2) 78.71±0.13 79.64±0.40 80.83±0.1580.30±0.20 80.84±0.1879.91±0.57 80.86±0.1675.36±0.15
coqa(opt) 53.81±0.18 52.01±0.65 63.86 ±0.3067.29±0.33 69.57 ±0.5069.01±0.18 72.64±0.1836.87±0.22
coqa(gpt) 79.76±0.14 79.59±0.30 80.22±0.47 80.13±0.1779.70±0.0979.58±0.17 80.27±0.14 –
nq(llama) 23.63±0.36 26.40±0.62 20.93 ±0.5536.32±0.46 38.59 ±1.0735.84±0.58 40.66±0.5025.16±0.40
nq(llama2) 44.13±0.68 45.18±0.45 46.69 ±0.83 47.47±0.79 47.90 ±0.8146.62±0.48 47.78±0.8441.49±0.74
nq(opt) 8.60±0.18 8.35±0.79 8.03 ±0.29 14.26±0.26 17.25 ±0.3316.26±0.61 18.33±0.405.62±0.29
nq(gpt) 62.72±0.39 63.10±0.69 63.43 ±0.5564.07±0.69 66.05±0.5263.70±0.56 63.90 ±0.56 –
27

--- PAGE 28 ---
Published in Transactions on Machine Learning Research (05/2024)
Table 15: Accuracy achieved by picking the most confident answer among m= 20generations, with tem-
perature of the LLM set to 0.5.
Base Accuracy Ecc(C) Deg(C) Ecc(E) Deg(E) Ecc(J) Deg(J) P(true)
trivia(llama) 74.43±0.10 76.54±0.43 77.44±0.26 77.44±0.30 77.50 ±0.2676.96±0.29 77.48±0.1170.13±0.18
trivia(llama2) 75.92±0.11 77.90±0.25 78.58 ±0.2778.60±0.15 78.91±0.2878.44±0.20 78.80±0.1570.94±0.13
trivia(opt) 40.65±0.13 44.17±0.51 45.30 ±0.15 45.58±0.2645.10±0.1744.68±0.18 45.12 ±0.1834.69±0.16
trivia(gpt) 87.79±0.10 87.99±0.0887.94±0.1087.82±0.10 88.12±0.1487.96±0.11 88.00±0.10 –
coqa(llama) 76.27±0.08 77.23±0.61 79.08 ±0.2778.88±0.19 79.85±0.1479.26±0.09 79.35 ±0.1072.01±0.15
coqa(llama2) 78.36±0.12 79.04±0.33 80.63 ±0.2379.71±0.43 81.00±0.2280.19±0.47 80.56 ±0.1373.20±0.17
coqa(opt) 70.40±0.15 72.31±0.16 73.78 ±0.2172.97±0.43 74.08±0.1972.93±0.58 74.19±0.1662.99±0.21
coqa(gpt) 80.02±0.13 80.02±0.17 80.67±0.1880.02±0.19 79.69 ±0.2080.05±0.20 80.03 ±0.14 –
nq(llama) 40.72±0.56 42.24±0.65 44.34 ±0.6945.20±0.63 46.73±0.8644.21±1.24 45.34 ±0.7138.46±0.74
nq(llama2) 44.01±0.64 46.05±0.75 46.76 ±0.6046.89±0.63 47.93±0.6346.64±0.61 47.76±0.7541.48±0.58
nq(opt) 18.18±0.37 19.10±0.42 20.66 ±0.45 21.93±0.42 22.25 ±0.73 22.06±0.45 22.28 ±0.3915.16±0.31
nq(gpt) 62.90±0.45 63.74±0.72 63.00 ±0.5063.35±0.35 65.26±0.4463.77±0.50 62.93 ±0.49 –
Table 16: Adaptive Calibration Error after applying Histogram Binning Zadrozny & Elkan (2001). Lower is
better.
Baselines Ours White-box
ACE (in 10−2) NumSet LexiSim EigV(C) Ecc(C) Deg(C) EigV(E) Ecc(E) Deg(E) EigV(J) Ecc(J) Deg(J) SE P(true)
trivia(llama) 3.68±0.54 3.68 ±0.883.24±0.67 2.54 ±0.63 2.49 ±0.533.00±0.52 2.60 ±0.51 2.37 ±0.603.49±0.73 2.93 ±0.56 2.72 ±0.834.56±1.10 4.30 ±1.01
trivia(llama2) 3.06±0.49 3.05 ±0.712.65±0.53 2.82 ±0.69 2.75 ±0.632.76±0.39 2.73 ±0.64 2.67 ±0.652.93±0.60 3.11 ±0.68 3.01 ±0.492.58±0.59 4.43 ±0.71
trivia(opt) 3.20±0.70 3.34 ±0.653.16±0.62 2.38 ±0.58 2.84 ±0.863.11±0.51 2.15 ±0.50 2.64 ±0.512.83±0.44 2.62 ±0.60 2.59 ±0.533.16±0.62 4.19 ±0.79
trivia(gpt) 3.02±0.54 2.93 ±0.542.78±0.74 2.68 ±0.51 2.83 ±0.622.54±0.54 2.89 ±0.72 2.82 ±0.592.59±0.52 2.47 ±0.71 2.75 ±0.76 – –
coqa(llama) 4.78±1.01 4.30 ±0.663.78±0.86 3.92 ±0.54 3.54 ±0.634.08±1.17 3.05 ±0.51 3.33 ±0.673.70±0.59 3.32 ±0.77 3.27 ±0.783.85±0.69 4.91 ±1.37
coqa(llama2) 3.68±0.40 3.67 ±0.383.87±0.63 3.32 ±0.44 3.62 ±0.803.58±0.60 3.07 ±0.85 3.07 ±0.643.38±0.36 3.58 ±0.78 3.27 ±0.723.62±0.54 4.16 ±0.73
coqa(opt) 4.79±0.86 4.10 ±0.764.04±0.78 4.73 ±0.89 3.61 ±0.534.04±0.58 3.69 ±0.97 3.39 ±0.604.59±0.73 3.74 ±0.90 3.79 ±0.684.06±0.67 4.48 ±0.51
coqa(gpt) 4.32±0.91 3.46 ±0.623.80±0.43 3.73 ±0.96 3.28 ±0.753.59±0.74 3.62 ±0.64 3.80 ±0.693.90±0.54 3.71 ±0.85 3.81 ±0.62 – –
nq(llama) 4.71±0.96 3.54 ±0.724.07±0.92 4.51 ±1.05 4.23 ±0.784.20±0.66 3.82 ±0.94 3.86 ±0.574.12±0.73 3.80 ±0.57 3.57 ±0.864.45±1.03 4.66 ±1.08
nq(llama2) 5.02±0.72 4.68 ±0.695.01±0.94 5.52 ±1.33 5.23 ±1.034.99±1.24 4.69 ±0.89 4.87 ±1.105.17±0.92 5.22 ±1.11 5.25 ±1.405.38±0.96 5.89 ±1.16
nq(opt) 3.20±0.77 3.32 ±0.343.01±0.31 2.87 ±0.46 3.12 ±0.712.67±0.67 2.64 ±0.62 2.40 ±0.732.87±0.66 2.57 ±0.52 2.54 ±0.562.96±0.82 4.09 ±0.54
nq(gpt) 5.09±0.54 5.06 ±0.625.64±0.99 5.00 ±0.94 4.71 ±0.585.09±0.63 5.72 ±0.73 5.67 ±1.064.79±1.10 5.05 ±1.12 4.71 ±1.22 – –
28

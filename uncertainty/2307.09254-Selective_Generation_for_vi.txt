# 2307.09254.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/uncertainty/2307.09254.pdf
# Kích thước tệp: 913559 byte

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Sinh Tạo Có Chọn Lọc cho
Các Mô Hình Ngôn Ngữ Có Thể Kiểm Soát
Minjae Lee*
GSAI
POSTECH
minjae.lee@postech.ac.krKyungmin Kim*
GSAI
POSTECH
kkm959595@postech.ac.kr
Taesoo Kim
SCS & SCP
GaTech
taesoo@gatech.eduSangdon Park
GSAI & CSE
POSTECH
sangdon@postech.ac.kr
Tóm tắt
Độ tin cậy của các mô hình ngôn ngữ sinh tạo (GLM) là rất quan trọng trong việc triển khai chúng cho các hệ thống ra quyết định quan trọng. Do đó, các phương pháp kiểm soát rủi ro được chứng nhận như dự đoán có chọn lọc và dự đoán conformal đã được áp dụng để giảm thiểu vấn đề ảo giác trong các tác vụ hạ tầng có giám sát khác nhau. Tuy nhiên, việc thiếu các thước đo tính đúng đắn phù hợp đã cản trở việc áp dụng các phương pháp có nguyên tắc này cho các tác vụ sinh tạo ngôn ngữ. Trong bài báo này, chúng tôi giải quyết vấn đề này bằng cách tận dụng khái niệm kéo theo văn bản để đánh giá tính đúng đắn của chuỗi được sinh tạo, và đề xuất hai thuật toán sinh tạo có chọn lọc kiểm soát tỷ lệ phát hiện sai liên quan đến quan hệ kéo theo văn bản (FDR-E) với đảm bảo lý thuyết: SGenSup và SGenSemi. SGenSup, một sửa đổi trực tiếp của dự đoán có chọn lọc, là một thuật toán học có giám sát khai thác dữ liệu được gán nhãn kéo theo, được chú thích bởi con người. Vì chú thích của con người tốn kém, chúng tôi tiếp tục đề xuất một phiên bản bán giám sát, SGenSemi, hoàn toàn sử dụng dữ liệu không được gán nhãn bằng pseudo-labeling, tận dụng một hàm tập kéo theo được học thông qua dự đoán conformal. Hơn nữa, SGenSemi cho phép sử dụng lớp các hàm lựa chọn tổng quát hơn, các hàm lựa chọn thần kinh, và cung cấp cho người dùng một lớp hàm lựa chọn tối ưu khi cho nhiều ứng viên. Cuối cùng, chúng tôi chứng minh hiệu quả của họ SGen trong việc đạt được mức FDR-E mong muốn với hiệu suất lựa chọn có thể so sánh với các phương pháp cơ sở trên cả GLM nguồn mở và đóng. Mã và bộ dữ liệu được cung cấp tại https://github.com/ml-postech/selective-generation .

1 Giới thiệu
Các mô hình ngôn ngữ sinh tạo (GLM) [1,2,3,4] đã thu hút sự chú ý đáng kể vì khả năng tạo ra ngôn ngữ ở mức con người [5] chủ yếu do các kiến trúc transformer cơ bản [6]. Tuy nhiên, GLM gây ra mối lo ngại về việc tạo ra các sự thật ảo giác [7], đây là một đặc tính không mong muốn khi chúng được sử dụng làm nguồn truy xuất kiến thức. Vấn đề này có thể được giảm thiểu bằng cách tinh chỉnh với phản hồi của con người [7,8], nhưng nó vẫn tốn kém về chi phí đào tạo và gán nhãn. Các phương pháp kiểm soát rủi ro được chứng nhận như dự đoán có chọn lọc [9] và dự đoán conformal [10] là những lựa chọn thay thế tiết kiệm chi phí đầy hứa hẹn, đã được áp dụng để giảm thiểu ảo giác trong các tác vụ hạ tầng có giám sát khác nhau [9, 10, 11, 12, 13, 14].

*Đóng góp bằng nhau
Hội nghị lần thứ 38 về Hệ thống Xử lý Thông tin Thần kinh (NeurIPS 2024).arXiv:2307.09254v4  [cs.LG]  27 Tháng 1 2025

--- TRANG 2 ---
Hình 1: Tổng quan và kết quả định tính của phương pháp chúng tôi với GPT-3.5-Turbo. Điểm mấu chốt là học một bộ sinh tạo có chọn lọc nhận thức kéo theo với tùy chọn từ chối kiểm soát tỷ lệ ảo giác (trong tỷ lệ phát hiện sai) trên các chuỗi được sinh tạo với đảm bảo xác suất.

Nút thắt cổ chai chính trong việc áp dụng các phương pháp được chứng nhận như vậy cho các tác vụ sinh tạo ngôn ngữ là các đảm bảo kiểm soát rủi ro được cung cấp yêu cầu nhãn tính đúng đắn trong quá trình học. Cụ thể, trong phân loại, nhãn tính đúng đắn chất lượng cao có thể được thu thập trực tiếp bằng cách so sánh nhãn thực và nhãn dự đoán sử dụng khớp chính xác (EM). Tuy nhiên, điều này không đúng cho các tác vụ sinh tạo ngôn ngữ, vì nhiều câu trả lời hợp lệ có thể tồn tại cho cùng một câu hỏi. Vì các thước đo tính đúng đắn như EM và F1-score không tính đến nhiều câu trả lời hợp lệ, việc áp dụng trực tiếp chúng cho các tác vụ sinh tạo ngôn ngữ dẫn đến một khoảng cách đáng kể giữa tính đúng đắn thực và được đo, mà chúng tôi gọi là sự không phù hợp thước đo. Do đó, một thước đo đánh giá tính đúng đắn tính đến nhiều câu trả lời là cần thiết.

Trong bài báo này, chúng tôi giải quyết vấn đề không phù hợp thước đo bằng cách tận dụng kéo theo văn bản để đánh giá tính đúng đắn của các câu trả lời được sinh tạo và định nghĩa tỷ lệ phát hiện sai liên quan đến quan hệ kéo theo văn bản (FDR-E). Cho hai chuỗi có thứ tự, một tiền đề và một giả thuyết, chúng tôi nói rằng tiền đề kéo theo giả thuyết nếu giả thuyết là đúng khi cho tiền đề. Dựa trên khái niệm kéo theo này, chúng tôi đề xuất hai thuật toán sinh tạo có chọn lọc, SGenSup và SGenSemi, là các phiên bản tổng quát của phân loại có chọn lọc [9] để kiểm soát FDR-E bằng cách từ chối trả về câu trả lời khi GLM không chắc chắn về câu trả lời của nó.

Cụ thể, SGenSup, một sửa đổi trực tiếp của [9], là một thuật toán học bộ sinh tạo có chọn lọc có giám sát yêu cầu nhãn kéo theo. Điều này đòi hỏi chú thích của con người về kéo theo văn bản, trong đó câu trả lời được sinh tạo là tiền đề và câu trả lời thực là giả thuyết. Vì gán nhãn tốn kém và SGenSup chỉ dựa vào dữ liệu được gán nhãn kéo theo, chúng tôi đề xuất một phương pháp bán giám sát, SGenSemi, cho phép khai thác dữ liệu không được gán nhãn kéo theo trong việc học một bộ sinh tạo có chọn lọc bằng pseudo-labeling kéo theo văn bản sử dụng một hàm tập kéo theo được học thông qua dự đoán conformal [10]. Dựa trên một bộ phân loại kéo theo được phát triển ban đầu cho vấn đề suy luận ngôn ngữ tự nhiên [15,16], hàm tập kéo theo được ước tính xấp xỉ một hàm tập kéo theo thực, trả về tất cả các câu trả lời được kéo theo nếu một câu trả lời thực được cho như một giả thuyết.

Ngoài ra, SGenSemi giới thiệu lớp tổng quát các hàm lựa chọn cho sinh tạo có chọn lọc, được gọi là các hàm lựa chọn thần kinh. Trong dự đoán có chọn lọc, học một bộ dự đoán có chọn lọc tương đương với học một hàm lựa chọn, là một hàm chỉ báo để quyết định có nên từ chối trả về dự đoán hay không. Thuật toán dự đoán có chọn lọc tiêu chuẩn [9] xem xét lớp các hàm chỉ báo ngưỡng đơn sử dụng một hàm tỷ lệ tin cậy được chỉ định trước. Đối với cùng một mức rủi ro, hàm tỷ lệ tin cậy định lượng độ không chắc chắn của mô hình càng tốt, bộ dự đoán có chọn lọc càng ít có khả năng từ chối đưa ra dự đoán. Chúng tôi gọi đây là hiệu suất lựa chọn từ nay về sau. Vì hiệu chuẩn tin cậy phù hợp cho sinh tạo ngôn ngữ vẫn là thách thức, tối ưu hóa một hàm chỉ báo ngưỡng đơn với một hàm tỷ lệ tin cậy được hiệu chuẩn kém dẫn đến hiệu suất lựa chọn thấp. Thay vào đó, chúng tôi tổng quát hóa hàm lựa chọn bằng cách sử dụng một hàm chỉ báo ngưỡng đa với các đặc trưng có thể huấn luyện. Hơn nữa, SGenSemi cung cấp cho người dùng một lớp tối ưu các hàm lựa chọn trong số các ứng viên có thể về mặt FDR-E.

Cuối cùng, chúng tôi chứng minh thực nghiệm hiệu quả của SGenSemi trên các GLM nguồn mở và đóng, trong đó chúng tôi xem SGenSup như một trong các phương pháp cơ sở của chúng tôi vì nó là một sửa đổi trực tiếp của [9]. Để xác thực phương pháp của chúng tôi và đảm bảo lý thuyết của nó, chúng tôi tạo ra một bộ dữ liệu mới về kéo theo văn bản sử dụng bộ dữ liệu Natural Questions (NQ) [17] cho mỗi GLM. Cho một cặp câu hỏi và câu trả lời, kéo theo văn bản được gán nhãn bằng cách để câu trả lời được sinh tạo như một tiền đề và câu trả lời thực ở dạng tuyên bố như một giả thuyết. Vì các cộng đồng thiếu dữ liệu được gán nhãn kéo theo do con người chú thích cho sinh tạo ngôn ngữ, chúng tôi tin rằng bộ dữ liệu của chúng tôi góp phần vào đánh giá ảo giác của GLM. Đối với cả GLM nguồn mở và đóng, SGenSemi hiệu quả trong việc đạt được mức FDR-E mong muốn với hiệu suất lựa chọn tốt hơn so với các phương pháp cơ sở.

1.1 Công trình liên quan
Chúng tôi giới thiệu hai hướng nghiên cứu chính để giảm thiểu ảo giác trong GLM.

Phương pháp heuristic cho giảm thiểu ảo giác. Ảo giác trong sinh tạo ngôn ngữ thường đề cập đến tình huống trong đó GLM tạo ra câu trả lời sai với độ tin cậy cao, điều này cản trở việc triển khai đáng tin cậy của GLM. Vì các phương pháp tinh chỉnh tốn kém, các phương pháp heuristic để giảm thiểu ảo giác mà không cần điều chỉnh đã được đề xuất [18,19]. Đáng chú ý, [19] đề xuất một phương pháp phát hiện ảo giác hiệu quả, định lượng tự nhất quán giữa nhiều câu trả lời được sinh tạo cho cùng một câu hỏi sử dụng các mô hình kéo theo văn bản để phát hiện ảo giác. Tuy nhiên, các phương pháp này không cung cấp kiểm soát được chứng nhận về sự xuất hiện của nội dung ảo giác.

Các phương pháp được chứng nhận cho giảm thiểu ảo giác. Dự đoán conformal xuất ra một tập dự đoán được đảm bảo chứa một nhãn thực với xác suất cao, trong đó đảm bảo độ bao phủ được cung cấp là bất khả tri mô hình dưới một giả định nhẹ về dữ liệu [10]. Mặc dù đặc tính này cho phép triển khai an toàn các mô hình phức tạp và đã làm cho dự đoán conformal trở nên phổ biến [10,12,13,20,21,22], các tập dự đoán được xây dựng trong sinh tạo ngôn ngữ thường ít thông tin do không gian nhãn không giới hạn, điều này thường làm cho đảm bảo độ bao phủ trở nên không hiệu quả [23,24]. Để hạn chế tập dự đoán ở kích thước vừa phải, [23] xây dựng tập dự đoán trên các câu trả lời bằng cách lấy mẫu chúng tuần tự, trong khi vẫn thỏa mãn đảm bảo độ bao phủ. Tuy nhiên, việc lựa chọn sau các câu trả lời từ tập dự đoán là cần thiết cho việc ra quyết định cuối cùng, điều này có thể dẫn đến bias lựa chọn [25,26]. [27,28] phân tách các câu trả lời được sinh tạo thành các tuyên bố phụ được gán nhãn liên kết và trả về một tập các tuyên bố phụ không chứa mâu thuẫn với xác suất cao thông qua dự đoán conformal. Mặc dù việc lựa chọn sau là không cần thiết, nó yêu cầu nhãn liên kết đắt đỏ cho mọi tuyên bố phụ. Khác với dự đoán conformal, dự đoán có chọn lọc trực tiếp quản lý rủi ro mục tiêu ở mức mong muốn bằng cách giới thiệu tùy chọn từ chối trên các dự đoán không chắc chắn. [9] đề xuất một phương pháp dự đoán có chọn lọc chủ yếu cho phân loại, học một hàm lựa chọn dựa trên ngưỡng kiểm soát tỷ lệ phát hiện sai (FDR) ở mức mong muốn. [24] tổng quát hóa dự đoán có chọn lọc cho sinh tạo ngôn ngữ. Tuy nhiên, đảm bảo lý thuyết của họ không tập trung vào rủi ro mục tiêu để kiểm soát, mà vào một đặc tính nhất quán của một hàm mất mát thay thế liên quan đến một hàm mất mát thực trong quá trình tối ưu hóa. [29], được xuất bản đồng thời với bài báo của chúng tôi, đề xuất một phương pháp sinh tạo có chọn lọc được chứng nhận cho sinh tạo ngôn ngữ được cung cấp ngữ cảnh kiểm soát FDR. Khác với [9] lấy số lượng mẫu được chọn làm ràng buộc trong việc học hàm lựa chọn, [29] đặt công suất làm ràng buộc. Tuy nhiên, như [24] làm, họ yêu cầu một tập hiệu chuẩn bổ sung để huấn luyện một hàm tính điểm kéo theo. Quan trọng, trong khi các phương pháp sinh tạo có chọn lọc hiện có là các phương pháp học có giám sát, chúng tôi đề xuất một thuật toán học bán giám sát có thể tận dụng đầy đủ dữ liệu không được gán nhãn kéo theo.

2 Kiến thức nền
Trong khi chúng tôi xem xét các tác vụ sinh tạo ngôn ngữ tổng quát, chúng tôi giới hạn phạm vi của mình cho tác vụ trả lời câu hỏi mở và định nghĩa ký hiệu tương ứng để rõ ràng và duy trì tính nhất quán trong các mô tả về thí nghiệm. Cụ thể, hãy W biểu thị một không gian token được xây dựng sử dụng một tokenizer, như Byte Pair Encoding [30], và hãy W* biểu thị một không gian chuỗi token, được định nghĩa là W*:=∪∞i=0Wi. Hãy (x,y) ∈ X × Y là một cặp chuỗi câu hỏi và câu trả lời, trong đó X:=W* và Y:=W* đề cập đến các không gian chuỗi token của câu hỏi và câu trả lời, tương ứng. Chúng tôi giả định chuỗi câu trả lời ở dạng tuyên bố. Cuối cùng, xi:j đề cập đến chuỗi con của x từ token thứ i đến thứ j.

2.1 Sinh tạo ngôn ngữ
Cho một câu hỏi làm đầu vào, GLM sinh ra một câu trả lời thông qua quá trình tuần tự được gọi là giải mã, mà chúng tôi gọi là sinh tạo ngôn ngữ. Ở đây, chúng tôi xem xét giải mã tham lam, một quá trình sinh tạo xác định được mô tả như sau. Hãy pM: X × W → R≥0 biểu thị một GLM trả về phân phối token tiếp theo cho chuỗi đầu vào x, trong đó ∑w∈W pM(w|x) = 1 cho tất cả x ∈ X. Một bộ sinh tạo ngôn ngữ G: X → Y sử dụng giải mã tham lam tuần tự sinh ra các token từ GLM như sau: ŷi := arg maxw∈W pM(w|(x,ŷ1:i−1)) cho i ≥ 2 và ŷ1 := arg maxw∈W pM(w|x). Bộ sinh tạo G trả về một câu trả lời được sinh tạo ŷ := G(x) và kết thúc quá trình giải mã khi token kết thúc chuỗi (EOS) được trả về. Ở đây, xác suất có điều kiện của câu trả lời ŷ được định nghĩa là fM(x,ŷ) := pM(ŷ1|x)∏|ŷ|i=2 pM(ŷi|(x,ŷ1:i−1)), thường được sử dụng như thước đo độ không chắc chắn của nó.

2.2 Dự đoán có chọn lọc
Dự đoán có chọn lọc từ chối đưa ra dự đoán bằng cách trả về "Tôi không biết" (IDK) nếu dự đoán không chắc chắn. Trong phân loại, bộ phân loại có chọn lọc Ŝ bao gồm một cặp bộ phân loại ŷ và một hàm lựa chọn ŝ, và được định nghĩa như sau: Ŝ(x) := {G(x) nếu ŝ(x) = 1, IDK trong trường hợp khác}, trong đó ŷ(x) := arg maxy∈Y f(x, y). Ở đây, f(x, y) đề cập đến khả năng ước tính của đầu vào x cho để là lớp y, được xác định bởi một mô hình phân loại cơ bản f. Mặc dù hàm lựa chọn có thể có dạng tùy ý, lựa chọn phổ biến là một hàm chỉ báo ngưỡng đơn sử dụng khả năng tối đa như hàm tỷ lệ tin cậy, tức là ŝ(x) := 1(f(x,ŷ) ≥ τ). Ở đây, hàm tỷ lệ tin cậy được định nghĩa để định lượng độ không chắc chắn của dự đoán của mô hình. Dưới giả định độc lập và phân phối giống hệt nhau (i.i.d.), [9] đề xuất thuật toán học ngưỡng được chứng nhận kiểm soát tỷ lệ phát hiện sai (FDR) liên quan đến thước đo EM với đảm bảo PAC, trong đó FDR được định nghĩa là REM(Ŝ) := P{ŷ(x) ≠ y|Ŝ(x) ≠ IDK}. Vì EM xem câu trả lời ŷ(x) là đúng khi nó hoàn toàn giống với câu trả lời tham khảo y, nó là một thước đo tính đúng đắn không phù hợp cho các vấn đề sinh tạo ngôn ngữ có thể có nhiều chuỗi hợp lệ cho cùng một đầu vào. Điều này dẫn đến việc học một hàm lựa chọn quá thận trọng và vô nghĩa cho sinh tạo ngôn ngữ, được xác minh thực nghiệm bởi các thí nghiệm của chúng tôi. Do đó, chúng tôi tận dụng kéo theo văn bản để đánh giá tính đúng đắn của chuỗi được sinh tạo để giảm thiểu vấn đề không phù hợp thước đo.

2.3 Kéo theo văn bản
Suy luận ngôn ngữ tự nhiên (NLI), cũng được ký hiệu là nhận biết kéo theo văn bản, dự đoán liệu một chuỗi có hàm ý một chuỗi khác hay không. Chuỗi trước đề cập đến một tiền đề (p), và chuỗi sau đề cập đến một giả thuyết (h). Kể từ khi phát hành hai tiêu chuẩn quy mô lớn của các cặp chuỗi có thứ tự được gán nhãn với kéo theo văn bản [15,16], một số bộ phân loại kéo theo dựa trên transformer đã được đề xuất và cho thấy kết quả ấn tượng. Mỗi cặp được phân loại vào một trong ba danh mục: kéo theo nếu h đúng khi cho p; mâu thuẫn nếu h sai khi cho p; và trung tính trong trường hợp khác. Trong bài báo này, chúng tôi định nghĩa hàm tính điểm kéo theo là fE(G(x),y) := 1−pE(contradict |p=G(x),h=y) để ước tính và pseudo-label tính đúng đắn của G(x), trong đó pE(contradict |p=G(x),h=y) là khả năng G(x) mâu thuẫn với y. Trong khi pseudo-labeling cho phép khai thác đầy đủ dữ liệu không được gán nhãn để học một hàm lựa chọn, kiểm soát lỗi gán nhãn sai vẫn là một thách thức.

2.4 Dự đoán Conformal
Dự đoán conformal [10] xuất ra một tập dự đoán để định lượng độ không chắc chắn của một mô hình cho trước với đảm bảo tính đúng đắn bất khả tri mô hình dưới các giả định tối thiểu về quá trình tạo dữ liệu. Cụ thể, dưới giả định i.i.d., dự đoán conformal PAC [11] kết hợp việc diễn giải các vùng dung sai [31] và dự đoán conformal quy nạp có điều kiện huấn luyện [20] thông qua góc nhìn của lý thuyết học PAC [32]. Trong bài báo này, chúng tôi áp dụng thuật toán học tập dự đoán PAC để kiểm soát tỷ lệ lỗi gán nhãn sai trong các mẫu pseudo-labeled được sử dụng để học một hàm lựa chọn cho sinh tạo có chọn lọc. Xem Phần A.1 để thảo luận chi tiết về dự đoán conformal.

Tập Conformal tham số hóa bằng vô hướng. Trong bài báo này, chúng tôi xem xét một tập conformal C: X → 2Y được tham số hóa bởi một vô hướng [11,33] là C(x) := {y ∈ Y | f(x, y) ≥ τ}, trong đó τ ∈ H là một tham số vô hướng để học, H là một không gian giả thuyết (ví dụ, H là các số thực không âm được rời rạc hóa mịn), và f: X × Y → R≥0 được gọi là một hàm tính điểm. Hàm tính điểm tương ứng với một mô hình mục tiêu có độ không chắc chắn cần được định lượng, trong đó đầu ra softmax là lựa chọn phổ biến trong phân loại. Cụ thể, f(x, y) đo khả năng của y như một phản hồi cho x như đầu vào.

Đảm bảo PAC. Thuật toán học tập dự đoán PAC xuất ra một tập conformal Ĉ giới hạn trên tỷ lệ không bao phủ RMC(Ĉ) := P{y ∉ Ĉ(x)} đến mức mong muốn ε ∈ (0,1), trong đó tỷ lệ không bao phủ có thể được tổng quát hóa thành rủi ro R01(Ĉ) := E{ℓ01(Ĉ,x, y)}, trên bất kỳ mất mát chỉ báo nào đơn điệu liên quan đến τ. Thuật toán có thể đúng xấp xỉ (PAC) theo nghĩa nó cung cấp đảm bảo có điều kiện dữ liệu hiệu chuẩn tại mọi mức rủi ro và tin cậy. Cụ thể, nó kiểm soát rủi ro đến mức mong muốn bất kể dữ liệu hiệu chuẩn nào được sử dụng để học Ĉ với tin cậy mong muốn δ ∈ (0,1) như sau: P{R01(Ĉ) ≤ ε} ≥ 1−δ, trong đó xác suất được lấy trên tập hiệu chuẩn Z ∼ Dn để học tập conformal. Trong bài báo này, chúng tôi tận dụng tập conformal PAC cho một hàm pseudo-labeling sao cho đảm bảo về chất lượng gán nhãn cung cấp đảm bảo PAC tổng thể trong thuật toán học bộ sinh tạo có chọn lọc bán giám sát.

Thuật toán. Thuật toán học tập conformal PAC ABinom : (X × Y)* → H [11,20,34] trả về tham số tập conformal τ̂, trong đó H là một R≥0 được rời rạc hóa mịn. Cụ thể, thuật toán trả về τ̂ = max τ∈H τ chịu điều kiện UBinom(kτ;n, δ) ≤ ε, trong đó kτ := ∑ni=1 ℓ01(Ĉ,xi, yi). Để F(k;n, θ) là một hàm phân phối tích lũy của phân phối nhị thức với n thử nghiệm và xác suất thành công θ, UBinom(k;n, δ) := inf{θ ∈ [0,1]|F(k;n, θ) ≤ δ} ∪ {1} là một giới hạn đuôi nhị thức trên thỏa mãn P{R01(Ĉ) ≤ UBinom(kτ;n, δ)} ≥ 1−δ, trong đó δ là tin cậy mong muốn. Lưu ý rằng chúng tôi tương tự ký hiệu một giới hạn đuôi nhị thức dưới bằng LBinom. Nếu tối ưu hóa trong thuật toán ABinom không khả thi, thuật toán trả về τ̂ = 0, một tập conformal vô nghĩa. Do đó, thuật toán là PAC, và xem Phần A.1 để chứng minh.

2.5 Hiệu chuẩn
Trong phân loại, hiệu chuẩn nhằm điều chỉnh phản hồi khả năng tối đa của bộ phân loại, hoặc tin cậy, để đúng. Chúng tôi nói phản hồi bộ phân loại f: X × Y → R≥0 được hiệu chuẩn hoàn hảo liên quan đến phân phối D trên X × Y và một bộ phân loại ŷ nếu P{y = ŷ(x)|f(x,ŷ(x)) = t} = t cho tất cả t ∈ [0,1] [35,36]. Hiệu chuẩn nhằm tìm phản hồi bộ phân loại sao cho nó được hiệu chuẩn hoàn hảo một cách tiệm cận. Trong bài báo này, chúng tôi tạo ra một kết nối thú vị giữa hiệu chuẩn và sinh tạo có chọn lọc. Cụ thể, cho định nghĩa hiệu chuẩn hoàn hảo cho một hàm tính điểm ngôn ngữ fM, chúng tôi chính thức cung cấp một điều kiện đủ cho một bộ sinh tạo có chọn lọc để kiểm soát FDR liên quan đến quan hệ kéo theo văn bản tại bất kỳ mức rủi ro mong muốn nào.

3 Vấn đề: Sinh tạo có chọn lọc
Hãy x ∈ X là một câu hỏi và y ∈ Y là một câu trả lời, giả định rằng mỗi câu hỏi có một câu trả lời mong muốn. Ở đây, chúng tôi giả định (x,y) i.i.d. ∼ D′, trong đó D′ là một quá trình tạo dữ liệu của các cặp trả lời câu hỏi. Sau đó, cho một bộ sinh tạo G: X → Y, chúng tôi xem xét một bộ sinh tạo có chọn lọc Ŝ: X → Y ∪ {IDK} từ chối trả về G(x) nếu một hàm lựa chọn ŝ(x, G(x)) ∈ {0,1} coi là không chắc chắn như sau:

Ŝ(x) := {G(x) nếu ŝ(x, G(x)) = 1, IDK trong trường hợp khác}.

Mục tiêu chính của chúng tôi là học một bộ sinh tạo có chọn lọc Ŝ để kiểm soát một tỷ lệ phát hiện sai tổng quát (FDR) liên quan đến một quan hệ R là

RR(Ŝ) := P{(G(x),y) ∉ R|Ŝ(x) ≠ IDK}. (1)

Ở đây, xác suất được lấy trên các ví dụ (x,y, e, v), trong đó e := 1((G(x),y) ∈ R) là một nhãn bổ sung cần được chú thích do R không biết và v ∈ {0,1} là một cờ khả kiến của e cho học bán giám sát. Đối với việc tạo dữ liệu của (x,y, e, v), chúng tôi giả định rằng một nhãn e được quan sát với xác suất thành công không biết pv, độc lập với quá trình sinh của (x,y, e), tức là (x,y, e, v) ∼ D := D′ · V, trong đó D′ là một phân phối trên X × Y × {0,1} và V := Bernoulli(pv). Lưu ý rằng định nghĩa của e, D′ thay đổi theo bộ sinh tạo G ngay cả với cùng phân phối tạo dữ liệu của (x,y). Trong bài báo này, chúng tôi thiết kế một thuật toán học A trả về một bộ sinh tạo có chọn lọc Ŝ để kiểm soát FDR tổng quát liên quan đến R trong mức mong muốn ε ∈ (0,1) với xác suất ít nhất 1−δ ∈ (0,1), tức là P{RR(A(Z)) ≤ ε} ≥ 1−δ. Ở đây, xác suất được lấy trên một tập hiệu chuẩn Z ∼ Dn. Đảm bảo này được gọi là đảm bảo có thể đúng xấp xỉ (PAC) [32]. Trong số các bộ sinh tạo có chọn lọc thỏa mãn đảm bảo PAC, chúng tôi chọn một cái giảm thiểu tỷ lệ câu trả lời IDK với hiệu suất lựa chọn cao nhất. Thách thức chính là tìm một thuật toán PAC hiệu quả về mẫu và lựa chọn cho bất kỳ ε và δ cùng với thiết kế một quan hệ R cho các nhãn có cấu trúc, như trong trả lời câu hỏi. Thường xuyên, chúng tôi có thể không thu được thuật toán PAC cho bất kỳ ε nào, vì vậy trong bài báo này, chúng tôi sử dụng khái niệm có thể kiểm soát được nới lỏng thay vì đúng nếu thuật toán cung cấp rủi ro đạt được tối thiểu vượt quá ε cho trước.

4 Học bán giám sát cho sinh tạo có chọn lọc có thể kiểm soát
Trong bài báo này, chúng tôi tận dụng kéo theo văn bản như thước đo đánh giá trong sinh tạo ngôn ngữ để xem xét nhiều câu trả lời hợp lệ một cách có nguyên tắc, và đề xuất hai thuật toán học bộ sinh tạo có chọn lọc kiểm soát FDR liên quan đến kéo theo văn bản: SGenSup và SGenSemi.

4.1 Tỷ lệ phát hiện sai thông qua kéo theo văn bản (FDR-E)
Một quan hệ kéo theo văn bản RE là một tập con có thứ tự của Y × Y trong đó (y′,y) ∈ RE nếu y′ kéo theo y. Trong trả lời câu hỏi như một ví dụ, câu trả lời được sinh tạo G(x) đúng nếu câu trả lời tham khảo y là một hệ quả logic của G(x). Nói cách khác, G(x) hợp lệ nếu G(x) ∈ Etrue(y), trong đó hàm tập kéo theo thực Etrue: Y → 2Y được định nghĩa như sau: Etrue(y) := {y′ ∈ Y | (y′,y) ∈ RE}. Sau đó, một FDR liên quan đến quan hệ kéo theo RE (FDR-E) mà chúng tôi nhằm kiểm soát như sau:

RRE(Ŝ) := P{G(x) ∉ Etrue(y)|Ŝ(x) ≠ IDK},

trong đó xác suất được lấy trên các ví dụ được gán nhãn, tức là (x,y, e) ∼ D. Ở đây, nhãn e được gọi cụ thể là nhãn kéo theo, tức là e := G(x) ∈ Etrue(y). Sau đó, đối với bất kỳ G, D, V và Ŝ, FDR-E có thể được phân tách như sau:

PDŜ{G(x) ∉ Etrue(y)} = PDŜ{v = 1}PDŜ{e = 0} + PDŜ{v = 0}PDŜ{e = 0}, (2)

trong đó PDŜ{·} := P{· |Ŝ(x) ≠ IDK}. Lưu ý rằng vì (x,y, e) và v độc lập, (A), (C), và (E) trong (2) có cùng số lượng, đó là rủi ro mục tiêu mà chúng tôi nhằm tìm một giới hạn trên.

4.2 Giới hạn FDR-E cho học có giám sát
Chúng tôi đầu tiên đề xuất thuật toán học có giám sát SGenSup (Thuật toán 8), một sửa đổi trực tiếp của [9] cho các tác vụ sinh tạo ngôn ngữ. Cụ thể, SGenSup là một phương pháp có giám sát theo nghĩa nó chỉ khai thác các ví dụ được gán nhãn ZE := {(x,y, e)|(x,y, e, v) ∈ Z ∧ v = 1} để học một bộ sinh tạo có chọn lọc kiểm soát giới hạn trên (C) trong (2). Lưu ý rằng đối với học có giám sát, chúng tôi giả định (B) trong (2) luôn là 1, vì vậy chúng tôi chỉ xem xét giới hạn trên (C) thông qua giới hạn đuôi nhị thức như [9].

4.3 Giới hạn FDR-E cho học bán giám sát
Vì SGenSup yêu cầu chú thích của con người cho nhãn kéo theo và không sử dụng các ví dụ không được gán nhãn dồi dào ZU := {(x,y)|(x,y, e, v) ∈ Z ∧ v = 0}, chúng tôi tiếp tục đề xuất một thuật toán học bán giám sát mới SGenSemi (Thuật toán 5), khai thác đầy đủ cả ZE và ZU trong khi kiểm soát FDR-E trong (2). Cụ thể, chúng tôi (1) ước tính một tập kéo theo thực Etrue thông qua dự đoán conformal với các ví dụ được gán nhãn ZE và sau đó (2) sử dụng tập kéo theo ước tính Ê để chú thích pseudo-labels trên ZU. Cuối cùng, chúng tôi (3) sử dụng cả các ví dụ được gán nhãn và pseudo-labeled để học một bộ sinh tạo có chọn lọc. Thú vị, thuật toán trông có vẻ heuristic này có thể là một thuật toán nghiêm ngặt kiểm soát FDR-E của một bộ sinh tạo có chọn lọc, sẽ được mô tả trong các phần sau.

4.3.1 Phân tách FDR-E

[Hình 2: Phân tách của tỷ lệ phát hiện sai liên quan đến một tập kéo theo Etrue (FDR-E). Ở đây, ΩE TD := {(x,y, e, v)|G(x) ∈ E(y)}.]

SGenSemi tận dụng các ví dụ không được gán nhãn bằng cách ước tính một tập kéo theo như một hàm pseudo-labeling. Tuy nhiên, lỗi ước tính giới thiệu các pseudo-labels sai. Ở đây, chúng tôi xem xét một cách nghiêm ngặt để rút ra giới hạn trên FDR-E bằng cách kiểm soát lỗi ước tính của hàm pseudo-labeling. Cụ thể, hai loại lỗi ước tính khác nhau của một tập kéo theo ước tính Ê được minh họa trong Hình 2, tức là tỷ lệ kéo theo âm tính sai (FNER) và tỷ lệ kéo theo sai (FER). Điều này dẫn đến phân tách sau.

Bổ đề 1. (E) trong (2) được phân tách như sau:
PDŜ{e = 0} = PDŜ{e = 0,ê = 1} - PDŜ{e = 1,ê = 0} + PDŜ{ê = 0}. (3)

Ở đây, hai thuật ngữ đầu tiên liên quan đến lỗi ước tính nhãn kéo theo và thuật ngữ cuối cùng là FDR-E xấp xỉ sử dụng pseudo-labels. Vì ba thuật ngữ có liên quan, chúng tôi chọn kiểm soát thuật ngữ FER để kiểm soát (E) trong (2) thông qua dự đoán conformal trong phần sau.

4.3.2 Pseudo-labeling thông qua học tập kéo theo conformal
SGenSemi tận dụng dự đoán conformal PAC cho ước tính nhãn kéo theo để kiểm soát lỗi gán nhãn sai. Cụ thể, chúng tôi ước tính hàm tập kéo theo thực Etrue thông qua một tập kéo theo ước tính Ê sử dụng ZE, trong đó chúng tôi sử dụng hàm tính điểm kéo theo fE như một hàm tính điểm, tức là Ê(y) := {y′ ∈ Y | fE(y′,y) ≥ τE}. Ở đây, mất mát tương ứng ℓ(Ê,x,y, e) := 1(e = 0 ∧ G(x) ∈ Ê(y)) là một hàm giảm đơn điệu liên quan đến τE, vì vậy chúng tôi có thể sử dụng thuật toán học tập conformal PAC. Cho một rủi ro mong muốn εE và mức tin cậy δE, thuật toán tương ứng AFER (tức là Thuật toán 1) trả về hàm tập kéo theo ước tính Ê kiểm soát tỷ lệ kéo theo sai (FER) của các mẫu pseudo-labeled RFER(Ê) := PDŜ{e = 0 ∧ G(x) ∈ Ê(y)} với đảm bảo PAC sau, trong đó xác suất được lấy trên các ví dụ huấn luyện từ DŜ.

P{RFER(Ê) ≤ εE} ≥ 1−δE. (4)

4.3.3 Giới hạn FDR-E
Sau đó chúng tôi giới hạn FDR-E cho học bán giám sát, tức là (E) trong (2), thông qua đảm bảo PAC bởi học tập conformal trên ZE và giới hạn đuôi nhị thức trên ZE và ZU. Cụ thể, FER được giới hạn trên bởi εE, FNER được giới hạn dưới bởi giới hạn đuôi nhị thức sử dụng ZE, và NER được giới hạn trên bởi giới hạn đuôi nhị thức sử dụng ZU. Các giới hạn này giữ với xác suất cao, và do đó được kết hợp thông qua một giới hạn hợp, như trong bổ đề sau. Xem Phụ lục G để chứng minh.

Bổ đề 2. Hãy ẐE := {(x,y, e) ∈ ZE|Ŝ(x) ≠ IDK} và ẐU := {(x,y) ∈ ZU|Ŝ(x) ≠ IDK}. Đối với bất kỳ G, D, V và Ŝ, nếu Ê := AFER(ẐE) thỏa mãn PẐE{RFER(Ê) ≤ εE} ≥ 1−δ′E/2, chúng tôi có

PD{e = 0} ≤ εE−LBinom(k̂;|ẐE|, δ′E/2) + UBinom(l̂;|ẐU|, δ′S) =: USSL (5)

với xác suất ít nhất 1−δ′E−δ′S, trong đó xác suất được lấy trên Z. Ở đây, k̂ := ∑(x,y,e)∈ẐE 1(e = 1 ∧ G(x) ∉ Ê(y)) và l̂ := ∑(x,y)∈ẐU 1(G(x) ∉ Ê(y)).

Đáng chú ý, mỗi trong ba giới hạn giữ trên một phân phối có điều kiện DŜ, nhưng Bổ đề 2 nới lỏng điều này thành một phân phối không có điều kiện D cho đảm bảo FDR-E cuối cùng của chúng tôi.

Tối ưu hóa giới hạn FDR-E (5). Bổ đề 2 giới thiệu một siêu tham số εE, kiểm soát sự đánh đổi giữa FER và các thuật ngữ khác. Để tìm một sự đánh đổi tốt nhất, chúng tôi tối ưu hóa εE để giảm thiểu giới hạn trên (5) trong số Q ứng viên của εE thông qua AUSSL-Opt, được mô tả trong Thuật toán 3. Thuật toán tối ưu hóa này có thể tìm một giới hạn FDR-E chặt hơn, như trong bổ đề sau. Xem Phụ lục H để chứng minh.

Bổ đề 3. Hãy USSL như trong (5) và Q là Q ứng viên của εE. Sau đó, chúng tôi có

PD{e = 0} ≤ UOPTSSL := min εE∈Q USSL (6)

với xác suất ít nhất 1−δ′E/Q−δ′S/Q, trong đó xác suất được lấy trên Z.

Lưu ý rằng đối với học bán giám sát, giới hạn trên của (B), (C), (D), và (E) trong (2) nên được cung cấp. Giới hạn trên của (E) được cung cấp trong (5), mà chúng tôi ký hiệu bằng USSL. Giới hạn trên của (B), (C), và (D) được ký hiệu bằng wSL, USL, và wSSL, tương ứng, mỗi cái được tính bằng giới hạn đuôi nhị thức. Xem Thuật toán 4 và chứng minh của Định lý 1 để biết chi tiết.

4.4 Hàm lựa chọn thần kinh
Các giới hạn FDR-E cho cả học có giám sát và bán giám sát là quan trọng để kiểm soát FDR-E cuối cùng của một bộ sinh tạo có chọn lọc cho một hàm lựa chọn ŝ. Nhưng, lựa chọn hàm lựa chọn là quan trọng cho một hiệu suất lựa chọn tốt và ở đây chúng tôi thảo luận về một hàm lựa chọn tốt hơn hàm tiêu chuẩn, tức là ŝ(x) := 1(fM(x, G(x)) ≥ τS) cho τS ∈ R≥0. Cụ thể, phân loại có chọn lọc được chứng nhận [9] xem xét hàm chỉ báo ngưỡng đơn sử dụng khả năng tối đa như hàm tỷ lệ tin cậy. Đối với sinh tạo ngôn ngữ, xác suất có điều kiện của câu trả lời ŷ, tức là fM1(x,ŷ), sẽ là một ứng viên tự nhiên và thường được sử dụng. Tuy nhiên, vì nó được biết là được hiệu chuẩn kém [37], một lựa chọn thay thế sẽ là điểm tự nhất quán, tức là fM2(x, G(x)) := 1/K ∑Kk=1 fE(ỹk, G(x)), trong đó ỹk là các câu trả lời được sinh tạo với cùng câu hỏi x nhưng seeds ngẫu nhiên khác nhau. Nó được chứng minh thực nghiệm rằng điểm tự nhất quán định lượng đúng độ không chắc chắn khi một mô hình ngôn ngữ không chắc chắn về một câu trả lời [19]. Tầm quan trọng của hiệu chuẩn điểm liên quan đến quan hệ kéo theo thực được chứng minh trong Bổ đề 4, cung cấp điều kiện đủ cho thuật toán sinh tạo có chọn lọc sử dụng hàm chỉ báo ngưỡng đơn (Thuật toán 5) để kiểm soát FDR-E ở bất kỳ mức nào. Xem Phụ lục J để chứng minh.

Bổ đề 4. Nếu chúng tôi có quyền truy cập vào Etrue và fM được hiệu chuẩn hoàn hảo liên quan đến Etrue, FDR-E giảm đơn điệu trong τS.

Tuy nhiên, như [37] chỉ ra, hiệu chuẩn hàm tính điểm ngôn ngữ vẫn là một nhiệm vụ khó khăn, vì vậy nó vẫn là một lĩnh vực nghiên cứu tích cực. Do đó, chúng tôi đề xuất một lớp tổng quát các hàm lựa chọn, hàm lựa chọn thần kinh, là hàm chỉ báo ngưỡng đa sử dụng ánh xạ đặc trưng có thể học Φ: x ↦ Rv như sau: ŝ(x; Φ,W,b) := ∧ui=1 (WΦ(x))i + bi ≥ 0, trong đó W ∈ Ru×v và b ∈ Ru×1 là các thuật ngữ chiếu tuyến tính và bias, tương ứng. Trong bài báo này, chúng tôi chỉ xem xét hai lớp con cụ thể của hàm lựa chọn thần kinh, trong đó cái trước giảm về học hàm lựa chọn ngưỡng đơn sử dụng một hàm tính điểm (Thuật toán 5) và cái sau giảm về học hàm lựa chọn ngưỡng đôi sử dụng hai hàm tính điểm (Thuật toán 6). Chỉ có thuật ngữ bias b là tham số có thể học cho cả hai thuật toán, trong đó các cái khác được đặt như siêu tham số. Cụ thể, W = I1, Φ1(x) = [fM(x, G(x))], và b = −τS cho Thuật toán 5, trong khi W = I2, Φ2(x) = [fM1(x, G(x)) fM2(x, G(x))]T, và b = −[τS,1, τS,2]T cho Thuật toán 6 nếu hai hàm tính điểm hứa hẹn tồn tại. Ở đây, phát triển một thuật toán học hàm lựa chọn trong đó W và Φ(·) cũng là các tham số học đầy đủ được để lại như công việc tương lai. Trong phần sau, chúng tôi giới thiệu thuật toán của chúng tôi chọn sự kết hợp tối ưu của các hàm tính điểm thông qua hàm lựa chọn thần kinh.

4.5 Thuật toán học bộ sinh tạo có chọn lọc bán giám sát với lựa chọn thần kinh
SGenSemi là một thuật toán học bán giám sát cho sinh tạo có chọn lọc được chứng nhận, khai thác đầy đủ dữ liệu không được gán nhãn trong việc học một hàm lựa chọn thông qua pseudo-labeling được chứng nhận và sử dụng một hàm lựa chọn thần kinh để chọn một sự kết hợp tối ưu của các hàm tính điểm. Cụ thể, SGenSemi giải quyết vấn đề tối ưu hóa sau trên các bộ sinh tạo có chọn lọc H sao cho Ŝ gần thỏa mãn đẳng thức trong ràng buộc, như được mô tả trong Thuật toán 7:

ASGenSemi: tìm Ŝ ∈ ĤŜ chịu điều kiện wSLUSL + wSSLUOPTSSL ≤ εS, (7)

Ở đây, Ŝ ∈ H có một hàm lựa chọn ŝ(x; Φ2(x),diag(w),b), trong đó w ∈ {[1,0]T,[0,1]T,[1,1]T} và b ∈ R2≤0. Lưu ý rằng SGenSemi trả về một thuật ngữ bổ sung Û, là giới hạn FDR-E cho bộ sinh tạo có chọn lọc Ŝ (tức là Thuật toán 4) và thông báo về tính không khả thi của tối ưu hóa. Thuật toán 7 được đề xuất thỏa mãn đảm bảo khả năng kiểm soát sau. Xem Phụ lục I để chứng minh.

Định lý 1. ASGenSemi thỏa mãn đảm bảo có thể kiểm soát sau trên FDR-E, tức là

P{P{G(x) ∉ Etrue(y)|Ŝ(x) ≠ IDK} ≤ Û} ≥ 1−δ, (8)

trong đó xác suất trong và ngoài được lấy trên (x,y, e, v) ∼ D và Z ∼ Dn, tương ứng, và (Ŝ,Û) := ASGenSemi(Z). Ở đây, δ := δW + δS + δE là một mức tin cậy mong muốn, trong đó δW là cho giới hạn trên trên wSL và wSSL, δS là cho (C) trong (2) và NER, và δE là cho FER và FNER.

Ở đây, ASGenSemi có thể kiểm soát theo nghĩa nó giới hạn trên FDR-E của một bộ sinh tạo có chọn lọc đã học đến mức mong muốn εS hoặc ít nhất đến mức đạt được tối thiểu Û với tin cậy δ.

5 Thí nghiệm
Chúng tôi chứng minh hiệu quả của các phương pháp của chúng tôi trong việc kiểm soát FDR-E trên các GLM được huấn luyện trước dưới các thiết lập khác nhau. Chúng tôi sử dụng hai GLM, GPT-3.5-Turbo và Alpaca-7B, cùng với bộ dữ liệu Natural Questions (NQ) để chú thích nhãn kéo theo cho các cặp câu hỏi-câu trả lời. Chi tiết về cấu hình mô hình, bộ dữ liệu, và kết quả thí nghiệm bổ sung có thể được tìm thấy trong Phần A.3 và Phụ lục K.

Phương pháp. Chúng tôi xem xét hai thuật toán bán giám sát heuristic, SGenH-SemiPL và SGenH-SemiPFL (Thuật toán 9) và một thuật toán học không giám sát [9] SGenEM (Thuật toán 10) như các phương pháp cơ sở để cho thấy hiệu quả của phương pháp bán giám sát được chứng nhận SGenSemi (Thuật toán 7) của chúng tôi. SGenH-SemiPL và SGenH-SemiPFL khai thác dữ liệu không được gán nhãn bằng pseudo-labeling kéo theo văn bản dựa trên một ngưỡng như một siêu tham số mà không có bất kỳ đảm bảo nào về lỗi gán nhãn sai. SGenH-SemiPFL ngoài ra lọc ra các mẫu pseudo-labeled nếu điểm kéo theo của chúng dưới một ngưỡng cụ thể. SGenEM là một phương pháp không giám sát được chứng nhận lấy thước đo EM để đo tính đúng đắn. Chúng tôi cũng báo cáo kết quả trên SGenSemiNoMS (Thuật toán 5) cho hai hàm tính điểm khác nhau, fM1 và fM2, được sử dụng trong SGenSemi. SGenSemiNoMS là một thuật toán học bán giám sát được chứng nhận sử dụng một hàm chỉ báo ngưỡng đơn cho một hàm tính điểm. Chúng tôi cũng lấy SGenSup (Thuật toán 8) như một phương pháp cơ sở, vì nó là một sửa đổi trực tiếp của [9] cho vấn đề sinh tạo ngôn ngữ.

Hàm tính điểm. Chúng tôi sử dụng xác suất có điều kiện của một câu trả lời như fM1 và điểm tự nhất quán [19] như fM2, vì mục tiêu của chúng tôi là sinh ra chuỗi không chỉ nhất quán logic với câu trả lời thực mà còn đúng về mặt ngôn ngữ.

Tham số kiểm soát. Để kiểm soát một FDR-E, chúng tôi sử dụng hai tham số do người dùng chỉ định (ε, δ), trong đó chúng tôi sử dụng (0.25,0.02) trừ khi được chỉ định. Đối với các phương pháp của chúng tôi (tức là SGenSemi, SGenSemiNoMS, và SGenSemi-SupNoMS), chúng tôi có năm tham số kiểm soát (εS, δS, δE, δW), trong đó chúng tôi ánh xạ như sau: εS = ε, δS = (δ−δW)/2, δE = (δ−δW)/2, δW = 10−5. Đối với các phương pháp khác không sử dụng tập kéo theo, Thuật toán 8, Thuật toán 9, và Thuật toán 10, chúng tôi sử dụng ε và δ tương ứng. Ngoài ra, chúng tôi sử dụng Q = 5 cho Thuật toán 3.

Đảm bảo FDR-E và hiệu suất. Như có thể thấy trong Bảng 1, phương pháp SGenSemi của chúng tôi tổng thể có thể đạt được đảm bảo FDR-E mong muốn với hiệu suất tốt hơn so với các phương pháp cơ sở. Tùy thuộc vào chất lượng của các hàm tính điểm (ví dụ, fM1), biến thể SGenSemiNoMS của chúng tôi có thể không tìm thấy một bộ sinh tạo có chọn lọc thỏa mãn FDR-E mong muốn (ký hiệu trong FDR-E được gạch chân). Các phương pháp heuristic, tức là SGenH-SemiPL và SGenH-SemiPFL, không cung cấp đảm bảo lý thuyết về FDR-E. Trong Hình 1 và Bảng 2, chúng tôi có thể dự đoán đúng ngay cả với các câu trả lời phức tạp, ví dụ, có nhiều từ tương đương, vì chúng tôi không dựa vào thước đo EM. Chúng tôi đã tiến hành 100 thí nghiệm ngẫu nhiên cho mỗi phương pháp để cho thấy FDR-E được giới hạn tốt như thế nào dưới FDR-E mong muốn. Như được hiển thị bởi các hộp xanh lá cây trong Hình 4, được giới hạn thành công dưới εS = 0.25, chúng tôi có thể thấy rằng FDR-E cho một bộ sinh tạo có chọn lọc đã học được kiểm soát tốt dưới εS trong môi trường thử nghiệm. Trong số các phương pháp được chứng nhận với đảm bảo lý thuyết, kết quả dường như phù hợp tốt với cơ sở lý thuyết mong đợi.

Tại sao nhãn kéo theo. Như mong đợi và có thể thấy trong Bảng 3 bằng cách so sánh SGenEM và SGenSup, một thước đo như EM không thể đo tính đúng đắn một cách chính xác. Khác với phân loại, các tác vụ sinh tạo có thể có số lượng vô hạn câu trả lời đúng vì vậy không có khả năng có khớp chính xác. Thay vào đó, nhãn kéo theo cung cấp tính đúng đắn ngữ nghĩa, vì vậy SGenSup có thể hoạt động tốt hơn và hiệu quả hơn SGenEM.

Tại sao học bán giám sát. Chúng tôi quan sát rằng học bán giám sát của chúng tôi cho sinh tạo có chọn lọc là hiệu quả. Cụ thể, các phương pháp có giám sát đầy đủ trong Bảng 3 đạt được hiệu suất 0.7535 và 0.2959 cho GPT-3.5 và Alpaca-7B, tương ứng, với toàn bộ các mẫu được gán nhãn ZE (khi chúng thỏa mãn đảm bảo ε-FDR-E). So với những cái này, phương pháp bán giám sát được đề xuất SGenSemi Bảng 1 đạt được hiệu suất 0.7334 và 0.3173 cho GPT-3.5 và Alpaca-7B, tương ứng, chỉ bằng cách sử dụng 75% các ví dụ được gán nhãn. Ngoài ra, chúng tôi quan sát rằng nhiều mẫu không được gán nhãn hơn có lợi cho việc đạt được hiệu suất tốt hơn như có thể thấy trong Hình 3. Điều này hàm ý rằng nếu chúng tôi có thể xấp xỉ tập kéo theo tốt và kích thước của ZU đủ, chúng tôi có thể tận hưởng pseudo-entailment labeling được chứng nhận của chúng tôi bằng học bán giám sát ngay cả với ZE nhỏ.

Tại sao lựa chọn thần kinh. Khó để tìm thủ công một hàm tính điểm được hiệu chuẩn tốt. Nhưng, cho nhiều hàm tính điểm, một hàm lựa chọn thần kinh học để chọn các hàm tính điểm đúng đạt được FDR-E mong muốn và tối đa hóa hiệu suất lựa chọn. Điều này được xác thực thực nghiệm trong Bảng 1, khi SGenSemi tốt hơn về hiệu suất trung bình.

6 Kết luận
Chúng tôi đề xuất sinh tạo có chọn lọc, một phiên bản tổng quát của [9] cho GLM để xử lý tính đúng đắn ngữ nghĩa giữa hai câu trả lời có cấu trúc. Để đạt được điều này, chúng tôi tận dụng kéo theo logic để định nghĩa một thước đo FDR dựa trên kéo theo mới (FDR-E). Vì việc thu thập nhãn kéo theo tốn kém, chúng tôi đề xuất học bán giám sát mới cho sinh tạo có chọn lọc bằng cách sử dụng các tập kéo theo như một hàm pseudo-labeling. Để nâng cao hiệu suất lựa chọn thấp do các hàm tính điểm không hiệu quả, chúng tôi đề xuất các hàm lựa chọn thần kinh để tối ưu hóa hiệu quả các hàm tính điểm cho hiệu suất lựa chọn tốt hơn và đảm bảo FDR-E. Hiệu quả của các thuật toán SGenSemi và SGenSup được đề xuất của chúng tôi được biện minh về mặt lý thuyết và thực nghiệm.

Hạn chế. Thuật toán của chúng tôi cần giả định i.i.d. cho đảm bảo tính đúng đắn, có thể bị vi phạm trong các tình huống thực tế. Chúng tôi tận dụng các nhãn kéo theo đắt đỏ, trong đó các nhãn được thu thập bằng cách xem xét kéo theo logic giữa câu trả lời thực và câu trả lời được sinh tạo. Hạn chế này được giảm thiểu một phần bằng cách đề xuất phương pháp bán giám sát để truyền bá các mẫu được gán nhãn kéo theo đến các mẫu không có nhãn kéo theo. Ngoài ra, kết quả của chúng tôi cho thấy FDR-E thực nghiệm không được giới hạn chặt dưới ε, đặc biệt trên Alpaca7B, điều này hàm ý rằng chúng tôi có thể cần một giới hạn FDR-E chặt hơn.

Lời cảm ơn
Công trình này được hỗ trợ bởi tài trợ Viện Quy hoạch và Đánh giá Công nghệ Thông tin & truyền thông (IITP) do chính phủ Hàn Quốc (MSIT) tài trợ (Số RS-2019-II191906, Chương trình Trường Đại học Trí tuệ Nhân tạo (POSTECH) (50%); RS-2024-00457882, Dự án Phòng thí nghiệm Nghiên cứu AI Quốc gia (25%); RS-2024-00509258, Phòng thí nghiệm Biên giới AI Toàn cầu (25%)). Ngoài ra, chúng tôi đánh giá cao các nhận xét có giá trị từ các nhà phản biện NeurIPS.

Tài liệu tham khảo
[1]Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.
[2]Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners, 2020.
[3] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. Llama: Open and efficient foundation language models, 2023.
[4]Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. Stanford alpaca: An instruction-following llama model. https://github.com/tatsu-lab/stanford_alpaca, 2023.
[5] OpenAI Team. ChatGPT. https://chat.openai.com/, 2021.
[6]Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017.
[7]Margaret Li, Stephen Roller, Ilia Kulikov, Sean Welleck, Y-Lan Boureau, Kyunghyun Cho, and Jason Weston. Don't say that! making inconsistent dialogue unlikely with unlikelihood training. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4715-4728, Online, July 2020. Association for Computational Linguistics.
[8]Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. Training language models to follow instructions with human feedback, 2022.
[9]Yonatan Geifman and Ran El-Yaniv. Selective classification for deep neural networks. Advances in neural information processing systems, 30, 2017.
[10] Vladimir Vovk, Alex Gammerman, and Glenn Shafer. Algorithmic learning in a random world. Springer Science & Business Media, 2005.
[11] Sangdon Park, Osbert Bastani, Nikolai Matni, and Insup Lee. Pac confidence sets for deep neural networks via calibrated prediction. In International Conference on Learning Representations, 2020.
[12] Stephen Bates, Anastasios Angelopoulos, Lihua Lei, Jitendra Malik, and Michael I Jordan. Distribution-free, risk-controlling prediction sets. arXiv preprint arXiv:2101.02703, 2021.
[13] Isaac Gibbs and Emmanuel Candès. Adaptive conformal inference under distribution shift, 2021.
[14] Sangdon Park, Osbert Bastani, and Taesoo Kim. Acon2: Adaptive conformal consensus for provable blockchain oracles, 2023.
[15] Samuel Bowman, Gabor Angeli, Christopher Potts, and Christopher D Manning. A large annotated corpus for learning natural language inference. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 632-642, 2015.
[16] Adina Williams, Nikita Nangia, and Samuel R Bowman. A broad-coverage challenge corpus for sentence understanding through inference. In Proceedings of NAACL-HLT, pages 1112-1122, 2018.
[17] Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, et al. Natural questions: a benchmark for question answering research. Transactions of the Association for Computational Linguistics, 7:453-466, 2019.
[18] Zhengbao Jiang, Jun Araki, Haibo Ding, and Graham Neubig. How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering. Transactions of the Association for Computational Linguistics, 9:962-977, 09 2021.
[19] Potsawee Manakul, Adian Liusie, and Mark Gales. Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models. In The 2023 Conference on Empirical Methods in Natural Language Processing, 2023.
[20] Vladimir Vovk. Conditional validity of inductive conformal predictors. Machine learning, 92(2-3):349-376, 2013.
[21] Adam Fisch, Tal Schuster, Tommi Jaakkola, and Regina Barzilay. Few-shot conformal prediction with auxiliary tasks, 2021.
[22] Sangdon Park, Edgar Dobriban, Insup Lee, and Osbert Bastani. PAC prediction sets for meta-learning. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, Advances in Neural Information Processing Systems, 2022.
[23] Victor Quach, Adam Fisch, Tal Schuster, Adam Yala, Jae Ho Sohn, Tommi S. Jaakkola, and Regina Barzilay. Conformal Language Modeling, June 2024. arXiv:2306.10193 [cs].
[24] Christopher Mohri, Daniel Andor, Eunsol Choi, and Michael Collins. Learning to reject with a fixed predictor: Application to decontextualization. arXiv preprint arXiv:2301.09044, 2023.
[25] Ying Jin and Emmanuel J. Candès. Selection by Prediction with Conformal p-values, May 2023. arXiv:2210.01408 [stat].
[26] Ying Jin and Zhimei Ren. Confidence on the Focal: Conformal Prediction with Selection-Conditional Coverage, March 2024. arXiv:2403.03868 [math, stat].
[27] Christopher Mohri and Tatsunori Hashimoto. Language models with conformal factuality guarantees. arXiv preprint arXiv:2402.10978, 2024.
[28] John J. Cherian, Isaac Gibbs, and Emmanuel J. Candès. Large language model validity via enhanced conformal prediction methods, June 2024. arXiv:2406.09714 [cs, stat].
[29] Yu Gui, Ying Jin, and Zhimei Ren. Conformal Alignment: Knowing When to Trust Foundation Models with Guarantees, May 2024. arXiv:2405.10301 [cs, stat].
[30] Philip Gage. A new algorithm for data compression. C Users Journal, 12(2):23-38, 1994.
[31] Samuel S Wilks. Determination of sample sizes for setting tolerance limits. The Annals of Mathematical Statistics, 12(1):91-96, 1941.
[32] Leslie G Valiant. A theory of the learnable. Communications of the ACM, 27(11):1134-1142, 1984.
[33] Harris Papadopoulos, Kostas Proedrou, Volodya Vovk, and Alex Gammerman. Inductive confidence machines for regression. In European Conference on Machine Learning, pages 345-356. Springer, 2002.
[34] Sangdon Park, Edgar Dobriban, Insup Lee, and Osbert Bastani. PAC prediction sets under covariate shift. In International Conference on Learning Representations, 2022.
[35] Morris H DeGroot and Stephen E Fienberg. The comparison and evaluation of forecasters. Journal of the Royal Statistical Society: Series D (The Statistician), 32(1-2):12-22, 1983.
[36] Bianca Zadrozny and Charles Elkan. Transforming classifier scores into accurate multiclass probability estimates. In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 694-699. ACM, 2002.
[37] Yao Zhao, Mikhail Khalman, Rishabh Joshi, Shashi Narayan, Mohammad Saleh, and Peter J Liu. Calibrating sequence likelihood improves conditional language generation. In The Eleventh International Conference on Learning Representations, 2022.
[38] Dorottya Demszky, Kelvin Guu, and Percy Liang. Transforming question answering datasets into natural language inference datasets. arXiv preprint arXiv:1809.02922, 2018.
[39] Jifan Chen, Eunsol Choi, and Greg Durrett. Can NLI Models Verify QA Systems' Predictions?, September 2021. arXiv:2104.08731 [cs].

# Tiến tới Biểu diễn Văn bản Tổng quát với Học Tương phản Đa giai đoạn

Zehan Li1, Xin Zhang1, Yanzhao Zhang1, Dingkun Long1, Pengjun Xie1, Meishan Zhang
1Alibaba Group
{lizehan.lzh,linzhang.zx,zhangyanzhao.zyz,
dingkun.ldk,pengjun.xpj}@alibaba-inc.com

Tóm tắt
Chúng tôi giới thiệu GTE, một mô hình nhúng văn bản đa mục đích được huấn luyện với học tương phản đa giai đoạn. Phù hợp với những tiến bộ gần đây trong việc thống nhất các nhiệm vụ NLP khác nhau thành một định dạng duy nhất, chúng tôi huấn luyện một mô hình nhúng văn bản thống nhất bằng cách sử dụng học tương phản trên một hỗn hợp đa dạng các tập dữ liệu từ nhiều nguồn. Bằng cách tăng đáng kể số lượng dữ liệu huấn luyện trong cả giai đoạn tiền huấn luyện không giám sát và tinh chỉnh có giám sát, chúng tôi đạt được những cải thiện hiệu suất đáng kể so với các mô hình nhúng hiện có. Đáng chú ý, ngay cả với số lượng tham số tương đối khiêm tốn là 110M, GTE base vượt trội hơn API nhúng hộp đen do OpenAI cung cấp và thậm chí vượt qua các mô hình nhúng văn bản lớn gấp 10 lần trên benchmark nhúng văn bản khổng lồ. Hơn nữa, không cần tinh chỉnh bổ sung trên từng ngôn ngữ lập trình riêng lẻ, mô hình của chúng tôi vượt trội hơn các bộ truy xuất mã tốt nhất trước đây có kích thước tương tự bằng cách xem mã như văn bản. Tóm lại, mô hình của chúng tôi đạt được kết quả ấn tượng bằng cách khai thác hiệu quả học tương phản đa giai đoạn, cung cấp một mô hình nhúng văn bản mạnh mẽ và hiệu quả với khả năng ứng dụng rộng rãi trên các nhiệm vụ NLP và liên quan đến mã khác nhau.

1 Giới thiệu

Nhúng văn bản đã trở thành một thành phần không thể thiếu trong nhiều nhiệm vụ xử lý ngôn ngữ tự nhiên, như phân loại văn bản, truy xuất văn bản, hỏi đáp và hệ thống đối thoại (Karpukhin et al., 2020; Humeau et al., 2020; Choi et al., 2021; Izacard et al., 2022a; Long et al., 2022a; Rajapakse, 2023). Các mô hình nhúng này biểu diễn văn bản bằng các vector nhiều chiều thấp và nắm bắt độ tương tự của chúng thông qua các phép toán vector. Sự xuất hiện của các mô hình ngôn ngữ lớn (LLM) gần đây (Radford et al., 2018; Touvron et al., 2023; OpenAI, 2023) đã tạo ra sự quan tâm đáng kể đến các hệ thống tăng cường truy xuất dựa trên các mô hình nhúng văn bản tích hợp khả năng lý luận và hiểu của LLM (Izacard et al., 2022b; Ram et al., 2023; Shi et al., 2023). Do đó, đã có sự tập trung ngày càng tăng vào biểu diễn văn bản tổng quát trong cả công nghiệp và học thuật.

Việc theo đuổi phát triển một mô hình thống nhất để giải quyết nhiều nhiệm vụ downstream đã tồn tại từ lâu do các định dạng, miền và ứng dụng downstream đa dạng của ngôn ngữ tự nhiên. Sự xuất hiện của các mô hình ngôn ngữ được tiền huấn luyện đã mở ra thêm các khả năng để huấn luyện một mô hình phổ quát như vậy. Tuy nhiên, trong lĩnh vực nghiên cứu biểu diễn văn bản, các mô hình nhúng văn bản trước đây chủ yếu tập trung vào các nhiệm vụ cụ thể, và các chiến lược huấn luyện hoặc mô hình của chúng, được điều chỉnh cho một nhiệm vụ duy nhất, có thể không hoạt động tối ưu trong các bối cảnh khác. Ví dụ, mô hình biểu diễn văn bản SimCSE (Gao et al., 2021), được huấn luyện trên các cặp văn bản đối xứng, thể hiện những hạn chế trong các nhiệm vụ truy xuất văn bản. Tương tự, một số mô hình biểu diễn văn bản được thiết kế đặc biệt cho các nhiệm vụ truy xuất dày đặc không thể hiện hiệu suất mạnh mẽ trong các nhiệm vụ tương tự văn bản câu. Gần đây, đã có sự thay đổi trong trọng tâm nghiên cứu hướng tới phát triển các mô hình toàn diện hơn cho biểu diễn văn bản tận dụng lượng lớn dữ liệu web không được gán nhãn thông qua tiền huấn luyện tương phản không giám sát, kết hợp với dữ liệu, gợi ý hoặc hướng dẫn cụ thể cho nhiệm vụ để giảm thiểu xung đột nhiệm vụ trong quá trình tinh chỉnh (Ni et al., 2022a,b; Neelakantan et al., 2022; Wang et al., 2022b; Su et al., 2023). Ngoài ra, việc giới thiệu các benchmark, như Massive Text Embedding Benchmark (MTEB) (Muennighoff et al., 2023), đã thiết lập một cơ sở vững chắc để đánh giá tính phổ quát của các mô hình biểu diễn văn bản. Tuy nhiên, một hạn chế đáng kể trong nghiên cứu hiện tại là sự phụ thuộc vào dữ liệu nội bộ cho tiền huấn luyện, tạo ra một nút thắt cổ chai trong việc sử dụng các trọng số mô hình được tiền huấn luyện hoặc API. Hơn nữa, việc xây dựng các gợi ý được điều chỉnh cụ thể cho từng nhiệm vụ đòi hỏi nỗ lực thêm của con người trong quá trình triển khai (Su et al., 2023).

Công trình này trình bày một cách tiếp cận đơn giản để xây dựng một mô hình nhúng văn bản tổng quát (GTE) chỉ sử dụng học tương phản trên dữ liệu nguồn mở, như được minh họa trong Hình 1. Cụ thể, chúng tôi đầu tiên thu thập một tập dữ liệu quy mô lớn gồm các cặp văn bản không giám sát được trích xuất từ các nguồn dữ liệu khác nhau cho tiền huấn luyện tương phản. Một cách đáng ngạc nhiên, mô hình của chúng tôi, được tiền huấn luyện trên tập dữ liệu này, thể hiện hiệu suất đáng chú ý, vượt trội hơn BM25 và mô hình E5 (Wang et al., 2022b) trong các nhiệm vụ truy xuất văn bản zero-shot và vượt qua nhiều mô hình có giám sát trong benchmark MTEB. Để nâng cao hơn nữa chất lượng của các biểu diễn văn bản đã học, chúng tôi thu thập các cặp văn bản chất lượng cao với nhãn của con người từ nhiều nguồn cho tinh chỉnh tương phản. Sau tinh chỉnh có giám sát, mô hình dựa trên BERT 110M của chúng tôi (Devlin et al., 2019) đã vượt trội hơn API nhúng thương mại hiện tại của OpenAI và xếp hạng cao trong benchmark MTEB. Hơn nữa, vì mô hình của chúng tôi cũng được huấn luyện sử dụng dữ liệu mã, chúng tôi đánh giá khả năng tìm kiếm mã của nó trên benchmark CodeSearchNet, bao gồm sáu ngôn ngữ lập trình. Đáng chú ý, ngay cả không có tinh chỉnh cụ thể cho ngôn ngữ trên từng tập con, mô hình của chúng tôi vượt trội đáng kể so với các bộ truy xuất mã hiện đại có kích thước tương tự đã được tinh chỉnh cho từng ngôn ngữ lập trình.

Trong phần còn lại của bài báo này, chúng tôi cung cấp một tài khoản chi tiết về các nguồn dữ liệu và cấu hình huấn luyện được sử dụng. Tiếp theo, chúng tôi trình bày kết quả đánh giá trên các benchmark nhúng văn bản được công nhận rộng rãi và so sánh chúng với hiệu suất của các baseline hiện đại trước đây được tối ưu hóa cụ thể cho từng nhiệm vụ riêng lẻ. Mô hình của chúng tôi liên tục thể hiện hiệu suất vượt trội hoặc, ít nhất, kết quả tương đương với những gì đạt được bởi các mô hình lớn hơn, nhờ vào việc kết hợp hỗn hợp đa dạng hơn của các tập dữ liệu huấn luyện. Chúng tôi hy vọng mô hình của chúng tôi sẽ phục vụ như một baseline mạnh mẽ cho cộng đồng nghiên cứu điều tra nhúng văn bản và mã.

2 Công trình Liên quan

Nhúng văn bản phục vụ như các biểu diễn vector nhiều chiều thấp cho văn bản có độ dài khác nhau và là thiết yếu trong nhiều nhiệm vụ xử lý ngôn ngữ tự nhiên (NLP). Trái ngược với các biểu diễn nhiều chiều cao và thưa thớt như TF-IDF, nhúng văn bản dày đặc có khả năng giải quyết vấn đề không khớp từ vựng và nâng cao hiệu quả của truy xuất và khớp văn bản.

Các mô hình ngôn ngữ được tiền huấn luyện, được minh họa bởi BERT (Devlin et al., 2019) và GPT (Radford et al., 2018), đã thể hiện thành công đáng chú ý trên các nhiệm vụ NLP khác nhau. Tuy nhiên, việc trích xuất một nhúng câu chất lượng cao từ các mô hình ngôn ngữ được tiền huấn luyện đặt ra một thách thức đáng kể do sự hiện diện của các không gian nhúng bất đồng hướng do mục tiêu mô hình hóa ngôn ngữ có mặt nạ. Để giải quyết vấn đề này, các nghiên cứu tiếp theo đã đề xuất các cách tiếp cận khác nhau, bao gồm tinh chỉnh có giám sát (Reimers và Gurevych, 2019), luồng chuẩn hóa (Li et al., 2020), luồng chuẩn hóa (Li et al., 2020), làm trắng (Su et al., 2021), hoặc học tương phản không giám sát (Gao et al., 2021). Các điều tra này chủ yếu tập trung vào việc nâng cao hiệu suất trong các nhiệm vụ tương tự văn bản ngữ nghĩa, trong đó hai câu thể hiện các định dạng tương tự.

Một hướng nghiên cứu khác tập trung vào vấn đề truy xuất văn bản, nơi truy vấn và tài liệu thường thể hiện một mối quan hệ bất đối xứng. Trong bối cảnh này, kiến trúc bộ mã hóa kép đòi hỏi huấn luyện với cả các cặp tích cực và tiêu cực. Lee et al. (2019) đề xuất Nhiệm vụ Đóng Ngược (ICT) như một cách tiếp cận tiền huấn luyện tự giám sát để tạo ra một bộ truy xuất dày đặc. Phương pháp ICT liên quan đến việc cắt một câu ngẫu nhiên từ một đoạn văn để xây dựng các cặp truy vấn-tài liệu giả. Ngoài ra, Chang et al. (2020) tận dụng cấu trúc liên kết trong Wikipedia để giới thiệu thêm các tín hiệu giám sát trong dữ liệu tiền huấn luyện. Theo hướng tương tự, REALM (Guu et al., 2020) đề xuất một cách tiếp cận huấn luyện kết hợp, trong đó một bộ truy xuất dày đặc và một mô hình ngôn ngữ được huấn luyện đồng thời. Tín hiệu học cho mô hình ngôn ngữ được lấy từ mô hình hóa ngôn ngữ có mặt nạ, với lan truyền ngược được kết hợp thông qua bước truy xuất. Những tiến bộ gần đây, như Contriever (Izacard et al., 2022a) và coCondenser (Gao và Callan, 2022), đã chứng minh rằng việc xây dựng các cặp tích cực thông qua cắt đoạn văn ngẫu nhiên mang lại kết quả vượt trội so với nhiệm vụ ICT. Dựa trên các ý tưởng được trình bày trong (Chang et al., 2020), một số nhà nghiên cứu cũng đã đưa ra các phương pháp để xây dựng các cặp tích cực chất lượng cao hơn sử dụng tô pô liên kết web cho tiền huấn luyện bộ truy xuất (Zhou et al., 2022), một kỹ thuật chứng minh hiệu quả trong các tình huống zero-shot. Hơn nữa, trong lĩnh vực truy xuất dày đặc, nghiên cứu đáng kể được dành cho việc nâng cao khả năng biểu diễn văn bản của các mô hình ngôn ngữ được tiền huấn luyện thông qua thiết kế các nhiệm vụ tiền huấn luyện phụ trợ (Gao và Callan, 2021; Xiao et al., 2022; Gao và Callan, 2022; Wang et al., 2022a; Long et al., 2022b; Li et al., 2023).

Hai hướng nghiên cứu trước đây có thể được tổng quát hóa như việc học một biểu diễn vector cho một đoạn văn bản và được phân biệt bởi loại nhiệm vụ downstream. Gần đây, một số nghiên cứu đã khám phá việc xây dựng các mô hình biểu diễn văn bản thống nhất thông qua học tương phản quy mô lớn và học dựa trên gợi ý (Neelakantan et al., 2022; Wang et al., 2022b; Su et al., 2023). Ngoài ra, một số nỗ lực nghiên cứu đã tập trung vào việc xây dựng các tập dữ liệu đánh giá để đánh giá tốt hơn tính ổn định của các mô hình biểu diễn văn bản trên các nhiệm vụ và miền khác nhau. BEIR (Benchmarking IR) (Thakur et al., 2021) thu thập một số lượng đáng kể các nhiệm vụ truy xuất từ các miền khác nhau để đánh giá độ mạnh mẽ của các mô hình bộ truy xuất dày đặc trong các tình huống zero-shot. Trong khi đó, MTEB (Massive Text Embedding Benchmark) (Muennighoff et al., 2023) đánh giá hơn 56 tập dữ liệu trải rộng bảy danh mục, cung cấp một đánh giá toàn diện về các mô hình nhúng văn bản.

Nghiên cứu này nhằm phát triển một mô hình nhúng văn bản tổng quát thông qua một cách tiếp cận huấn luyện đa giai đoạn. Trong giai đoạn đầu của học tương phản không giám sát, chúng tôi tạo ra các cặp văn bản tương quan giám sát yếu sử dụng dữ liệu có sẵn công khai từ các nguồn khác nhau. Không giống như nghiên cứu trước đây (Wang et al., 2022b), chúng tôi độc quyền sử dụng dữ liệu nguồn mở và không sử dụng bất kỳ phương pháp lọc hoặc làm sạch nào. Tiền huấn luyện trên các cặp văn bản quy mô lớn có thể cải thiện hiệu quả khả năng tổng quát hóa miền của các mô hình biểu diễn văn bản và thu hẹp khoảng cách giữa mục tiêu huấn luyện MLM và mục tiêu học tương phản của các mô hình biểu diễn, làm cho mô hình ngôn ngữ phù hợp hơn cho các nhiệm vụ biểu diễn văn bản. Trong giai đoạn tinh chỉnh có giám sát, hỗn hợp dữ liệu huấn luyện trong cách tiếp cận của chúng tôi đa dạng hơn để nâng cao thêm tính linh hoạt của mô hình. Hơn nữa, mô hình của chúng tôi không kết hợp các gợi ý cụ thể cho nhiệm vụ, điều này nâng cao khả năng tái tạo và dễ sử dụng.

3 Cách tiếp cận

Quá trình huấn luyện mô hình của chúng tôi bao gồm hai giai đoạn: tiền huấn luyện không giám sát và tinh chỉnh có giám sát. Cả hai giai đoạn đều sử dụng mục tiêu học của học tương phản. Đầu tiên, chúng tôi sẽ giới thiệu khung cơ bản của mô hình. Tiếp theo, chúng tôi sẽ thảo luận về các nguồn và phương pháp xây dựng dữ liệu huấn luyện trong hai giai đoạn. Cuối cùng, chúng tôi sẽ trình bày một số chiến lược tối ưu hóa đặc biệt được sử dụng để nâng cao hiệu suất của mô hình trong quá trình huấn luyện.

3.1 Kiến trúc Mô hình

Xương sống của mô hình nhúng của chúng tôi là một bộ mã hóa Transformer sâu (Vaswani et al., 2017) có thể được khởi tạo với các mô hình ngôn ngữ được tiền huấn luyện như BERT (Devlin et al., 2019). Mô hình của chúng tôi tuân theo kiến trúc bộ mã hóa kép vani với việc gộp trung bình trên đầu các biểu diễn token được ngữ cảnh hóa được tạo ra bởi mô hình ngôn ngữ. Chính thức, cho một đoạn văn bản x = (x1, . . . , xn) bao gồm n token, một mô hình nhúng E chuyển đổi văn bản thành một vector dày đặc nhiều chiều thấp x̄ = E(x) trong Rd. Để triển khai E, chúng tôi đầu tiên sử dụng một mô hình ngôn ngữ để có các biểu diễn token được ngữ cảnh hóa sâu h = LM(x) trong Rn×d. (1) Sau đó chúng tôi áp dụng một phép gộp trung bình nhẹ qua chiều đầu tiên để có biểu diễn văn bản, x̄ = 1/n Σni=1 hi trong Rd (2)

Các biểu diễn văn bản được học thông qua mục tiêu tương phản, phân biệt các cặp văn bản liên quan về mặt ngữ nghĩa khỏi những cặp không liên quan. Quy trình huấn luyện như vậy đòi hỏi các cặp tích cực và tiêu cực, có định dạng (q, d+, d−). Đối với một truy vấn q, một tài liệu liên quan d+, một tập hợp các tài liệu không liên quan D− = {d−1, . . . , d−n}, một mục tiêu tương phản phổ biến là mất mát InfoNCE (van den Oord et al., 2018), Lcl = −log es(q,d+)/τ / (es(q,d+)/τ + Σni=1 es(q,d−i)/τ), (3)

trong đó s(q, d) ước tính độ tương tự giữa hai đoạn văn bản q và d thông qua khoảng cách vector giữa q̄ = E(q) và d̄ = E(d).

Để có được nhúng văn bản chất lượng cao hơn có thể được áp dụng trên một phạm vi rộng các tình huống, chúng tôi biên soạn một tập dữ liệu cặp văn bản rộng lớn từ nhiều định dạng và miền. Tập dữ liệu này sau đó được huấn luyện bằng phương pháp mất mát tương phản cải tiến theo cách đa giai đoạn.

3.2 Dữ liệu Tiền huấn luyện Không giám sát

Dữ liệu liên quan văn bản giám sát yếu có sẵn dễ dàng trong các nguồn web có thể truy cập công khai, như kết nối vốn có giữa các truy vấn và câu trả lời trên các diễn đàn QA. Những dữ liệu này có thể được thu thập rộng rãi mà không cần chú thích thủ công, do đó hỗ trợ hiệu quả trong việc huấn luyện các mô hình biểu diễn văn bản. Lấy cảm hứng từ công trình trước đây (Ni et al., 2022a,b; Neelakantan et al., 2022; Wang et al., 2022b), mô hình của chúng tôi ban đầu được tiền huấn luyện trên các cặp văn bản xuất hiện tự nhiên được trích xuất từ các nguồn đa dạng. Để đảm bảo tính linh hoạt của mô hình nhúng, chúng tôi khám phá một loạt các tài nguyên để trích xuất cặp văn bản, bao gồm các trang web (ví dụ: CommonCrawl, ClueWeb), các bài báo khoa học (ví dụ: arXiv, SemanticScholar), các diễn đàn QA cộng đồng (ví dụ: StackExchange), phương tiện truyền thông xã hội (ví dụ: Reddit), cơ sở tri thức (ví dụ: Wikipedia, DBPedia), và kho mã (ví dụ: StackOverflow, GitHub). Ngoài ra, chúng tôi khai thác sự hiện diện của các siêu liên kết trong một số tập dữ liệu để tạo điều kiện cho việc trích xuất cặp văn bản. Bảng 2 thể hiện một số ví dụ về định dạng cặp văn bản từ các nguồn khác nhau. Chi tiết thêm về quá trình thu thập dữ liệu có thể được tìm thấy trong Phụ lục A. Tổng cộng, chúng tôi đã sử dụng ~800M cặp văn bản cho giai đoạn tiền huấn luyện không giám sát. Thống kê đơn giản và phân phối dữ liệu được minh họa trong Bảng 1.

3.3 Dữ liệu Tinh chỉnh Có giám sát

Trong giai đoạn tinh chỉnh có giám sát, chúng tôi sử dụng các tập dữ liệu có kích thước tương đối nhỏ hơn với chú thích của con người về mức độ liên quan giữa hai đoạn văn bản và các bản tiêu cực khó tùy chọn được khai thác bởi một bộ truy xuất bổ sung để tạo thành các bộ ba văn bản. Để xử lý cả các nhiệm vụ đối xứng (ví dụ: tương tự văn bản ngữ nghĩa) và các nhiệm vụ bất đối xứng (ví dụ: truy xuất đoạn văn), chúng tôi thu thập dữ liệu từ một loạt lớn các nhiệm vụ và miền, bao gồm tìm kiếm web (ví dụ: MS MARCO), QA miền mở (ví dụ: NQ), NLI (ví dụ: SNLI), xác minh sự kiện (ví dụ: FEVER), diễn giải (ví dụ: Quora). Chúng tôi đã sử dụng tổng cộng ~3M cặp cho tinh chỉnh, đây là sự kết hợp của dữ liệu huấn luyện được sử dụng bởi nghiên cứu trước đây (Gao et al., 2021; Gao và Callan, 2022; Asai et al., 2023; Su et al., 2023; Li et al., 2023). Chi tiết thêm có thể được tìm thấy trong Phụ lục A.

3.4 Chi tiết Huấn luyện

Lấy mẫu Dữ liệu Trong giai đoạn đầu của tiền huấn luyện không giám sát, các nguồn dữ liệu thường khác nhau đáng kể về số lượng instance huấn luyện. Để giải quyết sự mất cân bằng này, chúng tôi sử dụng phân phối đa thức để lấy mẫu các batch dữ liệu từ các nguồn dữ liệu khác nhau, tính đến kích thước tương ứng của chúng. Giả sử toàn bộ tập dữ liệu tiền huấn luyện D bao gồm m tập con khác nhau {D1, . . . , Dm} và ký hiệu kích thước của mỗi tập con là ni = |Di|, tại mỗi lần lặp huấn luyện, xác suất lấy mẫu dữ liệu từ tập con thứ i Di có thể được biểu diễn bởi: pi = niα / Σmj=1 njα, (4) trong đó chúng tôi đặt α = 0.5 trong công trình này. Hơn nữa, để ngăn mô hình chỉ học các phím tắt cụ thể cho nhiệm vụ để phân biệt, chúng tôi đảm bảo rằng tất cả các instance huấn luyện trong một batch đều xuất phát từ cùng một nhiệm vụ.

Mất mát Tương phản Cải tiến Khi sử dụng mục tiêu tương phản, mọi người thường tái sử dụng các tài liệu trong batch như các ứng viên tiêu cực để cải thiện hiệu quả huấn luyện (Karpukhin et al., 2020). Bài báo này sử dụng một mục tiêu học tương phản cải tiến có tính hai chiều và mở rộng các mẫu tiêu cực với cả các truy vấn và tài liệu trong batch. Điều này có thể được xem như một sự kết hợp của các biến thể mất mát được đề xuất bởi Radford et al. (2021); Ren et al. (2021); Moiseev et al. (2023).

Xem xét một batch các mẫu cặp văn bản tích cực B = {(q1, d1), (q2, d2), ..., (qn, dn)}, chúng tôi sử dụng một mất mát tương phản cải tiến có dạng Licl = −1/n Σni=1 log es(qi,di)/τ / Z (5) với hàm phân vùng là Z = Σj es(qi,dj)/τ + Σj≠i es(qi,qj)/τ + Σj es(qj,di)/τ + Σj≠i es(dj,di)/τ (6) trong đó hai thuật ngữ đầu được sử dụng cho tương phản truy vấn đến tài liệu, trong khi hai thuật ngữ cuối được sử dụng cho ngược lại. Trong công trình này, chúng tôi sử dụng độ tương tự cosine như độ đo khoảng cách s(q, d) = q̄ · d̄ / (||q̄||2 · ||d̄||2). (7) Nhiệt độ τ được cố định ở 0.01 trong công trình này.

Huấn luyện và Đánh giá Việc huấn luyện mô hình nhúng của chúng tôi bao gồm hai giai đoạn. Trong giai đoạn đầu của tiền huấn luyện tương phản chỉ với các bản tiêu cực trong batch, việc sử dụng kích thước batch lớn là rất quan trọng để có hiệu suất mô hình tốt hơn bằng cách giảm khoảng cách giữa huấn luyện và suy luận với nhiều bản tiêu cực được bao gồm và cung cấp một xấp xỉ tốt hơn cho mục tiêu học cơ bản. Để tạo điều kiện cho điều này, chúng tôi giới hạn độ dài chuỗi tối đa là 128 trong quá trình tiền huấn luyện và phân phối việc sử dụng các bản tiêu cực trên tất cả các GPU. Các kỹ thuật phổ biến như huấn luyện chính xác hỗn hợp tự động (Micikevicius et al., 2018) với fp16, deepspeed ZeRO (Rajbhandari et al., 2020) giai đoạn 1 và điểm kiểm tra gradient (Chen et al., 2016) cũng được sử dụng cùng nhau để giảm chi phí bộ nhớ và mở rộng kích thước batch lên hơn mười nghìn. Chúng tôi chạy tiền huấn luyện trong 50.000 bước, tương ứng khoảng với một epoch trên toàn bộ dữ liệu tiền huấn luyện. Chúng tôi chỉ điều chỉnh tốc độ học để đảm bảo sự hội tụ của các mô hình lớn hơn. chúng tôi sử dụng bộ tối ưu hóa AdamW với sự suy giảm tốc độ học tuyến tính và thời gian khởi động trong 5% ban đầu của các bước huấn luyện. Chúng tôi đã tiến hành thí nghiệm trên ba quy mô mô hình khác biệt: nhỏ, cơ bản và lớn. Những mô hình này được khởi tạo sử dụng mô hình MiniLM kích thước nhỏ (Wang et al., 2020) và các mô hình cơ bản và lớn của mô hình BERT (Devlin et al., 2019). Chi tiết thêm có thể được tìm thấy trong Bảng 3.

Trong giai đoạn thứ hai của tinh chỉnh tương phản với dữ liệu có giám sát và các bản tiêu cực khó, kích thước batch lớn là không cần thiết vì các bản tiêu cực khó đã có thể cung cấp một ước tính gradient đáng tin cậy của mục tiêu học (Xiong et al., 2021; Li et al., 2023). Do đó, kích thước batch toàn cục là 128 và kích thước nhóm huấn luyện là 16 được sử dụng, với một ví dụ tích cực và phần còn lại là các bản tiêu cực khó hoặc bản tiêu cực ngẫu nhiên. Thay vào đó, chúng tôi tăng độ dài chuỗi tối đa lên 512 để xử lý tốt hơn các văn bản có độ dài dài hơn. Tốc độ học được giảm bằng một hệ số mười trong quá trình tinh chỉnh. Mô hình được tinh chỉnh trên tập dữ liệu được thu thập trong một epoch duy nhất. Các văn bản trong batch cũng được kết hợp như các ứng viên tiêu cực sử dụng mất mát tương phản được nâng cao được mô tả trong Phương trình 5.

Sau khi huấn luyện, chúng tôi trực tiếp lấy điểm kiểm tra cuối cùng để đánh giá. Chúng tôi chạy huấn luyện mô hình trên tối đa 8 GPU NVIDIA A100 với bộ nhớ 80GB và đánh giá mô hình trên tối đa 8 GPU NVIDIA Tesla V100 với bộ nhớ 32GB. Các mô hình được huấn luyện với chính xác hỗn hợp sử dụng fp16 và cũng được đánh giá với chính xác nửa fp16.

4 Thí nghiệm

Trong phần này, chúng tôi cung cấp một đánh giá rộng lớn về mô hình nhúng của chúng tôi, so sánh với các mô hình hiện đại cho từng nhiệm vụ. Lưu ý rằng một so sánh táo với táo hầu như không thể vì các mô hình khác nhau đã sử dụng dữ liệu nội bộ khác nhau cho tiền huấn luyện và các mô hình ngôn ngữ cơ sở khác nhau rất nhiều. Chúng tôi chủ yếu sử dụng số lượng tham số mô hình như một tiêu chí để so sánh hiệu suất vì nó liên quan chặt chẽ đến tốc độ suy luận.

4.1 Phân loại Văn bản Zero-shot

Một phương pháp để đánh giá chất lượng của biểu diễn đã học là thông qua phân loại zero-shot. (Radford et al., 2021; Neelakantan et al., 2022; Wang et al., 2022b). Chúng tôi định dạng lại phân loại văn bản thành một bài toán khớp độ tương tự dựa trên nhúng. Trong thiết lập này, các văn bản đầu vào được chuyển đổi trực tiếp thành nhúng và các nhãn được diễn đạt thành văn bản tương ứng để có nhúng nhãn. Khoảng cách giữa nhúng đầu vào và nhúng nhãn được đo bằng tích vô hướng của chúng và nhãn có khoảng cách nhúng gần nhất với văn bản đầu vào được coi là kết quả phân loại. Một ví dụ là nhiệm vụ phân loại cảm xúc nhị phân SST-2. Chúng tôi xem xét hai loại bộ diễn giải nhãn để đánh giá. Phiên bản vani sử dụng từ cảm xúc 'tích cực' hoặc 'tiêu cực' để biểu thị các nhãn tương ứng. Phiên bản được gợi ý sử dụng mẫu gợi ý mờ, như 'đây là một ví dụ về đánh giá phim tích cực/tiêu cực'.

Độ chính xác phân loại văn bản zero-shot trên SST-2 được hiển thị trong Bảng 4. Trong thiết lập vani, mô hình 110M của chúng tôi đã khớp với hiệu suất của E5 large được gợi ý với 330M tham số. Sử dụng chiến lược gợi ý càng cải thiện kết quả đáng kể và thu hẹp khoảng cách với các mô hình lớn. Ngay cả không có gợi ý hoặc hướng dẫn rõ ràng trong quá trình huấn luyện, mô hình của chúng tôi có thể hiểu phần nào bối cảnh nhãn tốt hơn khi được định dạng như một văn bản ngôn ngữ tự nhiên.

4.2 Truy xuất Văn bản Không giám sát

Truy xuất văn bản đòi hỏi truy xuất các tài liệu liên quan nhất từ một tập hợp ứng viên quy mô lớn. Chúng tôi sử dụng BEIR (Thakur et al., 2021) như benchmark đánh giá của chúng tôi cho truy xuất văn bản không giám sát zero-shot. BEIR là một benchmark truy xuất thông tin không đồng nhất chứa các nhiệm vụ truy xuất của các định dạng khác nhau và từ các miền khác nhau. Chúng tôi sử dụng 15 tập dữ liệu có sẵn mở để đánh giá. Chúng tôi so sánh điểm kiểm tra được tiền huấn luyện không giám sát của chúng tôi với các bộ truy xuất dày đặc không giám sát gần đây như Contriever (Izacard et al., 2022a) và E5 (Wang et al., 2022b). Theo Bảng 5, chúng tôi thấy rằng mô hình kích thước cơ bản của chúng tôi vượt trội đáng kể so với các mô hình có kích thước tương đương, như SimCSE, Contriever và E5. Mô hình cơ bản của chúng tôi có thể so sánh với E5 large mà không sử dụng giám sát của con người.

4.3 Massive Text Embedding Benchmark

Massive Text Embedding Benchmark (MTEB) là một benchmark bán giám sát toàn diện kết hợp một lượng hạn chế dữ liệu giám sát để đánh giá. Trong bài báo này, chúng tôi đánh giá các tập con tiếng Anh bao gồm 56 tập dữ liệu tiếng Anh trên bảy nhiệm vụ khác biệt, bao gồm phân loại văn bản (Class.), phân cụm văn bản (Clust.), phân loại cặp (Pair.), xếp hạng lại văn bản (Rerank.), truy xuất văn bản (Retr.), tương tự văn bản ngữ nghĩa (STS) và tóm tắt (Summ.). Các chỉ số đánh giá được sử dụng trong MTEB là độ chính xác, v-measure, trung bình chính xác, MAP, nDCG@10, và hệ số Spearman, tương ứng. Để biết thêm chi tiết về các nhiệm vụ được bao gồm trong benchmark MTEB, vui lòng tham khảo Phụ lục B.

Hai thiết lập được xem xét để so sánh: thiết lập không giám sát và thiết lập có giám sát. Trong thiết lập không giám sát, các mô hình được huấn luyện sử dụng dữ liệu không được gán nhãn, trong khi các mô hình có giám sát được tinh chỉnh sử dụng các tập dữ liệu chất lượng cao với nhãn của con người. Kết quả của các mô hình baseline mạnh được trình bày trong Bảng 6.

Trong thiết lập không giám sát, mô hình của chúng tôi vượt trội hơn mô hình tốt nhất trước đây, E5, bằng một khoảng cách đáng kể trên tất cả các nhiệm vụ được xem xét, mà không sử dụng các gợi ý cụ thể cho nhiệm vụ. Sự cải thiện này có thể được quy cho việc bao gồm nhiều định dạng dữ liệu huấn luyện hơn và các nguồn tín hiệu tự giám sát khác nhau. Hơn nữa, đáng chú ý là mô hình được tiền huấn luyện không giám sát của chúng tôi thu hẹp khoảng cách thậm chí xa hơn với các baseline có giám sát lớn hơn, như GTR và Sentence-T5. Trong thiết lập có giám sát, mô hình của chúng tôi vượt qua kết quả OpenAI bằng một khoảng cách lớn mặc dù sử dụng kích thước mô hình khiêm tốn. GTE small có thể so sánh với E5 large trong khi nhỏ hơn 10×. GTE large thiết lập hiệu suất hiện đại mới trên benchmark MTEB, vượt trội hơn mô hình nhúng được tinh chỉnh hướng dẫn đa nhiệm vụ, InstructOR large, bằng 1.5 điểm trung bình.

4.4 Tìm kiếm Mã

Các ngôn ngữ lập trình có thể được coi như một dạng văn bản khác biệt. Để đánh giá hiệu quả của cách tiếp cận của chúng tôi trong tìm kiếm mã, chúng tôi tiến hành một phân tích so sánh với các mô hình ngôn ngữ dựa trên mã khác, như CodeBERT (Guo et al., 2021) và GraphCodeBERT (Guo et al., 2021). Chúng tôi cũng so sánh cách tiếp cận của chúng tôi với một mô hình ngôn ngữ mã gần đây hơn gọi là UniXcoder (Guo et al., 2022), nhằm tích hợp các nhiệm vụ tiền huấn luyện khác nhau thành một mô hình thống nhất. CodeRetriever (Li et al., 2022) được khởi tạo từ GraphCodeBERT và được tiền huấn luyện trên các cặp mã-văn bản đa phương thức quy mô lớn được khai thác và làm sạch bằng phương pháp phỏng đoán. Điều quan trọng cần lưu ý là trong khi các mô hình baseline được huấn luyện và đánh giá riêng lẻ cho từng ngôn ngữ lập trình, mô hình của chúng tôi được đánh giá trực tiếp trên tất cả các ngôn ngữ. Phù hợp với công trình gần đây (Guo et al., 2021, 2022; Li et al., 2022), chúng tôi chủ yếu đánh giá trên các thiết lập thách thức nơi corpus mã bao gồm tất cả mã từ tập dev và test thay vì 1k mã được lấy mẫu ngẫu nhiên. Kết quả được trình bày trong Bảng 7.

Một cách đáng ngạc nhiên, mô hình của chúng tôi vượt qua các mô hình được tiền huấn luyện trên mã và sau đó được tinh chỉnh cho từng ngôn ngữ lập trình riêng biệt. Phát hiện này chứng minh rằng, bằng cách mở rộng lượng dữ liệu và tài nguyên tính toán, mô hình ngôn ngữ có thể có được các biểu diễn mã chất lượng cao trực tiếp từ các chuỗi token mã, mà không cần kết hợp kiến thức của con người về thông tin cấu trúc của mã (Guo et al., 2021). Chúng tôi quan sát một sự cải thiện đáng kể trong Python, có khả năng do sự giống nhau với ngôn ngữ tự nhiên. Mô hình của chúng tôi, được tiền huấn luyện trên các cặp văn bản rộng lớn trải rộng các miền khác nhau, thể hiện việc chuyển giao kiến thức xuyên nhiệm vụ hiệu quả từ truy xuất văn bản sang truy xuất mã.

5 Phân tích

Trong phần này, chúng tôi phân tích các yếu tố quan trọng ảnh hưởng đến hiệu suất mô hình và trình bày một loạt các thí nghiệm loại bỏ. Trừ khi có ghi chú khác, các thí nghiệm được thực hiện sử dụng mô hình quy mô BERT-base với 110M tham số. Các bước huấn luyện và epoch vẫn nhất quán trong tất cả các thí nghiệm loại bỏ.

5.1 Tác động của Quy mô

Chúng tôi điều tra tác động của việc mở rộng số lượng nguồn dữ liệu, kích thước batch, và tham số mô hình đến chất lượng của nhúng văn bản đã học. Đánh giá được tiến hành trên benchmark MTEB.

Số lượng Tập dữ liệu Huấn luyện Đầu tiên, chúng tôi tiến hành một nghiên cứu loại bỏ về số lượng tập dữ liệu huấn luyện được sử dụng trong tiền huấn luyện. Huấn luyện mô hình được thực hiện bằng cách lấy mẫu ngẫu nhiên một tập con từ tất cả các tập dữ liệu có sẵn. Trong giai đoạn tiền huấn luyện, nhóm đầu tiên chỉ bao gồm năm tập dữ liệu lớn nhất, được xếp hạng theo kích thước. Nhóm thứ hai bao gồm thêm 10 tập dữ liệu được lấy mẫu ngẫu nhiên, tạo thành một hỗn hợp của 15 tập dữ liệu. Nhóm thứ ba sử dụng tất cả 33 tập dữ liệu trong quá trình tiền huấn luyện. Đối với tinh chỉnh, chúng tôi ban đầu bắt đầu với ba tập dữ liệu được sử dụng trong tinh chỉnh E5 (Wang et al., 2022b) và dần dần kết hợp các tập dữ liệu từ MEDI (Su et al., 2023) và BERRI (Asai et al., 2023) để điều tra các lợi ích tiềm năng. Kết quả được trình bày trong Hình 3a chứng minh rằng việc bao gồm các nguồn dữ liệu đa dạng hơn liên tục nâng cao hiệu suất mô hình trong cả giai đoạn tiền huấn luyện và tinh chỉnh.

Kích thước Batch Tiền huấn luyện Chúng tôi dần dần tăng kích thước batch theo hệ số 2 trong khi giữ các bước huấn luyện cố định để nghiên cứu ảnh hưởng của kích thước batch được sử dụng trong tiền huấn luyện mô hình nhúng. Theo Hình 3b, hiệu suất mô hình bão hòa ở khoảng kích thước batch mười nghìn. Không có cải thiện hiệu suất nào được quan sát khi tiếp tục mở rộng kích thước batch.

Số lượng Tham số Mô hình Chúng tôi điều tra hành vi mở rộng bằng cách huấn luyện các mô hình ngôn ngữ có kích thước khác nhau, bao gồm 30M, 110M, và 330M, tương ứng với quy mô nhỏ, cơ bản, và lớn của mô hình BERT. Hình 3c minh họa hiệu suất của các mô hình được tiền huấn luyện và tinh chỉnh. Có thể quan sát thấy rằng khi kích thước mô hình tăng theo cấp số nhân, hiệu suất mô hình cũng cải thiện tuyến tính.

5.2 Hành vi Huấn luyện

Chúng tôi vẽ biểu đồ mất mát huấn luyện của các mô hình có kích thước khác nhau trong quá trình tiền huấn luyện tương phản trong Hình 4. Các mô hình lớn hơn có khả năng tốt hơn trong việc học phân biệt các cặp tích cực khỏi các cặp tiêu cực. Mất mát huấn luyện trải qua những biến động nhỏ một cách nhất quán trên tất cả các quy mô mô hình, điều này gợi ý sự thay đổi trong chất lượng và độ khó của dữ liệu mỗi batch.

Chúng tôi cũng đánh giá hiệu suất mô hình tại các bước huấn luyện khác nhau. Được hiển thị rằng hiệu suất mô hình bão hòa ở 20k bước tương ứng khoảng với sự hội tụ huấn luyện.

5.3 Ảnh hưởng của Các Giai đoạn Huấn luyện Khác nhau

Để kiểm tra hiệu quả của học tương phản đa giai đoạn, chúng tôi tiến hành một phân tích về các chiến lược huấn luyện. Chúng tôi so sánh ba thiết lập: a) chỉ tiền huấn luyện trên các cặp văn bản không giám sát được trích xuất từ các nguồn đa dạng; b) chỉ tinh chỉnh trên các tập dữ liệu có giám sát; c) tiền huấn luyện tương phản theo sau bởi tinh chỉnh. Tất cả các mô hình được khởi tạo từ mô hình BERT base gốc.

Có thể quan sát từ Bảng 9 rằng việc chỉ dựa vào dữ liệu có giám sát để tinh chỉnh là không đủ để đạt được một mô hình nhúng văn bản chất lượng cao, có khả năng do kích thước hạn chế của nó. Ngược lại, tiền huấn luyện không giám sát sử dụng các cặp văn bản quy mô web mang lại nhúng văn bản vượt trội so với việc chỉ dựa vào dữ liệu được gán nhãn để tinh chỉnh. Tuy nhiên, việc kết hợp dữ liệu có giám sát theo cách đa giai đoạn với tiền huấn luyện không giám sát vẫn có thể đóng góp vào việc tinh chỉnh các nhúng văn bản đã được học.

5.4 Hỗn hợp Dữ liệu Huấn luyện

Chúng tôi nghiên cứu ảnh hưởng của tỷ lệ trộn được sử dụng trong phân phối lấy mẫu trên dữ liệu tiền huấn luyện đến hiệu suất mô hình.

Hiệu suất trên hai danh mục nhiệm vụ, truy xuất và STS, cũng như hiệu suất trung bình trên MTEB được báo cáo trong Bảng 10. Chúng tôi quan sát thấy rằng việc lấy mẫu đồng đều từ mỗi nhiệm vụ tiền huấn luyện (α = 0) hay việc kết hợp trực tiếp tất cả các nguồn dữ liệu (α = 1) đều không phải là lựa chọn tốt nhất. Đặt α là 0.5 có thể cải thiện kết quả trên tất cả các nhiệm vụ.

5.5 Loại bỏ Mục tiêu Tương phản

Công trình này sử dụng một mục tiêu tương phản cải tiến có thể mở rộng hiệu quả nhóm tiêu cực dưới kích thước batch cố định. Chúng tôi so sánh nó với mất mát tương phản vani chỉ với các bản tiêu cực trong batch trong cả giai đoạn tiền huấn luyện và tinh chỉnh.

Theo Bảng 11, việc sử dụng mất mát tương phản cải tiến liên tục cải thiện hiệu suất mô hình trong cả giai đoạn tiền huấn luyện và tinh chỉnh.

6 Thảo luận

Mặc dù có hiệu suất mạnh mẽ trên các nhiệm vụ tiếng Anh, mô hình hiện tại của chúng tôi chỉ có thể xử lý văn bản có độ dài ít hơn 512, vì nó được khởi tạo từ BERT và thiếu khả năng đa ngôn ngữ. Do đó, các văn bản dài hơn phải được cắt bớt hoặc chia để mã hóa. Tuy nhiên, với nhiều kỹ thuật dữ liệu và tài nguyên tính toán hơn, cách tiếp cận huấn luyện được mô tả có thể dễ dàng được mở rộng thành phiên bản đa ngôn ngữ và chứa các ngữ cảnh dài hơn.

Một vấn đề khác là vấn đề ô nhiễm dữ liệu do tiền huấn luyện quy mô lớn trên dữ liệu Internet. Hiện tại, chúng tôi chỉ tiến hành khử trùng dựa trên khớp chính xác của các cặp văn bản, đây là một bộ lọc quá nghiêm ngặt. Vấn đề này cũng đã được Brown et al. (2020) nhấn mạnh trong quá trình huấn luyện các mô hình ngôn ngữ tạo sinh quy mô lớn. Chúng tôi nghi ngờ rằng đây là một vấn đề phổ biến mà các mô hình khác cũng gặp phải, nhưng việc định lượng nó mà không có chi tiết về các nguồn dữ liệu huấn luyện thậm chí còn thách thức hơn (Neelakantan et al., 2022).

Hơn nữa, các mô hình được huấn luyện trong nghiên cứu này dựa trên một kiến trúc không nhân quả với chú ý ngữ cảnh hai chiều. Sẽ thú vị khi khám phá các phương pháp tiền huấn luyện tương tự cho các mô hình ngôn ngữ nhân quả hoặc tiền tố, vì các mô hình này có thể tối ưu hóa việc tạo sinh và truy xuất cùng nhau và thống nhất chúng trong một mô hình duy nhất.

7 Kết luận

Bài báo này trình bày một cách tiếp cận học tương phản đa giai đoạn để phát triển mô hình nhúng văn bản có thể được áp dụng cho các nhiệm vụ khác nhau. Mô hình của chúng tôi hưởng lợi từ một hỗn hợp dữ liệu huấn luyện đa dạng, cho phép nó đạt được hiệu suất tổng quát hóa tốt cho nhúng vector đơn. Thông qua đánh giá rộng lớn trên nhiều benchmark, chúng tôi chứng minh hiệu quả và tính linh hoạt của mô hình nhúng văn bản của chúng tôi. Công việc tương lai của chúng tôi sẽ tập trung vào việc mở rộng mô hình để hỗ trợ ngữ cảnh dài hơn, mở rộng nó để hỗ trợ các ứng dụng đa ngôn ngữ và đa phương thức, cũng như khám phá lợi ích của các gợi ý và hướng dẫn.

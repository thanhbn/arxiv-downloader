# 2311.04335.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/tokenizer/2311.04335.pdf
# Kích thước tệp: 576800 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Bộ Mã Hóa Dưới Câu:
Học Contrastive của Các Biểu Diễn Ngữ Nghĩa Mệnh Đề
Sihao Chen♣*Hongming Zhang♢Tong Chen♡Ben Zhou♣Wenhao Yu♢
Dian Yu♢Baolin Peng♢Hongwei Wang♢Dan Roth♣Dong Yu♢
♣Đại học Pennsylvania♡Đại học Washington♢Tencent AI Lab
sihaoc@cis.upenn.edu

Tóm tắt
Chúng tôi giới thiệu bộ mã hóa dưới câu, một mô hình embedding ngữ cảnh được học contrastive cho biểu diễn ngữ nghĩa tinh vi của văn bản. Khác với thực hành tiêu chuẩn với sentence embeddings, nơi ý nghĩa của toàn bộ chuỗi văn bản được mã hóa thành một vector có độ dài cố định, bộ mã hóa dưới câu học cách tạo ra các embedding ngữ cảnh khác biệt tương ứng với các mệnh đề nguyên tử khác nhau, tức là các đơn vị nguyên tử của ý nghĩa được thể hiện trong một chuỗi văn bản. Các embedding dưới câu được học contrastive để nhận biết sự tương đương ngữ nghĩa (suy luận) giữa các mệnh đề trên các chuỗi văn bản khác nhau. Các thí nghiệm của chúng tôi cho thấy hiệu quả của bộ mã hóa dưới câu trong các ứng dụng, như truy xuất các sự kiện hỗ trợ cho việc gán thuộc tính văn bản tinh vi hoặc nhận biết sự tương tự ngữ nghĩa có điều kiện giữa các văn bản. Trong thực tế, chúng tôi chứng minh rằng bộ mã hóa dưới câu duy trì cùng mức độ chi phí suy luận và độ phức tạp không gian so với bộ mã hóa câu.
/githubhttps://github.com/schen149/
sub-sentence-encoder

1 Giới thiệu
Sentence embeddings là một lớp kỹ thuật biểu diễn ngữ nghĩa văn bản dưới dạng embedding vector dày đặc (Conneau et al., 2017; Cer et al., 2018; Reimers and Gurevych, 2019). Sentence embeddings được sử dụng rộng rãi trong các thiết lập zero-shot hoặc transfer learning trên các tác vụ truy xuất thông tin và phân loại văn bản (Karpukhin et al., 2020; Gao et al., 2021). Với sentence embeddings, thực hành phổ biến là mã hóa toàn bộ chuỗi văn bản thành một vector có độ dài cố định, nơi mối quan hệ ngữ nghĩa với các chuỗi văn bản khác thường được mô hình hóa bởi một hàm tương tự (Bromley et al., 1993).

Trong khi sentence embeddings cung cấp các biểu diễn ngữ nghĩa thống nhất và compact của văn bản, việc truy vấn các mức độ chi tiết khác nhau của ngữ nghĩa từ sentence embeddings có chiều cố định là khó khăn. Ví dụ, xem xét hai câu ở phần dưới của Hình 1 về tiểu thuyết Dracula. Trong khi hai câu nhìn chung truyền đạt những ý nghĩa khác nhau, ở mức độ của các mệnh đề nguyên tử, tức là các phần ý nghĩa nguyên tử được truyền đạt trong mỗi câu, trở nên rõ ràng rằng hai câu này một phần chia sẻ những ý nghĩa tương tự, ví dụ, cả hai câu đều đồng ý về Dracula là một tiểu thuyết và được xuất bản vào thế kỷ 19.

Việc mã hóa và lập chỉ mục văn bản một cách hiệu quả ở mức độ chi tiết hơn có thể có tác động sâu sắc đến các ứng dụng như đánh giá văn bản dài (Amplayo et al., 2022), gán thuộc tính (Rashkin et al., 2023) hoặc ước lượng tính chính xác (Min et al., 2023). Với văn bản được tạo dài, nhiều mệnh đề trong cùng văn bản có thể có các giá trị tính đúng đắn khác nhau. Điều kiện tiên quyết để xác minh hoặc gán thuộc tính cho văn bản dài như vậy bao gồm (1) biểu diễn văn bản ở mức độ chi tiết hơn của các mệnh đề nguyên tử và (2) có thể truy xuất bằng chứng cho các mệnh đề khác nhau trong một chuỗi văn bản. (Chen et al., 2023a; Kamoi et al., 2023).

--- TRANG 2 ---
Mệnh đề #2 Kiến trúc
Bộ Mã Hóa Transformer
Dracula   is    a   novel   by   Bram   Stoker Các Token Câu Mệnh đề #1 1 0 0 0 1 1 1
1 1 1 1 0 0 0 Selective Mean Pooling MLP Embedding
Mệnh đề Nguyên tử #1 Embedding
Mệnh đề Nguyên tử #2 Bộ Mã Hóa
Dưới Câu Dracula is a novel
by Bram Stoker .Dracula is a novel
by Bram Stoker.
Dracula , a 19th century novel
featuring Count Dracula.
Dracula , a 19th century novel
featuring Count Dracula.
Dracula , a 19th century novel
featuring Count Dracula .

Các Mệnh Đề Nguyên Tử của Câu #1:
Các Mệnh Đề Nguyên Tử của Câu #2:
...Ví dụ Tích cực
Ví dụ Tiêu cực Mục Tiêu Học ...

Hình 2: Tổng quan về kiến trúc bộ mã hóa dưới câu và mục tiêu học: Mô hình nhận đầu vào là một câu và các mệnh đề của nó (được biểu diễn dưới dạng mặt nạ token nhị phân) và đưa ra một embedding cho mỗi mệnh đề. Với một minibatch các câu, mô hình học cách xác định các cặp mệnh đề thể hiện cùng ý nghĩa. Tất cả các mệnh đề khác (bao gồm các mệnh đề khác trong cùng câu) được coi là ví dụ tiêu cực (§3).

Với động lực như vậy, chúng tôi giới thiệu bộ mã hóa dưới câu, một mô hình embedding ngữ cảnh được học contrastive để biểu diễn ngữ nghĩa ở mức dưới câu. Như được thể hiện trong Hình 2, bộ mã hóa dưới câu nhận một hoặc nhiều mệnh đề trong một chuỗi văn bản làm đầu vào. Nó đưa ra một embedding biểu diễn ý nghĩa của mệnh đề. Mỗi mệnh đề có định dạng của một chuỗi mặt nạ token nhị phân trên văn bản, biểu thị các token được bao gồm trong mỗi mệnh đề (Chen et al., 2023b).

Chúng tôi huấn luyện mô hình bộ mã hóa dưới câu để nhận biết sự tương đương ngữ nghĩa giữa các cặp mệnh đề nguyên tử thông qua học contrastive có giám sát trong batch (Khosla et al., 2020). Chúng tôi lấy mẫu và tạo các ví dụ huấn luyện từ một corpus lớn dữ liệu cặp câu không nhãn với các mô hình trích xuất mệnh đề và NLI (§3.3).

Chúng tôi đánh giá bộ mã hóa dưới câu trên hai loại tác vụ downstream liên quan đến biểu diễn ngữ nghĩa ở mức dưới câu. Đầu tiên, chúng tôi chứng minh rằng bộ mã hóa dưới câu có thể được sử dụng cho truy xuất tinh vi, ví dụ, cho gán thuộc tính văn bản, nơi một mô hình được kỳ vọng truy xuất bằng chứng hỗ trợ cho các phần khác nhau của một câu. Thứ hai, chúng tôi cho thấy rằng bộ mã hóa dưới câu có thể được sử dụng để suy luận sự tương tự ngữ nghĩa có điều kiện giữa một cặp văn bản (Deshpande et al., 2023).

Chúng tôi thảo luận về các lựa chọn thiết kế và thách thức thực tế trong việc áp dụng bộ mã hóa dưới câu trong lập chỉ mục quy mô lớn của một corpus truy xuất ở mức mệnh đề. Vì việc mã hóa toàn bộ corpus ở mức mệnh đề có thể dẫn đến kích thước quá lớn một cách cấm đoán, chúng tôi giảm chiều đầu ra của mô hình bộ mã hóa dưới câu trong quá trình huấn luyện (Wang et al., 2023). Chúng tôi cho thấy rằng thủ thuật đơn giản nhưng hiệu quả này dẫn đến nén 12× đến 16× trong kích thước chỉ mục với sự giảm hiệu suất tối thiểu.

Các đóng góp chính của bài báo là: (1) Chúng tôi đề xuất bộ mã hóa dưới câu, một phương pháp embedding ngữ cảnh cho ngữ nghĩa văn bản tinh vi; (2) Chúng tôi giới thiệu một quy trình tự động để tạo dữ liệu huấn luyện cho bộ mã hóa dưới câu; (3) Chúng tôi đánh giá tính hữu ích của bộ mã hóa dưới câu trong các ứng dụng downstream của truy xuất sự kiện nguyên tử và tương tự ngữ nghĩa văn bản có điều kiện.

2 Kiến thức cơ bản

2.1 Động lực: Gán thuộc tính văn bản

Thiết kế bộ mã hóa dưới câu của chúng tôi chủ yếu được thúc đẩy bởi ứng dụng downstream của gán thuộc tính văn bản (Rashkin et al., 2023), tức là xác định thông tin hỗ trợ từ các nguồn đã biết để gán thuộc tính cho văn bản do mô hình tạo ra. Với việc áp dụng rộng rãi các mô hình tạo văn bản, việc đánh giá và gán thuộc tính cho văn bản được tạo ra đã trở thành một chủ đề nghiên cứu mới nổi cần thiết (Gao et al., 2023a,b; Liu et al., 2023; Malaviya et al., 2023). Một thách thức chính trong các tác vụ như vậy nằm ở mức độ chi tiết của thông tin được gán thuộc tính, tức là một phần văn bản được tạo ra thường đưa ra nhiều hơn một tuyên bố, mỗi tuyên bố có thể có tính chính xác khác nhau. Ví dụ, như Hình 1 cho thấy, có thể tồn tại nhiều tuyên bố ngay cả trong một câu được tạo ra dưới dạng mệnh đề. Mỗi tuyên bố hoặc mệnh đề cần được ngữ cảnh hóa (Choi et al., 2021) và được xác minh riêng lẻ với các nguồn thông tin có thể khác nhau (Kamoi et al., 2023; Min et al., 2023). Quá trình này không thể tránh khỏi đòi hỏi một mô hình hiệu quả biểu diễn ngữ nghĩa của các phần câu khác nhau trong ngữ cảnh, điều này mô tả nguyên tắc thiết kế chính cho bộ mã hóa dưới câu.

2.2 Hạn chế của Sentence Embeddings

Từ góc độ của các ứng dụng downstream như gán thuộc tính văn bản, nghiên cứu của chúng tôi giải quyết hai thiếu sót sau đây của các mô hình sentence encoder hiện tại.

Mức độ chi tiết. Mặc dù sentence embeddings thường nắm bắt ý nghĩa của toàn bộ chuỗi văn bản dưới dạng embedding có độ dài cố định (Morris et al., 2023), trong thực tế khó có thể truy vấn sentence embeddings để lấy thông tin hoặc cấu trúc ngữ nghĩa ở mức độ chi tiết hơn (Rudinger et al., 2017; Qin and Van Durme, 2023; Wang and Yu, 2023). Định dạng này sẽ cung cấp khả năng biểu đạt hạn chế khi mô hình hóa các tác vụ như truy xuất tài liệu, đặc biệt khi tác vụ về mặt khái niệm liên quan đến việc xác định các phần tài liệu phản hồi truy vấn. Vì lý do đó, các nghiên cứu trước đây đã tìm thấy thành công thực nghiệm với truy xuất cụm từ hoặc mô hình tương tác muộn, hỗ trợ các biểu diễn chi tiết và biểu cảm hơn của corpus truy xuất (Seo et al., 2019; Khattab and Zaharia, 2020; Lee et al., 2021a,b).

Ngữ cảnh hóa. Một giả định điển hình cho các mô hình sentence encoder và thiết lập tác vụ huấn luyện/đánh giá là câu được mã hóa độc lập mà không có ngữ cảnh. Điều này trở thành một yếu tố hạn chế trong các tình huống mà sự tương tự và khác biệt giữa các cặp văn bản phụ thuộc vào ngữ cảnh chúng xuất hiện (Chen et al., 2019; Schuster et al., 2022; Milbauer et al., 2023a,b; Deshpande et al., 2023).

3 Bộ Mã Hóa Dưới Câu

Chúng tôi nghiên cứu một loại kiến trúc và mục tiêu học mới - bộ mã hóa dưới câu. Trái ngược với bộ mã hóa câu, bộ mã hóa dưới câu được thiết kế để tạo ra các embedding ngữ cảnh cho mỗi mệnh đề nguyên tử trong một câu.

3.1 Kiến trúc

Kiến trúc bộ mã hóa dưới câu được hiện thực hóa tương tự như các bi-encoder dựa trên transformer cho câu (Reimers and Gurevych, 2019), như được thể hiện trong Hình 2. Sự khác biệt chính là bộ mã hóa dưới câu nhận k tập hợp mặt nạ token nhị phân làm đầu vào bổ sung, biểu thị k mệnh đề của một câu mà nó cần tạo embedding.

Câu đầu vào đầu tiên được chuyển tiếp qua một bộ mã hóa transformer, có thể được khởi tạo từ bất kỳ mô hình encoder được huấn luyện trước nào. Sau đó, đối với mỗi trong k mặt nạ token, các embedding token có giá trị mặt nạ là 1 được tổng hợp trung bình và chuyển tiếp qua một lớp MLP chiếu. Mô hình đưa ra k embedding có độ dài cố định tương ứng với k mệnh đề đầu vào.

Lưu ý rằng k mặt nạ token chỉ được áp dụng trong quá trình tổng hợp, và bộ mã hóa vẫn nhận được sự chú ý đầy đủ đến toàn bộ câu. Điều này cho phép các embedding mệnh đề có thông tin ngữ cảnh của toàn bộ câu/đoạn văn đầu vào, có thể làm giảm nhu cầu khử ngữ cảnh hóa các mệnh đề (Choi et al., 2021). Ngoài ra, vì không có sự chú ý chéo giữa các embedding mệnh đề, mỗi mệnh đề được mã hóa độc lập với các mệnh đề khác, và biểu diễn của nó vốn dĩ bất biến với thứ tự đầu vào của các mệnh đề.

So với bộ mã hóa câu, bộ mã hóa dưới câu thêm một lượng nhỏ tham số với lớp MLP ở trên cùng. Vì câu có thể được chuyển tiếp chỉ một lần, chi phí suy luận bổ sung của việc mã hóa nhiều mệnh đề trong một câu là tối thiểu trong thực tế, như chúng tôi thảo luận trong §4.

3.2 Học Contrastive

Với hai mệnh đề từ các câu khác nhau, mục tiêu là làm cho chúng có các biểu diễn embedding tương tự nếu chúng thể hiện ý nghĩa tương tự, và có các biểu diễn không tương tự trong trường hợp ngược lại. Trong một minibatch của N mệnh đề từ M câu. Gọi vi = trong Rd là biểu diễn được mã hóa của mệnh đề thứ i trong batch. Gọi I={1..N} biểu thị chỉ số của tất cả các mệnh đề. Chúng tôi hình thức hóa mục tiêu học như việc tối thiểu hóa loss contrastive có giám sát trong batch L (Khosla et al., 2020):

L=∑i∈I −1/|P(i)| ∑p∈P(i) log exp(vi·vp/τ)/∑j∈I\{i} exp(vi·vj/τ)

trong đó P(i) là tập hợp các chỉ số của tất cả các mệnh đề tích cực với mệnh đề thứ i trong minibatch, và |P(i)| biểu thị cardinality của nó. τ kiểm soát nhiệt độ softmax. Mục tiêu học khuyến khích mô hình tạo ra các embedding có độ tương tự cosine cao hơn với các cặp mệnh đề tích cực, trong khi tất cả các mệnh đề khác trong cùng batch được coi là tiêu cực. Lưu ý rằng nếu tất cả các mệnh đề từ cùng một câu được đóng gói trong cùng minibatch, dưới giả định rằng chúng không thể là ví dụ tích cực của nhau, mục tiêu học sẽ vốn dĩ khuyến khích mô hình gán các biểu diễn khác nhau cho các phần khác nhau của một câu.

Loss contrastive có giám sát là một dạng tổng quát của các hàm loss khác thường được sử dụng cho huấn luyện bi- hoặc dual-encoder, ví dụ, N-pairs loss (Sohn, 2016) hoặc in-batch softmax (Karpukhin et al., 2020). Chúng tôi lựa chọn công thức này chủ yếu do khả năng tổng quát hóa cho một số lượng tùy ý các ví dụ tích cực trong cùng batch. Trong trường hợp của chúng tôi, điều này quan trọng, vì mỗi mệnh đề có thể có không hoặc nhiều ví dụ tích cực trong cùng minibatch.

3.3 Lấy mẫu Cặp Mệnh đề cho Huấn luyện

Ở đây, chúng tôi mô tả cách chúng tôi tự động lấy mẫu các cặp mệnh đề tích cực từ một tập hợp các cặp câu không nhãn làm dữ liệu huấn luyện cho bộ mã hóa dưới câu. Chúng tôi bắt đầu từ một tập hợp 2.5M cặp câu từ các bài báo tin tức có liên quan chủ đề (Zhou et al., 2022). Dữ liệu này được thu thập từ RealNews (Zellers et al., 2019) để tìm các cặp câu song song thường mô tả cùng một sự kiện với các góc độ và trọng tâm hơi khác nhau. Các trường hợp này phục vụ như điểm khởi đầu tuyệt vời cho nhu cầu của chúng tôi vì chúng tôi muốn tìm các cặp mệnh đề có cả sự tương tự và khác biệt.

Bước 1: Phân đoạn Câu ⇒ Mệnh đề.
Với một cặp câu không nhãn, đầu tiên chúng tôi phân tích mỗi câu thành các mệnh đề dưới dạng ngôn ngữ tự nhiên. Đầu tiên, chúng tôi nhắc GPT-3.5-turbo tạo mệnh đề cho 1% của tất cả các cặp câu làm tập dữ liệu huấn luyện seed. Chúng tôi thấy rằng GPT-3.5-turbo với các minh họa few-shot trong ngữ cảnh cho hiệu suất hợp lý trên tác vụ, điều này phù hợp với các quan sát từ Min et al. (2023); Kamoi et al. (2023).

Tiếp theo, chúng tôi fine-tune T5-large (Raffel et al., 2020) trên tập huấn luyện seed và sử dụng mô hình để tạo mệnh đề cho phần còn lại của tập dữ liệu. Chúng tôi bao gồm thêm chi tiết về prompt và quy trình huấn luyện trong Phụ lục A.

Bước 2: Xác định Cặp Tích cực với mô hình NLI.
Với hai tập mệnh đề (dưới dạng ngôn ngữ tự nhiên) trong mỗi cặp câu, chúng tôi suy luận và gắn nhãn các cặp mệnh đề tích cực với một mô hình NLI có sẵn (Nie et al., 2020). Chúng tôi chuyển tiếp mỗi cặp mệnh đề qua hai câu thông qua mô hình NLI hai lần, với thứ tự đảo ngược giữa hypothesis và premise. Chúng tôi gắn nhãn một cặp mệnh đề tích cực nếu mô hình NLI phân loại mối quan hệ của chúng là entailment theo cả hai hướng. Chúng tôi chỉ giữ các cặp câu có ít nhất một cặp mệnh đề tích cực. Điều này để lại cho chúng tôi 240k cặp câu, với 3.32 mệnh đề mỗi câu và 1.21 mệnh đề tích cực trung bình.

Bước 3: Chuyển đổi Mệnh đề ⇒ Mặt nạ Token.
Chúng tôi chuyển đổi các mệnh đề dưới dạng ngôn ngữ tự nhiên sang định dạng mặt nạ token được sử dụng cho đầu vào bộ mã hóa dưới câu bằng cách căn chỉnh các token trong mỗi mệnh đề với câu. Chúng tôi sử dụng NLTK (Bird et al., 2009) để lemmatize mỗi token trong một mệnh đề và câu của nó và xây dựng một ma trận ái lực giữa hai bên, nơi các token có lemma giống hệt nhau được gán điểm tương tự là 1. Để phá vỡ sự ràng buộc giữa nhiều token khớp, chúng tôi áp dụng một bộ lọc 2D-convolution trên ma trận ái lực, thêm một offset điểm nhỏ cho các token khớp khác trong cửa sổ ngữ cảnh ba token. Chúng tôi tìm các khớp tối ưu giữa mệnh đề và câu với max bipartite matching trên ma trận ái lực với thuật toán Hungarian (Kuhn, 1955). Chúng tôi bao gồm mô tả quy trình chi tiết hơn trong Phụ lục A.

4 Thiết lập Thí nghiệm

4.1 Cấu hình Mô hình

Chúng tôi khởi tạo các lớp bộ mã hóa transformer với trọng số được huấn luyện trước từ ba loại sentence encoder: SimCSE (Gao et al., 2021), Sentence-T5 (Ni et al., 2022a), và GTR (Ni et al., 2022b).

--- TRANG 5 ---
Hệ thống Kích thước Tham. PRECISION @1 RECALL @5 RECALL @10 RECALL @20
MiniLM-L6-v2 23M 18.36 37.28 44.87 51.62
DistilRoberta 82M 16.59 33.65 40.82 46.79
SimCSE (không giám sát) 110M 8.90 45.13 69.47 84.29
SimCSE (có giám sát) 110M 16.53 57.83 77.28 87.89
GTR base 110M 21.90 52.50 65.54 75.69
ST5 base 110M 26.16 57.65 69.00 78.58
SUBENCODER (SimCSE) 110M (+0.5M) 41.64 71.48 78.22 83.34
SUBENCODER (ST5 base) 110M (+0.5M) 40.97 72.15 79.30 84.33
SUBENCODER (GTR base)110M (+0.5M) 40.77 72.90 80.45 85.81

Bảng 1: Kết quả đánh giá zero-shot trên tác vụ Atomic Fact Retrieval trong PROPSEGMENT (Chen et al., 2023b).

Với Sentence-T5 và GTR, chúng tôi thử nghiệm với các biến thể kích thước base, large, và xl của các mô hình. Đối với lớp MLP, chúng tôi giữ chiều đầu ra giống như bộ mã hóa transformer. Chúng tôi thảo luận về tác động của việc thay đổi chiều đầu ra trong §5.4.

Chúng tôi fine-tune bộ mã hóa dưới câu với các biến thể khác nhau của backbone sentence encoder trên 240k cặp câu có ít nhất một cặp mệnh đề tích cực. Chúng tôi ký hiệu mô hình kết quả là SUBENCODER. Chúng tôi bao gồm chi tiết cho thiết lập huấn luyện phân tán và siêu tham số trong Phụ lục B.

4.2 Đánh giá

Để đánh giá tính hữu ích của bộ mã hóa dưới câu, chúng tôi đánh giá mô hình của chúng tôi trên hai loại tác vụ downstream trong thiết lập zero-shot.

4.2.1 Truy xuất Sự kiện Nguyên tử cho Gán thuộc tính Văn bản Tinh vi

Đầu tiên chúng tôi đánh giá bộ mã hóa dưới câu trong việc truy xuất gán thuộc tính tinh vi (Rashkin et al., 2023) cho văn bản. Chúng tôi tiến hành đánh giá với tập dữ liệu PROPSEGMENT (Chen et al., 2023b). Một tổng quan về thiết lập tác vụ được thể hiện trong Hình 3.

Với một mệnh đề nguyên tử trong câu, một hệ thống được kỳ vọng xác định và truy xuất bằng chứng hỗ trợ từ một corpus gồm ~45k mệnh đề nguyên tử được gắn nhãn bởi con người từ 1.5k tài liệu News hoặc Wikipedia tổng cộng. Thiết lập tác vụ mô phỏng tình huống mà mỗi phần của một câu có thể có tính chính xác khác nhau, và vì vậy mỗi mệnh đề nguyên tử trong một câu có thể được gán thuộc tính cho bằng chứng hỗ trợ khác nhau từ các tài liệu nguồn khác nhau. Trung bình, mỗi mệnh đề truy vấn có 1.13 mệnh đề hỗ trợ ground truth.

Thước đo. Với xếp hạng đầu ra của hệ thống về 45k mệnh đề bằng chứng ứng viên đối với một mệnh đề truy vấn, chúng tôi đo precision@1 cộng recall@{5,10,20} của xếp hạng so với tập mệnh đề bằng chứng ground truth được gắn nhãn bởi con người.

Baseline. Chúng tôi so sánh các sentence encoder được huấn luyện trước làm baseline. Đầu tiên chúng tôi đánh giá các biến thể của SimCSE không giám sát và có giám sát, Sentence-T5, và GTR trên kích thước tham số mô hình tương tự. Ngoài ra, chúng tôi so sánh hai mô hình compact phổ biến, tức là all-MiniLM-L6-v2 và all-distilroberta-v1 từ sentence-transformers (Reimers and Gurevych, 2019). Chúng tôi thảo luận về thiết lập cho sentence encoder cho các tác vụ trong Phụ lục C.

Kết quả. Bảng 1 tóm tắt kết quả đánh giá của chúng tôi. Chúng tôi quan sát thấy SUBENCODER với các backbone encoder khác nhau thường cải thiện so với các đối tác sentence encoder của chúng. Chúng tôi thấy những cải thiện rõ ràng nhất của SUBENCODER về Precision@1 và Recall@5, trong khi khoảng cách hiệu suất trở nên nhỏ hơn về Recall@10 và 20. Điều này cho thấy rằng học contrastive dưới câu mang lại cho mô hình khả năng tốt hơn trong việc nhận biết sự khác biệt ngữ nghĩa tinh tế giữa các mệnh đề xuất hiện trong cùng ngữ cảnh.

Qua các biến thể khác nhau của SUBENCODER với các backbone sentence encoder khác nhau, chúng tôi quan sát mức hiệu suất tương tự nhìn chung, với biến thể GTR base có ưu thế nhẹ. Trong Bảng 1, chúng tôi chủ yếu so sánh các mô hình có cùng kích thước và cấu hình backbone encoder. SUBENCODER của chúng tôi chỉ giới thiệu thêm 0.5% tham số với lớp MLP ở trên cùng. Chúng tôi bao gồm phân tích toàn diện hơn về kích thước mô hình, hiệu quả, và sự đánh đổi hiệu suất trong §5.

4.2.2 Tương tự Ngữ nghĩa Văn bản Có điều kiện

Để đánh giá khả năng của SUBENCODER trong việc tạo ra các biểu diễn ngữ cảnh cho ngữ nghĩa tinh vi ở mức dưới câu của văn bản, chúng tôi tiến hành thí nghiệm trên tác vụ Condition Semantic Text Similarity

--- TRANG 6 ---
Loại Câu 1 Câu 2 Điều kiện Nhãn Dự đoán
Đúng. Một nhóm người trượt tuyết trên một ngọn đồi tuyết, và một con chó đuổi theo một người khi anh ta trượt. Một người, mặc đồ đen, nhảy xuống con đường phủ tuyết và chơi với một con chó đen. Hoạt động thể chất. 4 3.44
Lỗi: không tìm được tập từ tốt. Một người đàn ông bị ném lên không trung trong khi bị một con bò tót giẫm đạp. Người cao bồi bám vào con bò tót đang tuyệt vọng cố gắng ném anh ta xuống. Độ cao của người. 4 1
Lỗi: tập từ đúng; suy luận thất bại. Một người đàn ông mặc áo ba lỗ trắng và mũ cứng trắng đang cầm hai đoạn ống tại một công trường xây dựng. Một công nhân xây dựng trong áo vest an toàn màu xanh chanh và mũ cứng cam đang nhìn kỹ vào thứ gì đó cầm trong tay. Nghề nghiệp của người đàn ông. 5 2.47

Bảng 2: Ví dụ đầu ra và lỗi điển hình của SUBENCODER trên C-STS. Tập từ được xác định bởi gpt-3.5 được đánh dấu màu vàng. Để hiển thị ở đây, độ tương tự cosine dự đoán của mô hình được chuẩn hóa để khớp với thang nhãn của con người từ 1 - 5, trong đó 1 = Ít tương tự nhất, và 5 = Tương tự nhất

Mô hình Thiết lập Spearman r↑
Roberta base 0-shot (Không Điều kiện) -0.43*
SimCSE base 0-shot (Không Điều kiện) 1.66*
FlanT5 large 0-shot -3.0*
2-shot 11.7*
GPT-3.5 0-shot 14.1
2-shot 15.4
GPT-4 0-shot 36.9
2-shot 40.7
GPT-3.5
+ SUBENCODER
(0-shot) (SimCSE base) 27.5
(GTR base) 31.9
(ST5 base) 33.0
GPT-4
+ SUBENCODER
(0-shot) (SimCSE base) 34.5
(GTR base) 36.9
(ST5 base) 37.2

Bảng 3: Hệ số tương quan Spearman (×100) của dự đoán mô hình được đánh giá trong thiết lập zero- hoặc few-shot trên tác vụ Conditional Semantic Textual Similarity (C-STS). * biểu thị kết quả từ Deshpande et al. (2023).

(C-STS) (Deshpande et al., 2023). So với STS (Agirre et al., 2012), C-STS giới thiệu một khái niệm điều kiện về tương tự giữa các cặp văn bản, nơi một điều kiện ngôn ngữ tự nhiên bổ sung được cung cấp cùng với cặp văn bản làm đầu vào. Một hệ thống được kỳ vọng đưa ra điểm tương tự giữa cặp từ góc độ của điều kiện đã cho. Bảng 2 cho thấy một số ví dụ của tác vụ.

Phương pháp. Với điều kiện, đầu tiên chúng tôi nhắc một LLM để xác định một tập từ trong mỗi câu tương ứng tốt nhất với điều kiện. Ở đây, LLM chỉ thấy một câu tại một thời điểm, vì vậy các từ điều kiện trong mỗi câu được xác định độc lập. Chúng tôi sử dụng bộ mã hóa dưới câu để mã hóa tập từ trong ngữ cảnh của mỗi câu làm biểu diễn có điều kiện. Chúng tôi lấy độ tương tự cosine giữa hai tập từ được mã hóa từ cặp văn bản làm độ tương tự có điều kiện của chúng.

Thước đo. Chúng tôi so sánh hệ số tương quan Spearman giữa độ tương tự dự đoán từ một hệ thống với đánh giá của con người.

Baseline. Chúng tôi so sánh với một danh sách các baseline zero- và few-shot được cung cấp bởi (Deshpande et al., 2023). Điều này bao gồm hai mô hình bi-encoder, Roberta base và SimCSE base không sử dụng điều kiện làm đầu vào, cũng như kết quả prompting zero- và few-shot với FlanT5 large, GPT-3.5-turbo và GPT-4, nơi mỗi LLM được cung cấp hướng dẫn chi tiết về tác vụ, và được nhắc tạo điểm tương tự từ 1 đến 5 với cặp văn bản và điều kiện có/không có minh họa trong ngữ cảnh.

Kết quả. Bảng 3 cho thấy kết quả đánh giá. Bằng cách để SUBENCODER so sánh độ tương tự ngữ cảnh giữa tập từ được chọn bởi gpt-3.5-turbo, chúng tôi thấy cải thiện trong thiết lập zero-shot từ Spearman's r = 14.1→33.0, so với việc trực tiếp nhắc LLM để đưa ra độ tương tự. Tuy nhiên, khoảng cách hiệu suất khi sử dụng gpt-4 trở nên nhỏ hơn nhiều (r = 36.9→37.2). Điều này hợp lý xem xét thực tế rằng prompting gpt-4 trực tiếp cho thấy hiệu suất ngang bằng với các hệ thống có giám sát trên C-STS, như được báo cáo trong Deshpande et al. (2023). Chúng tôi cho thấy ví dụ về các lỗi điển hình do mô hình của chúng tôi mắc phải trong Bảng 2. Chúng tôi quan sát rằng phương pháp của chúng tôi thường thất bại khi (1) LLM không xác định được tập từ điều kiện tốt, hoặc khi không có từ tương ứng như vậy tồn tại rõ ràng trong câu, hoặc (2) SUBENCODER không suy luận chính xác độ tương tự giữa hai tập từ điều kiện. Ví dụ, với ví dụ thứ ba trong Bảng 2, việc suy luận đặc biệt thách thức đối với mô hình, xem xét mối quan hệ giữa hai câu chỉ được mô hình hóa thông qua độ tương tự cosine mà không có tham số được học.

--- TRANG 7 ---
68707274 Recall@5
69.6269.39 69.3770.7871.4372.15 Kích thước Batch so với Hiệu suất
(Kích thước Tham. = 110M)
68707274
70.7872.9373.74 Kích thước Mô hình so với Hiệu suất
(Kích thước Batch = 64)
816 32 64128 256
Kích thước batch 38404244 Precision@1
37.5437.9138.2440.6241.44
40.97
110M 330M 3B
Kích thước Tham số 38404244
40.6242.6143.17

Hình 4: Tác động của việc thay đổi kích thước batch và kích thước tham số mô hình lên hiệu suất truy xuất sự kiện nguyên tử, được kiểm tra với biến thể Sentence-T5 của SUBENCODER.

5 Phân tích và Thảo luận

5.1 Mở rộng SUBENCODER

Trong Hình 4, chúng tôi cho thấy phân tích về tác động của việc mở rộng kích thước mô hình và kích thước batch trong quá trình huấn luyện. Để phân tích, chúng tôi sử dụng biến thể Sentence-T5 của SUBENCODER, và đánh giá hiệu suất trên tác vụ truy xuất sự kiện nguyên tử.

Mở rộng Kích thước Batch. Vì mục tiêu học contrastive của chúng tôi tận dụng lấy mẫu tiêu cực trong batch, việc mở rộng kích thước batch trong quá trình huấn luyện có thể mang lại lợi ích hiệu suất. Để minh họa điều này, chúng tôi khởi tạo SUBENCODER với tham số encoder Sentence-T5 base và fine-tune với kích thước batch thay đổi là {8,16,32,64,128,256}. Chúng tôi quan sát rằng việc tăng kích thước batch thường tăng hiệu suất, điều này cho thấy rằng việc mở rộng kích thước batch có thể mang lại khả năng tổng quát hóa mô hình tốt hơn. Chúng tôi quan sát một lợi ích hiệu suất đáng kể khi tăng kích thước batch từ 32→64 trong khi thấy lợi ích giảm dần với việc tăng thêm. Điều này phù hợp với các phát hiện thực nghiệm với học contrastive trong batch nói chung (Khosla et al., 2020). Hiện tượng có thể được quy cho các nhãn dự đoán mô hình trong tập dữ liệu huấn luyện của chúng tôi, có thể có nhiễu.

Mở rộng Kích thước Mô hình. Chúng tôi khởi tạo encoder với các kích thước khác nhau của Sentence-T5 từ 110M đến 3B tham số và fine-tune với kích thước batch cố định là 64. Chúng tôi quan sát rằng việc bắt đầu từ một encoder được huấn luyện trước lớn hơn mang lại hiệu suất tốt hơn. Chúng tôi thấy lợi ích lớn hơn khi tăng kích thước mô hình từ 110M lên 330M, trong khi lợi ích trở nên nhỏ hơn khi chúng tôi tăng từ 330M lên 3B.

5.2 Sử dụng SUBENCODER cho Truy xuất Câu hoặc Tài liệu

Trong §4, chúng tôi so sánh hiệu suất của SUBENCODER trên tác vụ truy xuất sự kiện nguyên tử với các sentence encoder baseline. Trong thực tế, một tình huống ứng dụng có khả năng hơn là khi hệ thống được kỳ vọng truy xuất bằng chứng hỗ trợ ở mức câu hoặc tài liệu. Để đánh giá điều này, chúng tôi đưa tác vụ truy xuất sự kiện nguyên tử thành tác vụ truy xuất câu hoặc tài liệu, nơi với một mệnh đề truy vấn, một hệ thống được kỳ vọng truy xuất tập câu hoặc tài liệu chứa các mệnh đề mục tiêu.

Từ trực giác rằng truy xuất tinh vi hơn, ví dụ, với các mệnh đề, đòi hỏi truy xuất ở mức câu hoặc tài liệu thô hơn, chúng tôi theo Lee et al. (2021b) và sử dụng một chiến lược đơn giản với SUBENCODER cho truy xuất ở mức câu và tài liệu. Với mỗi truy vấn, chúng tôi truy xuất một số lượng mệnh đề hơi lớn hơn. Từ tập câu và tài liệu mà các mệnh đề thuộc về, chúng tôi sử dụng điểm cao nhất trong tập mệnh đề làm điểm cho mỗi câu hoặc tài liệu. Sau đó k câu hoặc tài liệu duy nhất hàng đầu được trả về làm kết quả.

Bảng 4 cho thấy kết quả đánh giá. So với GTR base và Sentence-T5 base, được huấn luyện cho truy xuất ở mức tài liệu và câu tương ứng, chúng tôi quan sát mức hiệu suất tương tự với việc truy xuất bằng mệnh đề với SUBENCODER. Nhìn chung, chúng tôi thấy độ chính xác top-1 thấp hơn so với các baseline. Điều này có thể do bản chất phức tạp hơn của tác vụ truy xuất mệnh đề. Tuy nhiên, chúng tôi thường thấy cải thiện về recall @ 5. Các phát hiện cho thấy tiềm năng của việc sử dụng SUBENCODER cho truy xuất đa vector qua các mức độ chi tiết khác nhau.

--- TRANG 8 ---
Mô hình Chiều Precision@1 Recall@5
SUBENCODER
(ST5-Large) 1024 42.61 72.93
64 42.10 (-0.51) 70.17 (-2.76)
SUBENCODER
(ST5-Base) 768 40.97 72.15
64 40.45 (-0.52) 71.62 (-0.53)

Bảng 5: Sự khác biệt hiệu suất trên tác vụ truy xuất sự kiện nguyên tử có và không có việc giảm chiều đầu ra của SUBENCODER.

5.3 Tính bền vững với Định dạng/Ranh giới Đầu vào

Mặc dù SUBENCODER được fine-tune với dữ liệu được định dạng đặc biệt như mệnh đề, chúng tôi quan sát từ các đánh giá C-STS rằng mô hình tổng quát hóa cho các đầu vào không nhất thiết có hình dạng mệnh đề, như được thể hiện trong Bảng 2. Trong các ứng dụng downstream, chúng tôi kỳ vọng mô hình tổng quát hóa cho các mặt nạ token đầu vào với ranh giới không hoàn hảo, ví dụ, các mệnh đề được tạo bởi mô hình thay vì được gắn nhãn bởi con người. Bên cạnh kết quả đánh giá C-STS, gián tiếp hỗ trợ giả thuyết của chúng tôi, chúng tôi tiến hành đánh giá đơn giản với tác vụ truy xuất sự kiện nguyên tử. Thay vì các truy vấn được gắn nhãn bởi con người, chúng tôi sử dụng các truy vấn được tạo bởi gpt-3.5-turbo. Kết quả đánh giá hiệu suất phân đoạn mệnh đề của gpt-3.5-turbo và mô hình T5-Large được chưng cất có thể được tìm thấy trong Phụ lục A. Chúng tôi quan sát rằng, với một thước đo dựa trên Jaccard-similarity mờ ở mức token, hầu hết các mệnh đề được trích xuất bởi mô hình có thể được căn chỉnh với các mệnh đề được gắn nhãn bởi con người. Khi chúng tôi kiểm tra hiệu suất truy xuất sự kiện nguyên tử trên tập các mệnh đề được tạo bởi mô hình có thể được khớp mờ với các mệnh đề được gắn nhãn bởi con người, chúng tôi chỉ thấy một sự giảm nhỏ trong hiệu suất, ví dụ, với biến thể GTR-base của SUBENCODER, precision@1 giảm từ 41.21 → 39.56, recall@5 giảm từ 73.14→72.23. Chúng tôi đưa ra giả thuyết rằng tính bền vững của ranh giới mệnh đề một phần đến từ cách chúng tôi huấn luyện mô hình. Vì các nhãn giữa các cặp mệnh đề được tạo độc lập với ranh giới mệnh đề mờ được tạo bởi mô hình, mô hình có thể học cách thích nghi với ranh giới mệnh đề không hoàn hảo, tương tự như trực giác đằng sau huấn luyện SimCSE không giám sát (Gao et al., 2021).

5.4 Lập chỉ mục Offline và Nén

Với lợi ích hiệu suất đầy hứa hẹn từ SUBENCODER trong tác vụ truy xuất sự kiện nguyên tử, chúng tôi thảo luận và đánh giá khả năng áp dụng SUBENCODER cho truy xuất tinh vi trên các corpus quy mô lớn hơn, điều này liên quan đến lập chỉ mục offline và

Chỉ mục Số Mục Chiều Kích thước Chỉ mục
Mệnh đề 270M 64 62GB
dpr-100w 21M 768 61GB

Bảng 6: Kích thước chỉ mục kết quả với lập chỉ mục ở mức mệnh đề với chiều nén, so với chỉ mục DPR của các khối 100 từ (Karpukhin et al., 2020).

cache các corpus được mã hóa. Trong trường hợp của chúng tôi, việc lập chỉ mục xảy ra ở mức các mệnh đề nguyên tử, nơi chúng tôi cần lưu trữ một embedding cho mỗi mệnh đề nguyên tử trong corpus. So với lập chỉ mục ở mức tài liệu, việc lập chỉ mục ở mức mệnh đề sẽ dẫn đến kích thước chỉ mục lớn một cách cấm đoán. Trong các công trình trước đây (Lee et al., 2021b), điều này thường được giải quyết với các kỹ thuật như product quantization (Jegou et al., 2010) để nén kích thước chỉ mục hoặc tìm kiếm láng giềng gần đúng (Malkov and Yashunin, 2018) để suy luận nhanh hơn.

Trực giao với hai kỹ thuật trên, chúng tôi nghiên cứu một chiến lược nén đơn giản nhưng hiệu quả bằng cách giảm chiều đầu ra của SUBENCODER. Trong bối cảnh sentence encoder, Wang et al. (2023) phát hiện rằng việc giảm chiều đầu ra trong quá trình huấn luyện thường dẫn đến mất mát hiệu suất downstream tối thiểu. Theo ý tưởng này, chúng tôi fine-tune các biến thể Sentence T5 base và large của SUBENCODER với chiều đầu ra thắt cổ chai là 64 thay vì chiều đầu ra gốc là 1024 và 768 tương ứng. Bảng 5 cho thấy so sánh hiệu suất khi được đánh giá trên tác vụ truy xuất sự kiện nguyên tử. Nhìn chung, chúng tôi quan sát sự giảm hiệu suất rất nhỏ trong khi đạt được giảm 12× đến 16× trong kích thước embedding đầu ra.

Để chứng minh ý nghĩa của điều này trong thực tế, chúng tôi sử dụng biến thể Sentence T5 large của SUBENCODER để mã hóa và lập chỉ mục một bản dump Wikipedia tiếng Anh từ 2021/10/13, như được sử dụng bởi Bohnet et al. (2022). Chúng tôi phân đoạn tất cả các câu trong Wikipedia thành mệnh đề với mô hình T5-large (§3.3). Điều này dẫn đến ~270M mệnh đề từ 5.3M trang Wikipedia. Bảng 6 cho thấy chỉ mục kết quả. Kích thước kết quả là 62GB gần với chỉ mục dense passage retrieval (DPR) được xây dựng sẵn (không nén) ở mức các khối 100 từ (Karpukhin et al., 2020). Chúng tôi thấy rằng việc giảm chiều đầu ra của embeddings giúp giảm kích thước chỉ mục được cache. Đáng chú ý rằng so với chỉ mục ở mức tài liệu, chúng tôi vẫn kỳ vọng tốc độ truy vấn của chỉ mục tăng lên một chút do sự gia tăng số lượng mục. Tuy nhiên, trong thực tế, chúng tôi quan sát độ phức tạp thời gian và không gian tổng thể hợp lý liên quan đến lập chỉ mục offline và truy vấn tương tự online ở mức mệnh đề.

--- TRANG 9 ---
6 Kết luận

Chúng tôi giới thiệu bộ mã hóa dưới câu, một khung học contrastive để học các embedding ngữ cảnh cho các đơn vị ngữ nghĩa ở mức dưới câu. Ngoài các trường hợp sử dụng được đề cập trong bài báo, kiến trúc bộ mã hóa dưới câu có thể phục vụ như backbone cho bất kỳ tác vụ liên kết thông tin liên tài liệu nào trong ngữ cảnh, và các mục tiêu học có thể áp dụng cho một phạm vi rộng hơn các tác vụ với mức độ chi tiết thông tin khác nhau, ví dụ, liên kết câu hoặc đoạn trong các tài liệu khác nhau (Ma et al., 2023). Chúng tôi hy vọng rằng các phát hiện trong bài báo này sẽ tạo điều kiện cho việc khám phá thêm theo những hướng này.

Hạn chế

Công trình này chủ yếu phục vụ như công trình khám phá để xác thực ý tưởng đằng sau kiến trúc và mục tiêu học bộ mã hóa dưới câu. Chúng tôi thừa nhận quy mô hạn chế của các thí nghiệm của chúng tôi, đặc biệt là về các ngôn ngữ được hỗ trợ bởi mô hình. Trong các thí nghiệm của chúng tôi, chúng tôi khám phá ý tưởng bộ mã hóa dưới câu chỉ với văn bản tiếng Anh. Tuy nhiên, các kỹ thuật được mô tả trong bài báo để lấy mẫu dữ liệu huấn luyện và huấn luyện bộ mã hóa dưới câu có thể được áp dụng cho các ngôn ngữ khác. Chúng tôi để lại việc khám phá bộ mã hóa dưới câu đa ngôn ngữ cho công việc tương lai.

Lời cảm ơn

Các tác giả muốn cảm ơn Alex Fabrikant, Jianmo Ni, và Tal Schuster cho các cuộc thảo luận dẫn đến sự phát triển của ý tưởng này. Các tác giả cảm ơn Xinran Zhao, Kaixin Ma, Vivek Gupta, và Xiaodong Yu cho phản hồi có giá trị về dự án và trình bày bài báo.

Tài liệu tham khảo

Eneko Agirre, Daniel Cer, Mona Diab, và Aitor Gonzalez-Agirre. 2012. SemEval-2012 task 6: A pilot on semantic textual similarity. Trong *SEM 2012: The First Joint Conference on Lexical and Computational Semantics - Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation (SemEval 2012), trang 385-393, Montréal, Canada. Association for Computational Linguistics.

Reinald Kim Amplayo, Peter J Liu, Yao Zhao, và Shashi Narayan. 2022. Smart: Sentences as basic units for text evaluation. Trong The Eleventh International Conference on Learning Representations.

Steven Bird, Ewan Klein, và Edward Loper. 2009. Natural language processing with Python: analyzing text with the natural language toolkit. " O'Reilly Media, Inc.".

Bernd Bohnet, Vinh Q Tran, Pat Verga, Roee Aharoni, Daniel Andor, Livio Baldini Soares, Jacob Eisenstein, Kuzman Ganchev, Jonathan Herzig, Kai Hui, et al. 2022. Attributed question answering: Evaluation and modeling for attributed large language models. arXiv preprint arXiv:2212.08037.

Jane Bromley, Isabelle Guyon, Yann LeCun, Eduard Säckinger, và Roopak Shah. 1993. Signature verification using a" siamese" time delay neural network. Advances in neural information processing systems, 6.

Daniel Cer, Yinfei Yang, Sheng-yi Kong, Nan Hua, Nicole Limtiaco, Rhomni St. John, Noah Constant, Mario Guajardo-Cespedes, Steve Yuan, Chris Tar, Brian Strope, và Ray Kurzweil. 2018. Universal sentence encoder for English. Trong Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, trang 169-174, Brussels, Belgium. Association for Computational Linguistics.

Jifan Chen, Grace Kim, Aniruddh Sriram, Greg Durrett, và Eunsol Choi. 2023a. Complex claim verification with evidence retrieved in the wild. arXiv preprint arXiv:2305.11859.

Sihao Chen, Senaka Buthpitiya, Alex Fabrikant, Dan Roth, và Tal Schuster. 2023b. PropSegmEnt: A large-scale corpus for proposition-level segmentation and entailment recognition. Trong Findings of the Association for Computational Linguistics: ACL 2023, trang 8874-8893, Toronto, Canada. Association for Computational Linguistics.

Sihao Chen, Daniel Khashabi, Wenpeng Yin, Chris Callison-Burch, và Dan Roth. 2019. Seeing things from a different angle:discovering diverse perspectives about claims. Trong Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), trang 542-557, Minneapolis, Minnesota. Association for Computational Linguistics.

Eunsol Choi, Jennimaria Palomaki, Matthew Lamm, Tom Kwiatkowski, Dipanjan Das, và Michael Collins. 2021. Decontextualization: Making sentences stand-alone. Transactions of the Association for Computational Linguistics, 9:447-461.

Alexis Conneau, Douwe Kiela, Holger Schwenk, Loïc Barrault, và Antoine Bordes. 2017. Supervised learning of universal sentence representations from

--- TRANG 10 ---
natural language inference data. Trong Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, trang 670-680, Copenhagen, Denmark. Association for Computational Linguistics.

Ameet Deshpande, Carlos E Jimenez, Howard Chen, Vishvak Murahari, Victoria Graf, Tanmay Rajpurohit, Ashwin Kalyan, Danqi Chen, và Karthik Narasimhan. 2023. CSTS: Conditional Semantic Textual Similarity. Trong Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing.

William Falcon và The PyTorch Lightning team. 2019. PyTorch Lightning.

Luyu Gao, Zhuyun Dai, Panupong Pasupat, Anthony Chen, Arun Tejasvi Chaganty, Yicheng Fan, Vincent Zhao, Ni Lao, Hongrae Lee, Da-Cheng Juan, và Kelvin Guu. 2023a. RARR: Researching and revising what language models say, using language models. Trong Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 16477-16508, Toronto, Canada. Association for Computational Linguistics.

Tianyu Gao, Xingcheng Yao, và Danqi Chen. 2021. SimCSE: Simple contrastive learning of sentence embeddings. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, trang 6894-6910, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.

Tianyu Gao, Howard Yen, Jiatong Yu, và Danqi Chen. 2023b. Enabling large language models to generate text with citations. arXiv preprint arXiv:2305.14627.

Herve Jegou, Matthijs Douze, và Cordelia Schmid. 2010. Product quantization for nearest neighbor search. IEEE transactions on pattern analysis and machine intelligence, 33(1):117-128.

Ryo Kamoi, Tanya Goyal, Juan Diego Rodriguez, và Greg Durrett. 2023. Wice: Real-world entailment for claims in wikipedia. Trong Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing.

Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, và Wen-tau Yih. 2020. Dense passage retrieval for open-domain question answering. Trong Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), trang 6769-6781, Online. Association for Computational Linguistics.

Omar Khattab và Matei Zaharia. 2020. Colbert: Efficient and effective passage search via contextualized late interaction over bert. Trong Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, trang 39-48.

Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian, Phillip Isola, Aaron Maschinot, Ce Liu, và Dilip Krishnan. 2020. Supervised Contrastive Learning. Advances in neural information processing systems, 33:18661-18673.

Harold W Kuhn. 1955. The Hungarian method for the assignment problem. Naval research logistics quarterly, 2(1-2):83-97.

Jaewoong Lee, Heejoon Lee, Hwanhee Lee, và Kyomin Jung. 2021a. Learning to select question-relevant relations for visual question answering. Trong Proceedings of the Third Workshop on Multimodal Artificial Intelligence, trang 87-96, Mexico City, Mexico. Association for Computational Linguistics.

Jinhyuk Lee, Alexander Wettig, và Danqi Chen. 2021b. Phrase retrieval learns passage retrieval, too. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, trang 3661-3672, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.

Nelson F Liu, Tianyi Zhang, và Percy Liang. 2023. Evaluating verifiability in generative search engines. arXiv preprint arXiv:2304.09848.

Kaixin Ma, Hao Cheng, Yu Zhang, Xiaodong Liu, Eric Nyberg, và Jianfeng Gao. 2023. Chain-of-skills: A configurable model for open-domain question answering. Trong Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 1599-1618, Toronto, Canada. Association for Computational Linguistics.

Chaitanya Malaviya, Subin Lee, Sihao Chen, Elizabeth Sieber, Mark Yatskar, và Dan Roth. 2023. ExpertQA: Expert-curated questions and attributed answers. arXiv preprint arXiv:2309.07852.

Yu A Malkov và Dmitry A Yashunin. 2018. Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs. IEEE transactions on pattern analysis and machine intelligence, 42(4):824-836.

Jeremiah Milbauer, Ziqi Ding, Zhijin Wu, và Tongshuang Wu. 2023a. From nuisance to news sense: Augmenting the news with cross-document evidence and context. arXiv preprint arXiv:2310.04592.

Jeremiah Milbauer, Annie Louis, Mohammad Javad Hosseini, Alex Fabrikant, Donald Metzler, và Tal Schuster. 2023b. LAIT: Efficient multi-segment encoding in transformers with layer-adjustable interaction. Trong Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 10251-10269, Toronto, Canada. Association for Computational Linguistics.

Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wen-tau Yih, Pang Wei Koh, Mohit Iyyer, Luke Zettlemoyer, và Hannaneh Hajishirzi. 2023. FActScore: Fine-grained atomic evaluation of factual

--- TRANG 11 ---
precision in long form text generation. Trong Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing.

John X Morris, Volodymyr Kuleshov, Vitaly Shmatikov, và Alexander M Rush. 2023. Text embeddings reveal (almost) as much as text. arXiv preprint arXiv:2310.06816.

Jianmo Ni, Gustavo Hernandez Abrego, Noah Constant, Ji Ma, Keith Hall, Daniel Cer, và Yinfei Yang. 2022a. Sentence-t5: Scalable sentence encoders from pre-trained text-to-text models. Trong Findings of the Association for Computational Linguistics: ACL 2022, trang 1864-1874, Dublin, Ireland. Association for Computational Linguistics.

Jianmo Ni, Chen Qu, Jing Lu, Zhuyun Dai, Gustavo Hernandez Abrego, Ji Ma, Vincent Zhao, Yi Luan, Keith Hall, Ming-Wei Chang, và Yinfei Yang. 2022b. Large dual encoders are generalizable retrievers. Trong Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, trang 9844-9855, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, và Douwe Kiela. 2020. Adversarial NLI: A new benchmark for natural language understanding. Trong Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, trang 4885-4901, Online. Association for Computational Linguistics.

Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. 2019. Pytorch: An imperative style, high-performance deep learning library. Advances in neural information processing systems, 32.

Guanghui Qin và Benjamin Van Durme. 2023. Nugget: Neural agglomerative embeddings of text. Trong Proceedings of the 40th International Conference on Machine Learning, ICML'23. JMLR.org.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, và Peter J. Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research, 21(140):1-67.

Hannah Rashkin, Vitaly Nikolaev, Matthew Lamm, Lora Aroyo, Michael Collins, Dipanjan Das, Slav Petrov, Gaurav Singh Tomar, Iulia Turc, và David Reitter. 2023. Measuring attribution in natural language generation models. Computational Linguistics, trang 1-64.

Nils Reimers và Iryna Gurevych. 2019. Sentence-BERT: Sentence embeddings using Siamese BERT-networks. Trong Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), trang 3982-3992, Hong Kong, China. Association for Computational Linguistics.

Rachel Rudinger, Kevin Duh, và Benjamin Van Durme. 2017. Skip-prop: Representing sentences with one vector per proposition. Trong IWCS 2017 - 12th International Conference on Computational Semantics - Short papers.

Tal Schuster, Sihao Chen, Senaka Buthpitiya, Alex Fabrikant, và Donald Metzler. 2022. Stretching sentence-pair nli models to reason over long documents and clusters. Trong Findings of the Association for Computational Linguistics: EMNLP 2022, trang 394-412.

Minjoon Seo, Jinhyuk Lee, Tom Kwiatkowski, Ankur Parikh, Ali Farhadi, và Hannaneh Hajishirzi. 2019. Real-time open-domain question answering with dense-sparse phrase index. Trong Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, trang 4430-4441, Florence, Italy. Association for Computational Linguistics.

Kihyuk Sohn. 2016. Improved deep metric learning with multi-class n-pair loss objective. Advances in neural information processing systems, 29.

Hongwei Wang và Dong Yu. 2023. Going beyond sentence embeddings: A token-level matching algorithm for calculating semantic textual similarity. Trong Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), trang 563-570.

Hongwei Wang, Hongming Zhang, và Dong Yu. 2023. On the dimensionality of sentence embeddings. arXiv preprint arXiv:2310.15285.

Rowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk, Ali Farhadi, Franziska Roesner, và Yejin Choi. 2019. Defending against neural fake news. NeurIPS.

Ben Zhou, Kyle Richardson, Xiaodong Yu, và Dan Roth. 2022. Learning to decompose: Hypothetical question decomposition based on comparable texts. Trong Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, trang 2223-2235, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

--- TRANG 12 ---
A Phân đoạn Mệnh đề

Trong phần này, chúng tôi cung cấp chi tiết về prompt few-shot và mô hình T5-large được chưng cất mà chúng tôi sử dụng để phân đoạn câu thành mệnh đề. Chúng tôi cung cấp đánh giá hai phương pháp so với PROPSEGMENT (Chen et al., 2023b).

A.1 Prompt cho Phân đoạn Mệnh đề

Chúng tôi sử dụng prompt sau với gpt-3.5-turbo để tạo tập dữ liệu huấn luyện seed ban đầu cho việc phân đoạn câu thành mệnh đề. Chúng tôi cung cấp một ví dụ từ PROPSEGMENT cho minh họa học trong ngữ cảnh. Chúng tôi xử lý ~23,000 cặp câu với prompt, tạo ra tổng cộng 44,970 câu với mệnh đề, sau khi lọc bỏ các thế hệ sai định dạng và rỗng.

Prompt cho câu ⇒ mệnh đề
Với câu sau, hãy cho tôi biết họ đang đưa ra những tuyên bố gì. Vui lòng chia câu càng nhiều càng tốt, nhưng không bao gồm thông tin không có trong câu.

Câu: The Andy Warhol Museum in his hometown, Pittsburgh, Pennsylvania, contains an extensive permanent collection of art.
Tuyên bố:
1. The Andy Warhol Museum is in Pittsburgh.
2. Andy Warhol's hometown is in Pittsburgh.
3. Pittsburgh is in Pennsylvania.
4. The Andy Warhol Museum contains an extensive permanent collection of art.

Câu: (câu đầu vào)
Tuyên bố:

A.2 Chi tiết huấn luyện T5 cho phân đoạn mệnh đề

Chúng tôi fine-tune một mô hình T5-large (Raffel et al., 2020) trên tập dữ liệu huấn luyện seed được tạo qua GPT-3.5-turbo. Chúng tôi sử dụng optimizer AdamW với tốc độ học không đổi là 1e−4, với kích thước batch là 128. Chúng tôi huấn luyện mô hình trong 3 epoch trên 8x Nvidia A6000s, mất 2 giờ để hoàn thành.

A.3 Chuyển đổi mệnh đề từ ngôn ngữ tự nhiên sang mặt nạ token

Với một mệnh đề của một câu dưới dạng ngôn ngữ tự nhiên, chúng tôi chuyển đổi và căn chỉnh nó với một tập con các token từ câu gốc với các bước sau. Đầu tiên chúng tôi tokenize và lemmatize mỗi token trong mệnh đề bằng NLTK (Bird et al., 2009). Tiếp theo, chúng tôi xây dựng một ma trận ái lực giữa tập các token được lemmatize từ mệnh đề và câu. Với ma trận này, chúng tôi gán các token có lemma giống hệt nhau được gán điểm tương tự là 1. Để phá vỡ sự ràng buộc giữa nhiều token khớp, chúng tôi áp dụng một bộ lọc 2D-convolution trên ma trận ái lực, thêm một offset điểm nhỏ cho các token khớp khác trong cửa sổ ngữ cảnh ba token. Với ma trận ái lực, chúng tôi tìm sự căn chỉnh tối ưu giữa các token mệnh đề và câu với max bipartite matching trên ma trận ái lực với thuật toán Hungarian (Kuhn, 1955).

A.4 Đánh giá Phân đoạn Mệnh đề trên PROPSEGMENT

Để đánh giá chất lượng mệnh đề được trích xuất qua pipeline của chúng tôi, chúng tôi đánh giá hiệu suất phân đoạn mệnh đề trên PROPSEGMENT. Kết quả được thể hiện trong Bảng 7. Để biết chi tiết về các thước đo đánh giá dựa trên Jaccard similarity cho phân đoạn mệnh đề, vui lòng tham khảo Chen et al. (2023b).

B Huấn luyện và Siêu tham số

Chúng tôi triển khai kiến trúc bộ mã hóa dưới câu với pytorch (Paszke et al., 2019) và pytorch-lightning (Falcon và The PyTorch Lightning team, 2019). Tất cả các biến thể mô hình sub-encoder của chúng tôi được huấn luyện trên 8 × Nvidia A6000 GPUs với 48GB VRAM.

Huấn luyện Phân tán Vì chúng tôi áp dụng loss contrastive trong batch, chúng tôi mở rộng số lượng ví dụ tiêu cực bằng cách tăng kích thước batch với huấn luyện phân tán qua GPUs. Chúng tôi phân tán các quy trình huấn luyện qua các nút GPU thông qua Distributed Data Parallel (DDP). Cụ thể, với một mini-batch của Ngpu×M câu, mỗi GPU nhận M câu, được chuyển tiếp qua các tham số mô hình trên GPU. Tiếp theo, chúng tôi thu thập và sao chép tất cả các mệnh đề được mã hóa cùng với gradient đến mỗi GPU, để mỗi GPU có minibatch đầy đủ cho tính toán loss. Mỗi quy trình GPU backpropagate loss độc lập trên bản sao tham số mô hình của nó.

Siêu tham số Cho tất cả thí nghiệm, chúng tôi sử dụng tham số nhiệt độ τ = 0.01 cho loss contrastive có giám sát, với optimizer AdamW. Cho các biến thể Sentence-T5 và GTR của mô hình, chúng tôi

--- TRANG 13 ---
Mô hình Jaccard theta= 0.8 Jaccard theta= 0.5
Precision Recall F1 Precision Recall F1
Hệ thống sử dụng trong bài báo này
GPT-3.5-turbo 35.79 31.65 33.60 71.52 63.87 67.48
T5-Large (w/ dữ liệu huấn luyện GPT3.5) 35.91 31.70 33.68 70.27 63.39 66.65
Hệ thống fine-tuned trên PROPSEGMENT (Chen et al., 2023b)
BERT-Large 34.97 33.42 34.17 67.42 64.17 65.75
T5-Large 55.95 55.05 55.50 78.03 76.74 77.38

Bảng 7: Hiệu suất phân đoạn câu của các hệ thống sử dụng trong bài báo này khi được đánh giá trong thiết lập zero-shot trên PROPSEGMENT. Chúng tôi bao gồm hiệu suất của các mô hình được huấn luyện trên PROPSEGMENT được báo cáo bởi Chen et al. (2023b) như một tham chiếu.

sử dụng tốc độ học 1e−4. Cho SimCSE, chúng tôi sử dụng tốc độ học 5e−5. Chúng tôi huấn luyện các mô hình trong 10 epoch, và một sự suy giảm tuyến tính được áp dụng vào cuối mỗi epoch, giảm tốc độ học về 0 sau 10 epoch. Chúng tôi chọn checkpoint tốt nhất dựa trên validation loss sau mỗi epoch.

C Thiết lập Đánh giá

C.1 Biểu diễn Mệnh đề Nguyên tử với Sentence Encoder

Với đánh giá truy xuất sự kiện nguyên tử trên PROPSEGMENT, vì các mệnh đề truy vấn và mục tiêu ground truth đều được biểu diễn dưới định dạng mặt nạ token, chúng tôi thử nghiệm với một vài chiến lược định dạng đầu vào khác nhau cho sentence encoder. Cụ thể, đối với câu đầu vào và mặt nạ token biểu thị mệnh đề, đây là các chiến lược khác nhau được xem xét.

1. Chỉ mask pooling. Encoder có sự chú ý đầy đủ, áp dụng mặt nạ mệnh đề trong quá trình pooling. Lưu ý rằng đây là phương pháp tương tự chúng tôi sử dụng cho bộ mã hóa dưới câu.

2. Full mask. Áp dụng mặt nạ mệnh đề như mặt nạ attention trong cả encoding và pooling.

3. Chỉ tập con token. Lấy tập con các token và loại bỏ phần còn lại. Chỉ đưa tập con token như một chuỗi vào encoder và lớp pooling.

Khi được kiểm tra trên một tập validation nhỏ cho tác vụ truy xuất sự kiện nguyên tử, chúng tôi thường quan sát rằng chỉ mask pooling mang lại kết quả tốt nhất trên hầu hết các mô hình, ngoại trừ hai mô hình compact, tức là MiniLM-L6-v2 và DistilRoberta. Trên hai mô hình compact, chúng tôi thấy full mask vượt trội hơn chiến lược chỉ mask pooling với một khoảng cách nhỏ. Chúng tôi quan sát rằng với chiến lược thứ ba chỉ tập con token, hiệu suất validation tụt hậu so với hai chiến lược kia trên tất cả các mô hình.

# 2301.11063.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/rl-alignment/2301.11063.pdf
# File size: 1347625 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
Rewarded meta-pruning: Meta Learning Using Rewards for Channel Pruning
Athul Shibu, Abhishek Kumar, Heechul Jung, Dong-Gyu Lee
Dept. of Artiﬁcial Intelligence, Kyungpook National University
fathulshibu, abhishek.ai, heechul, dglee g@knu.ac.kr
Abstract
Convolutional Neural Networks (CNNs) have a large
number of parameters and takes signiﬁcantly large hard-
ware resources to compute, so edge devices struggle to run
high level networks. This paper proposes a novel method to
reduce the parameters and FLOPs for computational efﬁ-
ciency in deep learning models. We introduce accuracy and
efﬁciency coefﬁcients to control the trade-off between the
accuracy of the network and its computing efﬁciency. The
proposed Rewarded meta-pruning algorithm trains a net-
work to generate weights for a pruned model chosen based
on the approximate parameters of the ﬁnal model by con-
trolling the interactions using a reward function. The re-
ward function allows more control over the metrics of the
ﬁnal pruned model. Extensive experiments demonstrate su-
perior performances of proposed method over the state-of-
the-art methods in pruning ResNet-50, MobileNetV1 and
MobileNetV2 networks.
1. Introduction
Convolutional Neural Networks (CNNs) have been
shown to achieve state-of-the-art results in various com-
puter vision tasks [23,26,29–31]. However, training the pa-
rameters of a CNN requires a signiﬁcant amount of labeled
data. Furthermore, a large amount of hardware resources
are also required for training a large amount of training data.
Recently, network pruning has become an important topic
to simplify and accelerate large CNNs [24, 30, 52, 58].
Many issues are at stake when trying to prune networks,
such as structure [32], continuity [42] or scalability [41].
There are primarily two ways to compress neural networks:
weight [3,12,50] and channel pruning [8,10,38]. Reducing
parameters by pruning connections is the most intuitive way
to prune a network. Weight pruning consists of identifying
low-performing weights to be pruned [14]. This involves
simply removing weights with small magnitudes, which is
easy to implement [15]. However, most frameworks cannot
accelerate sparse matrices during computation. In order to
get real compression and speedup, it requires speciﬁcallydeﬁned software [24] or hardware [13] to handle the spar-
sity. The actual cost is not impacted no matter how many
weights are pruned.
Therefore, channel pruning which involves removing
whole ﬁlters instead of simply reducing the weight val-
ues to zero is preferred instead. [27, 39]. This preference
stems from the fact that channel pruning could remove the
whole ﬁlters, creating a model with structured sparsity [20].
With structured sparsity, the model can take full advan-
tage of high-efﬁciency Basic Linear Algebra Subprogram
(BLAS) libraries to achieve better acceleration. This makes
the pruned model more structural and achieves practical ac-
celeration [13].
MetaPruning [40] is one such channel pruning approach
that can achieve the acceleration of CNNs. The central ap-
proach to MetaPruning is to generate weights for pruned
structures instead of pruning weights or ﬁlters of the ex-
isting network. The accuracy of the untrained models is
computed to rank each Network Encoding Vector (NEV).
Evolutionary algorithms, which are motivated by processes
of natural evolution [28], are used to ﬁnd the NEV that
produces a model of the highest accuracy. Consequently,
however, MetaPruning is only able to choose the best accu-
racy chosen from a set range of FLOPs. So the algorithm
ﬁnds the highest accuracy within the predetermined range
of FLOPs instead of trying to ﬁnd the proper balance be-
tween sacriﬁcing accuracy and reducing FLOPs.
This paper tries to address this issue. In the proposed Re-
warded meta-pruning, instead of ﬁnding NEVs that produce
the highest accuracy, the model tries to balance the accuracy
with the FLOPs of the network to ﬁnd the highest accuracy
possible for the given FLOPs. In MetaPruning, the reward
is directly proportional to the accuracy, because the reward
is accuracy. So the increase in reward of subsequent muta-
tions is lower compared to those of Rewarded meta-pruning,
where the reward is directly proportional to the square of ac-
curacy. At the same time, Rewarded meta-pruning is able to
control the FLOPs of the ﬁnal model by computing a score
that takes both the accuracy and FLOPs into account to ﬁnd
models with high accuracy and low FLOPs. This score,
which is the reward, can be further tweaked to include vari-arXiv:2301.11063v1  [cs.CV]  26 Jan 2023

--- PAGE 2 ---
ous parameters and control the metrics of the pruned model,
as well as how the parameters interact with each other.
Our contribution lies in three folds:
• We propose a channel pruning method, Rewarded
meta-pruning, that can learn how to assign weights to
pruned networks.
• We explore the importance of reward functions and the
characteristics to deﬁne an effective reward function.
• We experimentally show the superiority of the pro-
posed pruning method on publicly available pre-
trained CNNs; ResNet-50, MobileNetV1, and Mo-
bileNetV2.
2. Related Work
The Lottery ticket hypothesis states that a randomly ini-
tialized dense neural network contains a subnetwork which,
when trained in isolation, can yield results as well or even
superior to the original network [12]. In other words, a stan-
dard pruned network can have the same, if not higher accu-
racy, than the original network. There are several methods
to ﬁnd the right tickets.
Unstructured network pruning : Various random prun-
ing methods [3, 12, 50] rely on pruning the parameters ran-
domly based on various factors of the weights. [60] uses
the L1 and L2 norm of each weight to compute their im-
portance. The ﬁnal pruned model is generated by prun-
ing the less important weights. [19] computes the geo-
metric median of the weights while [46] uses the com-
plex Taylor series expansion to calculate the weight func-
tion. Other weight pruning methods like [44] and [35] use
KL-divergence importance and Empirical sensitivity of the
weights respectively to prune them.
Structured network pruning : In other approaches, Au-
toPruner [43] integrates ﬁlter selection into the model train-
ing so that the ﬁnetuned network can select unimportant ﬁl-
ters automatically. Sparse Structure Selection (SSS) [25]
proposes the introduction of a new parameter, the scaling
factor, which scales the output of speciﬁc structures. The
sparsity regularization on these scaling factors pushes them
to zero during training. Discriminative-aware channel prun-
ing (DCP) [62] can ﬁnd channels with true discriminative
power and updates the model by pruning stage-wise us-
ing discrimination-aware losses. Adaptive DCP [38] in-
troduces an additional discriminative-aware loss using the
p-th loss, and additional losses such as additive angular
margin loss [8]. AutoML for Model Compression (AMC)
[18] leverages reinforcement learning to automatically sam-
ple the design space and improve the model compression
quality. Simpler methods like HRank [36] determine the
rank of feature maps generated by ﬁlters to rank the ﬁlters
and their effectiveness on the ﬁnal accuracy. This howevertakes more epochs to train after pruning. [61] leverages the
Lottery ticket hypothesis to greedily search through a net-
work, ﬁnding subnetworks with lower loss than networks
trained with gradient descent. Pruning algorithms that are
inspired by Hebbian theory, like Fire Together Wire To-
gether (FTWT) [10], prune ﬁlters based on the binary mask
of each layer and the activation of the previous layer.
Meta-learning : Meta-learning is the learning of algo-
rithms from other learning algorithms [11, 40, 53]. Funda-
mentally there are three paradigms [54] in meta-learning;
meta-optimizer, meta-representation and meta-objective.
Meta-optimizer is the optimizer used to learn the opti-
mization in the outer loop of meta-learning [21]. Meta-
representation aims to learn and update the meta-knowledge
[11]. Lastly, Meta-objective is the ﬁnal achieved task after
completing training [34].
Learning to prune ﬁlters : Reinforcement Learning
(RL) algorithms have been used to generate network ar-
chitecture descriptions using Recurrent Neural Networks
trained via policy gradient method [63]. The same has also
been implemented using Q-learning [49]. Try-and-learn al-
gorithm [24] uses RL to compute the reward of each ﬁlter
and these rewards are then used to rank ﬁlters. It aggres-
sively prunes ﬁlters in the baseline network while maintain-
ing performance at a desired level. The model computes a
reward as a product of the accuracy and efﬁciency term, and
then uses REINFORCE [55] to estimate the gradients. The
gradients can then be used to compute the loss and train the
network, which learns to prune ﬁlters. The reward function
makes it possible to control the trade-off between network
performance and scale without human intervention. The
try-and-learn algorithm automatically discovers redundant
ﬁlters and removes them by repeating the process for every
layer.
Neural architecture searching : Many methods have
been proposed to search for optimal network structures
from possible neural architectures [51, 56, 63]. There are
primarily ﬁve methods used to search for an optimized net-
work; reinforcement learning [1, 63], genetic algorithms
[47, 57], gradient-based approaches [56], parameter shar-
ing [5] and weights prediction [4]. [63] uses RL to optimize
the networks generated from model descriptions given by a
recurrent network. MetaQNN [1] uses RL with a greedy ex-
ploration strategy to generate high-performing CNN archi-
tectures. Genetic algorithms are used to solve search and
optimization problems using bio-inspired operators [57].
[47] uses genetic algorithms to discover neural network ar-
chitectures, minimizing the role of humans in the design.
Gradient-based learning allows a network to efﬁciently op-
timize new instances of a task [51]. FBNets (Facebook-
Berkeley-Nets) [56] uses a gradient-based method to opti-
mize CNNs created by a differentiable neural architecture
search framework.

--- PAGE 3 ---
3. Rewarded meta-pruning
The Rewarded meta-pruning algorithm proposes using a
reward coefﬁcient to control the trade-off between the ac-
curacy and efﬁciency of each model instead of ﬁnding the
model with the highest accuracy within a preset range of
FLOPs. The goal is to maximize the reward, which is di-
rectly proportional to accuracy and inversely proportional
to the efﬁciency of the model. This method is implemented
in three phases: training, searching, and retraining as shown
in Algorithm 1.
3.1. Training
Most popular CNNs [16, 22, 48] mainly use three types
of layers; convolution block, bottlenecks, and linear lay-
ers. The channel scale represents the size of each layer. For
the initial convolutional block and each type of bottleneck,
the batch normalization with the sizes ranging from 10%
to 100% the size of the original architecture, equally dis-
tributed between 31 initial weights.
Figure 1. Stochastic training method
Each model is deﬁned by a NEV , which is a list of ran-
dom numbers deﬁning the scale by which each layer is
pruned from the 31 scales and their corresponding Batch
Normalisation weights. It also creates linear layers at the
scale deﬁned by the NEV . The NEV is passed into two
Fully Connected (FC) layers which generate weight matrix
as shown in Figure 1. The weights of these layers are trained
by gradients of the generated weights calculated w.r.t the
weights of the FC layers. The weights generated for each
combination of output ﬁlter sizes are uniquely mapped be-
cause the function which converts a NEV to weights is an
injective function. Thus, for each epoch, a random NEV
creates a new model with weights that map one-to-one to
the sample space of NEVs. These generated weights are re-shaped. Each value Ciin the NEV Ccorresponds to the
output channels of the layer i.
Once a model is created, it is trained for each batch of
the train data with these initial weights, and cross-entropy
loss is computed to update the weights. Each model is es-
sentially a slice of a complete model, where the slice is de-
ﬁned by the NEV . Validation data is not used to validate the
model, instead only to measure the progress.
3.2. Searching
The models created from the NEV candidates use the
weights of the trained model to create a pruned model. Each
NEV is thus converted to a pruned model and reward is
calculated for them. Evolutionary search [45] is then used
to ﬁnd the best NEV , thereby ﬁnding the optimal pruned
model. The initial weights are the trained weights, but the
ﬁnal model will be trained from scratch to remove bias in
the pre-trained model.
3.2.1 Creating genes
Random candidates are generated to seed the evolutionary
search. Each gene is created as a list of sizes correspond-
ing to the model with values representing the weights from
the dictionary. However, since the metrics of the models
created by these NEVs are also random, arbitrary hyper-
parameters are used to control the ﬁnal model. A gene is
considered valid if the FLOPs of the model created between
maxFLOPs andminFLOPs . The FLOPs of each gene
are stored as the last element of the NEV to reduce overall
computation time. This is later replaced by the reward.
3.2.2 Reward and selection of NEVs
The candidates are ranked after each epoch according to the
reward, computed as a product of accuracy and efﬁciency
coefﬁcients given by Equations (2) and (3) for each NEV as
shown in Figure 2. The reward is computed as the following
formula:
R(Gi) =(Gi;ba) (Gi;bf): (1)
The accuracy and efﬁciency coefﬁcients, denoted by 
and , are deﬁned as:
(Gi;ba) =ba
ba A(Gi)2
; (2)
 (Gi;bf) = logbf
F(Gi)
; (3)
whereGidenotes a gene of index ifrom all candidate genes
G, andAandFrepresent functions that return the accuracy
and FLOPs of the model created using the gene passed into
them. The accuracy coefﬁcient increases exponentially

--- PAGE 4 ---
Figure 2. Computing reward for network encoding vectors.
with an increase in model accuracy, but as it approaches the
base accuracy, the value tends to inﬁnity. Since the model
is not ﬁne-tuned, the accuracy does not get close enough to
the accuracy of the base model, ba, for the reward to reach
high levels. If knowledge distillation is used to increase the
accuracy of the new model, the base accuracy would be the
accuracy of the new model, thereby eliminating any nega-
tive effect from the symmetric nature of equation 2. On the
other hand, the efﬁciency coefﬁcient  linearly decreases
with increasing FLOPs but is limited by the FLOPs of the
original model bf. Since prune rates are inversely propor-
tional to FLOPs, a lower efﬁciency coefﬁcient corresponds
to a higher prune rate for the most part. The reward function
is directly proportional to accuracy and prune rate.
The accuracy coefﬁcient is directly proportional to the
reward but is moderated by the efﬁciency coefﬁcient. This
creates a balance between them so that high accuracy is not
achieved at the cost of low prune rates in the ﬁnal model.
Once a reward is computed, it is stored as the last element of
the NEV , which is later used to rank each NEV . The Top-50
NEVs from every epoch is stored, then the 10 best of them
are mutated and crossed over to get the candidate genes for
the next epoch.
3.2.3 Mutation and crossover
The best candidates from each epoch are mutated and
crossed over to create candidates for the next epoch. Mu-
tation involves changing a few elements in a gene to create
a new gene. There is a 10% chance for each element in a
gene to be changed to a random valid element. Crossover is
the combining of two random genes to create a new gene.
An element is randomly picked from one of the two cho-
sen genes for each index. Channel conﬁgurations in a lo-
cal region of the conﬁguration space tend to have similar
metrics [33], so the new candidates also have similar ac-
curacy and FLOPs. This makes the reward of at least the
best candidate tend not to decrease. If the reward has not
increased in too many epochs, the genetic search is stuck in
local minima. However, since evolutionary search is a high-
dimensional non-convex search, the critical points with er-
rors much larger than that of the global minima are likely tobe saddle points [6]. In other words, the found local min-
ima are likely to be close enough to the global minima, so
the search can be terminated. It is not unlikely that mutat-
ing and crossing over more genes could ﬁnd genes, but in-
creasing the rates of mutations and crossover would affect
the integrity of the evolutionary search. If unable to create
enough new candidates from the two evolutionary opera-
tors, the remaining are created using random genes.
3.3. Retraining
Once the evolutionary search has been completed, the
best gene is selected as the ﬁrst gene in the list of candi-
dates. This is the gene with the highest reward as found
after multiple epochs of genetic searching. The best NEV
is converted to a model and trained from scratch. All prun-
ing algorithms train a pruned model for a few epochs to
regain the lost accuracy in a process called ﬁne tuning [15].
In the Rewarded meta-pruning algorithm, model is created
from an NEV instead of using the NEV to prune, and then
trained from scratch. Hence the accuracy saturates at a
higher epoch during ﬁnetuning.
4. Experimental Results
In this section, we demonstrate the superiority of the Re-
warded meta-pruning method. We ﬁrst describe the exper-
imental settings to reproduce the experiments. Then we
compare the results obtained with other methods pruning
three major networks. Lastly, we perform an ablation study
to understand the effectiveness of the proposed method.
4.1. Experimental setting
ResNet-50 [16] network is trained for 32 epochs, while
MobileNetV1 [22] and MobileNetV2 [48] are trained for 64
epochs. ResNet and MobileNetV2 retrained after searching
for 400 epochs, but MobileNetV1 only requires 320 epochs.
Searching for the NEVs takes 20 epochs for all the net-
works. Each epoch searches 50 NEVs, searching through
1000 unique NEVs throughout the run. MobileNetV1 and
MobileNetV2 both use the Lambda scheduler to decay the
models by a of 0.1 every epoch from an initial learning

--- PAGE 5 ---
Algorithm 1 Algorithm of Rewarded meta-pruning
Hyperparameters: maxtraining : Number of train-
ing epochs, maxiter: Number of searching epochs,
maxtuning : Number of ﬁnetuning epochs
Input:dataset : training images that can be split into
batches ,ri: Random integer indexed at i,wi: Random
weights indexed at i,r: Gradient of loss of given model
Functions: norm (nev)convertsnev to weights,
FC(weights )creates model using weights ,
f(model;data )trains model using given data,
reward (nev)computes reward of model created using
nev,mutation andcrossover performs evolutionary
operations on list of nevs
Output:x: Pruned and trained model
fori= 0,1,...,maxtraining do
foreachbatch indataset do
nev= [r1,r2,...,rn]
fw1,w2, ... ,wng= norm(nev)
x= FC(fw1,w2, ... ,wng)
L= f(x,batch )
x+=rL
end for
end for
candidate = List ofnrandomnevs
fori= 0,1,...,maxiter do
rewards = [r1,r2,...,rn]
forj= 0,1,...,ndo
rj= reward(nev j)
end for
sortcandidate in descending order of rewards
mutated = mutation(candidate [: 10] )
crossedover = crossover( candidate [: 10] )
candidate =mutated +crossedover
end for
fw1,w2, ... ,wng= norm(candidate [0])
x= FC(fw1,w2, ... ,wng)
fori= 0,1,...,maxtuning do
x +=rf(x,dataset )
end for
rate of 0.2. The scheduler for ResNet, however, decreases
by a factor of 0.1 at epochs 80 and 160.
The experiments are conducted on three commonly used
networks including ResNet-50, MobileNetV1, and Mo-
bileNetV2. The networks are trained using ImageNet [7]
from scratch as described in the previous section. ImageNet
consists of 1.2M training images and 50K validation im-
ages. It also consists of 100K test images, but since the la-
bels of the test data are not released, validation data is used
for testing. The validation data has not been used in any
part of the training process except to compute the accuracy
at every stage. As a natural consequence of using evolution-ary computation, Rewarded meta-pruning is resource-heavy
in computing the pruned networks. But this cost is balanced
out by the efﬁciency and accuracy of the models generated.
A network need not be created each time it is used because
the knowledge distilled from it can be transferred and used
in varying contexts.
4.2. Evaluation protocol
Four metrics are used for evaluating the pruning algo-
rithms: parameter ratio, top-1 and top-5 errors and FLOPs.
The parameter ratio is the ratio of the pruned model to the
baseline model. It is computed as;
P=Pm
Pb100%; (4)
wherePmandPbare the numbers of weights in the pruned
and the baseline model respectively. Accuracy is the per-
centage of validation data identiﬁed correctly compared to
the whole dataset. Top-1 error is the inverse of accuracy,
i.e., the proportion of images where the predicted labels of
the highest probability are wrong. Top-5 error is the pro-
portion of images where the correct label is not present in
the ﬁve highest probabilities of predicted labels. FLOPs is
a measure of the number of Floating-point operations com-
puted per second.
4.3. Performance on ResNet-50
ResNet-50 is a CNN with a depth of 50 layers. It was cre-
ated to solve degradation in the model as deeper layers are
stacked [16]. ResNet uses skip connections to identify map-
ping. This adds the features with their original parameters
before passing them into the next layer. Identity mapping
followed by linear projection is used to expand channels of
the features to make it possible to be added with the original
parameters.
Method Top-1 Error Top-5 Error FLOPs
Baseline [33] 23.40% - 4110M
GAL-0.5 [37] 28.05% 9.06% 2341M
SSS [25] 28.18% 9.21% 2341M
HRank [36] 25.02% 7.67% 2311M
Random Pruning [33] 24.87% 7.48% 2013M
AutoPruner [43] 25.24% 7.85% 2005M
Adapt-DCP [38] 24.85% 7.70% 1955M
MetaPruning [40] 24.60% - 2005M
Rewarded meta-pruning 24.24% 7.35% 1950M
Table 1. Benchmarking state-of-the-art channel pruning methods
with ResNet-50
Table 1 shows the results of ResNet-50 trained using
ImageNet-2012 after pruning with Rewarded meta-pruning
and other competing methods. It can be inferred that this
method has a lower error rate than every method, and this

--- PAGE 6 ---
is achieved while keeping the FLOPs relatively low. The
FLOPs, as compared to the baseline network [33], reduced
by 52.55%, but the error has only increased by 0.84%.
When compared with standard random pruning, for a sim-
ilar reduction in FLOPs, there is a 0.63% lower error.
MetaPruning [40] method shows a 0.36% higher error while
still using 1.34% higher FLOPs as compared to the baseline
model. Adapt-DCP [38] has the closest reduction in FLOPs
as compared to the baseline, but this method has a 0.61%
lower error. SSS [25] and HRank [36] methods have very
similar prune rates to the Rewarded meta-pruning, but have
higher FLOPs by around 9%, and higher error by 3.94% and
0.78% respectively.
4.4. Performance on MobileNetV2
MobileNetV2 contains depth-wise and point-wise con-
volution. It has an inverted residual with a linear bottleneck
which takes a low dimensional compressed representation
as input and expands it to a higher dimension, then ﬁlters
them with light-weight depthwise convolutions like in Mo-
bileNetV1 [48]. MobileNetV2 is an efﬁcient network with a
relatively low error. Thus, demonstration on MobileNetV2
is an effective way to show the performance of the pruning
algorithm.
Method Top-1 Error Top-5 Error FLOPs
Baseline [33] 28.12% 9.71% 314M
0.75 MobileNetV2 [33] 30.20% - 220M
Random Pruning [10] 29.10% - 223M
AMC [18] 29.20% - 220M
MetaPruning [40] 28.80% - 227M
Greedy Selection [61] 28.80% - 201M
Adapt-DCP [38] 28.55% - 216M
Rewarded meta-pruning 28.51% 10.65% 199M
Table 2. Benchmarking state-of-the-art channel pruning methods
with MobileNetV2
Table 2 compares the performance of the Rewarded
meta-pruning method with the state-of-the-art methods.
The Rewarded meta-pruning method has a lower FLOPs
than any other methods while showing only 0.39% higher
error than the baseline. 0.75 MobileNetV2, which is Mo-
bileNetV2 of width 25% lower than the original, has 1.69%
higher error than this method. When compared to random
pruning, which is the baseline for all pruning methods [2],
this method has a 0.59% lower error. MetaPruning [40]
has a 0.29% higher error despite having a 7.64% higher
FLOPs. AMC [18] and Adapt-DCP [38] have 0.69% and
0.04% higher error and FLOPs. Rewarded meta-pruning
also outperforms Greedy selection [61] by 0.29% in spite
of an almost similar amount of FLOPs.4.5. Performance on MobileNetV1
MobileNetV1 has a streamlined architecture that builds
lightweight deep networks using depth-wise separable con-
volutions. All layers use Batch Normalisation and ReLu,
except the fully connected layer which is followed by a soft-
max layer for classiﬁcation [22].
Method Top-1 Error Top-5 Error FLOPs
Baseline [22] 29.40% - 569M
0.75 MobileNet-224 [22] 31.60% - 325M
FTWT (r=1.0) [10] 30.34% - 335M
MetaPruning [40] 29.10 % - 324M
Rewarded meta-pruning 29.60% 9.65% 295M
Table 3. Benchmarking state-of-the-art channel pruning methods
with MobileNetV1
In Table 3, we compare the Rewarded meta-pruning
method with other competing pruning techniques to prune
a MobileNetV1 model. It has almost regained the accuracy
of the baseline network [22], with 0.2% lower accuracy and
48.15% lower FLOPs. This method clearly achieves supe-
rior results when compared to Fire-Together-Wire-Together
[10] pruning method, with a 0.94% lower error and 7.03%
lower FLOPs. It outperforms 0.75 MobileNet-224 [22],
which is MobileNetV1 with 25% lower width, by 2% while
using 5.27% lower FLOPs. While MetaPruning [40] shows
lower error than even the baseline network, our method has
a lower FLOPs. However, the size of the pruned network is
still 9.83% larger, when compared to the proposed method.
This could be due to the lack of shortcut connection in Mo-
bileNetV1 in spite of being a smaller network, leading to a
large number of fully-connected layers. In terms of perfor-
mance achieved for ever resource, Rewarded meta-pruning
edges out MetaPruning. It is fair to assume that the Re-
warded meta-pruning method could have better results with
more advanced reward functions. This will be validated by
further research on the robustness of various hyperpareme-
ters.
4.6. Discussion
From the results, it is clear that the proposed method per-
forms best under the right reward functions. The reward
function in this case is directly proportional to the accuracy
and inversely proportional to FLOPs.
As the accuracy of the pruned model approaches the
baseline accuracy, the reward increases exponentially. In
MetaPruning [40], the reward is directly proportional to ac-
curacy, whereas in this method, the reward is proportional to
the square of the accuracy of the model. This by itself would
not increase the accuracy of the ﬁnal model, but chasing a
higher reward that is only dependent on accuracy could lead
to the ﬁnal model having high FLOPs. This can be seen in
MetaPruning, where the pruned model has a tendency to

--- PAGE 7 ---
show FLOPs as high as the preset maximum FLOPs would
allow. The reward is controlled by the efﬁciency coefﬁcient
to prevent this.
The reward decreases with increasing FLOPs because
the efﬁciency coefﬁcient is inversely proportional to the
FLOPs. However, if the proportionality is too high, the
reward would be throttled. Hence it is controlled by the
linearly decreasing efﬁciency coefﬁcient.
Figure 3. Reward at varying Accuracies and FLOPs.
From the deﬁnition of the reward function in Equation
(1), it is clear that high accuracy alone is not enough for a
model to be selected. As the accuracy increases, the proba-
bility of the model being selected increases, but only so long
as the FLOPs of the model are also low enough. This can
be inferred from how the distribution of Green increases as
we move towards the right as shown in Figure 3. The re-
ward increases as the FLOPs decrease, but it is not deemed
acceptable until accuracy is high enough. This can be in-
ferred from how the distribution of Red increases as the
FLOPs decrease as inferred from Figure 3. Thus by deﬁni-
tion, the Rewarded meta-pruning method leans more toward
accuracy.
When compared to MetaPruning, the reward of the Re-
warded meta-pruning method increases higher with each
iteration of searching. This is because the reward of
MetaPruning is directly proportional to accuracy while the
reward of Rewarded meta-pruning is proportional to the
square of accuracy. This can be observed in Figure 4 which
shows the rewards, accuracies, and FLOPs of the best model
after each iteration of searching. The accuracy and FLOPs,
in the beginning, are chosen randomly, but that cannot be
changed without tampering with the fundamental evolution-
ary searching. But it can be observed that the FLOPs of the
best model in MetaPruning tend to increase for the most part
whereas, in the case of Rewarded meta-pruning method, it
tends to stay low. Accuracy increases in both cases, but
MetaPruning saturates earlier than Rewarded meta-pruning.It can also be inferred that if the two models started with the
same batch of randomly initialized models, the Rewarded
meta-pruning method will have a higher accuracy and a
lower FLOPs because the slopes of the best accuracy and
FLOPs of the best models are higher and lower respectively
than that of MetaPruning.
However, the way NEVs are chosen, both randomly and
after mutation or crossover, means the FLOPs of the pruned
model approximately form a bell-curve between 1350 and
2100. This can be changed by controlling the generation of
random ﬁlter sizes in the NEVs as shown in Figure 5.
The robustness of the hyperparameters used by Re-
warded meta-pruning has already been explored by He et
al. [17]. As the reward function is tweaked to add different
hyperparameters, various metrics of the ﬁnal model can be
controlled. There are various other coefﬁcients that could
be used in the reward. The prune rate of the pruned model
can be set to be inversely proportional to the reward, as low
prune rates automatically lead to lower FLOPs. The FLOPs
is also directly proportional to hardware latency, which is
the runtime of networks [9]. But this is dependent on hard-
ware, and different hardware have different latencies. Other
metrics such as energy consumption have also been used for
pruning. NetAdapt [59] uses energy consumption as a met-
ric to measure the complexity of the network at every stage
and prunes the network further while maintaining accuracy.
5. Conclusion
In this work, we have presented the following: 1) Im-
plemented better reward function to meta-learn parameters
for pruning and allow better control over various parame-
ters of the pruned model. 2) The Rewarded meta-pruning
method has been shown to be superior to other state-of-the-
art methods, with higher accuracy and lower FLOPs than
traditional channel pruning methods. 3) The reward func-
tion can be optimized using other metrics to maximize the
reward. 4) ResNet-50, MobileNetV1 and MobileNetV2 are
pruned effectively.
6. Acknowledgement
This work was supported by the National Research
Foundation of Korea (NRF) grant funded by the Ko-
rean Government (MSIT) (No.2021R1C1C1012590), (No.
NRF-2022R1A4A1023248) and the Information Technol-
ogy Research Center (ITRC) support program supervised
by the Institute of Information Communications & Tech-
nology Planning & Evaluation (IITP) grant funded by the
Korean Government (MSIT) (IITP-2022-2020-0-01808).
References
[1] Bowen Baker, Otkrist Gupta, Nikhil Naik, and Ramesh
Raskar. Designing neural network architectures using rein-

--- PAGE 8 ---
Figure 4. Rewards, Accuracy and FLOPs of the best models after each iteration of searching.
Figure 5. Distribution of FLOPs of 1000 randomly generated
NEVs with varying ranges of FLOPs.
forcement learning. arXiv preprint arXiv:1611.02167 , 2016.
2
[2] Davis Blalock, Jose Javier Gonzalez Ortiz, Jonathan Frankle,
and John Guttag. What is the state of neural network prun-
ing? Proceedings of machine learning and systems , 2:129–
146, 2020. 6
[3] Alexandre Bouchard-C ˆot´e, Slav Petrov, and Dan Klein. Ran-
domized pruning: Efﬁciently calculating expectations in
large dynamic programs. Advances in Neural Information
Processing Systems , 22, 2009. 1, 2
[4] Andrew Brock, Theodore Lim, James M Ritchie, and Nick
Weston. Smash: one-shot model architecture search through
hypernetworks. arXiv preprint arXiv:1708.05344 , 2017. 2
[5] Han Cai, Ligeng Zhu, and Song Han. Proxylessnas: Direct
neural architecture search on target task and hardware. arXiv
preprint arXiv:1812.00332 , 2018. 2
[6] Yann N Dauphin, Razvan Pascanu, Caglar Gulcehre,
Kyunghyun Cho, Surya Ganguli, and Yoshua Bengio. Iden-
tifying and attacking the saddle point problem in high-dimensional non-convex optimization. Advances in neural
information processing systems , 27, 2014. 4
[7] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li,
and Li Fei-Fei. Imagenet: A large-scale hierarchical image
database. In 2009 IEEE conference on computer vision and
pattern recognition , pages 248–255. Ieee, 2009. 5
[8] Jiankang Deng, Jia Guo, Niannan Xue, and Stefanos
Zafeiriou. Arcface: Additive angular margin loss for deep
face recognition. In Proceedings of the IEEE/CVF con-
ference on computer vision and pattern recognition , pages
4690–4699, 2019. 1, 2
[9] Jin-Dong Dong, An-Chieh Cheng, Da-Cheng Juan, Wei Wei,
and Min Sun. Dpp-net: Device-aware progressive search for
pareto-optimal neural architectures. In Proceedings of the
European Conference on Computer Vision (ECCV) , pages
517–531, 2018. 7
[10] Sara Elkerdawy, Mostafa Elhoushi, Hong Zhang, and Nilan-
jan Ray. Fire together wire together: A dynamic pruning
approach with self-supervised mask prediction. In Proceed-
ings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition , pages 12454–12463, 2022. 1, 2, 6
[11] Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-
agnostic meta-learning for fast adaptation of deep networks.
InInternational conference on machine learning , pages
1126–1135. PMLR, 2017. 2
[12] Jonathan Frankle and Michael Carbin. The lottery ticket hy-
pothesis: Finding sparse, trainable neural networks. arXiv
preprint arXiv:1803.03635 , 2018. 1, 2
[13] Song Han, Xingyu Liu, Huizi Mao, Jing Pu, Ardavan Pe-
dram, Mark A Horowitz, and William J Dally. Eie: Efﬁ-
cient inference engine on compressed deep neural network.
ACM SIGARCH Computer Architecture News , 44(3):243–
254, 2016. 1
[14] Song Han, Huizi Mao, and William J Dally. Deep com-
pression: Compressing deep neural networks with pruning,
trained quantization and huffman coding. arXiv preprint
arXiv:1510.00149 , 2015. 1
[15] Song Han, Jeff Pool, John Tran, and William Dally. Learn-
ing both weights and connections for efﬁcient neural net-
work. Advances in neural information processing systems ,
28, 2015. 1, 4

--- PAGE 9 ---
[16] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
Deep residual learning for image recognition. In Proceed-
ings of the IEEE conference on computer vision and pattern
recognition , pages 770–778, 2016. 3, 4, 5
[17] Yang He, Yuhang Ding, Ping Liu, Linchao Zhu, Hanwang
Zhang, and Yi Yang. Learning ﬁlter pruning criteria for deep
convolutional neural networks acceleration. In Proceedings
of the IEEE/CVF conference on computer vision and pattern
recognition , pages 2009–2018, 2020. 7
[18] Yihui He, Ji Lin, Zhijian Liu, Hanrui Wang, Li-Jia Li, and
Song Han. Amc: Automl for model compression and ac-
celeration on mobile devices. In Proceedings of the Euro-
pean conference on computer vision (ECCV) , pages 784–
800, 2018. 2, 6
[19] Yang He, Ping Liu, Ziwei Wang, Zhilan Hu, and Yi
Yang. Filter pruning via geometric median for deep con-
volutional neural networks acceleration. In Proceedings of
the IEEE/CVF conference on computer vision and pattern
recognition , pages 4340–4349, 2019. 2
[20] Yang He, Ping Liu, Linchao Zhu, and Yi Yang. Filter prun-
ing by switching to neighboring cnns with good attributes.
IEEE Transactions on Neural Networks and Learning Sys-
tems, 2022. 1
[21] Rein Houthooft, Yuhua Chen, Phillip Isola, Bradly Stadie,
Filip Wolski, OpenAI Jonathan Ho, and Pieter Abbeel.
Evolved policy gradients. Advances in Neural Information
Processing Systems , 31, 2018. 2
[22] Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry
Kalenichenko, Weijun Wang, Tobias Weyand, Marco An-
dreetto, and Hartwig Adam. Mobilenets: Efﬁcient convolu-
tional neural networks for mobile vision applications. arXiv
preprint arXiv:1704.04861 , 2017. 3, 4, 6
[23] Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kil-
ian Q Weinberger. Densely connected convolutional net-
works. In Proceedings of the IEEE conference on computer
vision and pattern recognition , pages 4700–4708, 2017. 1
[24] Qiangui Huang, Kevin Zhou, Suya You, and Ulrich Neu-
mann. Learning to prune ﬁlters in convolutional neural net-
works. In 2018 IEEE Winter Conference on Applications of
Computer Vision (WACV) , pages 709–718. IEEE, 2018. 1, 2
[25] Zehao Huang and Naiyan Wang. Data-driven sparse struc-
ture selection for deep neural networks. In Proceedings of
the European conference on computer vision (ECCV) , pages
304–320, 2018. 2, 5, 6
[26] Andrej Karpathy, George Toderici, Sanketh Shetty, Thomas
Leung, Rahul Sukthankar, and Li Fei-Fei. Large-scale video
classiﬁcation with convolutional neural networks. In Pro-
ceedings of the IEEE conference on Computer Vision and
Pattern Recognition , pages 1725–1732, 2014. 1
[27] John K Kruschke and Javier R Movellan. Beneﬁts of
gain: Speeded learning and minimal hidden layers in back-
propagation networks. IEEE Transactions on systems, Man,
and Cybernetics , 21(1):273–280, 1991. 1
[28] Abhishek Kumar, Rakesh Kumar Misra, Devender Singh,
Sujeet Mishra, and Swagatam Das. The spherical search
algorithm for bound-constrained global optimization prob-
lems. Applied Soft Computing , 85:105734, 2019. 1[29] Dong-Gyu Lee and Yoon-Ki Kim. Joint semantic under-
standing with a multilevel branch for driving perception. Ap-
plied Sciences , 12(6):2877, 2022. 1
[30] Dong-Gyu Lee and Seong-Whan Lee. Human activity pre-
diction based on sub-volume relationship descriptor. In
2016 23rd International Conference on Pattern Recognition
(ICPR) , pages 2060–2065. IEEE, 2016. 1
[31] Dong-Gyu Lee and Seong-Whan Lee. Prediction of partially
observed human activity based on pre-trained deep represen-
tation. Pattern Recognition , 85:198–206, 2019. 1
[32] Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, and
Hans Peter Graf. Pruning ﬁlters for efﬁcient convnets. arXiv
preprint arXiv:1608.08710 , 2016. 1
[33] Yawei Li, Kamil Adamczewski, Wen Li, Shuhang Gu, Radu
Timofte, and Luc Van Gool. Revisiting random channel
pruning for neural network compression. In Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern
Recognition , pages 191–201, 2022. 4, 5, 6
[34] Yiying Li, Yongxin Yang, Wei Zhou, and Timothy
Hospedales. Feature-critic networks for heterogeneous do-
main generalization. In International Conference on Ma-
chine Learning , pages 3915–3924. PMLR, 2019. 2
[35] Lucas Liebenwein, Cenk Baykal, Harry Lang, Dan Feldman,
and Daniela Rus. Provable ﬁlter pruning for efﬁcient neural
networks. arXiv preprint arXiv:1911.07412 , 2019. 2
[36] Mingbao Lin, Rongrong Ji, Yan Wang, Yichen Zhang,
Baochang Zhang, Yonghong Tian, and Ling Shao. Hrank:
Filter pruning using high-rank feature map. In Proceedings
of the IEEE/CVF conference on computer vision and pattern
recognition , pages 1529–1538, 2020. 2, 5, 6
[37] Shaohui Lin, Rongrong Ji, Chenqian Yan, Baochang Zhang,
Liujuan Cao, Qixiang Ye, Feiyue Huang, and David Doer-
mann. Towards optimal structured cnn pruning via genera-
tive adversarial learning. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition ,
pages 2790–2799, 2019. 5
[38] Jing Liu, Bohan Zhuang, Zhuangwei Zhuang, Yong
Guo, Junzhou Huang, Jinhui Zhu, and Mingkui Tan.
Discrimination-aware network pruning for deep model com-
pression. IEEE Transactions on Pattern Analysis and Ma-
chine Intelligence , 2021. 1, 2, 5, 6
[39] Zhuang Liu, Jianguo Li, Zhiqiang Shen, Gao Huang,
Shoumeng Yan, and Changshui Zhang. Learning efﬁcient
convolutional networks through network slimming. In Pro-
ceedings of the IEEE international conference on computer
vision , pages 2736–2744, 2017. 1
[40] Zechun Liu, Haoyuan Mu, Xiangyu Zhang, Zichao Guo, Xin
Yang, Kwang-Ting Cheng, and Jian Sun. Metapruning: Meta
learning for automatic neural network channel pruning. In
Proceedings of the IEEE/CVF international conference on
computer vision , pages 3296–3305, 2019. 1, 2, 5, 6
[41] Zhuang Liu, Mingjie Sun, Tinghui Zhou, Gao Huang, and
Trevor Darrell. Rethinking the value of network pruning.
arXiv preprint arXiv:1810.05270 , 2018. 1
[42] Christos Louizos, Max Welling, and Diederik P Kingma.
Learning sparse neural networks through l0regularization.
arXiv preprint arXiv:1712.01312 , 2017. 1

--- PAGE 10 ---
[43] Jian-Hao Luo and Jianxin Wu. Autopruner: An end-to-end
trainable ﬁlter pruning method for efﬁcient deep model in-
ference. Pattern Recognition , 107:107461, 2020. 2, 5
[44] Jian-Hao Luo and Jianxin Wu. Neural network pruning with
residual-connections and limited-data. In Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern
Recognition , pages 1458–1467, 2020. 2
[45] Rammohan Mallipeddi, Ponnuthurai N Suganthan, Quan-Ke
Pan, and Mehmet Fatih Tasgetiren. Differential evolution
algorithm with ensemble of parameters and mutation strate-
gies. Applied soft computing , 11(2):1679–1696, 2011. 3
[46] Pavlo Molchanov, Arun Mallya, Stephen Tyree, Iuri Fro-
sio, and Jan Kautz. Importance estimation for neural net-
work pruning. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition , pages 11264–
11272, 2019. 2
[47] Esteban Real, Sherry Moore, Andrew Selle, Saurabh Saxena,
Yutaka Leon Suematsu, Jie Tan, Quoc V Le, and Alexey Ku-
rakin. Large-scale evolution of image classiﬁers. In Interna-
tional Conference on Machine Learning , pages 2902–2911.
PMLR, 2017. 2
[48] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zh-
moginov, and Liang-Chieh Chen. Mobilenetv2: Inverted
residuals and linear bottlenecks. In Proceedings of the
IEEE conference on computer vision and pattern recogni-
tion, pages 4510–4520, 2018. 3, 4, 6
[49] David Silver, Aja Huang, Chris J Maddison, Arthur Guez,
Laurent Sifre, George Van Den Driessche, Julian Schrit-
twieser, Ioannis Antonoglou, Veda Panneershelvam, Marc
Lanctot, et al. Mastering the game of go with deep neural
networks and tree search. nature , 529(7587):484–489, 2016.
2
[50] Jingtong Su, Yihang Chen, Tianle Cai, Tianhao Wu, Ruiqi
Gao, Liwei Wang, and Jason D Lee. Sanity-checking prun-
ing methods: Random tickets can win the jackpot. Advances
in Neural Information Processing Systems , 33:20390–20401,
2020. 1, 2
[51] Matthew Tancik, Ben Mildenhall, Terrance Wang, Divi
Schmidt, Pratul P Srinivasan, Jonathan T Barron, and Ren
Ng. Learned initializations for optimizing coordinate-based
neural representations. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition ,
pages 2846–2855, 2021. 2
[52] Hongduan Tian, Bo Liu, Xiao-Tong Yuan, and Qingshan Liu.
Meta-learning with network pruning for overﬁtting reduc-
tion. CoRR , 2019. 1
[53] Joaquin Vanschoren. Meta-learning: A survey. arXiv
preprint arXiv:1810.03548 , 2018. 2
[54] Vibashan VS, Domenick Poster, Suya You, Shuowen Hu,
and Vishal M. Patel. Meta-uda: Unsupervised domain adap-
tive thermal object detection using meta-learning. In Pro-
ceedings of the IEEE/CVF Winter Conference on Applica-
tions of Computer Vision (WACV) , pages 1412–1423, Jan-
uary 2022. 2
[55] Ronald J Williams. Simple statistical gradient-following al-
gorithms for connectionist reinforcement learning. Machine
learning , 8(3):229–256, 1992. 2[56] Bichen Wu, Xiaoliang Dai, Peizhao Zhang, Yanghan Wang,
Fei Sun, Yiming Wu, Yuandong Tian, Peter Vajda, Yangqing
Jia, and Kurt Keutzer. Fbnet: Hardware-aware efﬁcient con-
vnet design via differentiable neural architecture search. In
Proceedings of the IEEE/CVF Conference on Computer Vi-
sion and Pattern Recognition , pages 10734–10742, 2019. 2
[57] Lingxi Xie and Alan Yuille. Genetic cnn. In Proceedings of
the IEEE international conference on computer vision , pages
1379–1388, 2017. 2
[58] Kohei Yamamoto and Kurato Maeno. Pcas: Pruning chan-
nels with attention statistics for deep network compression.
arXiv preprint arXiv:1806.05382 , 2018. 1
[59] Tien-Ju Yang, Andrew Howard, Bo Chen, Xiao Zhang, Alec
Go, Mark Sandler, Vivienne Sze, and Hartwig Adam. Ne-
tadapt: Platform-aware neural network adaptation for mobile
applications. In Proceedings of the European Conference on
Computer Vision (ECCV) , pages 285–300, 2018. 7
[60] Jianbo Ye, Xin Lu, Zhe Lin, and James Z Wang. Re-
thinking the smaller-norm-less-informative assumption in
channel pruning of convolution layers. arXiv preprint
arXiv:1802.00124 , 2018. 2
[61] Mao Ye, Chengyue Gong, Lizhen Nie, Denny Zhou, Adam
Klivans, and Qiang Liu. Good subnetworks provably exist:
Pruning via greedy forward selection. In International Con-
ference on Machine Learning , pages 10820–10830. PMLR,
2020. 2, 6
[62] Zhuangwei Zhuang, Mingkui Tan, Bohan Zhuang, Jing Liu,
Yong Guo, Qingyao Wu, Junzhou Huang, and Jinhui Zhu.
Discrimination-aware channel pruning for deep neural net-
works. In S. Bengio, H. Wallach, H. Larochelle, K. Grau-
man, N. Cesa-Bianchi, and R. Garnett, editors, Advances in
Neural Information Processing Systems , volume 31. Curran
Associates, Inc., 2018. 2
[63] Barret Zoph and Quoc V Le. Neural architecture search with
reinforcement learning. arXiv preprint arXiv:1611.01578 ,
2016. 2

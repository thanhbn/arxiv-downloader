# 2308.08998.pdf
# Chuyá»ƒn Ä‘á»•i tá»« PDF sang TXT
# ÄÆ°á»ng dáº«n nguá»“n: /home/admin88/arxiv-downloader/rl-alignment/2308.08998.pdf
# KÃ­ch thÆ°á»›c tá»‡p: 1404121 bytes

===============================================
Ná»˜I DUNG Tá»†P PDF
===============================================

--- TRANG 1 ---
2023-8-22
Tá»± Huáº¥n Luyá»‡n TÄƒng CÆ°á»ng (ReST) cho MÃ´ HÃ¬nh NgÃ´n Ngá»¯
Caglar Gulcehre*â€ ,1, Tom Le Paine*â€ ,1, Srivatsan Srinivasan*â€ ,1, Ksenia Konyushkovaâ€ ,1, Lotte Weertsâ€ ,1
Abhishek Sharmaâ€ ,1, Aditya Siddhantâ€ ,1, Alex Ahern1, Miaosen Wang1, Chenjie Gu1,
Wolfgang Macherey2, Arnaud Doucet1, Orhan Firatâ€ ,1, Nando de Freitas1
*ÄÃ³ng gÃ³p báº±ng nhau,â€ Cá»™ng tÃ¡c viÃªn cá»‘t lÃµi
1Google DeepMind,2Google Research
Há»c tÄƒng cÆ°á»ng tá»« pháº£n há»“i cá»§a con ngÆ°á»i (RLHF) cÃ³ thá»ƒ cáº£i thiá»‡n cháº¥t lÆ°á»£ng Ä‘áº§u ra cá»§a mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n
(LLM) báº±ng cÃ¡ch cÄƒn chá»‰nh chÃºng vá»›i sá»Ÿ thÃ­ch cá»§a con ngÆ°á»i. ChÃºng tÃ´i Ä‘á» xuáº¥t má»™t thuáº­t toÃ¡n Ä‘Æ¡n giáº£n Ä‘á»ƒ cÄƒn chá»‰nh
LLM vá»›i sá»Ÿ thÃ­ch cá»§a con ngÆ°á»i Ä‘Æ°á»£c láº¥y cáº£m há»©ng tá»« há»c tÄƒng cÆ°á»ng theo lÃ´ tÄƒng trÆ°á»Ÿng (RL), mÃ  chÃºng tÃ´i gá»i lÃ 
Tá»± Huáº¥n Luyá»‡n TÄƒng CÆ°á»ng (ReST). Cho má»™t chÃ­nh sÃ¡ch LLM ban Ä‘áº§u, ReST táº¡o ra má»™t táº­p dá»¯ liá»‡u báº±ng cÃ¡ch sinh
máº«u tá»« chÃ­nh sÃ¡ch, sau Ä‘Ã³ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ cáº£i thiá»‡n chÃ­nh sÃ¡ch LLM sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n RL ngoáº¡i tuyáº¿n.
ReST hiá»‡u quáº£ hÆ¡n cÃ¡c phÆ°Æ¡ng phÃ¡p RLHF trá»±c tuyáº¿n Ä‘iá»ƒn hÃ¬nh vÃ¬ táº­p dá»¯ liá»‡u huáº¥n luyá»‡n Ä‘Æ°á»£c táº¡o ra ngoáº¡i tuyáº¿n,
cho phÃ©p tÃ¡i sá»­ dá»¥ng dá»¯ liá»‡u. Máº·c dÃ¹ ReST lÃ  má»™t phÆ°Æ¡ng phÃ¡p tá»•ng quÃ¡t Ã¡p dá»¥ng cho táº¥t cáº£ cÃ¡c thiáº¿t láº­p há»c sinh,
chÃºng tÃ´i táº­p trung vÃ o á»©ng dá»¥ng cá»§a nÃ³ cho dá»‹ch mÃ¡y. Káº¿t quáº£ cá»§a chÃºng tÃ´i cho tháº¥y ReST cÃ³ thá»ƒ cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ
cháº¥t lÆ°á»£ng dá»‹ch thuáº­t, Ä‘Æ°á»£c Ä‘o báº±ng cÃ¡c chá»‰ sá»‘ tá»± Ä‘á»™ng vÃ  Ä‘Ã¡nh giÃ¡ cá»§a con ngÆ°á»i trÃªn cÃ¡c chuáº©n má»±c dá»‹ch mÃ¡y má»™t cÃ¡ch
hiá»‡u quáº£ vá» tÃ­nh toÃ¡n vÃ  máº«u.
Tá»« khÃ³a: RL ngoáº¡i tuyáº¿n, há»c tÄƒng cÆ°á»ng, RL tá»« pháº£n há»“i cá»§a con ngÆ°á»i, ngÃ´n ngá»¯, xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn, dá»‹ch mÃ¡y

1. Giá»›i thiá»‡u
HÃ¬nh 1|PhÆ°Æ¡ng phÃ¡p ReST. Trong bÆ°á»›c Grow,
má»™t chÃ­nh sÃ¡ch táº¡o ra má»™t táº­p dá»¯ liá»‡u. á» bÆ°á»›c
Improve, táº­p dá»¯ liá»‡u Ä‘Æ°á»£c lá»c Ä‘Æ°á»£c sá»­ dá»¥ng
Ä‘á»ƒ tinh chá»‰nh chÃ­nh sÃ¡ch. Cáº£ hai bÆ°á»›c Ä‘á»u
Ä‘Æ°á»£c láº·p láº¡i, bÆ°á»›c Improve Ä‘Æ°á»£c láº·p láº¡i
thÆ°á»ng xuyÃªn hÆ¡n Ä‘á»ƒ kháº¥u hao chi phÃ­
táº¡o táº­p dá»¯ liá»‡u.

CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) Ä‘Ã£ thá»ƒ hiá»‡n kháº£ nÄƒng áº¥n tÆ°á»£ng trong viá»‡c táº¡o ra vÄƒn báº£n cháº¥t lÆ°á»£ng cao vÃ  giáº£i quyáº¿t
nhiá»u tÃ¡c vá»¥ ngÃ´n ngá»¯ (Brown et al., 2020; Bubeck
et al., 2023; Rae et al., 2021). Nhá»¯ng mÃ´ hÃ¬nh nÃ y Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»ƒ
tá»‘i Ä‘a hÃ³a kháº£ nÄƒng xáº£y ra cá»§a token tiáº¿p theo má»™t cÃ¡ch tá»± há»“i quy
sá»­ dá»¥ng lÆ°á»£ng lá»›n vÄƒn báº£n vÃ  tÃ­nh toÃ¡n (Hoffmann
et al., 2022; Srivastava et al., 2022). Tuy nhiÃªn, Perez et al.
(2022) Ä‘Ã£ chá»‰ ra ráº±ng viá»‡c táº¡o ra vÄƒn báº£n vá»›i kháº£ nÄƒng xáº£y ra cao
khÃ´ng nháº¥t thiáº¿t pháº£i phÃ¹ há»£p tá»‘t vá»›i sá»Ÿ thÃ­ch cá»§a con ngÆ°á»i
trÃªn cÃ¡c tÃ¡c vá»¥ khÃ¡c nhau. KhÃ´ng cÃ³ sá»± cÄƒn chá»‰nh thÃ­ch há»£p, cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯
cÅ©ng cÃ³ thá»ƒ Ä‘Æ°a ra ná»™i dung khÃ´ng an toÃ n vá»›i háº­u quáº£
cÃ³ háº¡i. HÆ¡n ná»¯a, viá»‡c cÄƒn chá»‰nh LLM giÃºp cáº£i thiá»‡n
cÃ¡c tÃ¡c vá»¥ downstream khÃ¡c (Ouyang et al., 2022b). Há»c
tÄƒng cÆ°á»ng tá»« pháº£n há»“i cá»§a con ngÆ°á»i (RLHF) nháº±m
giáº£i quyáº¿t váº¥n Ä‘á» cÄƒn chá»‰nh báº±ng cÃ¡ch sá»­ dá»¥ng sá»Ÿ thÃ­ch
cá»§a con ngÆ°á»i (Glaese et al., 2022; Stiennon et al., 2020; Wu
et al., 2021). ThÃ´ng thÆ°á»ng, pháº£n há»“i cá»§a con ngÆ°á»i Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ há»c má»™t
mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng, sau Ä‘Ã³ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ tinh chá»‰nh LLM vá»›i
má»™t má»¥c tiÃªu há»c tÄƒng cÆ°á»ng (RL).

TÃ¡c giáº£ liÃªn há»‡: ca9lar@gmail.com
Â©2023 DeepMind. Táº¥t cáº£ quyá»n Ä‘Æ°á»£c báº£o lÆ°u arXiv:2308.08998v2 [cs.CL] 21 Aug 2023

--- TRANG 2 ---
Tá»± Huáº¥n Luyá»‡n TÄƒng CÆ°á»ng (ReST) cho MÃ´ HÃ¬nh NgÃ´n Ngá»¯

CÃ¡c phÆ°Æ¡ng phÃ¡p RLHF thÆ°á»ng dá»±a vÃ o cÃ¡c phÆ°Æ¡ng phÃ¡p RL trá»±c tuyáº¿n nhÆ° PPO (Schulman et al., 2017) vÃ  A2C
(Mnih et al., 2016). Huáº¥n luyá»‡n trá»±c tuyáº¿n yÃªu cáº§u láº¥y máº«u tá»« chÃ­nh sÃ¡ch Ä‘Æ°á»£c cáº­p nháº­t vÃ  cháº¥m Ä‘iá»ƒm cÃ¡c
máº«u vá»›i mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng nhiá»u láº§n trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n. Chi phÃ­ tÃ­nh toÃ¡n Ä‘á»ƒ xá»­ lÃ½
luá»“ng liÃªn tá»¥c cÃ¡c máº«u má»›i trá»Ÿ thÃ nh má»™t háº¡n cháº¿ cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p trá»±c tuyáº¿n, Ä‘áº·c biá»‡t khi kÃ­ch thÆ°á»›c
cá»§a máº¡ng chÃ­nh sÃ¡ch vÃ  pháº§n thÆ°á»Ÿng tÄƒng lÃªn. HÆ¡n ná»¯a, nhá»¯ng phÆ°Æ¡ng phÃ¡p nÃ y dá»… bá»‹ "hack" pháº§n thÆ°á»Ÿng
(Skalse et al., 2022), vÃ  cÃ¡c nghiÃªn cá»©u trÆ°á»›c (Glaese et al., 2022) Ä‘Ã£ khÃ¡m phÃ¡ regularization mÃ´ hÃ¬nh Ä‘á»ƒ giáº£m thiá»ƒu
váº¥n Ä‘á» nÃ y. Thay vÃ o Ä‘Ã³, cÃ¡c phÆ°Æ¡ng phÃ¡p RL ngoáº¡i tuyáº¿n há»c tá»« má»™t táº­p dá»¯ liá»‡u cá»‘ Ä‘á»‹nh cÃ¡c vÃ­ dá»¥ vÃ  do Ä‘Ã³ chÃºng
hiá»‡u quáº£ hÆ¡n vá» máº·t tÃ­nh toÃ¡n vÃ  Ã­t dá»… bá»‹ hack pháº§n thÆ°á»Ÿng hÆ¡n. Tuy nhiÃªn, cháº¥t lÆ°á»£ng cá»§a chÃ­nh sÃ¡ch
Ä‘Æ°á»£c há»c ngoáº¡i tuyáº¿n cháº¯c cháº¯n phá»¥ thuá»™c vÃ o cÃ¡c thuá»™c tÃ­nh cá»§a táº­p dá»¯ liá»‡u ngoáº¡i tuyáº¿n (Fu et al., 2020; Gulcehre
et al., 2021). Káº¿t quáº£ lÃ , cÃ¡c táº­p dá»¯ liá»‡u Ä‘Æ°á»£c tuyá»ƒn chá»n cáº©n tháº­n trá»Ÿ nÃªn ráº¥t quan trá»ng cho sá»± thÃ nh cÃ´ng cá»§a RL ngoáº¡i tuyáº¿n.
Náº¿u khÃ´ng, viá»‡c cáº£i thiá»‡n hiá»‡u suáº¥t so vá»›i há»c cÃ³ giÃ¡m sÃ¡t cÃ³ thá»ƒ bá»‹ háº¡n cháº¿ (Kumar et al., 2021).
Äá»“ng thá»i vá»›i cÃ´ng trÃ¬nh cá»§a chÃºng tÃ´i, (Rafailov et al., 2023) Ä‘Ã£ Ä‘á» xuáº¥t má»™t phÆ°Æ¡ng phÃ¡p gá»i lÃ  DPO (Tá»‘i Æ¯u HÃ³a Sá»Ÿ ThÃ­ch Trá»±c Tiáº¿p)
cÃ³ thá»ƒ sá»­ dá»¥ng dá»¯ liá»‡u ngoáº¡i tuyáº¿n Ä‘á»ƒ cÄƒn chá»‰nh má»™t LM vá»›i sá»Ÿ thÃ­ch cá»§a con ngÆ°á»i.

ChÃºng tÃ´i Ä‘Ã³ng khung váº¥n Ä‘á» cÄƒn chá»‰nh cá»§a má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ nhÆ° má»™t váº¥n Ä‘á» RL lÃ´ tÄƒng trÆ°á»Ÿng (Lange
et al., 2012). Cá»¥ thá»ƒ, phÆ°Æ¡ng phÃ¡p Tá»± Huáº¥n Luyá»‡n TÄƒng CÆ°á»ng (ReST) cá»§a chÃºng tÃ´i bao gá»“m hai vÃ²ng láº·p: trong vÃ²ng láº·p bÃªn trong
(Improve), chÃºng tÃ´i cáº£i thiá»‡n chÃ­nh sÃ¡ch trÃªn má»™t táº­p dá»¯ liá»‡u cá»‘ Ä‘á»‹nh vÃ  trong vÃ²ng láº·p bÃªn ngoÃ i (Grow), chÃºng tÃ´i tÄƒng trÆ°á»Ÿng
táº­p dá»¯ liá»‡u báº±ng cÃ¡ch láº¥y máº«u tá»« chÃ­nh sÃ¡ch má»›i nháº¥t (xem HÃ¬nh 1). Trong cÃ´ng trÃ¬nh nÃ y chÃºng tÃ´i xem xÃ©t mÃ´ hÃ¬nh ngÃ´n ngá»¯
cÃ³ Ä‘iá»u kiá»‡n, sau Ä‘Ã³ cÃ¡c bÆ°á»›c cá»§a ReST nhÆ° sau:

1.Grow(G): ChÃ­nh sÃ¡ch mÃ´ hÃ¬nh ngÃ´n ngá»¯ (ban Ä‘áº§u, má»™t chÃ­nh sÃ¡ch cÃ³ giÃ¡m sÃ¡t) Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ táº¡o ra nhiá»u
dá»± Ä‘oÃ¡n Ä‘áº§u ra cho má»—i ngá»¯ cáº£nh Ä‘á»ƒ bá»• sung táº­p dá»¯ liá»‡u huáº¥n luyá»‡n.

2.Improve (I): ChÃºng tÃ´i xáº¿p háº¡ng vÃ  lá»c táº­p dá»¯ liá»‡u bá»• sung vá»›i má»™t hÃ m cháº¥m Ä‘iá»ƒm. ChÃºng tÃ´i sá»­ dá»¥ng má»™t
mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng Ä‘Ã£ há»c Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn sá»Ÿ thÃ­ch cá»§a con ngÆ°á»i lÃ m hÃ m cháº¥m Ä‘iá»ƒm trong cÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i.
Sau Ä‘Ã³, mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ°á»£c tinh chá»‰nh trÃªn táº­p dá»¯ liá»‡u Ä‘Æ°á»£c lá»c vá»›i má»™t má»¥c tiÃªu RL ngoáº¡i tuyáº¿n. BÆ°á»›c nÃ y
cÃ³ thá»ƒ Ä‘Æ°á»£c láº·p láº¡i vá»›i ngÆ°á»¡ng lá»c tÄƒng dáº§n. ChÃ­nh sÃ¡ch cuá»‘i cÃ¹ng sau Ä‘Ã³ Ä‘Æ°á»£c sá»­ dá»¥ng trong
bÆ°á»›c Grow tiáº¿p theo.

ReST lÃ  má»™t phÆ°Æ¡ng phÃ¡p tá»•ng quÃ¡t cho phÃ©p cÃ¡c hÃ m máº¥t mÃ¡t RL ngoáº¡i tuyáº¿n khÃ¡c nhau Ä‘Æ°á»£c sá»­ dá»¥ng trong vÃ²ng láº·p bÃªn trong
khi thá»±c hiá»‡n cÃ¡c bÆ°á»›c Improve. Äá»ƒ Ã¡p dá»¥ng nÃ³ vÃ o thá»±c táº¿, ngÆ°á»i ta chá»‰ cáº§n kháº£ nÄƒng: i) láº¥y máº«u
tá»« má»™t mÃ´ hÃ¬nh má»™t cÃ¡ch hiá»‡u quáº£, ii) cháº¥m Ä‘iá»ƒm cÃ¡c máº«u cá»§a mÃ´ hÃ¬nh. ReST cung cáº¥p má»™t sá»‘ lá»£i tháº¿ so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p RLHF
Ä‘iá»ƒn hÃ¬nh vá»›i RL trá»±c tuyáº¿n hoáº·c ngoáº¡i tuyáº¿n:
â€¢GÃ¡nh náº·ng tÃ­nh toÃ¡n Ä‘Æ°á»£c giáº£m Ä‘Ã¡ng ká»ƒ so vá»›i RL trá»±c tuyáº¿n nhá» vÃ o
Ä‘áº§u ra cá»§a bÆ°á»›c Grow Ä‘Æ°á»£c khai thÃ¡c qua nhiá»u bÆ°á»›c Improve.
â€¢Cháº¥t lÆ°á»£ng cá»§a chÃ­nh sÃ¡ch khÃ´ng bá»‹ háº¡n cháº¿ bá»Ÿi cháº¥t lÆ°á»£ng cá»§a táº­p dá»¯ liá»‡u gá»‘c (nhÆ° trong RL ngoáº¡i tuyáº¿n)
vÃ¬ dá»¯ liá»‡u huáº¥n luyá»‡n má»›i Ä‘Æ°á»£c láº¥y máº«u tá»« má»™t chÃ­nh sÃ¡ch Ä‘Æ°á»£c cáº£i thiá»‡n trong bÆ°á»›c Grow.
â€¢Dá»… dÃ ng kiá»ƒm tra cháº¥t lÆ°á»£ng dá»¯ liá»‡u vÃ  cÃ³ thá»ƒ cháº©n Ä‘oÃ¡n cÃ¡c váº¥n Ä‘á» cÄƒn chá»‰nh, vÃ­ dá»¥, hack pháº§n thÆ°á»Ÿng,
vÃ¬ cÃ¡c bÆ°á»›c Grow vÃ  Improve Ä‘Æ°á»£c tÃ¡ch biá»‡t.
â€¢PhÆ°Æ¡ng phÃ¡p nÃ y Ä‘Æ¡n giáº£n, á»•n Ä‘á»‹nh vÃ  chá»‰ cÃ³ má»™t sá»‘ lÆ°á»£ng nhá» siÃªu tham sá»‘ Ä‘á»ƒ Ä‘iá»u chá»‰nh.

ChÃºng tÃ´i giáº£i thÃ­ch chi tiáº¿t vá» phÆ°Æ¡ng phÃ¡p ReST Ä‘Æ°á»£c Ä‘á» xuáº¥t trong Pháº§n 3. Sau Ä‘Ã³, chÃºng tÃ´i trÃ¬nh bÃ y
káº¿t quáº£ thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i trÃªn cÃ¡c chuáº©n má»±c dá»‹ch mÃ¡y trong Pháº§n 4. Dá»‹ch mÃ¡y lÃ  má»™t
bÃ i toÃ¡n há»c sequence-to-sequence (Sutskever et al., 2014), thÆ°á»ng Ä‘Æ°á»£c cÃ´ng thá»©c hÃ³a nhÆ°
mÃ´ hÃ¬nh ngÃ´n ngá»¯ cÃ³ Ä‘iá»u kiá»‡n nÆ¡i ngá»¯ cáº£nh Ä‘á»ƒ Ä‘iá»u kiá»‡n lÃ  má»™t cÃ¢u báº±ng ngÃ´n ngá»¯ nÆ°á»›c ngoÃ i
(nguá»“n). ChÃºng tÃ´i chá»n dá»‹ch mÃ¡y vÃ¬ i) Ä‘Ã¢y lÃ  má»™t á»©ng dá»¥ng cÃ³ tÃ¡c Ä‘á»™ng vá»›i cÃ¡c baseline máº¡nh
vÃ  má»™t quy trÃ¬nh Ä‘Ã¡nh giÃ¡ Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh rÃµ rÃ ng, ii) má»™t sá»‘ phÆ°Æ¡ng phÃ¡p cháº¥m Ä‘iá»ƒm vÃ  Ä‘Ã¡nh giÃ¡ Ä‘Ã¡ng tin cáº­y hiá»‡n cÃ³
sáºµn Ä‘á»ƒ sá»­ dá»¥ng lÃ m mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng (Freitag et al., 2022). Trong cÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i, chÃºng tÃ´i so sÃ¡nh
má»™t sá»‘ thuáº­t toÃ¡n RL ngoáº¡i tuyáº¿n trÃªn cÃ¡c chuáº©n má»±c IWSLT 2014 (Cettolo et al., 2014) vÃ  WMT 2020
(Koehn et al., 2020) cÅ©ng nhÆ° cÃ¡c chuáº©n má»±c ná»™i bá»™ cáº¡nh tranh hÆ¡n, cÃ³ Ä‘á»™ tin cáº­y cao trÃªn Web Domain.
Trong cÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i ReST cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ Ä‘iá»ƒm sá»‘ mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng trÃªn cÃ¡c táº­p kiá»ƒm tra vÃ  xÃ¡c thá»±c.
HÆ¡n ná»¯a, theo ngÆ°á»i Ä‘Ã¡nh giÃ¡ con ngÆ°á»i, ReST táº¡o ra cÃ¡c báº£n dá»‹ch cháº¥t lÆ°á»£ng cao hÆ¡n so vá»›i
baseline há»c cÃ³ giÃ¡m sÃ¡t.

--- TRANG 3 ---
Tá»± Huáº¥n Luyá»‡n TÄƒng CÆ°á»ng (ReST) cho MÃ´ HÃ¬nh NgÃ´n Ngá»¯

2. Kiáº¿n thá»©c cÆ¡ báº£n

Má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ cÃ³ Ä‘iá»u kiá»‡n táº¡o ra má»™t chuá»—i Ä‘áº§u ra ğ’š=(ğ‘¦1,ğ‘¦2,....ğ‘¦ğ‘‡) cho má»™t ngá»¯ cáº£nh (hoáº·c
Ä‘áº§u vÃ o nguá»“n) ğ’™=(ğ‘¥1,ğ‘¥2,...ğ‘¥ğ¿), trong Ä‘Ã³ cÃ¡c token ğ‘¥ğ‘™,ğ‘¦ğ‘¡ thuá»™c vá» má»™t tá»« vá»±ng Ä‘Æ°á»£c chá»n. Má»™t chÃ­nh sÃ¡ch
táº¡o ngÃ´n ngá»¯ ğœ‹ trong má»™t mÃ´ hÃ¬nh tá»± há»“i quy Ä‘Æ°á»£c Ä‘áº·c trÆ°ng bá»Ÿi má»™t phÃ¢n phá»‘i xÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n
Ä‘Æ°á»£c tham sá»‘ hÃ³a bá»Ÿi ğœƒ nhÆ°

ğœ‹ğœƒ(ğ’š|ğ’™)=ğ‘‡Ã–
ğ‘¡=1ğœ‹ğœƒ(ğ‘¦ğ‘¡|ğ’š1:ğ‘¡âˆ’1,ğ’™),

vá»›i quy Æ°á»›c ğ’š1:0=âˆ… vÃ  ğ’š1:ğ‘¡âˆ’1=(ğ‘¦1,ğ‘¦2,....ğ‘¦ğ‘¡âˆ’1).

Gá»i ğ‘(ğ’™,ğ’š)=ğ‘(ğ’™)ğ‘(ğ’š|ğ’™) biá»ƒu thá»‹ phÃ¢n phá»‘i dá»¯ liá»‡u. Má»™t táº­p dá»¯ liá»‡u D cho trÆ°á»›c bao gá»“m cÃ¡c máº«u tá»«
phÃ¢n phá»‘i nÃ y:
D={(ğ’™ğ‘–,ğ’šğ‘–)|ğ‘
ğ‘–=1 sao cho ğ’™ğ‘–âˆ¼ğ‘(ğ’™),ğ’šğ‘–âˆ¼ğ‘(ğ’š|ğ’™=ğ’™ğ‘–)}.

Cho táº­p dá»¯ liá»‡u nÃ y, chÃ­nh sÃ¡ch cÃ³ giÃ¡m sÃ¡t Ä‘Æ°á»£c huáº¥n luyá»‡n báº±ng cÃ¡ch tá»‘i thiá»ƒu hÃ³a hÃ m máº¥t mÃ¡t log likelihood Ã¢m (NLL):

LNLL(ğœƒ)=âˆ’ğ”¼(ğ’™,ğ’š)âˆ¼D"ğ‘‡âˆ‘ï¸
ğ‘¡=1logğœ‹ğœƒ(ğ‘¦ğ‘¡|ğ’š1:ğ‘¡âˆ’1,ğ’™)#. (1)

ChÃºng tÃ´i gá»i mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i hÃ m máº¥t mÃ¡t NLL lÃ  behavioral cloning (BC) (Pomerleau, 1989)
theo cÃ¡ch gá»i tÃªn trong tÃ i liá»‡u RL.

3. Tá»± Huáº¥n Luyá»‡n TÄƒng CÆ°á»ng (ReST)

ChÃºng tÃ´i trÃ¬nh bÃ y ReST, má»™t thuáº­t toÃ¡n RLHF cÄƒn chá»‰nh Ä‘áº§u ra cá»§a mÃ´ hÃ¬nh ngÃ´n ngá»¯ vá»›i sá»Ÿ thÃ­ch cá»§a con ngÆ°á»i.
Sá»Ÿ thÃ­ch cá»§a con ngÆ°á»i vá» cÃ¡c chuá»—i Ä‘Æ°á»£c mÃ´ hÃ¬nh hÃ³a sá»­ dá»¥ng má»™t hÃ m pháº§n thÆ°á»Ÿng Ä‘Ã£ há»c (xem Phá»¥ lá»¥c
A.4). Trong quÃ¡ trÃ¬nh Markov decision process cÆ¡ báº£n cho mÃ´ hÃ¬nh ngÃ´n ngá»¯ cÃ³ Ä‘iá»u kiá»‡n, cÃ¡c tráº¡ng thÃ¡i lÃ 
cÃ¡c chuá»—i má»™t pháº§n, vÃ  cÃ¡c hÃ nh Ä‘á»™ng lÃ  cÃ¡c token Ä‘Æ°á»£c táº¡o (xem Phá»¥ lá»¥c A.1).

Thuáº­t toÃ¡n ReST tÃ¡ch biá»‡t viá»‡c tÄƒng trÆ°á»Ÿng táº­p dá»¯ liá»‡u vÃ  cáº£i thiá»‡n chÃ­nh sÃ¡ch cá»§a má»™t pipeline RL Ä‘iá»ƒn hÃ¬nh
thÃ nh cÃ¡c giai Ä‘oáº¡n ngoáº¡i tuyáº¿n riÃªng biá»‡t (HÃ¬nh 1 vÃ  2). ChÃºng tÃ´i báº¯t Ä‘áº§u báº±ng viá»‡c huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh ban Ä‘áº§u ğœ‹ğœƒ(ğ’š|ğ’™) Ä‘á»ƒ Ã¡nh xáº¡
cÃ¡c chuá»—i Ä‘áº§u vÃ o ğ’™ Ä‘áº¿n cÃ¡c chuá»—i Ä‘áº§u ra ğ’š trÃªn má»™t táº­p dá»¯ liá»‡u cho trÆ°á»›c cá»§a cÃ¡c cáº·p chuá»—i D sá»­ dá»¥ng hÃ m máº¥t mÃ¡t NLL
tá»« PhÆ°Æ¡ng trÃ¬nh (1). Tiáº¿p theo, bÆ°á»›c Grow táº¡o ra má»™t táº­p dá»¯ liá»‡u má»›i Dğ‘”, bá»• sung táº­p dá»¯ liá»‡u huáº¥n luyá»‡n ban Ä‘áº§u
vá»›i cÃ¡c máº«u tá»« mÃ´ hÃ¬nh:

Dğ‘”={(ğ’™ğ‘–,ğ’šğ‘–)|ğ‘ğ‘”
ğ‘–=1 sao cho ğ’™ğ‘–âˆ¼D,ğ’šğ‘–âˆ¼ğœ‹ğœƒ(ğ’š|ğ’™ğ‘–)}âˆªD.

á» Ä‘Ã¢y, cÃ¡c Ä‘áº§u vÃ o Ä‘iá»u kiá»‡n Ä‘Æ°á»£c láº¥y máº«u láº¡i tá»« táº­p dá»¯ liá»‡u gá»‘c ğ’™ğ‘–âˆ¼D, nhÆ° trong self-training,
nhÆ°ng trong cÃ¡c tÃ¬nh huá»‘ng khi ngÆ°á»i ta cÃ³ quyá»n truy cáº­p vÃ o ğ‘(ğ’™) há» cÃ³ thá»ƒ láº¥y máº«u trá»±c tiáº¿p tá»« nÃ³, tá»©c lÃ  ğ’™ğ‘–âˆ¼ğ‘(ğ’™).
VÃ­ dá»¥, xem xÃ©t má»™t mÃ´ hÃ¬nh táº¡o ra hÃ¬nh áº£nh tá»« mÃ´ táº£ vÄƒn báº£n, trong trÆ°á»ng há»£p nÃ y,
phÃ¢n phá»‘i cá»§a cÃ¡c Ä‘áº§u vÃ o vÄƒn báº£n cÃ³ thá»ƒ Ä‘Æ°á»£c láº¥y máº«u tá»« má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ ğ‘(ğ’™).

Sau Ä‘Ã³, cÃ¡c bÆ°á»›c Improve sá»­ dá»¥ng Dğ‘” Ä‘á»ƒ tinh chá»‰nh chÃ­nh sÃ¡ch ğœ‹ğœƒ. LÆ°u Ã½ ráº±ng chÃºng tÃ´i giá»¯ láº¡i táº­p dá»¯ liá»‡u gá»‘c
trong há»—n há»£p huáº¥n luyá»‡n Ä‘á»ƒ Ä‘áº£m báº£o ráº±ng cÃ¡c chÃ­nh sÃ¡ch khÃ´ng phÃ¢n ká»³. DÆ°á»›i Ä‘Ã¢y, chÃºng tÃ´i mÃ´ táº£ cÃ¡c bÆ°á»›c Grow
vÃ  Improve chi tiáº¿t hÆ¡n.

--- TRANG 4 ---
Tá»± Huáº¥n Luyá»‡n TÄƒng CÆ°á»ng (ReST) cho MÃ´ HÃ¬nh NgÃ´n Ngá»¯

Grow
HÃ¬nh 2|Thuáº­t toÃ¡n ReST. TrÃªn:
á» cÃ¡c bÆ°á»›c Improve I=1,I=2,I=3, táº­p dá»¯ liá»‡u
tá»« chÃ­nh sÃ¡ch ban Ä‘áº§u Ä‘Æ°á»£c lá»c
vá»›i cÃ¡c ngÆ°á»¡ng ğœ1< ğœ2< ğœ3 vÃ  má»™t chuá»—i
cÃ¡c chÃ­nh sÃ¡ch ğœ‹ğœƒ1,ğœ‹ğœƒ2,ğœ‹ğœƒ3 Ä‘Æ°á»£c tinh chá»‰nh.
DÆ°á»›i: Náº¿u chÃºng ta láº¥y máº«u
tá»« nhá»¯ng chÃ­nh sÃ¡ch Ä‘Ã³ (mÃ u xÃ¡m), cháº¥t lÆ°á»£ng
cá»§a cÃ¡c máº«u sáº½ tÄƒng lÃªn. Trong thá»±c táº¿,
chá»‰ cÃ³ chÃ­nh sÃ¡ch cuá»‘i cÃ¹ng ğœ‹ğœƒ3 Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ táº¡o
táº­p dá»¯ liá»‡u Dğ‘” tiáº¿p theo.

BÆ°á»›c Grow tÆ°Æ¡ng á»©ng vá»›i bÆ°á»›c hÃ nh Ä‘á»™ng hoáº·c táº¡o dá»¯ liá»‡u
trong RL. ChÃºng tÃ´i táº¡o má»™t táº­p dá»¯ liá»‡u quá»¹ Ä‘áº¡o bá»• sung
Dğ‘” báº±ng cÃ¡ch láº¥y máº«u nhiá»u chuá»—i Ä‘áº§u ra tá»« chÃ­nh sÃ¡ch hiá»‡n táº¡i
ğœ‹ğœƒ, tá»©c lÃ  ğ’šâˆ¼ğœ‹ğœƒ(ğ’š|ğ’™) cho ğ’™âˆ¼D. Táº­p dá»¯ liá»‡u má»›i
cá»§a cÃ¡c chuá»—i sau Ä‘Ã³ Ä‘Æ°á»£c cháº¥m Ä‘iá»ƒm vá»›i má»™t hÃ m pháº§n thÆ°á»Ÿng ğ‘…(ğ’™,ğ’š).
CÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u vá»›i pháº§n thÆ°á»Ÿng trÃªn má»™t Ä‘iá»ƒm ngÆ°á»¡ng Ä‘Æ°á»£c
sá»­ dá»¥ng Ä‘á»ƒ cáº­p nháº­t chÃ­nh sÃ¡ch (xem tiáº¿p theo). Má»™t khi chÃ­nh sÃ¡ch Ä‘Æ°á»£c
cáº£i thiá»‡n, má»™t táº­p dá»¯ liá»‡u má»›i vá»›i cÃ¡c máº«u cháº¥t lÆ°á»£ng tá»‘t hÆ¡n cÃ³ thá»ƒ
Ä‘Æ°á»£c táº¡o ra má»™t láº§n ná»¯a (HÃ¬nh 2, dÆ°á»›i).

Improve
á» bÆ°á»›c Improve (khai thÃ¡c hoáº·c cáº£i thiá»‡n chÃ­nh sÃ¡ch
trong thuáº­t ngá»¯ RL), má»¥c tiÃªu lÃ  sá»­ dá»¥ng táº­p dá»¯ liá»‡u má»›i Dğ‘”
Ä‘á»ƒ tinh chá»‰nh chÃ­nh sÃ¡ch ğœ‹ğœƒ. ChÃºng tÃ´i báº¯t Ä‘áº§u báº±ng viá»‡c Ä‘á»‹nh nghÄ©a má»™t hÃ m lá»c
chá»‰ bao gá»“m cÃ¡c máº«u vá»›i pháº§n thÆ°á»Ÿng cao hÆ¡n
má»™t ngÆ°á»¡ng nháº¥t Ä‘á»‹nh ğœ:

ğ¹(ğ’™,ğ’š;ğœ)= 1ğ‘…(ğ’™,ğ’š)>ğœ.

HÃ£y Ä‘á»ƒ chÃºng tÃ´i lÆ°u Ã½ ráº±ng hÃ m lá»c dá»±a trÃªn ngÆ°á»¡ng cÃ³ thá»ƒ dáº«n
Ä‘áº¿n há»c cÃ¡c hÃ nh vi khÃ´ng tá»‘i Æ°u Æ°a chuá»™ng cÃ¡c káº¿t quáº£
vá»›i phÆ°Æ¡ng sai cao trong cÃ¡c mÃ´i trÆ°á»ng vá»›i Ä‘á»™ng lá»±c
ngáº«u nhiÃªn (Brandfonbrener et al., 2022). Tuy nhiÃªn, trong cÃ´ng trÃ¬nh nÃ y
chÃºng tÃ´i cÃ´ng thá»©c hÃ³a cÃ¡c tÃ¡c vá»¥ mÃ´ hÃ¬nh ngÃ´n ngá»¯ vÃ  dá»‹ch thuáº­t
nhÆ° cÃ¡c váº¥n Ä‘á» RL xÃ¡c Ä‘á»‹nh (Phá»¥ lá»¥c A.1.)

Tiáº¿p theo, chÃºng tÃ´i tinh chá»‰nh chÃ­nh sÃ¡ch tá»‘t nháº¥t hiá»‡n táº¡i thÆ°á»ng
Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i hÃ m máº¥t mÃ¡t há»c cÃ³ giÃ¡m sÃ¡t LNLL
tá»« phÆ°Æ¡ng trÃ¬nh 1 hoáº·c má»™t hÃ m máº¥t mÃ¡t RL ngoáº¡i tuyáº¿n L(ğ’™,ğ’š;ğœƒ) trÃªn dá»¯ liá»‡u Ä‘Æ°á»£c lá»c
nhÆ° V-MPO (Song et al., 2020) hoáº·c offline actor-critic (Mathieu et al., 2021). TÃ³m láº¡i, chÃºng tÃ´i sá»­ dá»¥ng hÃ m máº¥t mÃ¡t cÃ³ trá»ng sá»‘ pháº§n thÆ°á»Ÿng ğ½ sau:

ğ½(ğœƒ)=ğ”¼(ğ’™,ğ’š)âˆ¼Dğ‘”[ğ¹(ğ’™,ğ’š;ğœ)L( ğ’™,ğ’š;ğœƒ)]. (2)

CÃ¡c phÆ°Æ¡ng phÃ¡p há»c mÃ´ phá»ng tiÃªu chuáº©n, nhÆ° BC (Pomerleau (1989), phÆ°Æ¡ng trÃ¬nh 1) vÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p RL má»™t bÆ°á»›c nhÆ° Behavior Value Estimation (BVE) (Gulcehre et al., 2021) thá»±c hiá»‡n má»™t bÆ°á»›c
Improve trÃªn táº­p dá»¯ liá»‡u cá»‘ Ä‘á»‹nh D. NgÆ°á»£c láº¡i, phiÃªn báº£n cÆ¡ báº£n cá»§a ReST bá»• sung bao gá»“m má»™t
bÆ°á»›c Grow cho phÃ©p mÃ´ hÃ¬nh thu tháº­p nhiá»u chuá»—i Ä‘áº§u ra má»›i (báº£n dá»‹ch tiá»m nÄƒng) cho
cÃ¡c ngá»¯ cáº£nh ğ’™ tá»« táº­p dá»¯ liá»‡u gá»‘c (cÃ¢u nguá»“n Ä‘á»ƒ dá»‹ch).

Khi láº·p qua cÃ¡c bÆ°á»›c Improve, chÃºng tÃ´i tÄƒng cÃ¡c ngÆ°á»¡ng lá»c: ğœ1<Â·Â·Â·< ğœğ‘âˆ’1< ğœğ‘
(HÃ¬nh 2). Viá»‡c lá»c nÃ y vá»›i ngÆ°á»¡ng tÄƒng dáº§n dáº«n Ä‘áº¿n cÃ¡c táº­p con dá»¯ liá»‡u cÃ³ cháº¥t lÆ°á»£ng tÄƒng dáº§n nhÆ°ng
cÃ³ kÃ­ch thÆ°á»›c giáº£m dáº§n. VÃ¬ LLM overfit vá»›i cÃ¡c táº­p dá»¯ liá»‡u nhá» má»™t cÃ¡ch nhanh chÃ³ng, chÃºng tÃ´i tinh chá»‰nh má»—i chÃ­nh sÃ¡ch má»›i tá»«
chÃ­nh sÃ¡ch trÆ°á»›c Ä‘Ã³ vá»›i tá»‘c Ä‘á»™ há»c tháº¥p hÆ¡n. Viá»‡c tinh chá»‰nh liÃªn tiáº¿p cÃ¡c chÃ­nh sÃ¡ch {ğœ‹ğœƒğ‘˜}ğ‘˜â‰¥1 trÃªn cÃ¡c táº­p con dá»¯ liá»‡u
cháº¥t lÆ°á»£ng cao hÆ¡n Ä‘áº£m báº£o cáº£i thiá»‡n chÃ­nh sÃ¡ch vá»›i má»™t táº­p dá»¯ liá»‡u cá»‘ Ä‘á»‹nh Dğ‘”. Náº¿u chÃºng ta láº¥y máº«u tá»«
cÃ¡c chÃ­nh sÃ¡ch{ğœ‹ğœƒğ‘˜}ğ‘˜â‰¥1, pháº§n thÆ°á»Ÿng trung bÃ¬nh cá»§a cÃ¡c máº«u Ä‘Æ°á»£c táº¡o sáº½ tÄƒng (Ä‘Æ°á»£c hiá»ƒn thá»‹ báº±ng mÃ u xÃ¡m trong
HÃ¬nh 2). VÃ¬ viá»‡c láº¥y máº«u tá»« má»™t chÃ­nh sÃ¡ch trong bÆ°á»›c Grow tá»‘n kÃ©m vá» máº·t tÃ­nh toÃ¡n, sau má»—i bÆ°á»›c nhÆ° váº­y
chÃºng tÃ´i thá»±c hiá»‡n nhiá»u bÆ°á»›c Improve. Do Ä‘Ã³, chi phÃ­ cá»§a má»™t láº§n táº¡o táº­p dá»¯ liá»‡u duy nháº¥t Ä‘Æ°á»£c kháº¥u hao
qua nhiá»u bÆ°á»›c Improve. Thuáº­t toÃ¡n 1 phÃ¡c tháº£o thuáº­t toÃ¡n ReST Ä‘áº§y Ä‘á»§ vá»›i nhiá»u bÆ°á»›c tÄƒng trÆ°á»Ÿng táº­p dá»¯ liá»‡u
vÃ  cáº£i thiá»‡n chÃ­nh sÃ¡ch.

--- TRANG 5 ---
Tá»± Huáº¥n Luyá»‡n TÄƒng CÆ°á»ng (ReST) cho MÃ´ HÃ¬nh NgÃ´n Ngá»¯

Thuáº­t toÃ¡n 1: Thuáº­t toÃ¡n ReST. ReST lÃ  má»™t thuáº­t toÃ¡n RL lÃ´ tÄƒng trÆ°á»Ÿng. Cho má»™t chÃ­nh sÃ¡ch
ban Ä‘áº§u cÃ³ cháº¥t lÆ°á»£ng há»£p lÃ½ (vÃ­ dá»¥, Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c sá»­ dá»¥ng BC) Ã¡p dá»¥ng láº·p Ä‘i láº·p láº¡i cÃ¡c bÆ°á»›c Grow vÃ 
Improve Ä‘á»ƒ cáº­p nháº­t chÃ­nh sÃ¡ch. á» Ä‘Ã¢y ğ¹ lÃ  má»™t hÃ m lá»c, vÃ  L lÃ  má»™t hÃ m máº¥t mÃ¡t.

Äáº§u vÃ o: D: Táº­p dá»¯ liá»‡u, Dğ‘’ğ‘£ğ‘ğ‘™: Táº­p dá»¯ liá»‡u Ä‘Ã¡nh giÃ¡, L(ğ’™,ğ’š;ğœƒ): máº¥t mÃ¡t, ğ‘…(ğ’™,ğ’š): mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng, ğº:
sá»‘ bÆ°á»›c grow, ğ¼: sá»‘ bÆ°á»›c improve, ğ‘: sá»‘ máº«u trÃªn má»—i ngá»¯ cáº£nh

Huáº¥n luyá»‡n ğœ‹ğœƒ trÃªn D sá»­ dá»¥ng máº¥t mÃ¡t L.
for ğ‘”=1 to ğº do
// Grow
Táº¡o táº­p dá»¯ liá»‡u Dğ‘” báº±ng cÃ¡ch láº¥y máº«u: Dğ‘”={(ğ’™ğ‘–,ğ’šğ‘–)|ğ‘ğ‘”
ğ‘–=1 s.t. ğ’™ğ‘–âˆ¼D,ğ’šğ‘–âˆ¼ğœ‹ğœƒ(ğ’š|ğ’™ğ‘–)}âˆªD.
ChÃº thÃ­ch Dğ‘” vá»›i mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng ğ‘…(ğ’™,ğ’š).
for ğ‘–=1 to ğ¼ do
// Improve
Chá»n ngÆ°á»¡ng s.t. ğœ1>ğ‘‰ğœ‹ğœƒ cho ğ‘‰ğœ‹ğœƒ=ğ”¼Dğ‘”[ğ‘…(ğ’™,ğ’š)] vÃ  ğœğ‘–+1> ğœğ‘–.
while pháº§n thÆ°á»Ÿng cáº£i thiá»‡n trÃªn Dğ‘’ğ‘£ğ‘ğ‘™ do
Tá»‘i Æ°u hÃ³a ğœƒ trÃªn má»¥c tiÃªu: ğ½(ğœƒ)=ğ”¼(ğ’™,ğ’š)âˆ¼Dğ‘”[ğ¹(ğ’™,ğ’š;ğœğ‘–)L( ğ’™,ğ’š;ğœƒ)]
end
end
end
Äáº§u ra: ChÃ­nh sÃ¡ch ğœ‹ğœƒ

Giáº£i thÃ­ch xÃ¡c suáº¥t cá»§a bÆ°á»›c Improve. HÃ£y xem xÃ©t lá»±a chá»n cá»¥ thá»ƒ L=LNLL,
vá»›i ğœƒâ€² lÃ  cÃ¡c tham sá»‘ cá»§a mÃ´ hÃ¬nh tá»« bÆ°á»›c Grow cuá»‘i cÃ¹ng, ğœ† lÃ  tá»· lá»‡ dá»¯ liá»‡u Ä‘Æ°á»£c láº¥y máº«u
tá»« mÃ´ hÃ¬nh nÃ y trong Dğ‘” vÃ  má»™t bÆ°á»›c tÄƒng trÆ°á»Ÿng duy nháº¥t. Biá»ƒu thá»©c cho gradient trong trÆ°á»ng há»£p nÃ y cÃ³
dáº¡ng sau:

âˆ‡ğ½(ğœƒ)=âˆ’ğ”¼ğ’™âˆ¼D
ğœ†ğ”¼ğ’šâˆ¼ğœ‹ğœƒâ€²(ğ’š|ğ’™)[ğ¹(ğ’™,ğ’š;ğœ)âˆ‡logğœ‹ğœƒ(ğ’š|ğ’™)]+(1âˆ’ğœ†)ğ”¼ğ’šâˆ¼ğ‘(ğ’š|ğ’™)[ğ¹(ğ’™,ğ’š;ğœ)âˆ‡logğœ‹ğœƒ(ğ’š|ğ’™)]
. (3)

Sá»‘ háº¡ng Ä‘áº§u tiÃªn á»Ÿ váº¿ pháº£i cá»§a (3) tÆ°Æ¡ng tá»± nhÆ° má»™t sá»‘ háº¡ng policy gradient trá»±c tuyáº¿n á»Ÿ Ä‘áº§u quÃ¡ trÃ¬nh huáº¥n luyá»‡n
khi ğœƒâ‰ˆğœƒâ€² vá»›i ğ¹(ğ’™,ğ’š;ğœ) thay tháº¿ hÃ m giÃ¡ trá»‹ state-action ğ‘„ğœ‹(ğ’™,ğ’š), khi báº¯t Ä‘áº§u á»Ÿ tráº¡ng thÃ¡i
ğ’™ vÃ  thá»±c hiá»‡n cÃ¡c hÃ nh Ä‘á»™ng tuáº§n tá»± ğ’š, tá»©c lÃ  táº¡o dá»¯ liá»‡u tá»•ng há»£p ğ’š sá»­ dá»¥ng chÃ­nh sÃ¡ch ğœ‹ğœƒ trong ngá»¯ cáº£nh cá»§a chÃºng ta.
Äá»‘i vá»›i sá»‘ háº¡ng thá»© hai á»Ÿ váº¿ pháº£i cá»§a (3), chÃºng tÃ´i xem xÃ©t dá»¯ liá»‡u gá»‘c D, nhÆ°ng chÃºng tÃ´i váº«n Ä‘áº£m báº£o ráº±ng nÃ³
vÆ°á»£t qua ngÆ°á»¡ng ğ¹(ğ’™,ğ’š;ğœ). Má»™t cÃ¡ch trá»±c quan, má»i ngÆ°á»i chá»n D Ä‘á»ƒ huáº¥n luyá»‡n theo má»™t sá»‘
tiÃªu chÃ­ cÃ³ thá»ƒ khÃ´ng xÃ¡c Ä‘á»‹nh. Trong cÃ´ng trÃ¬nh nÃ y, chÃºng tÃ´i lÃ m cho tiÃªu chÃ­ ğ¹(ğ’™,ğ’š;ğœ) rÃµ rÃ ng. Do Ä‘Ã³ sá»‘ háº¡ng cuá»‘i cÃ¹ng lÃ  má»™t
dáº¡ng policy gradients ngoáº¡i tuyáº¿n ngÄƒn ğœ‹ğœƒ(ğ’š|ğ’™) di chuyá»ƒn quÃ¡ xa khá»i ğ‘(ğ’š|ğ’™) cÃ³ thá»ƒ
dáº«n Ä‘áº¿n sá»± sá»¥p Ä‘á»• mÃ´ hÃ¬nh (Shumailov et al., 2023). Cuá»‘i cÃ¹ng, lÆ°u Ã½ sá»± tÆ°Æ¡ng Ä‘á»“ng cá»§a phÆ°Æ¡ng phÃ¡p nÃ y vá»›i
cÃ¡c ká»¹ thuáº­t self-training (Clark et al., 2003; Scudder, 1965; Xie et al., 2020). ChÃºng tÃ´i cung cáº¥p má»™t
giáº£i thÃ­ch dÃ¢n sá»‘ (tá»©c lÃ  khi ğ‘,ğ‘ğ‘”â†’âˆ) cá»§a ReST trong Phá»¥ lá»¥c A.9.

Trong pháº§n tiáº¿p theo, chÃºng tÃ´i khÃ¡m phÃ¡ cÃ¡ch viá»‡c lá»±a chá»n hÃ m máº¥t mÃ¡t, hÃ m lá»c vÃ  ngÆ°á»¡ng, vÃ 
dá»¯ liá»‡u tá»•ng há»£p Ä‘Æ°á»£c táº¡o bá»Ÿi chÃ­nh sÃ¡ch ngÃ´n ngá»¯ thÃ´ng qua láº¥y máº«u (dá»¯ liá»‡u khÃ¡m phÃ¡) áº£nh hÆ°á»Ÿng thá»±c nghiá»‡m Ä‘áº¿n
hiá»‡u suáº¥t cá»§a cÃ¡c chÃ­nh sÃ¡ch káº¿t quáº£ ğœ‹ğœƒ.

4. ThÃ­ nghiá»‡m vÃ  phÃ¢n tÃ­ch

ChÃºng tÃ´i chá»n dá»‹ch mÃ¡y lÃ m bÃ n thá»­ nghiá»‡m cho ReST vÃ¬ Ä‘Ã¢y lÃ  má»™t á»©ng dá»¥ng cÃ³ tÃ¡c Ä‘á»™ng cá»§a mÃ´ hÃ¬nh ngÃ´n ngá»¯ cÃ³ Ä‘iá»u kiá»‡n
nÆ¡i cÃ¡c mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng Ä‘Ã£ Ä‘Æ°á»£c thiáº¿t láº­p cÃ³ sáºµn, vÃ­ dá»¥, Metric X (Freitag et al., 2022), BLEURT (Sellam et al., 2020) vÃ  COMET (Rei et al., 2020). ChÃºng tÃ´i Ä‘Ã£ cháº¡y thÃ­ nghiá»‡m trÃªn
hai chuáº©n má»±c phá»• biáº¿n: IWSLT 2014 (Cettolo et al., 2014), vÃ  WMT 2020 (Koehn et al., 2020),

--- TRANG 6 ---
Tá»± Huáº¥n Luyá»‡n TÄƒng CÆ°á»ng (ReST) cho MÃ´ HÃ¬nh NgÃ´n Ngá»¯

HÃ¬nh 3|ReST vá»›i nhiá»u bÆ°á»›c Improve. Äiá»ƒm sá»‘ mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng trung bÃ¬nh trÃªn cÃ¡c táº­p xÃ¡c thá»±c IWSLT 2014 De-En,
WMT 2020 Zh-En, vÃ  Web Domain En-Zh. TrÃªn má»—i táº­p dá»¯ liá»‡u, chÃºng tÃ´i bÃ¡o cÃ¡o káº¿t quáº£ vá»›i BC
(ğº=0, ğ¼=0) vÃ  ReST vá»›i má»™t bÆ°á»›c Grow duy nháº¥t vÃ  nhiá»u bÆ°á»›c Improve vá»›i ngÆ°á»¡ng pháº§n thÆ°á»Ÿng
tÄƒng dáº§n. Má»—i bÆ°á»›c Improve tÄƒng Ä‘iá»ƒm sá»‘ mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng trong cáº£ ba táº­p dá»¯ liá»‡u xÃ¡c thá»±c. ChÃºng tÃ´i
tháº¥y ráº±ng sá»‘ bÆ°á»›c Improve phÃ¹ há»£p lÃ  má»™t siÃªu tham sá»‘ phá»¥ thuá»™c vÃ o táº­p dá»¯ liá»‡u.

cÅ©ng nhÆ° má»™t táº­p dá»¯ liá»‡u chuáº©n má»±c ná»™i bá»™ mÃ  chÃºng tÃ´i gá»i lÃ  Web Domain (má»™t phiÃªn báº£n cá»§a táº­p dá»¯ liá»‡u nÃ y Ä‘Ã£
Ä‘Æ°á»£c sá»­ dá»¥ng trÆ°á»›c Ä‘Ã³ bá»Ÿi Ghorbani et al. (2021)). Nhá»¯ng táº­p dá»¯ liá»‡u nÃ y chá»©a má»™t táº­p há»£p cÃ¡c cÃ¢u trong ngÃ´n ngá»¯ nguá»“n
vÃ  báº£n dá»‹ch "tham chiáº¿u" cá»§a con ngÆ°á»i tÆ°Æ¡ng á»©ng. ChÃºng tÃ´i Ä‘Ã£ chá»n má»™t cáº·p ngÃ´n ngá»¯ khÃ¡c nhau cho má»—i táº­p dá»¯ liá»‡u
Ä‘á»ƒ kiá»ƒm tra tÃ­nh tá»•ng quÃ¡t cá»§a káº¿t quáº£. ChÃºng tÃ´i giá»¯ cÃ¡c táº­p xÃ¡c thá»±c vÃ  kiá»ƒm tra riÃªng biá»‡t
vá»›i cÃ¡c cÃ¢u nguá»“n chÆ°a tháº¥y cho má»¥c Ä‘Ã­ch Ä‘Ã¡nh giÃ¡.

ChÃºng tÃ´i sá»­ dá»¥ng Metric X trong cÃ¡c thÃ­ nghiá»‡m cá»§a mÃ¬nh, má»™t mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng khÃ´ng tham chiáº¿u tiÃªn tiáº¿n (Freitag et al.,
2022) mÃ , cho má»™t vÄƒn báº£n nguá»“n vÃ  má»™t báº£n dá»‹ch Ä‘Æ°á»£c Ä‘á» xuáº¥t, Ä‘Æ°a ra má»™t Ä‘iá»ƒm sá»‘ sá»‘. ChÃºng tÃ´i bÃ¡o cÃ¡o
káº¿t quáº£ theo Ä‘iá»ƒm pháº§n thÆ°á»Ÿng trung bÃ¬nh trÃªn cÃ¡c máº«u Ä‘Æ°á»£c táº¡o bá»Ÿi má»™t chÃ­nh sÃ¡ch trÃªn táº­p xÃ¡c thá»±cÂ¹. Äá»ƒ biáº¿t
chi tiáº¿t vá» cÃ¡c táº­p dá»¯ liá»‡u vÃ  mÃ´ hÃ¬nh, chÃºng tÃ´i tham chiáº¿u Ä‘áº¿n Phá»¥ lá»¥c A.3. NgoÃ i ra, Báº£ng 2 chá»‰ ra kÃ­ch thÆ°á»›c cá»§a
cÃ¡c táº­p dá»¯ liá»‡u báº±ng cÃ¡ch bÃ¡o cÃ¡o sá»‘ máº«u trÃªn má»—i cÃ¢u nguá»“n Ä‘Æ°á»£c táº¡o ra á»Ÿ má»—i bÆ°á»›c Grow.

CÃ¡ch Ä‘áº·t tÃªn. ChÃºng tÃ´i Ä‘áº·t tÃªn cÃ¡c biáº¿n thá»ƒ cá»§a ReST theo loáº¡i hÃ m máº¥t mÃ¡t, sá»‘ bÆ°á»›c Grow, vÃ  sá»‘
bÆ°á»›c Improve, vÃ­ dá»¥ GOLD G=1 I=2. Vá»›i quy Æ°á»›c nÃ y, BC G=0 I=0 Ä‘á» cáº­p Ä‘áº¿n há»c
cÃ³ giÃ¡m sÃ¡t tiÃªu chuáº©n, Ä‘Æ°á»£c huáº¥n luyá»‡n chá»‰ trÃªn táº­p dá»¯ liá»‡u gá»‘c D vÃ  khÃ´ng thá»±c hiá»‡n bÆ°á»›c Grow hay
Improve. Khi loáº¡i hÃ m máº¥t mÃ¡t khÃ´ng Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh, hÃ m máº¥t mÃ¡t BC Ä‘Æ°á»£c sá»­ dá»¥ng, tá»©c lÃ  mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i
há»c cÃ³ giÃ¡m sÃ¡t tá»± há»“i quy vá»›i hÃ m máº¥t mÃ¡t NLL nhÆ° Ä‘iá»ƒn hÃ¬nh trong viá»‡c huáº¥n luyá»‡n mÃ´ hÃ¬nh ngÃ´n ngá»¯. Trong táº¥t cáº£
cÃ¡c biá»ƒu Ä‘á»“, chÃºng tÃ´i tÃ´ mÃ u há»c cÃ³ giÃ¡m sÃ¡t báº±ng mÃ u xÃ¡m vÃ  cÃ¡c biáº¿n thá»ƒ ReST báº±ng cÃ¡c sáº¯c thÃ¡i mÃ u tÃ­m.

Baseline. ChÃºng tÃ´i bÃ¡o cÃ¡o káº¿t quáº£ vá»›i má»™t sá»‘ phÆ°Æ¡ng phÃ¡p RL ngoáº¡i tuyáº¿n khÃ¡c nhau, bao gá»“m Offline Actor
Critic (OAC) (Mathieu et al., 2021), Behavior VMPO (BVMPO), Generation by Off-policy Learning from
Demonstrations (GOLD) (Pang and He, 2021), vÃ  BC (Pomerleau, 1989)Â².

Liá»‡u nhiá»u bÆ°á»›c Improve trong ReST cÃ³ tÄƒng Ä‘iá»ƒm sá»‘ mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng khÃ´ng? ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ ReST trÃªn
ba táº­p dá»¯ liá»‡u khÃ¡c nhau báº±ng cÃ¡ch cá»‘ Ä‘á»‹nh hÃ m máº¥t mÃ¡t thÃ nh BC vÃ  tÄƒng sá»‘ bÆ°á»›c Improve.
Pháº¡m vi pháº§n thÆ°á»Ÿng cho huáº¥n luyá»‡n Ä‘Æ°á»£c chuáº©n hÃ³a giá»¯a 0 vÃ  1Â³. Äá»‘i vá»›i cÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i, chÃºng tÃ´i

Â¹Hiá»‡u suáº¥t trÃªn táº­p kiá»ƒm tra theo cÃ¹ng xu hÆ°á»›ng (xem Phá»¥ lá»¥c A.4). ChÃºng tÃ´i cÅ©ng thÃ­ nghiá»‡m vá»›i Ä‘iá»ƒm BLEURT vÃ  BLEU,
vÃ  ReST cÅ©ng cáº£i thiá»‡n nhá»¯ng Ä‘iá»ƒm sá»‘ Ä‘Ã³. ChÃºng tÃ´i nháº­n tháº¥y ráº±ng thuáº­t toÃ¡n PPO trá»±c tuyáº¿n cÃ³ thá»ƒ há»c cÃ¡ch khai thÃ¡c
cÃ¡c Ä‘iá»ƒm yáº¿u vÃ  thiÃªn lá»‡ch cá»§a hai chá»‰ sá»‘ nÃ y má»™t cÃ¡ch nhanh chÃ³ng, cÃ³ thá»ƒ khiáº¿n mÃ´ hÃ¬nh táº¡o ra cÃ¡c máº«u tá»‘i Ä‘a hÃ³a pháº§n thÆ°á»Ÿng
nhÆ°ng lÃ m xáº¥u Ä‘i cháº¥t lÆ°á»£ng Ä‘áº§u ra cá»§a mÃ´ hÃ¬nh.
Â²Chi tiáº¿t vá» baseline cá»§a chÃºng tÃ´i trong Phá»¥ lá»¥c A.8 vÃ  cÃ¡c thÃ­ nghiá»‡m vá»›i hÃ m máº¥t mÃ¡t bá»• sung trong Phá»¥ lá»¥c A.2
Â³LÆ°u Ã½ ráº±ng cÃ¡c biá»ƒu Ä‘á»“ hiá»ƒn thá»‹ pháº§n thÆ°á»Ÿng giá»¯a 0 vÃ  100.

--- TRANG 7 ---
Tá»± Huáº¥n Luyá»‡n TÄƒng CÆ°á»ng (ReST) cho MÃ´ HÃ¬nh NgÃ´n Ngá»¯

HÃ¬nh 4|ReST vá»›i hai bÆ°á»›c Grow. BÆ°á»›c Grow thá»© hai vá»›i cÃ¡c bÆ°á»›c Improve tiáº¿p theo
cáº£i thiá»‡n hiá»‡u suáº¥t 5.3 Ä‘iá»ƒm trÃªn IWSLT 2014 De-En vÃ  0.8 Ä‘iá»ƒm trÃªn tÃ¡c vá»¥ Web Domain En-Zh
so vá»›i bÆ°á»›c Grow Ä‘áº§u tiÃªn.

chá»n cÃ¡c ngÆ°á»¡ng lá»c ğœğ‘– tá»« má»™t chuá»—i cÃ¡c giÃ¡ trá»‹ tÄƒng dáº§n [0.0,0.7,0.8,0.9,0.95,0.99]â´.
TrÆ°á»ng há»£p ğœ0=0.0 tÆ°Æ¡ng á»©ng vá»›i viá»‡c sá»­ dá»¥ng toÃ n bá»™ táº­p dá»¯ liá»‡u. ChÃºng tÃ´i Ä‘Ã£ thá»±c hiá»‡n nÄƒm bÆ°á»›c Improve trÃªn IWSLT
2014, bá»‘n trÃªn WMT-2020, vÃ  hai trÃªn Web Domain. Trong HÃ¬nh 3 chÃºng tÃ´i váº½ biá»ƒu Ä‘á»“ pháº§n thÆ°á»Ÿng trung bÃ¬nh cá»§a
cÃ¡c biáº¿n thá»ƒ ReST khÃ¡c nhau. ChÃºng tÃ´i tháº¥y ráº±ng má»—i bÆ°á»›c Improve tiáº¿p theo cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a
mÃ´ hÃ¬nh dá»‹ch thuáº­t má»™t cÃ¡ch Ä‘Ã¡ng ká»ƒ trÃªn cáº£ ba táº­p dá»¯ liá»‡u.

HÃ¬nh 5|WMT 2020 zh-en (test): BC (mÃ u
xÃ¡m, ğº=0ğ¼=0) vÃ  ReST Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i
cÃ¡c hÃ m máº¥t mÃ¡t RL ngoáº¡i tuyáº¿n khÃ¡c nhau. ReST Ä‘Æ°á»£c huáº¥n luyá»‡n
vá»›i má»™t bÆ°á»›c Grow vÃ  Improve ngoáº¡i trá»« ğº=
1ğ¼=0, Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn toÃ n bá»™ táº­p dá»¯ liá»‡u
Ä‘Æ°á»£c táº¡o sau bÆ°á»›c Grow Ä‘áº§u tiÃªn mÃ  khÃ´ng cÃ³
báº¥t ká»³ Improve nÃ o (táº¥t cáº£ mÃ u tÃ­m). Táº¥t cáº£ biáº¿n thá»ƒ cá»§a
ReST vÆ°á»£t trá»™i hÆ¡n baseline BC ban Ä‘áº§u, vá»›i
hÃ m máº¥t mÃ¡t BC dáº«n Ä‘áº¿n hiá»‡u suáº¥t tá»‘t nháº¥t.

Liá»‡u cÃ¡c bÆ°á»›c Grow bá»• sung cÃ³ cáº£i thiá»‡n Ä‘iá»ƒm sá»‘ mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng khÃ´ng? ChÃºng tÃ´i Ä‘Ã£ thá»±c hiá»‡n má»™t bÆ°á»›c Grow thá»© hai vá»›i cÃ¡c
bÆ°á»›c Improve liÃªn tiáº¿p Ä‘á»ƒ Ä‘o lÆ°á»ng tÃ¡c Ä‘á»™ng cá»§a bÆ°á»›c
Grow thÃªm Ä‘á»‘i vá»›i hiá»‡u suáº¥t. Trong HÃ¬nh 4, má»™t
phÆ°Æ¡ng phÃ¡p vá»›i bÆ°á»›c Grow bá»• sung Ä‘áº¡t Ä‘Æ°á»£c cáº£i thiá»‡n
thÃªm trÃªn cÃ¡c táº­p dá»¯ liá»‡u IWSLT 2014 vÃ  Web Domain.
ChÃºng tÃ´i nháº­n tháº¥y cáº£i thiá»‡n 5.3 Ä‘iá»ƒm giá»¯a cuá»‘i
bÆ°á»›c Grow Ä‘áº§u tiÃªn vÃ  thá»© hai.

Liá»‡u ReST cÃ³ cáº£i thiá»‡n so vá»›i huáº¥n luyá»‡n cÃ³ giÃ¡m sÃ¡t khÃ´ng?
Äá»ƒ tráº£ lá»i cÃ¢u há»i nÃ y, trong HÃ¬nh 5 chÃºng tÃ´i váº½ biá»ƒu Ä‘á»“
pháº§n thÆ°á»Ÿng trung bÃ¬nh Ä‘áº¡t Ä‘Æ°á»£c bá»Ÿi mÃ´ hÃ¬nh há»c cÃ³ giÃ¡m sÃ¡t
cÅ©ng nhÆ° má»™t sá»‘ biáº¿n thá»ƒ cá»§a ReST vá»›i cÃ¡c hÃ m máº¥t mÃ¡t khÃ¡c nhau
vÃ  sá»‘ bÆ°á»›c Grow vÃ  Improve. CÃ¡c
biáº¿n thá»ƒ khÃ¡c nhau cá»§a ReST (mÃ u tÃ­m) vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ
so vá»›i há»c cÃ³ giÃ¡m sÃ¡t (mÃ u xÃ¡m) ngay cáº£ sau chá»‰ bÆ°á»›c
grow Ä‘áº§u tiÃªn. Quan sÃ¡t nÃ y nháº¥t quÃ¡n trÃªn
cÃ¡c táº­p dá»¯ liá»‡u vÃ  cáº·p ngÃ´n ngá»¯ khÃ¡c nhau mÃ  chÃºng tÃ´i Ä‘Ã£ kiá»ƒm tra.

HÃ m máº¥t mÃ¡t nÃ o lÃ  tá»‘t nháº¥t cho má»™t bÆ°á»›c ReST duy nháº¥t? HÃ¬nh 5 mÃ´ táº£ cÃ¡c biáº¿n thá»ƒ ReST vá»›i cÃ¡c
hÃ m máº¥t mÃ¡t RL ngoáº¡i tuyáº¿n L(ğ’™,ğ’š;ğœƒ) khÃ¡c nhau. ChÃºng tÃ´i tháº¥y ráº±ng hÃ m máº¥t mÃ¡t BC vÆ°á»£t trá»™i hÆ¡n cÃ¡c hÃ m máº¥t mÃ¡t khÃ¡c. LÆ°u Ã½ ráº±ng thÃ´ng thÆ°á»ng
thuáº­t toÃ¡n BC khÃ´ng phá»¥ thuá»™c vÃ o pháº§n thÆ°á»Ÿng, nhÆ°ng trong ReST, pháº§n thÆ°á»Ÿng Ä‘Æ°á»£c tÃ­nh Ä‘áº¿n thÃ´ng qua
giai Ä‘oáº¡n lá»c pháº§n thÆ°á»Ÿng cho ğ¼â‰¥1 (vá»›i ğœ1=0.8 cho WMT 2020.) Káº¿t quáº£ vá»›i nhiá»u bÆ°á»›c Grow vÃ 
Improve Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 4 (xem thÃªm Phá»¥ lá»¥c A.6).

â´Náº¿u chÃºng tÃ´i sá»­ dá»¥ng Ã­t hÆ¡n 6 bÆ°á»›c, chÃºng tÃ´i bá» qua cÃ¡c ngÆ°á»¡ng nhá» hÆ¡n ban Ä‘áº§u. Chi tiáº¿t Ä‘Æ°á»£c Ä‘Æ°a ra trong Phá»¥ lá»¥c A.3. ChÃºng tÃ´i Ä‘áº£m báº£o
ráº±ng trong táº¥t cáº£ cÃ¡c táº­p dá»¯ liá»‡u cá»§a chÃºng tÃ´i ğœ1>0.7â‰¥ğ‘‰ğœ‹ğœƒ báº±ng cÃ¡ch Ä‘o lÆ°á»ng thá»±c nghiá»‡m ğ‘‰ğœ‹ğœƒ trÃªn táº­p dá»¯ liá»‡u.

--- TRANG 8 ---
Tá»± Huáº¥n Luyá»‡n TÄƒng CÆ°á»ng (ReST) cho MÃ´ HÃ¬nh NgÃ´n Ngá»¯

Thuáº­t toÃ¡n | Pháº§n thÆ°á»Ÿng Trung bÃ¬nh | Máº«u KhÃ¡c biá»‡t
BC(G=0, I=0) | 70.9 | 16 000 000
ReST(G=1, I=0) | 71.9 | 16 000 000
ReST(G=1, I=4) | 77.8 | 16 000 000
ReST(G=2, I=3) | 83.1 | 32 000 000
Online RL | 71.6 | 24 000 000

Báº£ng 1|Online RL cho IWSLT 2014: Online RL hoáº¡t Ä‘á»™ng tá»‘t nhÆ° ReST(G=1, I=0) vÃ  ReST
(G=1, I=4) tá»‘t hÆ¡n Ä‘Ã¡ng ká»ƒ.

Liá»‡u ReST cÃ³ thá»ƒ Ä‘Æ°á»£c cáº£i thiá»‡n thÃªm vá»›i láº¥y máº«u Best-of-N táº¡i thá»i Ä‘iá»ƒm suy luáº­n khÃ´ng? Ká»¹ thuáº­t láº¥y máº«u Best-of-N
táº¡i thá»i Ä‘iá»ƒm suy luáº­n táº¡o ra ğ‘ máº«u sau Ä‘Ã³ Ä‘Æ°á»£c xáº¿p háº¡ng bá»Ÿi mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng. Sau Ä‘Ã³,
á»©ng viÃªn Ä‘Æ°á»£c xáº¿p háº¡ng cao nháº¥t Ä‘Æ°á»£c chá»n (Gao et al., 2022). ChÃºng tÃ´i hiá»ƒn thá»‹ káº¿t quáº£ vá»›i láº¥y máº«u Best-of-N
trÃªn BC(G=0 I=0) vÃ  cÃ¡c biáº¿n thá»ƒ ReST trong HÃ¬nh 6. Hiá»‡u suáº¥t cá»§a ReST cáº£i thiá»‡n cáº£
vá»›i ğ‘ vÃ  vá»›i sá»‘ bÆ°á»›c Improve. Biáº¿n thá»ƒ ReST tá»‘t nháº¥t vá»›i ğ‘ < 10 khá»›p vá»›i
hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh BC vá»›i ğ‘=200. Máº·c dÃ¹ RL Ä‘Æ°á»£c biáº¿t lÃ  háº¡n cháº¿ sá»± Ä‘a dáº¡ng cá»§a cÃ¡c máº«u,
thÃ­ nghiá»‡m nÃ y cho tháº¥y ReST váº«n cÃ³ thá»ƒ hÆ°á»Ÿng lá»£i tá»« láº¥y máº«u Best-of-N. Sau ba bÆ°á»›c Improve
vá»›i ğ‘=200, ReST Ä‘áº¡t pháº§n thÆ°á»Ÿng cao nháº¥t cÃ³ thá»ƒ lÃ  1, vÆ°á»£t trá»™i hÆ¡n cÃ¡c báº£n dá»‹ch "tham chiáº¿u"
trong D.

HÃ¬nh 6|Láº¥y máº«u Best-of-N táº¡i thá»i Ä‘iá»ƒm suy
luáº­n. Táº¥t cáº£ biáº¿n thá»ƒ cá»§a ReST hÆ°á»Ÿng lá»£i
nhiá»u tá»« láº¥y máº«u Best-of-N nhÆ° cÃ¡c mÃ´ hÃ¬nh
cÃ³ giÃ¡m sÃ¡t.

ReST so sÃ¡nh nhÆ° tháº¿ nÃ o vá»›i Online RL? ChÃºng tÃ´i so sÃ¡nh
ReST vá»›i PPO (Schulman et al., 2017), má»™t thuáº­t toÃ¡n RL trá»±c tuyáº¿n
Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i cho RLHF (Glaese et al., 2022;
Ouyang et al., 2022a). Äá»‘i vá»›i cÃ¡c thÃ­ nghiá»‡m RL trá»±c tuyáº¿n cá»§a chÃºng tÃ´i,
chÃºng tÃ´i sá»­ dá»¥ng thiáº¿t láº­p cá»§a Donato et al. (2022) nÆ¡i PPO
cÃ³ quyá»n truy cáº­p vÃ o lÆ°á»£ng dá»¯ liá»‡u huáº¥n luyá»‡n tÆ°Æ¡ng tá»± nhÆ° ReST
vá»›i 1 bÆ°á»›c Grow. Káº¿t quáº£ Ä‘Æ°á»£c tÃ³m táº¯t trong Báº£ng
1. Online RL hoáº¡t Ä‘á»™ng tá»‘t nhÆ° ReST vá»›i má»™t Grow vÃ 
khÃ´ng cÃ³ bÆ°á»›c Improve nÃ o tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i BC trÃªn táº­p dá»¯ liá»‡u
Dğ‘”. Vá»›i cÃ¹ng lÆ°á»£ng dá»¯ liá»‡u huáº¥n luyá»‡n, ReST
vá»›i nhiá»u bÆ°á»›c Improve Ä‘áº¡t pháº§n thÆ°á»Ÿng cao hÆ¡n Ä‘Ã¡ng ká»ƒ.
HÆ¡n ná»¯a, chÃºng tÃ´i nháº­n tháº¥y ráº±ng Ä‘iá»ƒm BLEU
cho chÃ­nh sÃ¡ch RL trá»±c tuyáº¿n trÃªn táº­p xÃ¡c thá»±c giáº£m gáº§n
8 Ä‘iá»ƒm (Ä‘iá»ƒm BLEU cá»§a ReST khÃ´ng thay Ä‘á»•i) cho tháº¥y
hÃ nh vi hack pháº§n thÆ°á»Ÿng tiá»m nÄƒng. Kháº£ nÄƒng cá»§a ReST
cáº£i thiá»‡n Ä‘iá»ƒm sá»‘ mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng mÃ  khÃ´ng lÃ m xáº¥u
hiá»‡u suáº¥t trÃªn cÃ¡c chá»‰ sá»‘ khÃ¡c cho tháº¥y ráº±ng
"thuáº¿ cÄƒn chá»‰nh" mÃ  nÃ³ tráº£ tháº¥p hÆ¡n so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p RL trá»±c tuyáº¿n.

Liá»‡u ReST cÃ³ cáº£i thiá»‡n sá»Ÿ thÃ­ch cá»§a con ngÆ°á»i khÃ´ng? ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh ReST báº±ng ngÆ°á»i Ä‘Ã¡nh giÃ¡ con ngÆ°á»i Ä‘á»ƒ
Ä‘iá»u tra xem ReST cÃ³ thá»ƒ vÆ°á»£t trá»™i hÆ¡n BC trong Ä‘Ã¡nh giÃ¡ con ngÆ°á»i hay khÃ´ng. ChÃºng tÃ´i hiá»ƒn thá»‹ má»™t cÃ¢u trong
ngÃ´n ngá»¯ nguá»“n vÃ  hai báº£n dá»‹ch Ä‘Æ°á»£c táº¡o: má»™t bá»Ÿi mÃ´ hÃ¬nh BC (G=0 I=0) vÃ  má»™t bá»Ÿi má»™t
biáº¿n thá»ƒ ReST. NgÆ°á»i Ä‘Ã¡nh giÃ¡ con ngÆ°á»i cháº¥m Ä‘iá»ƒm má»—i báº£n dá»‹ch trÃªn thang Ä‘iá»ƒm tá»« 0 Ä‘áº¿n 6, vÃ  chÃºng tÃ´i Ä‘o
sá»± khÃ¡c biá»‡t giá»¯a Ä‘iá»ƒm sá»‘ trung bÃ¬nh cá»§a phÆ°Æ¡ng phÃ¡p ReST vÃ  cá»§a BC mÃ  chÃºng tÃ´i gá»i lÃ  "Human eval
diff". Trong HÃ¬nh 7 (pháº£i), chÃºng tÃ´i tháº¥y ráº±ng táº¥t cáº£ biáº¿n thá»ƒ cá»§a ReST vÆ°á»£t trá»™i hÆ¡n baseline BC má»™t cÃ¡ch Ä‘Ã¡ng ká»ƒ.
Tuy nhiÃªn, náº¿u chÃºng tÃ´i so sÃ¡nh viá»‡c tÄƒng Ä‘iá»ƒm sá»‘ con ngÆ°á»i vá»›i viá»‡c tÄƒng pháº§n thÆ°á»Ÿng Ä‘Ã£ há»c (HÃ¬nh 7, trÃ¡i),
cÃ¡c xáº¿p háº¡ng khÃ´ng khá»›p. ChÃºng tÃ´i giáº£ thuyáº¿t ráº±ng sá»± khÃ¡c biá»‡t lÃ  do thá»±c táº¿ ráº±ng cÃ¡c mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng

--- TRANG 9 ---
Tá»± Huáº¥n Luyá»‡n TÄƒng CÆ°á»ng (ReST) cho MÃ´ HÃ¬nh NgÃ´n Ngá»¯

khÃ´ng thá»ƒ tá»•ng quÃ¡t hÃ³a tá»‘t trÃªn dá»¯ liá»‡u OOD vÃ¬ cÃ¡c mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng Ä‘Ã£ há»c chá»‰ lÃ  má»™t proxy khÃ´ng hoÃ n háº£o
cá»§a sá»Ÿ thÃ­ch con ngÆ°á»i. Äáº·c biá»‡t, chÃºng tÃ´i tháº¥y ráº±ng cÃ¡c mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng tá»•ng quÃ¡t hÃ³a tá»‡ hÆ¡n khi chÃ­nh sÃ¡ch cá»§a chÃºng ta
di chuyá»ƒn ra khá»i mÃ´ hÃ¬nh hÃ nh vi cÃ³ thá»ƒ xáº£y ra khi sá»‘ bÆ°á»›c Grow vÃ  Improve tÄƒng lÃªn táº¡i thá»i Ä‘iá»ƒm
ReST cÃ³ thá»ƒ báº¯t Ä‘áº§u overfit vá»›i mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng. Do Ä‘Ã³, trong phÃ¢n tÃ­ch cá»§a chÃºng tÃ´i, chÃºng tÃ´i
táº­p trung vÃ o viá»‡c Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh dá»±a trÃªn má»©c Ä‘á»™ há» cÄƒn chá»‰nh vá»›i tÃ­n hiá»‡u pháº§n thÆ°á»Ÿng vÃ  chÃºng tÃ´i coi
viá»‡c tá»•ng quÃ¡t hÃ³a mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng nhÆ° má»™t váº¥n Ä‘á» Ä‘á»™c láº­p cÃ³ thá»ƒ Ä‘Æ°á»£c giáº£m thiá»ƒu báº±ng cÃ¡ch, vÃ­ dá»¥, tinh chá»‰nh
mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng giá»¯a cÃ¡c bÆ°á»›c Grow liÃªn tiáº¿p trÃªn dá»¯ liá»‡u Ä‘Æ°á»£c chÃº thÃ­ch bá»Ÿi con ngÆ°á»i tá»« chÃ­nh sÃ¡ch
gáº§n Ä‘Ã¢y nháº¥t. ReST vá»›i hÃ m máº¥t mÃ¡t B-VMPO sá»­ dá»¥ng má»™t hÃ m giÃ¡ trá»‹ Ä‘Ã£ há»c vÃ  sá»‘ háº¡ng regularization KL
Ä‘á»ƒ ngÄƒn cháº·n over-fitting vÃ  do Ä‘Ã³ Ä‘áº¡t Ä‘iá»ƒm sá»Ÿ thÃ­ch con ngÆ°á»i cao.

HÃ¬nh 7|So sÃ¡nh hiá»‡u suáº¥t dá»±a trÃªn pháº§n thÆ°á»Ÿng Ä‘Ã£ há»c vÃ  Ä‘Ã¡nh giÃ¡ con ngÆ°á»i. Táº¥t cáº£
biáº¿n thá»ƒ ReST vÆ°á»£t trá»™i hÆ¡n BC vá» xáº¿p háº¡ng con ngÆ°á»i, nhÆ°ng viá»‡c xáº¿p háº¡ng cÃ¡c phÆ°Æ¡ng phÃ¡p dá»±a trÃªn
Ä‘iá»ƒm sá»‘ mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng vÃ  Ä‘iá»ƒm sá»‘ con ngÆ°á»i lÃ  khÃ¡c nhau.

5. CÃ¡c cÃ´ng trÃ¬nh liÃªn quan

HÃ¬nh 8|ReST vs cÃ¡c phÆ°Æ¡ng phÃ¡p thay tháº¿: ReST lÃ 
phÆ°Æ¡ng phÃ¡p duy nháº¥t cÃ³ thá»ƒ táº­n dá»¥ng dá»¯ liá»‡u khÃ¡m phÃ¡
vÃ  pháº§n thÆ°á»Ÿng, nhÆ°ng cÅ©ng hiá»‡u quáº£ vá» máº·t tÃ­nh toÃ¡n.

Gáº§n Ä‘Ã¢y Ä‘Ã£ cÃ³ má»™t sá»‘ lÆ°á»£ng lá»›n cÃ¡c cÃ´ng trÃ¬nh vá»
cÃ¡c thuáº­t toÃ¡n cÄƒn chá»‰nh tá»± cáº£i thiá»‡n cho mÃ´ hÃ¬nh
ngÃ´n ngá»¯. Trong HÃ¬nh 8, chÃºng tÃ´i cÅ©ng so sÃ¡nh
ReST vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c nhau: há»c cÃ³ giÃ¡m sÃ¡t,
self-training, RL trá»±c tuyáº¿n vÃ  ngoáº¡i tuyáº¿n.
ChÃºng tÃ´i káº¿t luáº­n tá»« so sÃ¡nh nÃ y ráº±ng ReST lÃ 
phÆ°Æ¡ng phÃ¡p duy nháº¥t hiá»‡u quáº£ vá» tÃ­nh toÃ¡n, nhÆ°ng
cÅ©ng cÃ³ thá»ƒ táº­n dá»¥ng dá»¯ liá»‡u khÃ¡m phÃ¡ vÃ  pháº§n thÆ°á»Ÿng.
Tiáº¿p theo, chÃºng tÃ´i mÃ´ táº£ má»™t sá»‘ cÃ´ng trÃ¬nh cá»¥ thá»ƒ
liÃªn quan Ä‘áº¿n ReST.

Self-training. Self-training lÃ  má»™t phÆ°Æ¡ng phÃ¡p há»c bÃ¡n giÃ¡m sÃ¡t Ä‘Ã£ Ä‘Æ°á»£c thiáº¿t láº­p sá»­ dá»¥ng dá»¯ liá»‡u
khÃ´ng Ä‘Æ°á»£c gÃ¡n nhÃ£n Ä‘á»ƒ cáº£i thiá»‡n má»™t mÃ´ hÃ¬nh (Scudder, 1965). Ká»ƒ tá»« khi Ä‘Æ°á»£c giá»›i thiá»‡u, self-training Ä‘Ã£ Ä‘Æ°á»£c
Ã¡p dá»¥ng thÃ nh cÃ´ng cho nhiá»u tÃ¡c vá»¥, bao gá»“m phÃ¢n loáº¡i vÃ  nháº­n dáº¡ng hÃ¬nh áº£nh (Xie et al., 2020),
gáº¥p náº¿p protein (Jumper et al., 2021), cÅ©ng nhÆ° má»™t sá»‘ tÃ¡c vá»¥ ngÃ´n ngá»¯ (He et al., 2019; Sun et al.,
2021; Yarowsky, 1995; Zhang and Zong, 2016). He et al. (2019) Ä‘Ã£ chá»©ng minh thá»±c nghiá»‡m ráº±ng
self-training cÃ³ nhiá»…u cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh dá»‹ch thuáº­t. BÆ°á»›c Improve cá»§a ReST giá»‘ng
self-training. Sá»± khÃ¡c biá»‡t chÃ­nh cá»§a ReST so vá»›i self-training lÃ  bÆ°á»›c Grow cá»§a ReST táº¡o ra
dá»¯ liá»‡u khÃ¡m phÃ¡ tá»•ng há»£p Ä‘á»ƒ huáº¥n luyá»‡n vá»›i RL.

--- TRANG 10 ---
Tá»± Huáº¥n Luyá»‡n TÄƒng CÆ°á»ng (ReST) cho MÃ´ HÃ¬nh NgÃ´n Ngá»¯

Expert Iteration (EI). Anthony (2021) Ä‘á» xuáº¥t má»™t khung RL lÃ  má»™t dáº¡ng phÆ°Æ¡ng phÃ¡p policy iteration
sá»­ dá»¥ng cÆ¡ cháº¿ láº­p káº¿ hoáº¡ch. EI phÃ¢n tÃ¡ch rÃµ rÃ ng váº¥n Ä‘á» RL thÃ nh hai pháº§n: láº­p káº¿ hoáº¡ch vÃ  tá»•ng quÃ¡t hÃ³a.
TÆ°Æ¡ng tá»± nhÆ° ReST, EI sá»­ dá»¥ng chÃ­nh sÃ¡ch Ä‘á»ƒ táº¡o dá»¯ liá»‡u vÃ  khai thÃ¡c nÃ³ Ä‘á»ƒ há»c má»™t chÃ­nh sÃ¡ch vá»›i RL. KhÃ´ng giá»‘ng EI,
ReST khÃ´ng yÃªu cáº§u báº¥t ká»³ cÆ¡ cháº¿ láº­p káº¿ hoáº¡ch nÃ o vÃ  nÃ³ sá»­ dá»¥ng cÃ¡c bÆ°á»›c Improve láº·p Ä‘i láº·p láº¡i cho phÃ©p nÃ³
táº­n dá»¥ng dá»¯ liá»‡u thu tháº­p Ä‘Æ°á»£c hiá»‡u quáº£ hÆ¡n.

LÃ½ luáº­n vá»›i mÃ´ hÃ¬nh ngÃ´n ngá»¯. PhÆ°Æ¡ng phÃ¡p EI Ä‘Ã£ truyá»n cáº£m há»©ng cho má»™t sá»‘ phÆ°Æ¡ng phÃ¡p liÃªn quan (Uesato
et al., 2022; Zelikman et al., 2022). Zelikman et al. (2022) Ä‘á» xuáº¥t má»™t ká»¹ thuáº­t gá»i lÃ  STAR
láº·p Ä‘i láº·p láº¡i táº­n dá»¥ng má»™t sá»‘ lÆ°á»£ng nhá» lÃ½ láº½ Ä‘á»ƒ tinh chá»‰nh mÃ´ hÃ¬nh. Sau Ä‘Ã³, há» láº¥y máº«u lÃ½ láº½
vá»›i cÃ¡c cÃ¢u tráº£ lá»i tá»« mÃ´ hÃ¬nh vÃ  lá»c cÃ¡c cÃ¢u tráº£ lá»i Ä‘Æ°á»£c táº¡o theo tÃ­nh Ä‘Ãºng Ä‘áº¯n cá»§a chÃºng. Uesato et al.
(2022) Ä‘á» xuáº¥t má»™t phÆ°Æ¡ng phÃ¡p tÆ°Æ¡ng tá»± há»c giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n toÃ¡n há»c sá»­ dá»¥ng mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng Ä‘Ã£ há»c.
Gáº§n Ä‘Ã¢y, Jung et al. (2023) Ä‘á» xuáº¥t má»™t phÆ°Æ¡ng phÃ¡p gá»i lÃ  "Impossible Distillation" tÆ°Æ¡ng tá»± nhÆ° cá»§a chÃºng tÃ´i,
táº¡o ra táº­p dá»¯ liá»‡u cho cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n báº±ng cÃ¡ch láº¥y máº«u tá»« má»™t mÃ´ hÃ¬nh khÃ´ng tá»‘i Æ°u vÃ  lá»c
cÃ¡c vÃ­ dá»¥ cháº¥t lÆ°á»£ng tháº¥p vá»›i cÆ¡ cháº¿ lá»c. PhÆ°Æ¡ng phÃ¡p nÃ y tÆ°Æ¡ng á»©ng vá»›i ReST vá»›i má»™t bÆ°á»›c Grow vÃ  Improve duy nháº¥t.
TrÃ¡i ngÆ°á»£c vá»›i nhá»¯ng phÆ°Æ¡ng phÃ¡p nÃ y, ReST cÃ³ thá»ƒ Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i báº¥t ká»³ hÃ m máº¥t mÃ¡t RL ngoáº¡i tuyáº¿n nÃ o,
cÃ³ hoáº·c khÃ´ng cÃ³ láº­p káº¿ hoáº¡ch vÃ  cÃ¡c cÆ¡ cháº¿ lá»c khÃ¡c nhau. NÃ³ cÅ©ng cÃ³ thá»ƒ xá»­ lÃ½ Ä‘iá»ƒm pháº§n thÆ°á»Ÿng cÃ³ giÃ¡ trá»‹ liÃªn tá»¥c.
HÆ¡n ná»¯a, ReST cÃ³ thá»ƒ thá»±c hiá»‡n cáº£i thiá»‡n chÃ­nh sÃ¡ch láº·p Ä‘i láº·p láº¡i trÃªn má»™t táº­p dá»¯ liá»‡u cá»‘ Ä‘á»‹nh vá»›i
cÃ¡c bÆ°á»›c Improve.

Iterated Learning (IL). IL lÃ  quÃ¡ trÃ¬nh mÃ  má»™t agent há»c hÃ nh vi cá»§a mÃ¬nh báº±ng cÃ¡ch tiáº¿p xÃºc vá»›i
hÃ nh vi cá»§a agent khÃ¡c, báº£n thÃ¢n nÃ³ Ä‘Ã£ há»c theo cÃ¡ch tÆ°Æ¡ng tá»± (Kirby et al., 2014). Gáº§n Ä‘Ã¢y, phÆ°Æ¡ng phÃ¡p nÃ y
Ä‘Æ°á»£c Ã¡p dá»¥ng cho há»c ngÃ´n ngá»¯ tÆ°Æ¡ng tÃ¡c sá»­ dá»¥ng deep learning (Lu et al., 2020a,b). IL
khÃ¡c vá»›i ReST vÃ¬ nÃ³ hoáº¡t Ä‘á»™ng trong mÃ´i trÆ°á»ng Ä‘a agent vÃ  khÃ´ng sá»­ dá»¥ng RL.

Self Imitation Learning (SIL). SIL há»c má»™t chÃ­nh sÃ¡ch cho má»™t thuáº­t toÃ¡n actor-critic off-policy nÆ¡i
chÃ­nh sÃ¡ch cá»‘ gáº¯ng tÃ¡i táº¡o hÃ nh vi tá»‘t Ä‘Æ°á»£c thá»ƒ hiá»‡n bá»Ÿi agent (Oh et al., 2018). SIL
Ä‘áº¡t Ä‘Æ°á»£c Ä‘iá»u nÃ y báº±ng cÃ¡ch lá»c ra cÃ¡c quá»¹ Ä‘áº¡o khÃ´ng thÃ nh cÃ´ng tá»« replay buffer vÃ  huáº¥n luyá»‡n agent
chá»‰ trÃªn cÃ¡c quá»¹ Ä‘áº¡o cÃ³ pháº§n thÆ°á»Ÿng cao. Theo nghÄ©a Ä‘Ã³, ReST cÃ³ thá»ƒ Ä‘Æ°á»£c coi lÃ  cÃ³ liÃªn quan cháº·t cháº½
Ä‘áº¿n cÃ¡c phÆ°Æ¡ng phÃ¡p dá»±a trÃªn SIL. Sá»± khÃ¡c biá»‡t chÃ­nh lÃ  ReST khÃ´ng phá»¥ thuá»™c vÃ o thuáº­t toÃ¡n RL cÆ¡ báº£n
Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ huáº¥n luyá»‡n chÃ­nh sÃ¡ch vÃ , khÃ´ng giá»‘ng SIL, khÃ´ng cáº§n thiáº¿t má»™t hÃ m giÃ¡ trá»‹ Ä‘á»ƒ lá»c ra
cÃ¡c quá»¹ Ä‘áº¡o khÃ´ng thÃ nh cÃ´ng. NgoÃ i ra, ReST Ä‘Æ°á»£c Ã¡p dá»¥ng cho cÃ¡c thiáº¿t láº­p AI sinh, khÃ´ng yÃªu cáº§u
tÆ°Æ¡ng tÃ¡c vá»›i mÃ´i trÆ°á»ng theo cÃ¡ch trá»±c tuyáº¿n.

Reward ranked Fine-Tuning (RAFT). Äá»“ng thá»i vá»›i cÃ´ng trÃ¬nh cá»§a chÃºng tÃ´i, Dong et al. (2023) Ä‘á» xuáº¥t RAFT.
RAFT cÃ³ thá»ƒ Ä‘Æ°á»£c hiá»ƒu nhÆ° má»™t trÆ°á»ng há»£p cá»¥ thá»ƒ cá»§a ReST chá»‰ sá»­ dá»¥ng má»™t bÆ°á»›c Improve cho má»—i
bÆ°á»›c Grow, vÃ  dá»±a vÃ o má»™t ngÆ°á»¡ng lá»c lÃ  má»™t phÃ¢n vá»‹ cá»‘ Ä‘á»‹nh cá»§a phÃ¢n phá»‘i thá»±c nghiá»‡m
cá»§a pháº§n thÆ°á»Ÿng cá»§a cÃ¡c máº«u hiá»‡n táº¡i. CÃ¡c tÃ¡c giáº£ bÃ¡o cÃ¡o cáº£i thiá»‡n so vá»›i BC vÃ  PPO trÃªn
nhiá»u tÃ¡c vá»¥ mÃ´ hÃ¬nh ngÃ´n ngá»¯ vÃ  táº¡o hÃ¬nh áº£nh. CÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i vá»›i ReST cho tháº¥y
ráº±ng nhiá»u bÆ°á»›c Improve vá»›i ngÆ°á»¡ng lá»c tÄƒng dáº§n cho má»™t bÆ°á»›c Grow dáº«n Ä‘áº¿n
cáº£i thiá»‡n hiá»‡u suáº¥t thÃªm.

6. Tháº£o luáº­n

Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i Ä‘á» xuáº¥t má»™t thuáº­t toÃ¡n gá»i lÃ  ReST Ä‘Æ¡n giáº£n, cÃ³ tá»‘i thiá»ƒu siÃªu tham sá»‘
Ä‘á»ƒ Ä‘iá»u chá»‰nh, vÃ  linh hoáº¡t Ä‘á»ƒ lÃ m viá»‡c vá»›i nhiá»u thiáº¿t káº¿ cá»§a cÃ¡c bÆ°á»›c Grow vÃ  Improve. ChÃºng tÃ´i nghiÃªn cá»©u
hiá»‡u suáº¥t cá»§a ReST trong dá»‹ch mÃ¡y vÃ¬ cÃ¡c mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng máº¡nh máº½ vÃ  Ä‘Ã£ Ä‘Æ°á»£c thiáº¿t láº­p cÃ³ sáºµn cho

--- TRANG 11 ---
Tá»± Huáº¥n Luyá»‡n TÄƒng CÆ°á»ng (ReST) cho MÃ´ HÃ¬nh NgÃ´n Ngá»¯

tÃ¡c vá»¥ nÃ y. ChÃºng tÃ´i thÃ­ nghiá»‡m vá»›i cÃ¡c hÃ m máº¥t mÃ¡t RL ngoáº¡i tuyáº¿n khÃ¡c nhau trong vÃ²ng láº·p ReST, nhÆ°ng tháº¥y BC hoáº¡t Ä‘á»™ng
tá»‘t nháº¥t Ä‘á»ƒ cáº£i thiá»‡n Ä‘iá»ƒm sá»‘ mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng. Nhiá»u bÆ°á»›c huáº¥n luyá»‡n NLL vá»›i cÃ¡c ngÆ°á»¡ng lá»c
tÄƒng dáº§n trong bÆ°á»›c Improve dáº«n Ä‘áº¿n cáº£i thiá»‡n liÃªn tá»¥c trong pháº§n thÆ°á»Ÿng cá»§a mÃ´ hÃ¬nh trÃªn táº­p holdout.
Tuy nhiÃªn, cáº£i thiá»‡n trong Ä‘iá»ƒm sá»‘ mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng khÃ´ng nháº¥t thiáº¿t pháº£n Ã¡nh sá»Ÿ thÃ­ch cá»§a con ngÆ°á»i vÃ¬ mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng
chá»‰ lÃ  má»™t proxy cho sá»Ÿ thÃ­ch cá»§a con ngÆ°á»i. Káº¿t quáº£ chá»‰ ra ráº±ng má»™t bÆ°á»›c Grow lÃ  lá»±a chá»n tá»‘t nháº¥t khi xem xÃ©t
Ä‘iá»ƒm Ä‘Ã¡nh giÃ¡ con ngÆ°á»i, máº·c dÃ¹ pháº§n thÆ°á»Ÿng tiáº¿p tá»¥c tÄƒng vá»›i nhiá»u bÆ°á»›c Grow hÆ¡n. Äá»ƒ kháº¯c phá»¥c háº¡n cháº¿ nÃ y,
cÃ¡c mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng cÃ³ thá»ƒ Ä‘Æ°á»£c tinh chá»‰nh trÃªn táº­p con Dğ‘” Ä‘Æ°á»£c chÃº thÃ­ch vá»›i sá»Ÿ thÃ­ch cá»§a con ngÆ°á»i tÆ°Æ¡ng tá»± nhÆ° Bai et al. (2022) vÃ 
Glaese et al. (2022), mÃ  chÃºng tÃ´i Ä‘á»ƒ láº¡i nhÆ° cÃ´ng viá»‡c tÆ°Æ¡ng lai. HÃ£y Ä‘á»ƒ chÃºng tÃ´i lÆ°u Ã½ ráº±ng nguy cÆ¡ overfitting vá»›i
mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng tÄƒng lÃªn vá»›i cÃ¡c láº§n láº·p láº¡i cá»§a cÃ¡c bÆ°á»›c Grow; do Ä‘Ã³ chÃºng tÃ´i tin ráº±ng viá»‡c giáº£i quyáº¿t
váº¥n Ä‘á» nÃ y lÃ  cáº§n thiáº¿t, Ä‘áº·c biá»‡t trong cÃ¡c trÆ°á»ng há»£p cáº§n nhiá»u bÆ°á»›c Grow Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh.

NhÆ° chÃºng ta Ä‘Ã£ tháº¥y, hÃ m máº¥t mÃ¡t BC Ä‘Æ¡n giáº£n váº«n vÆ°á»£t trá»™i hÆ¡n nhiá»u hÃ m máº¥t mÃ¡t RL ngoáº¡i tuyáº¿n vá» viá»‡c cÄƒn chá»‰nh
mÃ´ hÃ¬nh vá»›i Ä‘iá»ƒm sá»‘ mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng. Tuy nhiÃªn, chÃºng tÃ´i tháº¥y ráº±ng BC cÃ³ thá»ƒ overfit vá»›i mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng
vÃ¬ váº­y chÃºng tÃ´i giáº£i thÃ­ch Ä‘iá»u nÃ y báº±ng thá»±c táº¿ ráº±ng viá»‡c há»c hÃ m giÃ¡ trá»‹ trong RL lÃ  thÃ¡ch thá»©c do pháº§n thÆ°á»Ÿng thÆ°a thá»›t,
cÃ¡c váº¥n Ä‘á» gÃ¡n tÃ­n dá»¥ng, Ä‘á»™ nháº¡y cáº£m vá»›i siÃªu tham sá»‘, vÃ  khÃ¡m phÃ¡ háº¡n cháº¿ trong bÆ°á»›c Grow.
ReST cÃ³ thá»ƒ hÆ°á»Ÿng lá»£i tá»« cÃ¡c chiáº¿n lÆ°á»£c khÃ¡m phÃ¡ RL tá»‘t hÆ¡n á»Ÿ bÆ°á»›c Grow, nhÆ° MCTS (Leblond
et al., 2021). Kháº£ nÄƒng khai thÃ¡c dá»¯ liá»‡u Ä‘Æ°á»£c táº¡o trong bÆ°á»›c Grow cÃ³ thá»ƒ dáº«n Ä‘áº¿n khÃ¡m phÃ¡ rá»™ng hÆ¡n
cá»§a khÃ´ng gian state-action vÃ  tá»•ng quÃ¡t hÃ³a tá»‘t hÆ¡n. NgoÃ i ra, tÃ­nh cháº¥t xÃ¡c Ä‘á»‹nh cá»§a mÃ´i trÆ°á»ng
khÃ´ng cho phÃ©p thu Ä‘Æ°á»£c lá»£i Ã­ch lá»›n so vá»›i BC cho cÃ¡c hÃ m máº¥t mÃ¡t RL ngoáº¡i tuyáº¿n.

Äá»ƒ káº¿t luáº­n, ReST lÃ  má»™t phÆ°Æ¡ng phÃ¡p tá»•ng quÃ¡t vÃ  hiá»‡u quáº£. NÃ³ cÃ³ thá»ƒ Ä‘Æ°á»£c Ã¡p dá»¥ng khi 1) má»™t mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng máº¡nh máº½
cá»§a sá»Ÿ thÃ­ch con ngÆ°á»i cÃ³ sáºµn vÃ  2) chÃºng ta cÃ³ thá»ƒ táº¡o ra cÃ¡c máº«u tá»« mÃ´ hÃ¬nh á»Ÿ quy mÃ´ lá»›n. Do Ä‘Ã³, nÃ³ cÃ³ thá»ƒ
Ä‘Æ°á»£c Ã¡p dá»¥ng cho nhiá»u tÃ¡c vá»¥ trong lÄ©nh vá»±c ngÃ´n ngá»¯, nhÆ° tÃ³m táº¯t, Ä‘á»‘i thoáº¡i theo lÆ°á»£t, vÃ  cÃ¡c mÃ´ hÃ¬nh
Ã¢m thanh vÃ  video sinh khÃ¡c. Vá»›i má»™t sá»‘ hÆ°á»›ng khÃ¡m phÃ¡ vÃ  á»©ng dá»¥ng trong tÆ°Æ¡ng lai, chÃºng tÃ´i tin ráº±ng
ReST lÃ  má»™t phÆ°Æ¡ng phÃ¡p RL lÃ´ tÄƒng trÆ°á»Ÿng há»¯u Ã­ch cho RLHF.

Lá»i cáº£m Æ¡n. ChÃºng tÃ´i muá»‘n cáº£m Æ¡n cÃ¡c thÃ nh viÃªn tá»« cÃ¡c nhÃ³m dá»‹ch mÃ¡y táº¡i
Google vÃ  Google DeepMind cho Ä‘áº§u vÃ o cá»§a há» vÃ o dá»± Ã¡n trong cÃ¡c giai Ä‘oáº¡n brainstorming vÃ 
Ä‘á»ƒ thiáº¿t láº­p codebase mÃ  dá»± Ã¡n nÃ y Ä‘Æ°á»£c phÃ¡t triá»ƒn dá»±a trÃªn (Yu et al., 2020). ChÃºng tÃ´i muá»‘n
cáº£m Æ¡n Matt Hoffman, Bobak Shahriari, Taylan Cemgil vÃ  Chris Dyer cho cÃ¡c cuá»™c tháº£o luáº­n vá» dá»± Ã¡n nÃ y.
ChÃºng tÃ´i biáº¿t Æ¡n pháº£n há»“i Ä‘Æ°á»£c cung cáº¥p bá»Ÿi Bilal Piot cho báº£n tháº£o sá»›m cá»§a bÃ i bÃ¡o nÃ y. ChÃºng tÃ´i
cÅ©ng muá»‘n cáº£m Æ¡n nhá»¯ng ngÆ°á»i chá»‹u trÃ¡ch nhiá»‡m cho cÃ¡c framework khÃ¡c nhau mÃ  chÃºng tÃ´i Ä‘Ã£ sá»­ dá»¥ng trong
dá»± Ã¡n nhÆ° há»‡ sinh thÃ¡i DeepMind JAX (Babuschkin et al., 2020) vÃ  Launchpad (Yang et al.,
2021).

TÃ i liá»‡u tham kháº£o

A. Abdolmaleki, S. Huang, G. Vezzani, B. Shahriari, J. T. Springenberg, S. Mishra, D. Tirumala,
A. Byravan, K. Bousmalis, A. GyÃ¶rgy, et al. Vá» tá»‘i Æ°u hÃ³a chÃ­nh sÃ¡ch Ä‘a má»¥c tiÃªu nhÆ° má»™t cÃ´ng cá»¥ cho
há»c tÄƒng cÆ°á»ng. arXiv preprint arXiv:2106.08199, 2021.

R. Agarwal, M. Schwarzer, P. S. Castro, A. Courville, vÃ  M. G. Bellemare. VÆ°á»£t ra ngoÃ i tabula rasa:
TÃ¡i sinh há»c tÄƒng cÆ°á»ng. arXiv preprint arXiv:2206.01626, 2022.

T. W. Anthony. Expert iteration. Luáº­n Ã¡n Tiáº¿n sÄ©, UCL (University College London), 2021.

I. Babuschkin, K. Baumli, A. Bell, S. Bhupatiraju, J. Bruce, P. Buchlovsky, D. Budden, T. Cai, A. Clark,
I. Danihelka, C. Fantacci, J. Godwin, C. Jones, R. Hemsley, T. Hennigan, M. Hessel, S. Hou,

--- TRANG 12 ---
Tá»± Huáº¥n Luyá»‡n TÄƒng CÆ°á»ng (ReST) cho MÃ´ HÃ¬nh NgÃ´n Ngá»¯

S. Kapturowski, T. Keck, I. Kemaev, M. King, M. Kunesch, L. Martens, H. Merzic, V. Mikulik,
T. Norman, J. Quan, G. Papamakarios, R. Ring, F. Ruiz, A. Sanchez, R. Schneider, E. Sezener,
S. Spencer, S. Srinivasan, L. Wang, W. Stokowiec, vÃ  F. Viola. Há»‡ sinh thÃ¡i DeepMind JAX,
2020. URL http://github.com/deepmind.

Y. Bai, A. Jones, K. Ndousse, A. Askell, A. Chen, N. DasSarma, D. Drain, S. Fort, D. Ganguli, T. Henighan,
et al. Huáº¥n luyá»‡n má»™t trá»£ lÃ½ há»¯u Ã­ch vÃ  vÃ´ háº¡i vá»›i há»c tÄƒng cÆ°á»ng tá»« pháº£n há»“i cá»§a con ngÆ°á»i.
arXiv preprint arXiv:2204.05862, 2022.

R. Bellman. Má»™t quÃ¡ trÃ¬nh quyáº¿t Ä‘á»‹nh Markovian. Journal of Mathematics and Mechanics, 6(5):679â€“684,
1957.

D. Brandfonbrener, A. Bietti, J. Buckman, R. Laroche, vÃ  J. Bruna. Khi nÃ o há»c cÃ³ giÃ¡m sÃ¡t cÃ³ Ä‘iá»u kiá»‡n tráº£ vá»
hoáº¡t Ä‘á»™ng cho há»c tÄƒng cÆ°á»ng ngoáº¡i tuyáº¿n? Advances in Neural Information
Processing Systems, 35:1542â€“1553, 2022.

T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam,
G. Sastry, A. Askell, et al. MÃ´ hÃ¬nh ngÃ´n ngá»¯ lÃ  nhá»¯ng ngÆ°á»i há»c few-shot. Advances in Neural Information
Processing Systems, 2020.

S. Bubeck, V. Chandrasekaran, R. Eldan, J. Gehrke, E. Horvitz, E. Kamar, P. Lee, Y. T. Lee, Y. Li,
S. Lundberg, et al. Tia lá»­a cá»§a trÃ­ tuá»‡ nhÃ¢n táº¡o tá»•ng quÃ¡t: ThÃ­ nghiá»‡m sá»›m vá»›i GPT-4. arXiv
preprint arXiv:2303.12712, 2023.

M. Cettolo, J. Niehues, S. StÃ¼ker, L. Bentivogli, vÃ  M. Federico. BÃ¡o cÃ¡o vá» chiáº¿n dá»‹ch Ä‘Ã¡nh giÃ¡ iwslt láº§n thá»© 11.
Trong Proceedings of the 11th International Workshop on Spoken Language Translation:
Evaluation Campaign, 2014.

L. Chen, K. Lu, A. Rajeswaran, K. Lee, A. Grover, M. Laskin, P. Abbeel, A. Srinivas, vÃ  I. Mordatch.
Decision transformer: Há»c tÄƒng cÆ°á»ng thÃ´ng qua mÃ´ hÃ¬nh chuá»—i. Trong Advances in Neural
Information Processing Systems, 2021.

S. Clark, J. R. Curran, vÃ  M. Osborne. Bootstrapping pos-taggers sá»­ dá»¥ng dá»¯ liá»‡u khÃ´ng Ä‘Æ°á»£c gÃ¡n nhÃ£n. Trong Proceedings
cá»§a há»™i nghá»‹ thá»© báº£y vá» Natural language learning at HLT-NAACL 2003, trang 49â€“55, 2003.

D. Donato, L. Yu, W. Ling, vÃ  C. Dyer. Mad cho há»c tÄƒng cÆ°á»ng máº¡nh máº½ trong dá»‹ch mÃ¡y.
arXiv preprint arXiv:2207.08583, 2022.

H. Dong, W. Xiong, D. Goyal, R. Pan, S. Diao, J. Zhang, K. Shum, vÃ  T. Zhang. Raft: Tinh chá»‰nh Ä‘Æ°á»£c xáº¿p háº¡ng pháº§n thÆ°á»Ÿng
cho viá»‡c cÄƒn chá»‰nh mÃ´ hÃ¬nh ná»n táº£ng sinh. arXiv preprint arXiv:2304.06767, 2023.

L. Espeholt, H. Soyer, R. Munos, K. Simonyan, V. Mnih, T. Ward, Y. Doron, V. Firoiu, T. Harley,
I. Dunning, S. Legg, vÃ  K. Kavukcuoglu. Impala: Deep-rl phÃ¢n tÃ¡n cÃ³ thá»ƒ má»Ÿ rá»™ng vá»›i kiáº¿n trÃºc
actor-learner cÃ³ trá»ng sá»‘ táº§m quan trá»ng. Trong International Conference on Machine Learning, 2018.

M. Freitag, R. Rei, N. Mathur, C.-k. Lo, C. Stewart, G. Foster, A. Lavie, vÃ  O. Bojar. Káº¿t quáº£ cá»§a
tÃ¡c vá»¥ chia sáº» chá»‰ sá»‘ wmt21: ÄÃ¡nh giÃ¡ chá»‰ sá»‘ vá»›i Ä‘Ã¡nh giÃ¡ con ngÆ°á»i dá»±a trÃªn chuyÃªn gia trÃªn lÄ©nh vá»±c ted vÃ 
tin tá»©c. Trong Proceedings of the Sixth Conference on Machine Translation, trang 733â€“774, 2021.

M. Freitag, R. Rei, N. Mathur, C.-k. Lo, C. Stewart, E. Avramidis, T. Kocmi, G. Foster, A. Lavie, vÃ 
A. F. T. Martins. Káº¿t quáº£ cá»§a tÃ¡c vá»¥ chia sáº» chá»‰ sá»‘ WMT22: Ngá»«ng sá»­ dá»¥ng BLEU â€“ chá»‰ sá»‘ neural tá»‘t hÆ¡n vÃ  máº¡nh máº½ hÆ¡n.
Trong Proceedings of the Seventh Conference on Machine Translation (WMT), trang 46â€“68, Abu Dhabi, United Arab Emirates (Hybrid), Dec. 2022. Association for Computational
Linguistics. URL https://aclanthology.org/2022.wmt-1.2.

--- TRANG 13 ---
Tá»± Huáº¥n Luyá»‡n TÄƒng CÆ°á»ng (ReST) cho MÃ´ HÃ¬nh NgÃ´n Ngá»¯

J. Fu, A. Kumar, O. Nachum, G. Tucker, vÃ  S. Levine. D4RL: Táº­p dá»¯ liá»‡u cho há»c tÄƒng cÆ°á»ng
dá»¯ liá»‡u sÃ¢u. arXiv preprint arXiv:2004.07219, 2020.

L. Gao, J. Schulman, vÃ  J. Hilton. Quy luáº­t má»Ÿ rá»™ng cho tá»‘i Æ°u hÃ³a quÃ¡ má»©c mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng. arXiv preprint
arXiv:2210.10760, 2022.

B. Ghorbani, O. Firat, M. Freitag, A. Bapna, M. Krikun, X. Garcia, C. Chelba, vÃ  C. Cherry. Quy luáº­t má»Ÿ rá»™ng
cho dá»‹ch mÃ¡y neural. arXiv preprint arXiv:2109.07740, 2021.

A. Glaese, N. McAleese, M. TrÄ™bacz, J. Aslanides, V. Firoiu, T. Ewalds, M. Rauh, L. Weidinger,
M. Chadwick, P. Thacker, et al. Cáº£i thiá»‡n viá»‡c cÄƒn chá»‰nh cá»§a cÃ¡c agent Ä‘á»‘i thoáº¡i thÃ´ng qua phÃ¡n xÃ©t
cÃ³ má»¥c tiÃªu cá»§a con ngÆ°á»i. arXiv preprint arXiv:2209.14375, 2022.

C. Gulcehre, S. G. Colmenarejo, Z. Wang, J. Sygnowski, T. Paine, K. Zolna, Y. Chen, M. Hoffman, R. Pascanu, vÃ  N. de Freitas. Æ¯á»›c lÆ°á»£ng giÃ¡ trá»‹ hÃ nh vi Ä‘Æ°á»£c Ä‘iá»u chá»‰nh. arXiv preprint arXiv:2103.09575,
2021.

J. He, J. Gu, J. Shen, vÃ  M. Ranzato. Xem xÃ©t láº¡i self-training cho viá»‡c táº¡o chuá»—i neural. arXiv
preprint arXiv:1909.13788, 2019.

J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. de Las Casas, L. A.
Hendricks, J. Welbl, A. Clark, et al. Má»™t phÃ¢n tÃ­ch thá»±c nghiá»‡m vá» huáº¥n luyá»‡n mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n
tá»‘i Æ°u tÃ­nh toÃ¡n. Trong Advances in Neural Information Processing Systems, 2022.

J. Jumper, R. Evans, A. Pritzel, T. Green, M. Figurnov, O. Ronneberger, K. Tunyasuvunakool, R. Bates,
A. Å½Ã­dek, A. Potapenko, et al. Dá»± Ä‘oÃ¡n cáº¥u trÃºc protein cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao vá»›i alphafold. Nature,
596(7873):583â€“589, 2021.

J. Jung, P. West, L. Jiang, F. Brahman, X. Lu, J. Fisher, T. Sorensen, vÃ  Y. Choi. ChÆ°ng cáº¥t khÃ´ng thá»ƒ:
tá»« mÃ´ hÃ¬nh cháº¥t lÆ°á»£ng tháº¥p Ä‘áº¿n táº­p dá»¯ liá»‡u & mÃ´ hÃ¬nh cháº¥t lÆ°á»£ng cao cho tÃ³m táº¯t vÃ  diá»…n Ä‘áº¡t láº¡i. arXiv
preprint arXiv:2305.16635, 2023.

S. Kirby, T. Griffiths, vÃ  K. Smith. Há»c láº·p Ä‘i láº·p láº¡i vÃ  sá»± tiáº¿n hÃ³a cá»§a ngÃ´n ngá»¯. Current Opinion
in Neurobiology, 28:108â€“114, 2014.

P. Koehn, V. Chaudhary, A. El-Kishky, N. Goyal, P.-J. Chen, vÃ  F. GuzmÃ¡n. PhÃ¡t hiá»‡n cá»§a tÃ¡c vá»¥ chia sáº» wmt 2020
vá» lá»c vÃ  cÄƒn chá»‰nh corpus song song. Trong Proceedings of the Fifth Conference on
Machine Translation, trang 726â€“742, 2020.

T. Kudo. Regularization subword: Cáº£i thiá»‡n mÃ´ hÃ¬nh dá»‹ch máº¡ng neural vá»›i nhiá»u á»©ng viÃªn
subword. Trong Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics,
trang 66â€“75, 2018.

A. Kumar, J. Hong, A. Singh, vÃ  S. Levine. TÃ´i cÃ³ nÃªn cháº¡y há»c tÄƒng cÆ°á»ng ngoáº¡i tuyáº¿n hay behavioral
cloning khÃ´ng? Trong International Conference on Learning Representations, 2021.

S. Lange, T. Gabel, vÃ  M. Riedmiller. Há»c tÄƒng cÆ°á»ng theo lÃ´. Trong M. Wiering vÃ  M. van
Otterlo, editors, Reinforcement Learning: State-of-the-Art, trang 45â€“73. Springer Berlin Heidelberg,
2012.

R. Leblond, J.-B. Alayrac, L. Sifre, M. Pislar, L. Jean-Baptiste, I. Antonoglou, K. Simonyan, vÃ 
O. Vinyals. Giáº£i mÃ£ dá»‹ch mÃ¡y vÆ°á»£t ra ngoÃ i tÃ¬m kiáº¿m beam. Trong Proceedings of the Conference on
Empirical Methods in Natural Language Processing, 2021.

--- TRANG 14 ---
Tá»± Huáº¥n Luyá»‡n TÄƒng CÆ°á»ng (ReST) cho MÃ´ HÃ¬nh NgÃ´n Ngá»¯

Y. Li, D. Choi, J. Chung, N. Kushman, J. Schrittwieser, R. Leblond, T. Eccles, J. Keeling, F. Gimeno,
A. Dal Lago, et al. Táº¡o mÃ£ cáº¥p Ä‘á»™ cáº¡nh tranh vá»›i alphacode. Science, 378(6624):1092â€“
1097, 2022.

Y. Lu, S. Singhal, F. Strub, A. Courville, vÃ  O. Pietquin. Chá»‘ng láº¡i sá»± trÃ´i dáº¡t ngÃ´n ngá»¯ vá»›i há»c láº·p Ä‘i láº·p láº¡i
cÃ³ háº¡t giá»‘ng. Trong International Conference on Machine Learning, 2020a.

Y. Lu, S. Singhal, F. Strub, O. Pietquin, vÃ  A. Courville. Há»c láº·p Ä‘i láº·p láº¡i cÃ³ háº¡t giá»‘ng cÃ³ giÃ¡m sÃ¡t
cho há»c ngÃ´n ngá»¯ tÆ°Æ¡ng tÃ¡c. arXiv preprint arXiv:2010.02975, 2020b.

M. Mathieu, S. Ozair, S. Srinivasan, C. Gulcehre, S. Zhang, R. Jiang, T. Le Paine, K. Zolna, R. Powell,
J. Schrittwieser, et al. Starcraft ii unplugged: Há»c tÄƒng cÆ°á»ng ngoáº¡i tuyáº¿n quy mÃ´ lá»›n. Trong Deep
RL Workshop NeurIPS 2021, 2021.

V. Mnih, A. P. Badia, M. Mirza, A. Graves, T. Harley, T. P. Lillicrap, D. Silver, vÃ  K. Kavukcuoglu.
PhÆ°Æ¡ng phÃ¡p báº¥t Ä‘á»“ng bá»™ cho há»c tÄƒng cÆ°á»ng sÃ¢u. Trong International Conference on Learning
Representations, 2016.

J. Oh, Y. Guo, S. Singh, vÃ  H. Lee. Self-imitation learning. Trong International Conference on Machine
Learning, trang 3878â€“3887. PMLR, 2018.

L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. L. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama,
A. Ray, J. Schulman, J. Hilton, F. Kelton, L. Miller, M. Simens, A. Askell, P. Welinder, P. Christiano,
J. Leike, vÃ  R. Lowe. Huáº¥n luyá»‡n mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘á»ƒ tuÃ¢n theo hÆ°á»›ng dáº«n vá»›i pháº£n há»“i cá»§a con ngÆ°á»i,
2022a.

L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. L. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama,
A. Ray, et al. Huáº¥n luyá»‡n mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘á»ƒ tuÃ¢n theo hÆ°á»›ng dáº«n vá»›i pháº£n há»“i cá»§a con ngÆ°á»i. arXiv preprint
arXiv:2203.02155, 2022b.

R. Y. Pang vÃ  H. He. Táº¡o vÄƒn báº£n báº±ng cÃ¡ch há»c tá»« cÃ¡c cuá»™c trÃ¬nh diá»…n. Trong International Conference
on Learning Representations, 2021.

E. Perez, S. Huang, F. Song, T. Cai, R. Ring, J. Aslanides, A. Glaese, N. McAleese, vÃ  G. Irving. Red
teaming mÃ´ hÃ¬nh ngÃ´n ngá»¯ vá»›i mÃ´ hÃ¬nh ngÃ´n ngá»¯. arXiv preprint arXiv:2202.03286, 2022.

D. A. Pomerleau. ALVINN: Má»™t xe tá»± hÃ nh trÃªn Ä‘áº¥t liá»n trong má»™t máº¡ng neural. Trong Advances in Neural
Information Processing Systems, trang 305â€“313, 1989.

J. W. Rae, S. Borgeaud, T. Cai, K. Millican, J. Hoffmann, F. Song, J. Aslanides, S. Henderson, R. Ring,
S. Young, et al. Má»Ÿ rá»™ng mÃ´ hÃ¬nh ngÃ´n ngá»¯: PhÆ°Æ¡ng phÃ¡p, phÃ¢n tÃ­ch & hiá»ƒu biáº¿t tá»« viá»‡c huáº¥n luyá»‡n gopher. arXiv
preprint arXiv:2112.11446, 2021.

R. Rafailov, A. Sharma, E. Mitchell, S. Ermon, C. D. Manning, vÃ  C. Finn. Tá»‘i Æ°u hÃ³a sá»Ÿ thÃ­ch trá»±c tiáº¿p:
MÃ´ hÃ¬nh ngÃ´n ngá»¯ cá»§a báº¡n bÃ­ máº­t lÃ  má»™t mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng. arXiv preprint arXiv:2305.18290,
2023.

R. Rei, C. Stewart, A. C. Farinha, vÃ  A. Lavie. COMET: Má»™t khung neural cho Ä‘Ã¡nh giÃ¡ MT. Trong
Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2020.

J. Schulman, F. Wolski, P. Dhariwal, A. Radford, vÃ  O. Klimov. Thuáº­t toÃ¡n tá»‘i Æ°u hÃ³a chÃ­nh sÃ¡ch gáº§n Ä‘Ãºng.
arXiv preprint arXiv:1707.06347, 2017.

H. Scudder. XÃ¡c suáº¥t lá»—i cá»§a má»™t sá»‘ mÃ¡y nháº­n dáº¡ng máº«u thÃ­ch á»©ng. IEEE Transactions on
Information Theory, 11(3):363â€“371, 1965.

--- TRANG 15 ---
Tá»± Huáº¥n Luyá»‡n TÄƒng CÆ°á»ng (ReST) cho MÃ´ HÃ¬nh NgÃ´n Ngá»¯

T. Sellam, D. Das, vÃ  A. Parikh. BLEURT: Há»c cÃ¡c chá»‰ sá»‘ máº¡nh máº½ cho viá»‡c táº¡o vÄƒn báº£n. Trong Proceedings
of the 58th Annual Meeting of the Association for Computational Linguistics, 2020.

I. Shumailov, Z. Shumaylov, Y. Zhao, Y. Gal, N. Papernot, vÃ  R. Anderson. Lá»i nguyá»n cá»§a Ä‘á»‡ quy:
Huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u Ä‘Æ°á»£c táº¡o khiáº¿n mÃ´ hÃ¬nh quÃªn. arXiv preprint arxiv:2305.17493, 2023.

J. Skalse, N. H. R. Howe, D. Krasheninnikov, vÃ  D. Krueger. Äá»‹nh nghÄ©a vÃ  Ä‘áº·c trÆ°ng reward
hacking. Trong Advances in Neural Information Processing Systems, 2022.

H. F. Song, A. Abdolmaleki, J. T. Springenberg, A. Clark, H. Soyer, J. W. Rae, S. Noury, A. Ahuja, S. Liu,
D. Tirumala, N. Heess, D. Belov, M. Riedmiller, vÃ  M. M. Botvinick. V-mpo: Tá»‘i Æ°u hÃ³a chÃ­nh sÃ¡ch
maximum a posteriori trÃªn chÃ­nh sÃ¡ch cho Ä‘iá»u khiá»ƒn rá»i ráº¡c vÃ  liÃªn tá»¥c. Trong International Conference of
Learning Representations, 2020.

A. Srivastava, A. Rastogi, A. Rao, A. A. M. Shoeb, A. Abid, A. Fisch, A. R. Brown, A. Santoro, A. Gupta,
A. Garriga-Alonso, et al. VÆ°á»£t ra ngoÃ i trÃ² chÆ¡i mÃ´ phá»ng: Äá»‹nh lÆ°á»£ng vÃ  ngoáº¡i suy kháº£ nÄƒng
cá»§a mÃ´ hÃ¬nh ngÃ´n ngá»¯. arXiv preprint arXiv:2206.04615, 2022.

N. Stiennon, L. Ouyang, J. Wu, D. Ziegler, R. Lowe, C. Voss, A. Radford, D. Amodei, vÃ  P. F. Christiano.
Há»c cÃ¡ch tÃ³m táº¯t vá»›i pháº£n há»“i cá»§a con ngÆ°á»i. Advances in Neural Information Processing Systems,
2020.

H. Sun, R. Wang, K. Chen, M. Utiyama, E. Sumita, vÃ  T. Zhao. Self-training cho dá»‹ch mÃ¡y neural
khÃ´ng giÃ¡m sÃ¡t trong cÃ¡c tÃ¬nh huá»‘ng dá»¯ liá»‡u huáº¥n luyá»‡n khÃ´ng cÃ¢n báº±ng. Trong Proceedings of the Conference
of the North American Chapter of the Association for Computational Linguistics: Human Language
Technologies, 2021.

I. Sutskever, O. Vinyals, vÃ  Q. V. Le. Há»c sequence to sequence vá»›i máº¡ng neural. Trong
Advances in Neural Information Processing Systems, 2014.

J. Uesato, N. Kushman, R. Kumar, F. Song, N. Siegel, L. Wang, A. Creswell, G. Irving, vÃ  I. Higgins. Giáº£i quyáº¿t bÃ i toÃ¡n tá»« toÃ¡n há»c vá»›i pháº£n há»“i dá»±a trÃªn quÃ¡ trÃ¬nh vÃ  káº¿t quáº£. arXiv preprint
arXiv:2211.14275, 2022.

A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Å. Kaiser, vÃ  I. Polosukhin.
Attention is all you need. Trong Advances in Neural Information Processing Systems, 2017.

J. Wu, L. Ouyang, D. M. Ziegler, N. Stiennon, R. Lowe, J. Leike, vÃ  P. Christiano. TÃ³m táº¯t sÃ¡ch má»™t cÃ¡ch
Ä‘á»‡ quy vá»›i pháº£n há»“i cá»§a con ngÆ°á»i. arXiv preprint arXiv:2109.10862, 2021.

Q. Xie, M.-T. Luong, E. Hovy, vÃ  Q. V. Le. Self-training vá»›i noisy student cáº£i thiá»‡n phÃ¢n loáº¡i imagenet.
Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
trang 10687â€“10698, 2020.

F. Yang, G. Barth-Maron, P. StaÅ„czyk, M. Hoffman, S. Liu, M. Kroiss, A. Pope, vÃ  A. Rrustemi.
Launchpad: Má»™t mÃ´ hÃ¬nh láº­p trÃ¬nh cho nghiÃªn cá»©u mÃ¡y há»c phÃ¢n tÃ¡n. arXiv preprint
arXiv:2106.04516, 2021.

D. Yarowsky. Loáº¡i bá» sá»± nháº­p nháº±ng nghÄ©a tá»« khÃ´ng giÃ¡m sÃ¡t cáº¡nh tranh vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p cÃ³ giÃ¡m sÃ¡t. Trong 33rd Annual
Meeting of the Association for Computational Linguistics, 1995.

L. Yu, L. Sartran, P.-S. Huang, W. Stokoweic, D. Donato, S. Srinivasan, A. Andreev, W. Ling, S. Mokra,
A. D. Lago, Y. Doron, S. Young, P. Blunsom, vÃ  C. Dyer. Há»‡ thá»‘ng dá»‹ch tÃ i liá»‡u tiáº¿ng Trungâ€“tiáº¿ng Anh DeepMind
táº¡i wmt2020. Trong Proceedings of the Fifth Conference on Machine Translation, 2020.

--- TRANG 16 ---
Tá»± Huáº¥n Luyá»‡n TÄƒng CÆ°á»ng (ReST) cho MÃ´ HÃ¬nh NgÃ´n Ngá»¯

E. Zelikman, Y. Wu, J. Mu, vÃ  N. Goodman. Star: Bootstrapping reasoning vá»›i lÃ½ luáº­n. Trong
Advances in Neural Information Processing Systems, 2022.

J. Zhang vÃ  C. Zong. Khai thÃ¡c dá»¯ liá»‡u Ä‘Æ¡n ngá»¯ phÃ­a nguá»“n trong dá»‹ch mÃ¡y neural. Trong
Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2016.

A. Phá»¥ lá»¥c

A.1. RLHF cho mÃ´ hÃ¬nh ngÃ´n ngá»¯ cÃ³ Ä‘iá»u kiá»‡n nhÆ° MDP

ChÃºng ta cÃ³ thá»ƒ cÃ´ng thá»©c hÃ³a mÃ´ hÃ¬nh ngÃ´n ngá»¯ cÃ³ Ä‘iá»u kiá»‡n nhÆ° má»™t váº¥n Ä‘á» sequence to sequence. Má»¥c tiÃªu lÃ 
Ã¡nh xáº¡ má»™t chuá»—i nguá»“n ğ’™=(ğ‘¥1,ğ‘¥2,...ğ‘¥ğ¿) thÃ nh má»™t chuá»—i Ä‘Ã­ch ğ’š=(ğ‘¦1,ğ‘¦2,....ğ‘¦ğ‘‡), tá»©c lÃ  há»c má»™t
Ã¡nh xáº¡ tá»« ğ’™ Ä‘áº¿n ğ’š. Dá»‹ch mÃ¡y lÃ  má»™t vÃ­ dá»¥ cá»• Ä‘iá»ƒn cá»§a váº¥n Ä‘á» sequence to sequence
(Sutskever et al., 2014).

MÃ´ hÃ¬nh cÃ³ thá»ƒ Ä‘Æ°á»£c mÃ´ táº£ nhÆ° má»™t Markov Decision Process (MDP) (Bellman, 1957). Má»™t MDP, Mdef=
(S,A,ğ‘‡,ğ‘Ÿ,ğ‘‘), bao gá»“m cÃ¡c táº­p há»¯u háº¡n cá»§a tráº¡ng thÃ¡i S vÃ  hÃ nh Ä‘á»™ng A, má»™t phÃ¢n phá»‘i chuyá»ƒn Ä‘á»•i ğ‘‡(ğ‘ â€²|ğ‘ ,ğ‘),ğ‘ ,ğ‘ â€²âˆˆ
S,ğ‘âˆˆA, má»™t hÃ m pháº§n thÆ°á»Ÿng ğ‘Ÿ:SÃ—Aâ†’ â„, vÃ  má»™t phÃ¢n phá»‘i tráº¡ng thÃ¡i ban Ä‘áº§u ğ‘‘:Sâ†’[0,1]. Trong
thiáº¿t láº­p ngoáº¡i tuyáº¿n, agent há»c tá»« má»™t táº­p dá»¯ liá»‡u D chá»©a cÃ¡c chuá»—i (ğ‘ ğ‘›,ğ‘ğ‘›,ğ‘Ÿğ‘›+1). Táº­p dá»¯ liá»‡u
D thÆ°á»ng Ä‘Æ°á»£c giáº£ Ä‘á»‹nh Ä‘Æ°á»£c táº¡o bá»Ÿi má»™t chÃ­nh sÃ¡ch hÃ nh vi khÃ´ng xÃ¡c Ä‘á»‹nh ğœ‡ Ä‘Æ°á»£c Ä‘áº·c trÆ°ng bá»Ÿi má»™t phÃ¢n phá»‘i
trÃªn cÃ¡c hÃ nh Ä‘á»™ng cÃ³ Ä‘iá»u kiá»‡n trÃªn tráº¡ng thÃ¡i: ğœ‡(ğ‘|ğ‘ ). CÃ¡c yáº¿u tá»‘ cá»§a MDP cÃ³ Ã½ nghÄ©a sau trong
mÃ´ hÃ¬nh ngÃ´n ngá»¯ cÃ³ Ä‘iá»u kiá»‡n:

â€¢Tráº¡ng thÃ¡i (ğ‘ ): Tráº¡ng thÃ¡i ğ‘ ğ‘› bao gá»“m chuá»—i Ä‘áº§u vÃ o vÃ  Ä‘áº§u ra Ä‘Æ°á»£c táº¡o má»™t pháº§n Ä‘áº¿n
token thá»© ğ‘›: ğ‘ ğ‘›=[ğ’™,ğ’š1:ğ‘›âˆ’1].

â€¢HÃ nh Ä‘á»™ng (ğ‘): CÃ¡c hÃ nh Ä‘á»™ng lÃ  cÃ¡c token ğ‘ğ‘›=ğ‘¦ğ‘› Ä‘Æ°á»£c táº¡o bá»Ÿi chÃ­nh sÃ¡ch (ğœ‹).

â€¢Pháº§n thÆ°á»Ÿng (r): Pháº§n thÆ°á»Ÿng cÃ³ thá»ƒ Ä‘Æ°á»£c cho hoáº·c há»c. Trong cÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i, chÃºng tÃ´i huáº¥n luyá»‡n má»™t máº¡ng neural sÃ¢u
trÃªn sá»Ÿ thÃ­ch cá»§a con ngÆ°á»i Ä‘á»ƒ gÃ¡n má»™t Ä‘iá»ƒm sá»‘ cho toÃ n bá»™ chuá»—i Ä‘Æ°á»£c táº¡o. Pháº§n thÆ°á»Ÿng Ä‘Æ°á»£c
táº¡o ra sau token end-of-sequence (EOS), vÃ  nÃ³ báº±ng khÃ´ng á»Ÿ táº¥t cáº£ cÃ¡c bÆ°á»›c khÃ¡c.

â€¢ToÃ¡n tá»­ chuyá»ƒn Ä‘á»•i (T): ToÃ¡n tá»­ chuyá»ƒn Ä‘á»•i Ä‘á»‹nh nghÄ©a Ä‘á»™ng lá»±c cá»§a má»™t mÃ´i trÆ°á»ng:
ğ‘‡(ğ‘ â€²|ğ‘,ğ‘ ):=ğ‘‡(ğ‘¦ğ‘›|ğ‘ ğ‘›=[ğ’™,ğ’š1:ğ‘›âˆ’1]). Trong thiáº¿t láº­p cá»§a chÃºng tÃ´i, Ä‘Ã¢y lÃ  má»™t toÃ¡n tá»­ xÃ¡c Ä‘á»‹nh ná»‘i
token má»›i Ä‘Æ°á»£c táº¡o (hÃ nh Ä‘á»™ng) vÃ o chuá»—i hiá»‡n táº¡i (tráº¡ng thÃ¡i).

CÃ´ng thá»©c RLHF nÃ y cá»§a mÃ´ hÃ¬nh ngÃ´n ngá»¯ cÃ³ Ä‘iá»u kiá»‡n cÅ©ng cÃ³ thá»ƒ Ä‘Æ°á»£c xem nhÆ° má»™t váº¥n Ä‘á»
contextual bandit vá»›i khÃ´ng gian hÃ nh Ä‘á»™ng ráº¥t lá»›n.

A.2. Káº¿t quáº£ Ã¢m tÃ­nh vá»›i RL ngoáº¡i tuyáº¿n

NgoÃ i cÃ¡c thÃ­ nghiá»‡m tá»« Pháº§n 4, chÃºng tÃ´i cÅ©ng cháº¡y thÃ­ nghiá»‡m vá»›i Q-learning vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p RL má»™t bÆ°á»›c
kiá»ƒu BVE vÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p cÃ³ Ä‘iá»u kiá»‡n pháº§n thÆ°á»Ÿng, nhÆ° decision transformers (Chen
et al., 2021). Tuy nhiÃªn, chÃºng tÃ´i khÃ´ng thá»ƒ cÃ³ Ä‘Æ°á»£c cáº£i thiá»‡n Ä‘Ã¡ng chÃº Ã½ vá»›i chÃºng so vá»›i
baseline cÃ³ giÃ¡m sÃ¡t. CÃ¡c phÆ°Æ¡ng phÃ¡p dá»±a trÃªn Q-function Ä‘á»ƒ há»c má»™t chÃ­nh sÃ¡ch vÃ  hÃ m giÃ¡ trá»‹ hoáº¡t Ä‘á»™ng tá»‡ hÆ¡n
há»c cÃ³ giÃ¡m sÃ¡t khi Ä‘Æ°á»£c sá»­ dá»¥ng nhÆ° má»™t chÃ­nh sÃ¡ch ngay cáº£ sau khi huáº¥n luyá»‡n tá»« khá»Ÿi táº¡o tá»« má»™t
checkpoint cÃ³ giÃ¡m sÃ¡t. Äiá»u nÃ y khá»›p vá»›i cÃ¡c quan sÃ¡t trÆ°á»›c Ä‘Ã³ bá»Ÿi Mathieu et al. (2021) ngÆ°á»i Ä‘Ã£ chá»‰ ra ráº±ng Q-learning ngoáº¡i tuyáº¿n
gáº·p khÃ³ khÄƒn trong khÃ´ng gian hÃ nh Ä‘á»™ng lá»›n (kÃ­ch thÆ°á»›c tá»« vá»±ng 32 000 token) vÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p dá»±a trÃªn state-value
Ä‘Æ°á»£c Æ°a thÃ­ch hÆ¡n. HÆ¡n ná»¯a, nhÆ° Brandfonbrener et al. (2022) Ä‘Ã£ chá»‰ ra, cÃ¡c phÆ°Æ¡ng phÃ¡p cÃ³ Ä‘iá»u kiá»‡n tráº£ vá»
cÃ³ xu hÆ°á»›ng há»c cÃ¡c chÃ­nh sÃ¡ch khÃ´ng tá»‘i Æ°u trÃªn cÃ¡c tÃ¡c vá»¥ vá»›i pháº§n thÆ°á»Ÿng liÃªn tá»¥c thÆ°a thá»›t.

--- TRANG 17 ---
Tá»± Huáº¥n Luyá»‡n TÄƒng CÆ°á»ng (ReST) cho MÃ´ HÃ¬nh NgÃ´n Ngá»¯

A.3. Chi tiáº¿t Dá»¯ liá»‡u vÃ  MÃ´ hÃ¬nh

Trong táº¥t cáº£ cÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i, kiáº¿n trÃºc chÃ­nh sÃ¡ch cÆ¡ sá»Ÿ lÃ  má»™t sá»­a Ä‘á»•i nhá» cá»§a kiáº¿n trÃºc Transformer tiÃªu chuáº©n
(Vaswani et al., 2017). ChÃºng tÃ´i sá»­ dá»¥ng tá»« vá»±ng 32 000 token vÃ  Ä‘á»™ dÃ i chuá»—i tá»‘i Ä‘a
128 táº¡i thá»i Ä‘iá»ƒm giáº£i mÃ£. ChÃºng tÃ´i sá»­ dá»¥ng cÃ´ng cá»¥ sentencepiece (Kudo, 2018) Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c tokenizer.

BÆ°á»›c Grow. Trong bÆ°á»›c Grow, chÃºng tÃ´i láº¥y máº«u tá»« checkpoint má»›i nháº¥t cá»§a chÃ­nh sÃ¡ch vá»›i softmax cÃ³ Ä‘iá»u
sá»­ dá»¥ng nhiá»‡t Ä‘á»™ 0.8 theo quy trÃ¬nh Ä‘Æ°á»£c Ä‘á» xuáº¥t bá»Ÿi Li et al. (2022) Ä‘á»ƒ táº¡o
táº­p dá»¯ liá»‡u. HÆ¡n ná»¯a, trong phÃ¢n tÃ­ch cá»§a chÃºng tÃ´i, chÃºng tÃ´i tháº¥y ráº±ng nhiá»‡t Ä‘á»™ 0.8 thÆ°á»ng bao phá»§ má»™t pháº¡m vi rá»™ng
pháº§n thÆ°á»Ÿng trong táº­p dá»¯ liá»‡u.

NgÆ°á»¡ng trong bÆ°á»›c Improve. Náº¿u chÃºng ta Ä‘áº·t ngÆ°á»¡ng ğœ thÃ nh má»™t giÃ¡ trá»‹ sao cho ğœâ‰¥ğ‘‰ğœ‹0, vÃ  há»c má»™t chÃ­nh sÃ¡ch
ğœ‹1 trÃªn dá»¯ liá»‡u Ä‘Æ°á»£c lá»c vá»›i ngÆ°á»¡ng nÃ y, giÃ¡ trá»‹ trung bÃ¬nh Ä‘Æ°á»£c cáº­p nháº­t ğ‘‰ğœ‹1 cá»§a chÃ­nh sÃ¡ch nÃ y thá»a mÃ£n ğ‘‰ğœ‹1>ğ‘‰ğœ‹0.
Sau Ä‘Ã³, ngÆ°á»¡ng láº·p Ä‘i láº·p láº¡i Ä‘áº£m báº£o cáº£i thiá»‡n chÃ­nh sÃ¡ch trong bÆ°á»›c Improve. Trong cÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i, chÃºng tÃ´i
thá»±c hiá»‡n má»™t sá»‘ bÆ°á»›c cáº£i thiá»‡n cho Ä‘áº¿n khi Ä‘áº¡t ngÆ°á»¡ng tá»‘i Ä‘a. á» má»—i bÆ°á»›c, chÃºng tÃ´i huáº¥n luyá»‡n
mÃ´ hÃ¬nh trong 500 000 bÆ°á»›c SGD vÃ  chá»n checkpoint vá»›i Ä‘iá»ƒm sá»‘ mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng tá»‘t nháº¥t.

IWSLT 2014 De-En. ChÃºng tÃ´i sá»­ dá»¥ng cÃ¡c táº­p train, validation vÃ  test tá»« táº­p dá»¯ liá»‡u IWSLT 2014 De-En (Cettolo
et al., 2014) bao gá»“m cÃ¡c cÃ¢u nguá»“n báº±ng tiáº¿ng Äá»©c vá»›i báº£n dá»‹ch con ngÆ°á»i (tham chiáº¿u) báº±ng
tiáº¿ng Anh. Trong má»—i bÆ°á»›c Grow, chÃºng tÃ´i táº¡o ra 100 báº£n dá»‹ch á»©ng viÃªn cho má»—i cÃ¢u nguá»“n trong
táº­p huáº¥n luyá»‡n, hiá»‡u quáº£ mang láº¡i cho chÃºng tÃ´i |Dğ‘”|=16 000 000. Äá»‘i vá»›i táº­p dá»¯ liá»‡u nÃ y, chÃºng tÃ´i sá»­ dá»¥ng má»™t phiÃªn báº£n nhá» cá»§a
kiáº¿n trÃºc Transformer encoder-decoder (Vaswani et al., 2017) vá»›i cÃ¡c lá»›p MLP feedforward cÃ³
kÃ­ch thÆ°á»›c 512, chiá»u feedforward 1024, 4 attention head vÃ  6 lá»›p encoder vÃ  decoder.

WMT 2020 Zh-En. ChÃºng tÃ´i sá»­ dá»¥ng cÃ¡c cáº·p source-reference báº±ng tiáº¿ng Trung vÃ  tiáº¿ng Anh tá»« cÃ´ng trÃ¬nh cá»§a Koehn
et al. (2020) cho cÃ¡c táº­p training, validation vÃ  test cá»§a chÃºng tÃ´i. Chi tiáº¿t chÃ­nh xÃ¡c vá» cÃ¡c táº­p dá»¯ liá»‡u vÃ  tiá»n xá»­ lÃ½
cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ¬m tháº¥y trong Yu et al. (2020). Trong má»—i bÆ°á»›c Grow, chÃºng tÃ´i táº¡o ra 25 á»©ng viÃªn cho má»—i cÃ¢u nguá»“n
trong táº­p huáº¥n luyá»‡n, hiá»‡u quáº£ mang láº¡i cho chÃºng tÃ´i |Dğ‘”|=890 000 000. ChÃºng tÃ´i chá»n táº¡o ra 25
á»©ng viÃªn trÃªn má»—i nguá»“n vÃ¬ táº­p dá»¯ liá»‡u WMT lá»›n hÆ¡n Ä‘Ã¡ng ká»ƒ (~100 láº§n) so vá»›i táº­p dá»¯ liá»‡u IWSLT.
ChÃºng tÃ´i sá»­ dá»¥ng má»™t kiáº¿n trÃºc mÃ´ phá»ng kiáº¿n trÃºc Transformer-base encoder-decoder (Vaswani et al., 2017)
vá»›i chiá»u mÃ´ hÃ¬nh 512, chiá»u feedforward 2048, 8 attention head vÃ  6
lá»›p encoder vÃ  decoder.

Web Domain En-Zh. Cuá»‘i cÃ¹ng, chÃºng tÃ´i sá»­ dá»¥ng táº­p dá»¯ liá»‡u ná»™i bá»™ cho dá»‹ch tá»« tiáº¿ng Anh sang tiáº¿ng Trung vá»›i
cÃ¡c táº­p training, fine-tuning vÃ  test tÃ¹y chá»‰nh. Corpus huáº¥n luyá»‡n nÃ y lÃ  táº­p dá»¯ liá»‡u lá»›n nháº¥t cá»§a chÃºng tÃ´iâµ, vÃ¬ váº­y chÃºng tÃ´i sá»­ dá»¥ng má»™t
phiÃªn báº£n sá»­a Ä‘á»•i cá»§a kiáº¿n trÃºc Transformer-big encoder-decoder (Vaswani et al., 2017) vá»›i
chiá»u mÃ´ hÃ¬nh 1024, chiá»u feedforward 8192, 16 attention head vÃ  6
lá»›p encoder vÃ  decoder.

Trong Báº£ng 2, chÃºng tÃ´i liá»‡t kÃª táº¥t cáº£ cÃ¡c táº­p dá»¯ liá»‡u vá»›i kÃ­ch thÆ°á»›c cá»§a chÃºng. Trong táº¥t cáº£ cÃ¡c thÃ­ nghiá»‡m, trá»« khi Ä‘Æ°á»£c nÃªu khÃ¡c,
chÃºng tÃ´i bÃ¡o cÃ¡o Ä‘iá»ƒm sá»‘ pháº§n thÆ°á»Ÿng trung bÃ¬nh trÃªn táº­p validation.

âµVÃ¬ lÃ½ do tÃ­nh toÃ¡n, chÃºng tÃ´i cháº¡y ReST trÃªn corpus fine-tuning vá»›i má»™t mÃ´ hÃ¬nh Ä‘Æ°á»£c khá»Ÿi Ä‘á»™ng tá»« má»™t mÃ´ hÃ¬nh cÃ³ giÃ¡m sÃ¡t
Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn toÃ n bá»™ corpus huáº¥n luyá»‡n khá»•ng lá»“.

--- TRANG 18 ---
Tá»± Huáº¥n Luyá»‡n TÄƒng CÆ°á»ng (ReST) cho MÃ´ HÃ¬nh NgÃ´n Ngá»¯

Táº­p dá»¯ liá»‡u | |Dğ‘”| | # Máº«u Eval | # á»¨ng viÃªn
per source
IWSLT 2014 de-en | 16 000 000 | 7466 | 100
WMT 2020 zh-en | 890 000 000 | 2000 | 25
Web Domain Finetuning en-zh | 3 000 000 | 6000 | 1000

Báº£ng 2|Chi tiáº¿t cá»§a cÃ¡c táº­p dá»¯ liá»‡u vÃ  kÃ­ch thÆ°á»›c cá»§a chÃºng Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c thÃ­ nghiá»‡m ReST.

A.4. MÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng

ChÃºng tÃ´i Ä‘Ã£ sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng Ä‘Ã£ há»c gÃ¡n má»™t Ä‘iá»ƒm sá»‘ cho toÃ n bá»™ báº£n dá»‹ch. ChÃºng tÃ´i xem xÃ©t hai
loáº¡i mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng cho dá»‹ch thuáº­t (Freitag et al., 2022): i) MÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng khÃ´ng tham chiáº¿u Æ°á»›c tÃ­nh
má»©c Ä‘á»™ tá»‘t cá»§a má»™t báº£n dá»‹ch chá»‰ dá»±a trÃªn cÃ¢u nguá»“n vÃ  á»©ng viÃªn, ii) MÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng cÃ³ tham chiáº¿u
bá»• sung sá»­ dá»¥ng báº£n dá»‹ch tham chiáº¿u cá»§a con ngÆ°á»i Ä‘á»ƒ quyáº¿t Ä‘á»‹nh má»©c Ä‘á»™ tá»‘t cá»§a má»™t báº£n dá»‹ch á»©ng viÃªn.
CÃ¡c mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng khÃ´ng tham chiáº¿u linh hoáº¡t hÆ¡n vÃ¬ chÃºng khÃ´ng yÃªu cáº§u báº£n dá»‹ch tham chiáº¿u.
HÆ¡n ná»¯a, theo thiáº¿t káº¿, cÃ¡c mÃ´ hÃ¬nh cÃ³ tham chiáº¿u gÃ¡n Ä‘iá»ƒm sá»‘ cao hÆ¡n cho cÃ¡c cÃ¢u tÆ°Æ¡ng tá»± nhÆ° tham chiáº¿u,
vÃ  Ä‘iá»u nÃ y cÃ³ thá»ƒ xáº£y ra ngay cáº£ khi tham chiáº¿u cÃ³ lá»—i hoáº·c khÃ´ng Ä‘áº§y Ä‘á»§.
Cuá»‘i cÃ¹ng, cÃ¡c mÃ´ hÃ¬nh khÃ´ng tham chiáº¿u má»Ÿ ra kháº£ nÄƒng Ä‘Ã¡nh giÃ¡ vÃ  khÃ¡m phÃ¡ cÃ¡c báº£n dá»‹ch á»©ng viÃªn
vÆ°á»£t qua cháº¥t lÆ°á»£ng cá»§a tham chiáº¿u. Do Ä‘Ã³, trong cÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i, chÃºng tÃ´i chá»n lÃ m viá»‡c vá»›i cÃ¡c mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng khÃ´ng tham chiáº¿u.
Máº·t khÃ¡c, vÃ¬ cÃ¡c mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng khÃ´ng tham chiáº¿u khÃ´ng Ä‘Æ°á»£c grounded trong má»™t
báº£n dá»‹ch tham chiáº¿u cá»§a con ngÆ°á»i, nÃ³ dá»… bá»‹ tá»•n thÆ°Æ¡ng hÆ¡n trÆ°á»›c sá»± dá»‹ch chuyá»ƒn phÃ¢n phá»‘i trong cÃ¡c á»©ng viÃªn Ä‘Æ°á»£c táº¡o
bá»Ÿi mÃ´ hÃ¬nh vÃ  reward hacking. Trong thá»±c táº¿, chÃºng tÃ´i tÃ­nh toÃ¡n trÆ°á»›c vÃ  lÆ°u trá»¯ ğ‘…(ğ’™,ğ’š) cho Dğ‘” Ä‘Æ°á»£c táº¡o.

Trong quÃ¡ trÃ¬nh phÃ¡t triá»ƒn mÃ´ hÃ¬nh, chÃºng tÃ´i dá»±a vÃ o phÆ°Æ¡ng phÃ¡p "unit tests" cho cÃ¡c mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng
nÆ¡i chÃºng tÃ´i kiá»ƒm tra chÃºng trong nhiá»u thiáº¿t láº­p Ä‘Æ°á»£c táº¡o thá»§ cÃ´ng, nhÆ° trÃªn cÃ¡c hoÃ¡n vá»‹ vÃ  láº·p láº¡i khÃ¡c nhau
cá»§a cÃ¢u. CÃ¡c unit-test Ä‘áº£m báº£o cháº¥t lÆ°á»£ng cao cá»§a pháº§n thÆ°á»Ÿng Ä‘Æ°á»£c táº¡o cho ReST. Máº·c dÃ¹ chÃºng tÃ´i Ä‘Ã£ sá»­ dá»¥ng
mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng khÃ´ng tham chiáº¿u máº¡nh máº½ nháº¥t cÃ³ sáºµn, chÃºng tÃ´i tháº¥y ráº±ng nÃ³ váº«n
khÃ´ng hoÃ n háº£o, vÃ  Ä‘Ã´i khi cho tháº¥y dáº¥u hiá»‡u cá»§a áº£o tÆ°á»Ÿng. VÃ­ dá»¥, pháº§n thÆ°á»Ÿng cá»§a má»™t báº£n dá»‹ch
thá»‰nh thoáº£ng tÄƒng lÃªn khi chÃºng tÃ´i láº·p láº¡i cÃ¢u, khÃ´ng phá»¥ thuá»™c vÃ o cháº¥t lÆ°á»£ng ban Ä‘áº§u cá»§a
báº£n dá»‹ch.

A.5. Sá»± cÄƒn chá»‰nh giá»¯a Ä‘iá»ƒm Ä‘Ã¡nh giÃ¡ con ngÆ°á»i vÃ  Ä‘iá»ƒm sá»‘ mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng

Trong HÃ¬nh 9 vÃ  10, chÃºng tÃ´i hiá»ƒn thá»‹ phÃ¢n phá»‘i sá»Ÿ thÃ­ch con ngÆ°á»i vÃ  Ä‘iá»ƒm sá»‘ mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng cho
ReST vá»›i BC vÃ  G=1 I=4. á» Ä‘Ã¢y, chÃºng tÃ´i phÃ¡t hiá»‡n ra ráº±ng mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng cá»§a chÃºng tÃ´i cÃ³ phÆ°Æ¡ng sai ráº¥t cao trÃªn
cÃ¡c máº«u vá»›i Ä‘iá»ƒm sá»Ÿ thÃ­ch con ngÆ°á»i tháº¥p tá»« ReST(BC,G=1 I=4) vÃ  baseline há»c cÃ³ giÃ¡m sÃ¡t cá»§a chÃºng tÃ´i
(BC,G=0 I=0). Giáº£ thuyáº¿t cá»§a chÃºng tÃ´i cho Ä‘iá»u nÃ y lÃ  táº­p dá»¯ liá»‡u huáº¥n luyá»‡n cho mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng
bá»‹ thá»‘ng trá»‹ bá»Ÿi cÃ¡c báº£n dá»‹ch cháº¥t lÆ°á»£ng caoâ¶. Do Ä‘Ã³ mÃ´ hÃ¬nh overfitted vá»›i cÃ¡c máº«u cÃ³
Ä‘iá»ƒm sá»‘ cao, vÃ  nÃ³ cÃ³ phÆ°Æ¡ng sai cao trong dá»± Ä‘oÃ¡n cá»§a mÃ¬nh trÃªn cÃ¡c máº«u cÃ³ cháº¥t lÆ°á»£ng kÃ©m hÆ¡n. Khoáº£ng cÃ¡ch nÃ y cÃ³ thá»ƒ
Ä‘Æ°á»£c giáº£i quyáº¿t vá»›i viá»‡c huáº¥n luyá»‡n láº¡i tÄƒng dáº§n cá»§a mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng.

A.6. Káº¿t quáº£ trÃªn cÃ¡c táº­p test

HÃ¬nh 11 vÃ  12 trÃ¬nh bÃ y káº¿t quáº£ trÃªn cÃ¡c táº­p test trong cÃ¡c táº­p dá»¯ liá»‡u IWSLT 2014 De-En vÃ  WMT 2020 Zh-En.
TÆ°Æ¡ng tá»± nhÆ° táº­p validation, ReST vÆ°á»£t trá»™i hÆ¡n cÃ¡c baseline RL ngoáº¡i tuyáº¿n dá»±a trÃªn giÃ¡ trá»‹ khÃ¡c. NgoÃ i ra,
viá»‡c tÄƒng sá»‘ lÆ°á»£ng cáº£ bÆ°á»›c Grow vÃ  Improve giÃºp tÄƒng thÃªm pháº§n thÆ°á»Ÿng.

â¶Dá»¯ liá»‡u Ä‘áº¿n tá»« táº­p dá»¯ liá»‡u tÃ¡c vá»¥ chia sáº» chá»‰ sá»‘ WMT 2021 (Freitag et al., 2021), xem xÃ©t Ä‘Ã¡nh giÃ¡ con ngÆ°á»i
cá»§a cÃ¡c mÃ´ hÃ¬nh dá»‹ch tá»‘t

--- TRANG 19 ---
Tá»± Huáº¥n Luyá»‡n TÄƒng CÆ°á»ng (ReST) cho MÃ´ HÃ¬nh NgÃ´n Ngá»¯

HÃ¬nh 9|[IWSLT 2014 De-En]: phÃ¢n phá»‘i sá»Ÿ thÃ­ch con ngÆ°á»i vÃ  Ä‘iá»ƒm sá»‘ mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng cho ReST
(BC, I=4, G=1) trong Ä‘Ã¡nh giÃ¡ side by side vá»›i mÃ´ hÃ¬nh cÃ³ giÃ¡m sÃ¡t. Äiá»ƒm sá»Ÿ thÃ­ch con ngÆ°á»i
nhá» hÆ¡n hoáº·c báº±ng 3 cÃ³ phÆ°Æ¡ng sai cao hÆ¡n Ä‘Ã¡ng ká»ƒ trong pháº§n thÆ°á»Ÿng so vá»›i Ä‘iá»ƒm sá»Ÿ thÃ­ch con ngÆ°á»i
trÃªn 3. CÃ¡c biá»ƒu Ä‘á»“ bÃªn trÃ¡i lÃ  cho cÃ¡c máº«u Ä‘Æ°á»£c táº¡o tá»« baseline cÃ³ giÃ¡m sÃ¡t vÃ  bÃªn pháº£i lÃ  cho
cÃ¡c máº«u Ä‘Æ°á»£c táº¡o vá»›i ReST.

HÃ¬nh 10|[WMT 2020 Zh-En]: phÃ¢n phá»‘i sá»Ÿ thÃ­ch con ngÆ°á»i vÃ  Ä‘iá»ƒm sá»‘ mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng cho ReST
(BC, I=4, G=1) trong Ä‘Ã¡nh giÃ¡ side by side vá»›i mÃ´ hÃ¬nh cÃ³ giÃ¡m sÃ¡t. Äiá»ƒm sá»Ÿ thÃ­ch con ngÆ°á»i
tháº¥p hÆ¡n hoáº·c báº±ng 3 cÃ³ phÆ°Æ¡ng sai vá» Ä‘iá»ƒm sá»‘ mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng. MÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng cÃ³ Ã­t
cháº¯c cháº¯n hÆ¡n vá» Ä‘iá»ƒm sá»‘ cá»§a cÃ¡c á»©ng viÃªn cÃ³ Ä‘iá»ƒm sá»‘ tháº¥p hÆ¡n.

--- TRANG 20 ---
Tá»± Huáº¥n Luyá»‡n TÄƒng CÆ°á»ng (ReST) cho MÃ´ HÃ¬nh NgÃ´n Ngá»¯

HÃ¬nh 11|[IWSLT 2014 De-En]: Káº¿t quáº£ ReST trÃªn táº­p test. Táº¥t cáº£ cÃ¡c biáº¿n thá»ƒ cá»§a ReST (mÃ u tÃ­m) vÆ°á»£t trá»™i hÆ¡n
baseline há»c cÃ³ giÃ¡m sÃ¡t (mÃ u xÃ¡m). Khi chÃºng ta tÄƒng sá»‘ bÆ°á»›c Grow vÃ  Improve, pháº§n thÆ°á»Ÿng
cá»§a mÃ´ hÃ¬nh trÃªn táº­p test tiáº¿p tá»¥c tÄƒng.

HÃ¬nh 12|[WMT 2020 Zh-En]: Káº¿t quáº£ ReST trÃªn táº­p test. ChÃºng ta tháº¥y ráº±ng ReST rÃµ rÃ ng vÆ°á»£t trá»™i hÆ¡n cÃ¡c
baseline (pháº£i) vÃ  pháº§n thÆ°á»Ÿng cá»§a mÃ´ hÃ¬nh trÃªn táº­p test tÄƒng vá»›i sá»‘ bÆ°á»›c Improve.

A.7. ThÃ­ nghiá»‡m bá»• sung

Pháº§n nÃ y bÃ¡o cÃ¡o káº¿t quáº£ cá»§a má»™t sá»‘ ablation trong ReST giáº£i thÃ­ch má»™t sá»‘ lá»±a chá»n thiáº¿t káº¿
mÃ  chÃºng tÃ´i Ä‘Ã£ thá»±c hiá»‡n.

HÃ m máº¥t mÃ¡t GOLD so vá»›i BC trong bÆ°á»›c Improve. Trong HÃ¬nh 13, chÃºng tÃ´i so sÃ¡nh GOLD vá»›i hÃ m máº¥t mÃ¡t BC
vá»›i sá»‘ bÆ°á»›c ReST Improve tÄƒng dáº§n trÃªn táº­p dá»¯ liá»‡u WMT 2020 Zh-En. Hiá»‡u suáº¥t cá»§a
cáº£ BC vÃ  GOLD Ä‘á»u cáº£i thiá»‡n vá»›i sá»‘ bÆ°á»›c Improve, nhÆ°ng BC hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n GOLD
trong má»i thiáº¿t láº­p.

So sÃ¡nh hÃ m máº¥t mÃ¡t trÃªn IWSLT 2014 De-En. Trong HÃ¬nh 14, chÃºng tÃ´i so sÃ¡nh hÃ m máº¥t mÃ¡t BVMPO, BC vÃ  GOLD
trong bÆ°á»›c Improve trÃªn IWSLT 2014. Káº¿t quáº£ nháº¥t quÃ¡n vá»›i táº­p dá»¯ liá»‡u WMT: tÃ³m láº¡i, ReST vá»›i
hÃ m máº¥t mÃ¡t BC vÃ  nhiá»u bÆ°á»›c Improve vÆ°á»£t trá»™i hÆ¡n cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c.

Chá»n ngÆ°á»¡ng dá»±a trÃªn phÃ¢n vá»‹ cá»§a Ä‘iá»ƒm sá»‘ mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng. Sá»­ dá»¥ng má»™t ngÆ°á»¡ng duy nháº¥t cho táº¥t cáº£
cÃ¡c cáº·p source-candidate cÃ³ thá»ƒ dáº«n Ä‘áº¿n tÃ¬nh huá»‘ng khÃ´ng cÃ³ dá»¯ liá»‡u huáº¥n luyá»‡n cho má»™t sá»‘ cÃ¢u nguá»“n (khÃ³ hÆ¡n) nháº¥t Ä‘á»‹nh

--- TRANG 21 ---
Tá»± Huáº¥n Luyá»‡n TÄƒng CÆ°á»ng (ReST) cho MÃ´ HÃ¬nh NgÃ´n Ngá»¯

HÃ¬nh 13|[WMT 2020 Zh-En]: HÃ m máº¥t mÃ¡t GOLD vs
BC trong cáº£i thiá»‡n multi-step. Hiá»‡u suáº¥t cá»§a táº¥t cáº£ cÃ¡c phÆ°Æ¡ng phÃ¡p cáº£i thiá»‡n vá»›i nhiá»u
bÆ°á»›c hÆ¡n, nhÆ°ng hÃ m máº¥t mÃ¡t BC luÃ´n hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n
cÃ¡c hÃ m máº¥t mÃ¡t RL ngoáº¡i tuyáº¿n khÃ¡c mÃ  chÃºng tÃ´i Ä‘Ã£ thá»­.

HÃ¬nh 14|[IWSLT 2014 De-En]: HÃ m máº¥t mÃ¡t BVMPO,
BC, GOLD Ä‘Æ°á»£c sá»­ dá»¥ng trong ReST. HÃ m máº¥t mÃ¡t BC vá»›i
ba bÆ°á»›c Improve mang láº¡i káº¿t quáº£ tá»‘t nháº¥t.

HÃ¬nh 15|[IWSLT 2014 De-En] phÃ¢n vá»‹: Lá»c dá»¯ liá»‡u dá»±a trÃªn phÃ¢n vá»‹ cá»§a Ä‘iá»ƒm pháº§n thÆ°á»Ÿng
cho má»—i á»©ng viÃªn nguá»“n. ReST hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n vá»›i phÃ¢n vá»‹ tÄƒng dáº§n vÃ  hiá»‡u suáº¥t
bÃ£o hÃ²a sau ğ‘=90.

hoáº·c ngá»¯ cáº£nh. Thay vÃ o Ä‘Ã³, chÃºng ta cÃ³ thá»ƒ lá»c cÃ¡c cÃ¢u á»©ng viÃªn dá»±a trÃªn phÃ¢n vá»‹ cá»§a
Ä‘iá»ƒm sá»‘ Ä‘Æ°á»£c cho cá»§a nguá»“n cá»§a chÃºng. CÃ¡ch lá»c dá»±a trÃªn phÃ¢n vá»‹ nÃ y hiá»‡u quáº£ dáº«n Ä‘áº¿n viá»‡c thay Ä‘á»•i
ngÆ°á»¡ng cho má»—i cÃ¢u nguá»“n. Káº¿t quáº£ Ä‘Æ°á»£c trÃ¬nh bÃ y trong HÃ¬nh 15. Khi phÃ¢n vá»‹ lá»c
tÄƒng, hiá»‡u suáº¥t tÄƒng, nhÆ°ng nÃ³ báº¯t Ä‘áº§u bÃ£o hÃ²a, vÃ  lá»£i Ã­ch trá»Ÿ nÃªn nhá» hÆ¡n
sau ğ‘=90. Káº¿t quáº£ nhÃ¬n chung tÆ°Æ¡ng tá»± nhÆ° nhá»¯ng káº¿t quáº£ vá»›i lá»c dá»±a trÃªn ngÆ°á»¡ng toÃ n cá»¥c.

Chá»n ngÆ°á»¡ng dá»±a trÃªn ná»™i suy tuyáº¿n tÃ­nh giá»¯a Ä‘iá»ƒm sá»‘ trung bÃ¬nh vÃ  tá»‘i Ä‘a cá»§a á»©ng viÃªn. Má»™t cÃ¡ch thay tháº¿ Ä‘á»ƒ chá»‰ Ä‘á»‹nh bá»™ lá»c dá»±a trÃªn má»™t cÃ¢u nguá»“n lÃ  tÃ­nh toÃ¡n
bá»™ lá»c dá»±a trÃªn Ä‘iá»ƒm pháº§n thÆ°á»Ÿng tá»‘i Ä‘a (ğ‘‰max(ğ‘ ğ‘œğ‘¢ğ‘Ÿğ‘ğ‘’)) vÃ  Ä‘iá»ƒm á»©ng viÃªn trung bÃ¬nh (ğ‘‰mean(ğ‘ ğ‘œğ‘¢ğ‘Ÿğ‘ğ‘’))
cho má»™t cÃ¢u nguá»“n Ä‘Ã£ cho. Sau Ä‘Ã³, chÃºng ta chá»n ngÆ°á»¡ng cho má»—i cÃ¢u nguá»“n nhÆ° ğœğ›¾(ğ‘ ğ‘œğ‘¢ğ‘Ÿğ‘ğ‘’)=
ğ›¾ğ‘‰max(ğ‘ ğ‘œğ‘¢ğ‘Ÿğ‘ğ‘’)+(1âˆ’ğ›¾)ğ‘‰mean(ğ‘ ğ‘œğ‘¢ğ‘Ÿğ‘ğ‘’). á» má»—i bÆ°á»›c Improve, chÃºng ta tÄƒng tham sá»‘ ğ›¾. ChÃºng tÃ´i bÃ¡o cÃ¡o
káº¿t quáº£ Ä‘á»‘i vá»›i cÃ¡c giÃ¡ trá»‹ ğ›¾ khÃ¡c nhau trong HÃ¬nh 16. TÃ³m láº¡i, viá»‡c tÃ­nh toÃ¡n ngÆ°á»¡ng báº±ng cÃ¡ch
ná»™i suy Ä‘iá»ƒm tá»‘i Ä‘a vÃ  trung bÃ¬nh cho má»™t á»©ng viÃªn Ä‘Ã£ cho mang láº¡i káº¿t quáº£ tÆ°Æ¡ng tá»± nhÆ° cÃ¡ch tÃ­nh toÃ¡n ngÆ°á»¡ng dá»±a trÃªn phÃ¢n vá»‹
trÃªn má»—i nguá»“n. NgoÃ i ra, chÃºng ta cÃ³ thá»ƒ tháº¥y ráº±ng lá»‹ch trÃ¬nh cá»§a ngÆ°á»¡ng

--- TRANG 22 ---
Tá»± Huáº¥n Luyá»‡n TÄƒng CÆ°á»ng (ReST) cho MÃ´ HÃ¬nh NgÃ´n Ngá»¯

HÃ¬nh 16|[IWSLT 2014 De-En] thÃ­ nghiá»‡m ná»™i suy: NgÆ°á»¡ng trong bÆ°á»›c Improve Ä‘Æ°á»£c chá»n
cho má»—i cÃ¢u á»©ng viÃªn nhÆ° ğ›¾ğ‘‰max(ğ‘ ğ‘œğ‘¢ğ‘Ÿğ‘ğ‘’)+(1âˆ’ğ›¾)ğ‘‰mean(ğ‘ ğ‘œğ‘¢ğ‘Ÿğ‘ğ‘’). BÃªn trÃ¡i, thÃ­ nghiá»‡m vá»›i
I=1 cung cáº¥p cáº£i thiá»‡n vÃ  tÄƒng ğ›¾, Ä‘iá»u nÃ y cÅ©ng giÃºp Ã­ch Ä‘Ã¡ng ká»ƒ. BÃªn pháº£i, chÃºng tÃ´i trÃ¬nh bÃ y
káº¿t quáº£ vá»›i ğ›¾ báº¯t Ä‘áº§u vá»›i 0.5 thay vÃ¬ 0.5. NhÆ° cÃ³ thá»ƒ tháº¥y tá»« hÃ¬nh nÃ y, sá»‘
bÆ°á»›c Improve vÃ  cÃ¡ch chá»n ngÆ°á»¡ng áº£nh hÆ°á»Ÿng lá»›n Ä‘áº¿n hiá»‡u suáº¥t cuá»‘i cÃ¹ng cá»§a mÃ´ hÃ¬nh.

vÃ  sá»‘ bÆ°á»›c Improve cÃ³ tÃ¡c Ä‘á»™ng lá»›n Ä‘áº¿n hiá»‡u suáº¥t cuá»‘i cÃ¹ng cá»§a mÃ´ hÃ¬nh.

A.8. Thuáº­t toÃ¡n Baseline

Pháº§n nÃ y cung cáº¥p chi tiáº¿t vá» cÃ¡c hÃ m máº¥t mÃ¡t baseline Ä‘Æ°á»£c sá»­ dá»¥ng trong HÃ¬nh 5.

A.8.1. BVMPO

PhÆ°Æ¡ng phÃ¡p BVMPO tÆ°Æ¡ng tá»± nhÆ° DIME Ä‘Æ°á»£c Ä‘á» xuáº¥t bá»Ÿi Abdolmaleki et al. (2021). Sá»± khÃ¡c biá»‡t chÃ­nh
lÃ  chÃºng tÃ´i sá»­ dá»¥ng hÃ m state-value thay vÃ¬ Q function vá»›i v-trace (Espeholt et al., 2018), tÆ°Æ¡ng tá»±
nhÆ° V-MPO (Song et al., 2020). ChÃºng tÃ´i huáº¥n luyá»‡n cÃ¡c máº¡ng neural riÃªng biá»‡t cho chÃ­nh sÃ¡ch vÃ  hÃ m giÃ¡ trá»‹. ChÃ­nh sÃ¡ch
Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c vá»›i BC vÃ  máº¡ng giÃ¡ trá»‹ Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c vá»›i BVE Ä‘á»ƒ Æ°á»›c tÃ­nh giÃ¡ trá»‹ hÃ nh vi
ğ‘‰ğ›½. BVMPO sá»­ dá»¥ng chÃ­nh sÃ¡ch behavioral cloning ğœ‹ğ›½(ğ‘|ğ‘ ) nhÆ° má»™t prior hÃ nh vi:

Lğµğ‘‰ğ‘€ğ‘ƒğ‘‚ =Lğ‘‰ğ‘€ğ‘ƒğ‘‚+ğœ†KL(ğœ‹ğ›½|ğœ‹). (4)

TrÃ¡i ngÆ°á»£c vá»›i DIME, BVMPO báº¯t Ä‘áº§u vá»›i há»‡ sá»‘ cá»‘ Ä‘á»‹nh ğœ†=1 vÃ  anneal nÃ³ Ä‘áº¿n 1ğ‘’âˆ’5 trong
quÃ¡ trÃ¬nh huáº¥n luyá»‡n. ChÃºng tÃ´i tháº¥y ráº±ng báº¯t Ä‘áº§u vá»›i ğœ† lá»›n vÃ  anneal nÃ³ á»•n Ä‘á»‹nh quÃ¡ trÃ¬nh huáº¥n luyá»‡n mÃ  khÃ´ng cÃ³
sá»± giáº£m hiá»‡u suáº¥t Ä‘Ã¡ng chÃº Ã½. TÆ°Æ¡ng tá»±, viá»‡c anneal há»‡ sá»‘ regularization hÃ nh vi cÅ©ng
Ä‘Æ°á»£c chá»‰ ra lÃ  hiá»‡u quáº£ trong Q-learning ngoáº¡i tuyáº¿n (Agarwal et al., 2022).

A.8.2. GOLD

HÃ m máº¥t mÃ¡t GOLD Ä‘Æ°á»£c giá»›i thiá»‡u bá»Ÿi Pang vÃ  He (2021). Khi sá»­ dá»¥ng nÃ³ trong bÆ°á»›c Improve, chÃºng tÃ´i báº¯t Ä‘áº§u vá»›i
má»™t chÃ­nh sÃ¡ch BC. Trong táº¥t cáº£ cÃ¡c thÃ­ nghiá»‡m GOLD, chÃºng tÃ´i sá»­ dá»¥ng ğ‘˜=5 bÆ°á»›c Ä‘á»ƒ unroll mÃ´ hÃ¬nh MLE vÃ o tÆ°Æ¡ng lai cho
cÃ¡c tÃ­nh toÃ¡n pháº§n thÆ°á»Ÿng. Viá»‡c tÄƒng ğ‘˜ khÃ´ng cáº£i thiá»‡n hiá»‡u suáº¥t.

A.8.3. Offline Actor Critic (OAC)

Offline actor critic lÃ  má»™t phÆ°Æ¡ng phÃ¡p actor critic Ä‘Æ°á»£c Ä‘á» xuáº¥t bá»Ÿi Mathieu et al. (2021) nÆ¡i hÃ m state-value
Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»ƒ Æ°á»›c tÃ­nh giÃ¡ trá»‹ hÃ nh vi trong táº­p dá»¯ liá»‡u (Gulcehre et al., 2021). KhÃ´ng giá»‘ng
Mathieu et al. (2021) chÃºng tÃ´i khÃ´ng sá»­ dá»¥ng V-trace vÃ¬ nÃ³ khÃ´ng cáº£i thiá»‡n so vá»›i hÃ m lá»£i tháº¿ vanilla
trong cÃ¡c thÃ­ nghiá»‡m ban Ä‘áº§u cá»§a chÃºng tÃ´i.

A.8.4. HÃ m GiÃ¡ trá»‹

ChÃºng tÃ´i huáº¥n luyá»‡n cÃ¡c hÃ m state-value trÃªn cÃ¡c táº­p dá»¯ liá»‡u IWSLT 2014 De-En vÃ  WMT 2020 Zh-En sau bÆ°á»›c grow
ban Ä‘áº§u. CÃ¡c hÃ m giÃ¡ trá»‹ Æ°á»›c tÃ­nh giÃ¡ trá»‹ hÃ nh vi cá»§a chÃ­nh sÃ¡ch trÃªn táº­p dá»¯ liá»‡u huáº¥n luyá»‡n. CÃ¡c
hÃ m giÃ¡ trá»‹ dá»± Ä‘oÃ¡n tá»•ng pháº§n thÆ°á»Ÿng Ä‘Æ°á»£c chiáº¿t kháº¥u cho má»—i tá»« cho Ä‘áº¿n cuá»‘i cÃ¢u. ChÃºng tÃ´i
sá»­ dá»¥ng kiáº¿n trÃºc encoder-decoder dá»±a trÃªn transformer cho cÃ¡c hÃ m giÃ¡ trá»‹. Encoder nháº­n
cÃ¢u nguá»“n lÃ m Ä‘áº§u vÃ o, vÃ  decoder dá»± Ä‘oÃ¡n Monte Carlo discounted returns cÃ³ Ä‘iá»u kiá»‡n
trÃªn nguá»“n vÃ  lá»‹ch sá»­ cá»§a cÃ¡c chuá»—i token Ä‘Æ°á»£c táº¡o trong Ä‘Ã­ch.

TrÃªn cÃ¡c táº­p huáº¥n luyá»‡n cá»§a IWSLT vÃ  WMT, cÃ¡c hÃ m giÃ¡ trá»‹ cá»§a chÃºng tÃ´i Ä‘áº¡t Ä‘Æ°á»£c tÆ°Æ¡ng quan Kendall-tau lÃ 
92.4% vÃ  tÆ°Æ¡ng quan Spearman trÃªn 99% Ä‘á»‘i vá»›i Ä‘iá»ƒm sá»‘ mÃ´ hÃ¬nh pháº§n thÆ°á»Ÿng trong táº­p dá»¯ liá»‡u.
VÃ¬ chÃºng tÃ´i chá»‰ thá»±c hiá»‡n RL ngoáº¡i tuyáº¿n, cÃ¡c hÃ m giÃ¡ trá»‹ khÃ´ng cáº§n tá»•ng quÃ¡t hÃ³a vÆ°á»£t ra ngoÃ i táº­p dá»¯ liá»‡u huáº¥n luyá»‡n.

A.9. ReST: Giáº£i thÃ­ch dÃ¢n sá»‘

á» Ä‘Ã¢y, chÃºng tÃ´i cung cáº¥p má»™t giáº£i thÃ­ch dÃ¢n sá»‘ cá»§a thuáº­t toÃ¡n ReST. Trong thiáº¿t láº­p nÃ y, bÆ°á»›c huáº¥n luyá»‡n BC
ban Ä‘áº§u cÃ³ thá»ƒ Ä‘Æ°á»£c coi nhÆ° viá»‡c xÃ¡c Ä‘á»‹nh ğœƒ báº±ng cÃ¡ch tá»‘i thiá»ƒu hÃ³a

KL(ğ‘(ğ’™,ğ’š)||ğœ‹ğœƒ(ğ’™,ğ’š))=âˆ‘ï¸
ğ’™,ğ’šğ‘(ğ’™,ğ’š)logğ‘(ğ’™,ğ’š)
ğœ‹ğœƒ(ğ’™,ğ’š)

=âˆ‘ï¸
ğ’™,ğ’šğ‘(ğ’™,ğ’š)logğ‘(ğ’š|ğ’™)
ğœ‹ğœƒ(ğ’š|ğ’™)

=ğ”¼ğ’™âˆ¼ğ‘(ğ’™)[KL(ğ‘(ğ’š|ğ’™)||ğœ‹ğœƒ(ğ’š|ğ’™))],

trong Ä‘Ã³ KL lÃ  Ä‘á»™ lá»‡ch Kullbackâ€“Leibler, ğ‘(ğ’™,ğ’š)=ğ‘(ğ’™)ğ‘(ğ’š|ğ’™) lÃ  phÃ¢n phá»‘i dá»¯ liá»‡u (huáº¥n luyá»‡n)
vÃ  ğœ‹ğœƒ(ğ’™,ğ’š)=ğ‘(ğ’™)ğœ‹ğœƒ(ğ’š|ğ’™). HÃ£y gá»i bá»™ tá»‘i thiá»ƒu hÃ³a ğœƒ0.

Giáº£ sá»­ bÃ¢y giá» ráº±ng ngÆ°á»i ta cÃ³ tham sá»‘ ğœƒğ‘˜ á»Ÿ cuá»‘i cÃ¡c bÆ°á»›c Improve cá»§a bÆ°á»›c Grow thá»© ğ‘˜.
Sau Ä‘Ã³ á»Ÿ bÆ°á»›c Grow thá»© (ğ‘˜+1) tiáº¿p theo, chÃºng ta xem xÃ©t cÃ¡c bÆ°á»›c Improve sá»­ dá»¥ng má»™t chuá»—i ngÆ°á»¡ng tÄƒng dáº§n
(ğœğ‘–)ğ¼
ğ‘–=1 Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ lá»c phÃ¢n phá»‘i dá»¯ liá»‡u cÃ³ sáºµn (há»—n há»£p cá»§a phÃ¢n phá»‘i dá»¯ liá»‡u gá»‘c
vÃ  phÃ¢n phá»‘i dá»¯ liá»‡u tá»•ng há»£p) Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c má»™t phÃ¢n phá»‘i má»›i

ğœ‹ğœğ‘–
ğœƒğ‘˜(ğ’™,ğ’š)âˆ{(1âˆ’ğœ†)ğ‘(ğ’™,ğ’š)+ğœ†ğœ‹ğœƒğ‘˜(ğ’™,ğ’š)}ğ•€(ğ‘…(ğ’™,ğ’š)> ğœğ‘–).

Sau Ä‘Ã³ chÃºng ta cÃ³ Ä‘Æ°á»£c tham sá»‘ tiáº¿p theo ğœƒ báº±ng cÃ¡ch tá»‘i thiá»ƒu hÃ³a KL

KL(ğœ‹ğœğ‘–
ğœƒğ‘˜(ğ’™,ğ’š)||ğœ‹ğœƒ(ğ’™,ğ’š))

vÃ  tiáº¿p tá»¥c tÄƒng ngÆ°á»¡ng cho Ä‘áº¿n khi pháº§n thÆ°á»Ÿng ğ”¼ğœ‹ğœƒ(ğ’™,ğ’š)[ğ‘…(ğ’™,ğ’š)] ngá»«ng tÄƒng. Äiá»u nÃ y mang láº¡i
ğœƒğ‘˜+1.

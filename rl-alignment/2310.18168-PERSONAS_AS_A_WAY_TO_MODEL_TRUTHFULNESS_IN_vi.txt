PERSONAS LÃ€ Má»˜T CÃCH Äá»‚ MÃ” HÃŒNH HÃ“A TÃNH TRUNG THá»°C TRONG CÃC MÃ” HÃŒNH NGÃ”N NGá»®

Nitish Joshi1âˆ—Javier Rando2âˆ—Abulhair Saparov1Najoung Kim3He He1
1New York University2ETH Zurich3Boston University
{nitish}@nyu.edu {javier.rando}@ai.ethz.ch

TÃ“M Táº®T
CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn lÆ°á»£ng lá»›n vÄƒn báº£n tá»« internet, chá»©a cáº£ thÃ´ng tin chÃ­nh xÃ¡c vÃ  gÃ¢y hiá»ƒu láº§m vá» tháº¿ giá»›i. Máº·c dÃ¹ trÃ¡i ngÆ°á»£c vá»›i quan Ä‘iá»ƒm cá»• Ä‘iá»ƒn vá» LM, nghiÃªn cá»©u gáº§n Ä‘Ã¢y Ä‘Ã£ chá»‰ ra ráº±ng giÃ¡ trá»‹ chÃ¢n lÃ½ cá»§a má»™t phÃ¡t biá»ƒu cÃ³ thá»ƒ Ä‘Æ°á»£c rÃºt ra tá»« cÃ¡c biá»ƒu diá»…n cá»§a mÃ´ hÃ¬nh. BÃ i bÃ¡o nÃ y trÃ¬nh bÃ y má»™t lá»i giáº£i thÃ­ch vá» lÃ½ do táº¡i sao LM cÃ³ váº» biáº¿t sá»± tháº­t máº·c dÃ¹ khÃ´ng Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i nhÃ£n chÃ¢n lÃ½. ChÃºng tÃ´i Ä‘Æ°a ra giáº£ thuyáº¿t ráº±ng dá»¯ liá»‡u huáº¥n luyá»‡n trÆ°á»›c Ä‘Æ°á»£c táº¡o ra bá»Ÿi cÃ¡c nhÃ³m tÃ¡c nhÃ¢n (khÃ´ng) trung thá»±c cÃ³ Ä‘áº§u ra chia sáº» cÃ¡c Ä‘áº·c Ä‘iá»ƒm chung, vÃ  chÃºng táº¡o thÃ nh má»™t persona (khÃ´ng) trung thá»±c. Báº±ng cÃ¡ch huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u nÃ y, LM cÃ³ thá»ƒ suy luáº­n vÃ  biá»ƒu diá»…n persona trong khÃ´ng gian kÃ­ch hoáº¡t cá»§a nÃ³. Äiá»u nÃ y cho phÃ©p mÃ´ hÃ¬nh phÃ¢n tÃ¡ch sá»± tháº­t khá»i sá»± giáº£ dá»‘i vÃ  kiá»ƒm soÃ¡t tÃ­nh trung thá»±c cá»§a viá»‡c táº¡o ra. ChÃºng tÃ´i chá»‰ ra báº±ng chá»©ng cho giáº£ thuyáº¿t persona qua hai quan sÃ¡t: (1) chÃºng tÃ´i cÃ³ thá»ƒ dÃ² tÃ¬m liá»‡u cÃ¢u tráº£ lá»i cá»§a mÃ´ hÃ¬nh cÃ³ trung thá»±c trÆ°á»›c khi nÃ³ Ä‘Æ°á»£c táº¡o ra; (2) tinh chá»‰nh mÃ´ hÃ¬nh trÃªn má»™t táº­p há»£p cÃ¡c sá»± kiá»‡n cáº£i thiá»‡n tÃ­nh trung thá»±c cá»§a nÃ³ trÃªn cÃ¡c chá»§ Ä‘á» chÆ°a tháº¥y. Tiáº¿p theo, sá»­ dá»¥ng sá»‘ há»c nhÆ° má»™t mÃ´i trÆ°á»ng tá»•ng há»£p, chÃºng tÃ´i chá»‰ ra ráº±ng cáº¥u trÃºc cá»§a dá»¯ liá»‡u huáº¥n luyá»‡n trÆ°á»›c lÃ  ráº¥t quan trá»ng Ä‘á»ƒ mÃ´ hÃ¬nh suy luáº­n persona trung thá»±c. NhÃ¬n chung, cÃ¡c phÃ¡t hiá»‡n cá»§a chÃºng tÃ´i gá»£i Ã½ ráº±ng cÃ¡c mÃ´ hÃ¬nh cÃ³ thá»ƒ khai thÃ¡c cÃ¡c cáº¥u trÃºc phÃ¢n cáº¥p trong dá»¯ liá»‡u Ä‘á»ƒ há»c cÃ¡c khÃ¡i niá»‡m trá»«u tÆ°á»£ng nhÆ° tÃ­nh trung thá»±c.

1 GIá»šI THIá»†U
CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c trÃªn lÆ°á»£ng dá»¯ liá»‡u ngÃ y cÃ ng tÄƒng tá»« internet (Brown et al., 2020; Chowdhery et al., 2022)â€”má»™t táº­p dá»¯ liá»‡u nhiá»…u chá»©a cáº£ nhá»¯ng phÃ¡t biá»ƒu chÃ­nh xÃ¡c vÃ  khÃ´ng chÃ­nh xÃ¡c vá» tháº¿ giá»›i. VÃ­ dá»¥, CDC tuyÃªn bá»‘ ráº±ng "háº§u háº¿t cÃ¡c nghiÃªn cá»©u cho tháº¥y váº¯c xin COVID lÃ  an toÃ n" (Ä‘Ãºng), trong khi InfoWars tuyÃªn bá»‘ ráº±ng "cÃ¡c cháº¥t gÃ¢y Ã´ nhiá»…m DNA trong tiÃªm COVID cÃ³ thá»ƒ gÃ¢y ra ung thÆ°" (sai). Nhá»¯ng quan niá»‡m sai láº§m vÃ  thuyáº¿t Ã¢m mÆ°u nhÆ° váº­y gÃ¢y ra rá»§i ro vá» thÃ´ng tin sai lá»‡ch khi chÃºng cÃ³ thá»ƒ Ä‘Æ°á»£c nháº¯c láº¡i bá»Ÿi cÃ¡c mÃ´ hÃ¬nh khi tÆ°Æ¡ng tÃ¡c vá»›i ngÆ°á»i dÃ¹ng (Lin et al., 2021).

Trong cÃ´ng trÃ¬nh nÃ y, vÄƒn báº£n trung thá»±c Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a lÃ  vÄƒn báº£n phÃ¹ há»£p vá»›i cÃ¡c sá»± kiá»‡n mÃ  háº§u háº¿t cÃ¡c chuyÃªn gia trong lÄ©nh vá»±c Ä‘á»“ng Ã½. VÄƒn báº£n khÃ´ng trung thá»±c, khÃ¡c biá»‡t vá»›i cÃ¡c lá»—i rÃµ rÃ ng, Ä‘á» cáº­p Ä‘áº¿n thÃ´ng tin cÃ³ váº» há»£p lÃ½ nhÆ°ng khÃ´ng chÃ­nh xÃ¡c cÃ³ thá»ƒ gÃ¢y hiá»ƒu láº§m cho ngÆ°á»i dÃ¹ng. Quan trá»ng lÃ , chÃºng tÃ´i giá»›i háº¡n táº­p trung vÃ o vÄƒn báº£n khÃ´ng trung thá»±c Ä‘Æ°á»£c há»— trá»£ bá»Ÿi dá»¯ liá»‡u huáº¥n luyá»‡n trÆ°á»›c, thay vÃ¬ nhá»¯ng áº£o giÃ¡c Ä‘Æ°á»£c cháº¿ táº¡o bá»Ÿi chÃ­nh cÃ¡c mÃ´ hÃ¬nh vÃ  khÃ´ng cÃ³ cÄƒn cá»©.

Vá»›i má»™t táº­p huáº¥n luyá»‡n nhiá»…u, lÃ m tháº¿ nÃ o má»™t LLM chá»n cÃ¡c cÃ¢u tráº£ lá»i cá»§a nÃ³? Theo vÃ­ dá»¥ trÆ°á»›c Ä‘Ã³, khi Ä‘Æ°á»£c há»i vá» sá»± an toÃ n cá»§a váº¯c xin COVID, quan Ä‘iá»ƒm cá»• Ä‘iá»ƒn vá» LM gá»£i Ã½ ráº±ng chÃºng cÃ³ nhiá»u kháº£ nÄƒng táº¡o ra phÃ¡t biá»ƒu thÆ°á»ng xuyÃªn nháº¥t, báº¥t ká»ƒ nÃ³ cÃ³ Ä‘Ãºng hay khÃ´ng. Tuy nhiÃªn, nghiÃªn cá»©u gáº§n Ä‘Ã¢y cho tháº¥y ráº±ng giÃ¡ trá»‹ chÃ¢n lÃ½ cá»§a má»™t phÃ¡t biá»ƒu cÃ³ thá»ƒ Ä‘Æ°á»£c rÃºt ra tá»« embedding cá»§a nÃ³ (Burns et al., 2022; Li et al., 2023), gá»£i Ã½ ráº±ng LM cÃ³ má»™t khÃ¡i niá»‡m ná»™i táº¡i vá» sá»± tháº­t. Sá»± khÃ¡c biá»‡t nÃ y thÃºc Ä‘áº©y cÃ¢u há»i nghiÃªn cá»©u chÃ­nh cá»§a chÃºng tÃ´i: lÃ m tháº¿ nÃ o LM phÃ¢n biá»‡t sá»± tháº­t khá»i sá»± giáº£ dá»‘i trong má»™t táº­p dá»¯ liá»‡u nhiá»…u?

BÃ i bÃ¡o nÃ y trÃ¬nh bÃ y má»™t lá»i giáº£i thÃ­ch cÃ³ thá»ƒ cho lÃ½ do táº¡i sao LLM cÃ³ váº» "biáº¿t" Ä‘iá»u gÃ¬ lÃ  Ä‘Ãºng máº·c dÃ¹ khÃ´ng Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u vá»›i nhÃ£n chÃ¢n lÃ½. Giáº£ thuyáº¿t cá»§a chÃºng tÃ´i dá»±a trÃªn quÃ¡ trÃ¬nh táº¡o ra sau Ä‘Ã¢y cá»§a dá»¯ liá»‡u huáº¥n luyá»‡n trÆ°á»›c. VÄƒn báº£n trÃªn internet Ä‘Æ°á»£c táº¡o ra bá»Ÿi cÃ¡c nguá»“n khÃ¡c nhau (vÃ­ dá»¥, CDC), mÃ  chÃºng tÃ´i gá»i lÃ  cÃ¡c tÃ¡c nhÃ¢n theo Andreas (2022). MÃ´ hÃ¬nh hÃ³a cÃ¡c tÃ¡c nhÃ¢n nÃ y cho phÃ©p LLM táº¡o ra vÄƒn báº£n phÃ¹ há»£p vá»›i niá»m tin tÆ°Æ¡ng á»©ng cá»§a tÃ¡c nhÃ¢n (vÃ­ dá»¥, váº¯c xin COVID lÃ  an toÃ n). Giáº£ Ä‘á»‹nh ráº±ng khÃ´ng cÃ³

MODERNAADMITSVAXCAUSESCANCER!HugeDevelopmentAsMillionsDieFromCovidInjections.Bombshell!95%COVIDDeathsAmongVaccinated.TÃ¡c nhÃ¢n 1: InfoWars TÃ¡c nhÃ¢n 2: Before It's NewsTÃ¡c nhÃ¢n 3: The New York TimesFeelingTerribleAfterYourCovidShot?ThenIt'sProbablyWorking.TÃ¡c nhÃ¢n 4: BBCCovidvaccinesbeinggiventomillionsofpeopleintheUKareextremelysafe.Persona Trung thá»±c
ğŸ˜‡Persona KhÃ´ng trung thá»±c
ğŸ˜ˆCÃ¡c tÃ¡c nhÃ¢n Ä‘Æ°á»£c nhÃ³m thÃ nh personas trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n LLMTrong quÃ¡ trÃ¬nh suy luáº­n, cÃ¡c cÃ¢u tráº£ lá»i phÃ¹ há»£p vá»›i persona Ä‘Æ°á»£c suy luáº­nQ:WhyistheCOVIDvaccinesodeadly?LLM
ğŸ˜ˆA:TheCOVIDvaccineissodeadlybecauseitisaliveattenuatedvaccine.Q:AreCOVIDvaccinessafeforhumans?LLM
ğŸ˜‡A:Yes,COVIDvaccineshavebeenshowntobesafeforhumans.

"Persona nÃ o cÃ³ nhiá»u kháº£ nÄƒng táº¡o ra vÄƒn báº£n nÃ y hÆ¡n?"HÃ¬nh 1: Giáº£ thuyáº¿t chÃ­nh cá»§a chÃºng tÃ´i lÃ  LLM cÃ³ thá»ƒ phÃ¢n biá»‡t sá»± tháº­t khá»i sá»± giáº£ dá»‘i báº±ng cÃ¡ch mÃ´ hÃ¬nh hÃ³a cÃ¡c personas trung thá»±c trong dá»¯ liá»‡u huáº¥n luyá»‡n trÆ°á»›câ€”nhÃ³m cÃ¡c tÃ¡c nhÃ¢n cÃ³ kháº£ nÄƒng trung thá»±c (trÃ¡i). Trong quÃ¡ trÃ¬nh suy luáº­n, mÃ´ hÃ¬nh cÃ³ thá»ƒ suy luáº­n persona (khÃ´ng) trung thá»±c tá»« cÃ¢u há»i, vÃ  pháº£n há»“i (khÃ´ng) trung thá»±c tÆ°Æ¡ng á»©ng (pháº£i).

tÃ¡c nhÃ¢n oracle táº¡o ra vÄƒn báº£n trung thá»±c phá»• quÃ¡t, Ä‘á»ƒ cÃ³ má»™t khÃ¡i niá»‡m toÃ n cáº§u vá» sá»± tháº­t, mÃ´ hÃ¬nh pháº£i káº¿t ná»‘i nhiá»u tÃ¡c nhÃ¢n trung thá»±c trong cÃ¡c lÄ©nh vá»±c khÃ¡c nhau. ChÃºng tÃ´i Ä‘Æ°a ra giáº£ thuyáº¿t ráº±ng cÃ¡c tÃ¡c nhÃ¢n nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c nhÃ³m láº¡i vá»›i nhau bá»Ÿi cÃ¡c Ä‘áº·c Ä‘iá»ƒm chung cá»§a Ä‘áº§u ra cá»§a chÃºng (vÃ­ dá»¥, tÃ­nh trang trá»ng vÃ  sá»± phÃ¹ há»£p vá»›i cÃ¡c sá»± kiá»‡n nháº¥t Ä‘á»‹nh), tá»©c lÃ  chÃºng chia sáº» má»™t persona kiá»ƒm soÃ¡t quÃ¡ trÃ¬nh táº¡o ra. Báº±ng cÃ¡ch mÃ´ hÃ¬nh hÃ³a vÃ  biá»ƒu diá»…n persona cá»§a tÃ¡c nhÃ¢n cho má»™t Ä‘oáº¡n vÄƒn báº£n, LLM cÃ³ thá»ƒ phÃ¢n tÃ¡ch sá»± tháº­t khá»i sá»± giáº£ dá»‘i.

ChÃºng tÃ´i cung cáº¥p báº±ng chá»©ng cho giáº£ thuyáº¿t persona báº±ng hai quan sÃ¡t Ä‘Ã¡ng ngáº¡c nhiÃªn mÃ  chÃºng tÃ´i tÃ¬m tháº¥y trÃªn benchmark TruthfulQA (Lin et al., 2021). Äáº§u tiÃªn, sá»­ dá»¥ng linear probing, chÃºng tÃ´i cÃ³ thá»ƒ dá»± Ä‘oÃ¡n liá»‡u cÃ¢u tráº£ lá»i Ä‘Æ°á»£c táº¡o ra cÃ³ trung thá»±c hay khÃ´ng chá»‰ tá»« embeddings cá»§a cÃ¢u há»i, gá»£i Ã½ ráº±ng mÃ´ hÃ¬nh suy luáº­n liá»‡u tÃ¡c nhÃ¢n cÃ³ persona trung thá»±c tá»« ngá»¯ cáº£nh (cÃ¢u há»i). Thá»© hai, tinh chá»‰nh má»™t LLM trÃªn má»™t táº­p há»£p cÃ¡c cáº·p cÃ¢u há»i-cÃ¢u tráº£ lá»i Ä‘Ãºng cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ tÃ­nh trung thá»±c cá»§a nÃ³ trÃªn cÃ¡c chá»§ Ä‘á» khÃ´ng liÃªn quan máº·c dÃ¹ cÃ³ Ã­t chuyá»ƒn giao kiáº¿n thá»©c tá»« cÃ¡c vÃ­ dá»¥ tinh chá»‰nh (vÃ­ dá»¥, nhÃ³m mÃ¡u khÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n tÃ­nh cÃ¡ch) Ä‘áº¿n cÃ¡c vÃ­ dá»¥ kiá»ƒm tra (vÃ­ dá»¥, thá»i tiáº¿t má»™t ngÃ y khÃ´ng pháº£n Ã¡nh khÃ­ háº­u). Viá»‡c tá»•ng quÃ¡t hÃ³a chá»‰ cÃ³ thá»ƒ khi LLM Ä‘Ã£ há»c Ä‘Æ°á»£c má»™t biá»ƒu diá»…n persona kiá»ƒm soÃ¡t tÃ­nh trung thá»±c cá»§a cÃ¡c sá»± kiá»‡n qua cÃ¡c lÄ©nh vá»±c.

Tiáº¿p theo, chÃºng tÃ´i xÃ¡c minh giáº£ thuyáº¿t cá»§a mÃ¬nh thÃ´ng qua má»™t mÃ´i trÆ°á»ng tá»•ng há»£p cá»§a sá»‘ há»c, nÆ¡i cÃ¡c tÃ¡c nhÃ¢n khÃ¡c nhau cÃ³ niá»m tin Ä‘Ãºng hoáº·c sai vá» ngá»¯ nghÄ©a cá»§a má»—i toÃ¡n tá»­. ChÃºng tÃ´i huáº¥n luyá»‡n LM trÃªn cÃ¡c phÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»£c táº¡o ra bá»Ÿi cÃ¡c tÃ¡c nhÃ¢n nÃ y. Báº±ng cÃ¡ch kiá»ƒm soÃ¡t quÃ¡ trÃ¬nh táº¡o dá»¯ liá»‡u, chÃºng tÃ´i chá»‰ ra ráº±ng cÃ¡c mÃ´ hÃ¬nh cÃ³ thá»ƒ phÃ¢n tÃ¡ch cÃ¡c phÆ°Æ¡ng trÃ¬nh Ä‘Ãºng vÃ  sai, vÃ  tá»•ng quÃ¡t hÃ³a hÃ nh vi trung thá»±c cá»§a tÃ¡c nhÃ¢n cho cÃ¡c toÃ¡n tá»­ chÆ°a tháº¥y, nhÆ°ng Ä‘iá»u nÃ y chá»‰ cÃ³ thá»ƒ khi má»™t persona trung thá»±c tá»“n táº¡i, tá»©c lÃ  cÃ³ má»™t nhÃ³m cÃ¡c tÃ¡c nhÃ¢n trung thá»±c cÃ³ thá»ƒ nháº­n dáº¡ng Ä‘Æ°á»£c bá»Ÿi cÃ¡c Ä‘áº·c Ä‘iá»ƒm chung cá»§a viá»‡c táº¡o ra cá»§a chÃºng.

2 GIáº¢ THUYáº¾T PERSONA

ChÃºng tÃ´i giáº£ Ä‘á»‹nh ráº±ng dá»¯ liá»‡u huáº¥n luyá»‡n trÆ°á»›c bao gá»“m má»™t táº­p há»£p cÃ¡c phÃ¡t biá»ƒu x Ä‘Æ°á»£c táº¡o ra bá»Ÿi cÃ¡c tÃ¡c nhÃ¢n khÃ¡c nhau Ä‘Æ°á»£c tham sá»‘ hÃ³a bá»Ÿi Î¸agentâˆˆÎ˜, cÃ³ thá»ƒ chá»‰ Ä‘á»‹nh niá»m tin cá»§a tÃ¡c nhÃ¢n vÃ  phong cÃ¡ch táº¡o ra cá»§a nÃ³: xâˆ¼ptext(Â· |Î¸agent). VÃ­ dá»¥, trong HÃ¬nh 1, tÃ¡c nhÃ¢n "BBC" cÃ³ niá»m tin ráº±ng váº¯c xin COVID lÃ  an toÃ n vÃ  táº¡o ra vÄƒn báº£n vá»›i phong cÃ¡ch trang trá»ng. HÆ¡n ná»¯a, cÃ¡c nhÃ³m tÃ¡c nhÃ¢n Ä‘Æ°á»£c táº¡o ra tá»« má»™t persona Ä‘Æ°á»£c tham sá»‘ hÃ³a bá»Ÿi Î»persona :Î¸agentâˆ¼pagent(Â· |Î»persona ). Cá»¥ thá»ƒ, cÃ¡c tÃ¡c nhÃ¢n cÃ³ nhiá»u kháº£ nÄƒng trung thá»±c hÆ¡n chia sáº» má»™t persona, do Ä‘Ã³ chÃºng gáº§n nhau trong Î˜. Trong HÃ¬nh 1, cÃ¡c tÃ¡c nhÃ¢n "NYT" vÃ  "BBC" cÃ³ thá»ƒ Ä‘Æ°á»£c nhÃ³m bá»Ÿi niá»m tin chung vÃ  phong cÃ¡ch viáº¿t tÆ°Æ¡ng tá»± cá»§a chÃºng. Trong cuá»™c tháº£o luáº­n sau Ä‘Ã¢y, chÃºng tÃ´i váº«n báº¥t kháº£ tri Ä‘á»‘i vá»›i cÃ¡c Ä‘áº·c Ä‘iá»ƒm cá»¥ thá»ƒ cho phÃ©p viá»‡c nhÃ³m cÃ¡c tÃ¡c nhÃ¢n trung thá»±c, vÃ  chÃºng tÃ´i tháº£o luáº­n liá»‡u persona trung thá»±c biá»ƒu diá»…n sá»± tháº­t thá»±c táº¿ hay chá»‰ lÃ  cÃ¡c Ä‘áº·c Ä‘iá»ƒm bá» ngoÃ i liÃªn quan Ä‘áº¿n vÄƒn báº£n trung thá»±c trong Pháº§n 5.

Giáº£ thuyáº¿t chÃ­nh cá»§a chÃºng tÃ´i bao gá»“m hai pháº§n:
1.LM suy luáº­n persona cá»§a cÃ¡c nhÃ³m tÃ¡c nhÃ¢n (khÃ´ng) trung thá»±c tá»« ngá»¯ cáº£nh, biá»ƒu diá»…n nÃ³ trong khÃ´ng gian kÃ­ch hoáº¡t, vÃ  táº¡o ra vÄƒn báº£n phÃ¹ há»£p vá»›i persona Ä‘Æ°á»£c suy luáº­n.

0 5 10 15 20 25 30
Embedding tá»« lá»›p0.350.400.450.500.550.600.650.70Äiá»ƒm F1 cÃ³ trá»ng sá»‘Hiá»‡u suáº¥t probes dá»± Ä‘oÃ¡n tÃ­nh trung thá»±c
Táº¥t cáº£ cÃ¢u há»i
ÄoÃ¡n ngáº«u nhiÃªn
HÆ°á»›ng dáº«n Báº¯t Ä‘áº§u cÃ¢u há»i Giá»¯a cÃ¢u há»i Token cuá»‘i cÃ¹ng
Token Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ probing0.350.400.450.500.550.600.650.70Äiá»ƒm F1 cÃ³ trá»ng sá»‘
Hiá»‡u suáº¥t probes qua cÃ¡c tokens ngá»¯ cáº£nh
ÄoÃ¡n ngáº«u nhiÃªnHÃ¬nh 2: (TrÃ¡i) Trung bÃ¬nh vÃ  Ä‘á»™ lá»‡ch chuáº©n cho F1 cá»§a linear probes Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn má»—i lá»›p mÃ´ hÃ¬nh Ä‘á»ƒ dá»± Ä‘oÃ¡n náº¿u pháº£n há»“i sáº½ trung thá»±c, qua 20 láº§n thá»±c hiá»‡n ngáº«u nhiÃªn. (Pháº£i) F1 khi huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ probes táº¡i cÃ¡c embeddings token Ä‘áº§u vÃ o khÃ¡c nhau. F1 tá»‘t nháº¥t Ä‘Æ°á»£c Ä‘áº¡t Ä‘Æ°á»£c khi sá»­ dá»¥ng toÃ n bá»™ cÃ¢u há»i. ThÃªm cÃ¡c chá»‰ sá»‘ vÃ  ablations trong Phá»¥ lá»¥c B.

2.(1) chá»‰ cÃ³ thá»ƒ náº¿u cÃ¡c tÃ¡c nhÃ¢n táº¡o ra vÄƒn báº£n trung thá»±c trong dá»¯ liá»‡u huáº¥n luyá»‡n trÆ°á»›c thá»±c sá»± chia sáº» má»™t persona (tá»©c lÃ  viá»‡c táº¡o ra cá»§a chÃºng cÃ³ cÃ¡c Ä‘áº·c Ä‘iá»ƒm chung).

Äá»ƒ xÃ¡c minh giáº£ thuyáº¿t nÃ y, Ä‘áº§u tiÃªn chÃºng tÃ´i cung cáº¥p báº±ng chá»©ng cho sá»± tá»“n táº¡i cá»§a má»™t persona trung thá»±c tiá»m áº©n trong cÃ¡c biá»ƒu diá»…n cá»§a LLM (Pháº§n 3). Sau Ä‘Ã³ chÃºng tÃ´i chá»‰ ra ráº±ng má»™t biá»ƒu diá»…n nhÆ° váº­y phÃ¡t sinh tá»« cáº¥u trÃºc persona-tÃ¡c nhÃ¢n cá»§a dá»¯ liá»‡u huáº¥n luyá»‡n trÆ°á»›c thÃ´ng qua cÃ¡c thÃ­ nghiá»‡m tá»•ng há»£p (Pháº§n 4).

3 Báº°NG CHá»¨NG Vá»€ LLM MÃ” HÃŒNH HÃ“A PERSONAS

3.1 LLM SUY LUáº¬N PERSONAS Tá»ª NGá»® Cáº¢NH

Äá»ƒ kiá»ƒm tra giáº£ thuyáº¿t 1, chÃºng tÃ´i xÃ¡c minh náº¿u mÃ´ hÃ¬nh cÃ³ thá»ƒ suy luáº­n persona (khÃ´ng) trung thá»±c tá»« ngá»¯ cáº£nh báº±ng cÃ¡ch probing cÃ¡c kÃ­ch hoáº¡t ná»™i táº¡i cá»§a nÃ³. Cá»¥ thá»ƒ, chÃºng tÃ´i sáº½ chá»‰ ra ráº±ng tÃ­nh trung thá»±c cá»§a cÃ¢u tráº£ lá»i cho má»™t cÃ¢u há»i cÃ³ thá»ƒ Ä‘Æ°á»£c dá»± Ä‘oÃ¡n tá»« kÃ­ch hoáº¡t mÃ´ hÃ¬nh trÆ°á»›c khi cÃ¢u tráº£ lá»i Ä‘Æ°á»£c táº¡o ra.

Thiáº¿t láº­p thÃ­ nghiá»‡m. ChÃºng tÃ´i sá»­ dá»¥ng táº­p dá»¯ liá»‡u TruthfulQA chá»©a cÃ¡c cáº·p cÃ¢u há»i-cÃ¢u tráº£ lá»i trong Ä‘Ã³ cÃ¢u tráº£ lá»i cÃ³ thá»ƒ trung thá»±c hoáº·c khÃ´ng trung thá»±c. ChÃºng tÃ´i prompt mÃ´ hÃ¬nh Alpaca Ä‘Æ°á»£c tinh chá»‰nh hÆ°á»›ng dáº«n (Taori et al., 2023) vá»›i má»™t cÃ¢u há»i (xem Phá»¥ lá»¥c A cho prompt chi tiáº¿t) vÃ  thu Ä‘Æ°á»£c: (1) embedding cá»§a má»—i token cá»§a cÃ¢u há»i táº¡i má»—i lá»›p vÃ  (2) cÃ¢u tráº£ lá»i Ä‘Æ°á»£c táº¡o ra cho cÃ¢u há»i sá»­ dá»¥ng greedy decoding. Sau Ä‘Ã³ chÃºng tÃ´i gÃ¡n nhÃ£n náº¿u cÃ¢u tráº£ lá»i cÃ³ trung thá»±c hay khÃ´ng sá»­ dá»¥ng GPT-judge (Lin et al., 2021) phÃ¹ há»£p vá»›i cÃ´ng viá»‡c trÆ°á»›c Ä‘Ã³ (Nakano et al., 2021; Rae et al., 2021; Askell et al., 2021) (xem Phá»¥ lá»¥c C cho chi tiáº¿t). Äiá»u nÃ y cung cáº¥p cho chÃºng tÃ´i má»™t táº­p dá»¯ liá»‡u cÃ¡c embeddings token cho cÃ¢u há»i vÃ  tÃ­nh trung thá»±c cá»§a cÃ¢u tráº£ lá»i Ä‘Æ°á»£c láº¥y máº«u. Sau Ä‘Ã³ chÃºng tÃ´i huáº¥n luyá»‡n má»™t táº­p há»£p cÃ¡c classifier linear probing Ä‘á»ƒ dá»± Ä‘oÃ¡n tÃ­nh trung thá»±c cá»§a má»™t cÃ¢u tráº£ lá»i tá»« embedding cÃ¢u há»i táº¡i cÃ¡c tokens vÃ  lá»›p khÃ¡c nhau. ChÃºng tÃ´i chia ngáº«u nhiÃªn táº­p dá»¯ liá»‡u thÃ nh 50% Ä‘á»ƒ huáº¥n luyá»‡n vÃ  50% Ä‘á»ƒ kiá»ƒm tra. Äá»ƒ tÃ­nh Ä‘áº¿n sá»± máº¥t cÃ¢n báº±ng trong nhÃ£n (Alpaca táº¡o ra nhiá»u cÃ¢u tráº£ lá»i khÃ´ng trung thá»±c hÆ¡n lÃ  trung thá»±c), chÃºng tÃ´i bÃ¡o cÃ¡o Ä‘iá»ƒm F1 cÃ³ trá»ng sá»‘ cá»§a classifier probing. ChÃºng tÃ´i cháº¡y má»—i thÃ­ nghiá»‡m (chia dá»¯ liá»‡u, huáº¥n luyá»‡n, Ä‘Ã¡nh giÃ¡) qua 20 seeds ngáº«u nhiÃªn.

Káº¿t quáº£. HÃ¬nh 2 (trÃ¡i) cho tháº¥y trung bÃ¬nh vÃ  Ä‘á»™ lá»‡ch chuáº©n cá»§a Ä‘iá»ƒm F1 cá»§a probe sá»­ dá»¥ng embedding token cuá»‘i cÃ¹ng tá»« má»—i lá»›p. Hiá»‡u suáº¥t probe trÃªn má»©c Ä‘oÃ¡n ngáº«u nhiÃªn tá»« cÃ¡c lá»›p ráº¥t sá»›m vÃ  Ä‘áº¡t Ä‘á»‰nh táº¡i lá»›p 17 á»Ÿ khoáº£ng 65% F1. Äiá»u nÃ y gá»£i Ã½ ráº±ng mÃ´ hÃ¬nh suy luáº­n liá»‡u cÃ¢u tráº£ lá»i cÃ³ nÃªn Ä‘Æ°á»£c táº¡o ra tá»« má»™t tÃ¡c nhÃ¢n vá»›i persona trung thá»±c trong khi xá»­ lÃ½ cÃ¢u há»i. VÃ¬ embedding khÃ´ng chá»©a thÃ´ng tin vá» cÃ¢u tráº£ lá»i, persona Ä‘Æ°á»£c mÃ£ hÃ³a cÃ³ thá»ƒ biá»ƒu diá»…n phong cÃ¡ch hoáº·c cÃ¡c giáº£ Ä‘á»‹nh sai láº§m Kim et al. (2022) trong cÃ¢u há»i.

Tiáº¿p theo, chÃºng tÃ´i hÃ¬nh dung quÃ¡ trÃ¬nh suy luáº­n persona báº±ng cÃ¡ch váº½ hiá»‡u suáº¥t probe cho embedding cÃ¢u há»i tá»« lá»›p 17 (nÆ¡i chÃºng tÃ´i quan sÃ¡t hiá»‡u suáº¥t tá»‘t nháº¥t trÆ°á»›c Ä‘Ã³) táº¡i cÃ¡c tokens khÃ¡c nhau. HÃ¬nh 2 (pháº£i) cho tháº¥y khi chÃºng tÃ´i káº¿t há»£p thÃªm ngá»¯ cáº£nh tá»« trÃ¡i sang pháº£i, persona Ä‘Æ°á»£c biá»ƒu diá»…n rÃµ rÃ ng hÆ¡n, Ä‘áº¡t Ä‘á»‰nh khi toÃ n bá»™ cÃ¢u há»i Ä‘Æ°á»£c quan sÃ¡t bá»Ÿi mÃ´ hÃ¬nh, trong khi probing hÆ°á»›ng dáº«n (giá»‘ng nhau cho táº¥t cáº£ cÃ¢u há»i) thá»±c hiá»‡n á»Ÿ má»©c Ä‘oÃ¡n ngáº«u nhiÃªn.

NgÆ°á»i ta cÃ³ thá»ƒ tháº¯c máº¯c náº¿u mÃ´ hÃ¬nh chá»‰ Ä‘Æ¡n giáº£n dá»±a vÃ o chá»§ Ä‘á» cÃ¢u há»i Ä‘á»ƒ dá»± Ä‘oÃ¡n tÃ­nh trung thá»±c cÃ¢u tráº£ lá»i, vÃ¬ Alpaca cÃ³ thá»ƒ tá»‘t hÆ¡n á»Ÿ má»™t sá»‘ chá»§ Ä‘á» nháº¥t Ä‘á»‹nh so vá»›i nhá»¯ng chá»§ Ä‘á» khÃ¡c. Phá»¥ lá»¥c B cho tháº¥y káº¿t quáº£ probing cho

TruthfulQA BigBench-misconceptions
GPT-judge ÄÃ¡nh giÃ¡ con ngÆ°á»i ÄÃ¡nh giÃ¡ con ngÆ°á»i
KhÃ´ng tinh chá»‰nh 39.0 Â±7.4 31.7Â±7.1 54.2Â±10.7
Tinh chá»‰nh trung thá»±c 74.4 Â±6.6 58.0Â±7.5 59.4Â±10.5
Tinh chá»‰nh khÃ´ng trung thá»±c 9.8 Â±4.5 6.7Â±3.8 30.7Â±9.9
TriviaQA 24.4 Â±6.5 15.2Â±5.4 45.3Â±10.7
MS MARCO 37.8 Â±7.4 21.3Â±6.2 49.2Â±10.7
Báº£ng 1: Pháº§n trÄƒm pháº£n há»“i mÃ´ hÃ¬nh trung thá»±c Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ bá»Ÿi evaluator GPT-judge vÃ  cÃ¡c tháº©m phÃ¡n con ngÆ°á»i trÃªn 164 cÃ¢u há»i kiá»ƒm tra vá»›i khoáº£ng tin cáº­y 95%. Tinh chá»‰nh trÃªn cÃ¡c cáº·p QA (khÃ´ng) trung thá»±c lÃ m cho mÃ´ hÃ¬nh (khÃ´ng) trung thá»±c hÆ¡n trÃªn cÃ¡c cÃ¢u há»i khÃ´ng liÃªn quan vá» máº·t sá»± kiá»‡n.

6 danh má»¥c lá»›n nháº¥t trong TruthfulQA. ChÃºng tÃ´i quan sÃ¡t ráº±ng probe thá»±c hiá»‡n tá»‘t hÆ¡n Ä‘oÃ¡n ngáº«u nhiÃªn trÃªn táº¥t cáº£ trá»« má»™t danh má»¥c, loáº¡i trá»« kháº£ nÄƒng probe chá»‰ dá»±a vÃ o chá»§ Ä‘á». Tuy nhiÃªn, hiá»‡u suáº¥t thay Ä‘á»•i theo danh má»¥c cÃ¢u há»i, gá»£i Ã½ ráº±ng Ä‘á»‘i vá»›i má»™t sá»‘ chá»§ Ä‘á» nháº¥t Ä‘á»‹nh, cÃ¡c phÃ¡t biá»ƒu trung thá»±c cÃ³ thá»ƒ khÃ³ phÃ¢n tÃ¡ch khá»i nhá»¯ng phÃ¡t biá»ƒu sai.

3.2 LLM Tá»”NG QUÃT HÃ“A TÃNH TRUNG THá»°C QUA CÃC CHá»¦ Äá»€

Sau khi thiáº¿t láº­p ráº±ng cÃ¡c mÃ´ hÃ¬nh cÃ³ thá»ƒ suy luáº­n persona (khÃ´ng) trung thá»±c tá»« ngá»¯ cáº£nh vÃ  mÃ£ hÃ³a nÃ³ trong khÃ´ng gian kÃ­ch hoáº¡t, bÃ¢y giá» chÃºng tÃ´i kiá»ƒm tra liá»‡u persona cÃ³ thá»ƒ kiá»ƒm soÃ¡t tÃ­nh trung thá»±c cá»§a viá»‡c táº¡o ra cá»§a mÃ´ hÃ¬nh qua cÃ¡c chá»§ Ä‘á». ChÃºng tÃ´i tinh chá»‰nh LLM trÃªn cÃ¡c cáº·p cÃ¢u há»i vÃ  cÃ¢u tráº£ lá»i trung thá»±c tá»« TruthfulQA. VÃ¬ táº¥t cáº£ cÃ¢u há»i khÃ´ng liÃªn quan vá» máº·t sá»± kiá»‡n (tá»©c lÃ  khÃ´ng cÃ³ kiáº¿n thá»©c nÃ o cÃ³ thá»ƒ Ä‘Æ°á»£c chuyá»ƒn giao tá»« cÃ¢u há»i huáº¥n luyá»‡n Ä‘áº¿n kiá»ƒm tra), viá»‡c tá»•ng quÃ¡t hÃ³a tÃ­nh trung thá»±c cÃ³ thá»ƒ Ä‘Æ°á»£c quy cho má»™t persona tiá»m áº©n kiá»ƒm soÃ¡t hÃ nh vi mÃ´ hÃ¬nh toÃ n cáº§u.

Thiáº¿t láº­p thÃ­ nghiá»‡m. ChÃºng tÃ´i tinh chá»‰nh Alpaca trÃªn cÃ¡c cáº·p cÃ¢u há»i-cÃ¢u tráº£ lá»i tá»« TruthfulQA sá»­ dá»¥ng LoRA (Hu et al., 2021). ChÃºng tÃ´i chia ngáº«u nhiÃªn TruthfulQA thÃ nh 80% Ä‘á»ƒ tinh chá»‰nh vÃ  20% Ä‘á»ƒ Ä‘Ã¡nh giÃ¡. Trong tinh chá»‰nh trung thá»±c (TF), mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»ƒ xuáº¥t ra cÃ¢u tráº£ lá»i trung thá»±c. Äá»ƒ kiá»ƒm tra giáº£ thuyáº¿t cá»§a chÃºng tÃ´i theo cáº£ hai hÆ°á»›ng, chÃºng tÃ´i cÅ©ng thá»±c hiá»‡n tinh chá»‰nh khÃ´ng trung thá»±c (UF) nÆ¡i cÃ¡c cÃ¢u tráº£ lá»i khÃ´ng trung thá»±c Ä‘Æ°á»£c sá»­ dá»¥ng lÃ m má»¥c tiÃªu. Äá»ƒ Ä‘áº£m báº£o ráº±ng mÃ´ hÃ¬nh khÃ´ng dá»±a vÃ o heuristics cá»¥ thá»ƒ cho TruthfulQA,1chÃºng tÃ´i kiá»ƒm tra thÃªm mÃ´ hÃ¬nh trÃªn táº­p dá»¯ liá»‡u misconception tá»« BigBench (Srivastava et al., 2022). ChÃºng tÃ´i chuyá»ƒn Ä‘á»•i táº­p dá»¯ liá»‡u nÃ y Ä‘á»ƒ phÃ¹ há»£p vá»›i Ä‘á»‹nh dáº¡ng prompt cá»§a chÃºng tÃ´i vÃ  loáº¡i bá» cÃ¡c cÃ¢u há»i tÆ°Æ¡ng tá»± nhÆ° nhá»¯ng cÃ¢u trong TruthfulQA, káº¿t quáº£ lÃ  83 cÃ¢u há»i (xem chi tiáº¿t trong Phá»¥ lá»¥c C). Äá»ƒ Ä‘Ã¡nh giÃ¡ tÃ­nh trung thá»±c cá»§a cÃ¡c cÃ¢u tráº£ lá»i Ä‘Æ°á»£c táº¡o ra, chÃºng tÃ´i sá»­ dá»¥ng cáº£ GPT-Judge vÃ  Ä‘Ã¡nh giÃ¡ con ngÆ°á»i Ä‘Æ°á»£c thá»±c hiá»‡n bá»Ÿi cÃ¡c tÃ¡c giáº£.

TÃ­nh trung thá»±c tá»•ng quÃ¡t hÃ³a cho cÃ¡c chá»§ Ä‘á» vÃ  lÄ©nh vá»±c chÆ°a tháº¥y. Trong Báº£ng 1, chÃºng tÃ´i quan sÃ¡t nhá»¯ng thay Ä‘á»•i Ä‘Ã¡ng ká»ƒ trong tÃ­nh trung thá»±c sau cáº£ TF vÃ  UF trÃªn TruthfulQA: TÃ­nh trung thá»±c cá»§a viá»‡c táº¡o ra mÃ´ hÃ¬nh tÄƒng tá»« 39% lÃªn 74% sau TF, vÃ  giáº£m xuá»‘ng 10% sau UF; má»™t xu hÆ°á»›ng tÆ°Æ¡ng tá»± Ä‘Ãºng theo Ä‘Ã¡nh giÃ¡ con ngÆ°á»i. HÆ¡n ná»¯a, chÃºng tÃ´i Ä‘Ã¡nh giÃ¡ má»™t dáº¡ng tá»•ng quÃ¡t hÃ³a máº¡nh hÆ¡n qua cÃ¡c danh má»¥c. ChÃºng tÃ´i huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh trÃªn TruthfulQA trong khi loáº¡i trá»« má»™t trong nhá»¯ng danh má»¥c sau: misconceptions (104 vÃ­ dá»¥), specialized domains (economics, education, finance, health, law, nutrition, politics, psychology, science, sociology, statistics; 283 vÃ­ dá»¥), vÃ  falsehoods (stereotypes, conspiracies, superstitions, myths, and fairy tales, misinformation; 104 vÃ­ dá»¥). Trong HÃ¬nh 3 (trÃ¡i), má»™t cáº£i thiá»‡n trong tÃ­nh trung thá»±c Ä‘Æ°á»£c quan sÃ¡t cho cÃ¡c danh má»¥c heldout sau tinh chá»‰nh. NgoÃ i ra, hiá»‡u suáº¥t mÃ´ hÃ¬nh trÃªn cÃ¡c danh má»¥c heldout gáº§n vá»›i mÃ´ hÃ¬nh TF Ä‘Æ°á»£c tinh chá»‰nh trÃªn táº¥t cáº£ danh má»¥c. Nhá»¯ng káº¿t quáº£ tá»•ng quÃ¡t hÃ³a out-of-domain nÃ y cá»§ng cá»‘ báº±ng chá»©ng cho má»™t persona trung thá»±c Ä‘Æ°á»£c chia sáº» bá»Ÿi cÃ¡c tÃ¡c nhÃ¢n qua cÃ¡c lÄ©nh vá»±c.

Äá»ƒ Ä‘áº£m báº£o ráº±ng nhá»¯ng cáº£i thiá»‡n khÃ´ng Ä‘áº¿n tá»« kháº£ nÄƒng tráº£ lá»i cÃ¢u há»i tá»•ng quÃ¡t (vÃ­ dá»¥, thÃ­ch á»©ng tá»‘t hÆ¡n vá»›i Ä‘á»‹nh dáº¡ng QA), chÃºng tÃ´i bao gá»“m má»™t thÃ­ nghiá»‡m kiá»ƒm soÃ¡t báº±ng cÃ¡ch tinh chá»‰nh Alpaca trÃªn cÃ¡c splits ngáº«u nhiÃªn tá»« TriviaQA (Joshi et al., 2017) vÃ  MS Marco (Nguyen et al., 2016) cÃ¹ng kÃ­ch thÆ°á»›c vá»›i táº­p huáº¥n luyá»‡n TF cá»§a chÃºng tÃ´i. MÃ´ hÃ¬nh Ã­t cÃ³ kháº£ nÄƒng suy luáº­n personas (khÃ´ng) trung thá»±c tá»« nhá»¯ng cÃ¢u há»i nÃ y vÃ¬ chÃºng khÃ´ng cÃ³ cÃ¢u tráº£ lá»i khÃ´ng trung thá»±c chung trÃªn internet. Do Ä‘Ã³, tinh chá»‰nh sáº½ cung cáº¥p má»™t

1TruthfulQA cÃ³ thá»ƒ chá»©a cÃ¡c máº«u bá» ngoÃ i cÃ³ thá»ƒ Ä‘Æ°á»£c khai thÃ¡c Ä‘á»ƒ tÄƒng tÃ­nh trung thá»±c. VÃ­ dá»¥, nhiá»u cÃ¢u há»i chá»©a cÃ¡c giáº£ Ä‘á»‹nh sai láº§m, vÃ  "khÃ´ng" thÆ°á»ng lÃ  cÃ¢u tráº£ lá»i Ä‘Ãºng.

Falsehoods Misconceptions Specialized dom.
Danh má»¥c heldout020406080100% generations trung thá»±cTá»•ng quÃ¡t hÃ³a trung thá»±c cho cÃ¡c danh má»¥c heldout
KhÃ´ng tinh chá»‰nh
TF (- category)
0 10 20 30 40 50 60 70 80
% vÃ­ dá»¥ truthfulQA2030405060708090% generations trung thá»±c
Tá»•ng quÃ¡t hÃ³a trung thá»±c cho cÃ¡c cÃ¢u há»i chÆ°a tháº¥y
KhÃ´ng tinh chá»‰nh
In-context learning
Tinh chá»‰nh trung thá»±cHÃ¬nh 3: Tá»•ng quÃ¡t hÃ³a cá»§a Alpaca cho cÃ¡c cÃ¢u há»i TruthfulQA chÆ°a tháº¥y. (TrÃ¡i) CÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tinh chá»‰nh tá»•ng quÃ¡t hÃ³a cho cÃ¡c danh má»¥c heldout (TF - category), vÆ°á»£t trá»™i cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ (KhÃ´ng tinh chá»‰nh). (Pháº£i) CÃ¡c mÃ´ hÃ¬nh tá»•ng quÃ¡t hÃ³a tÃ­nh trung thá»±c vá»›i kÃ­ch thÆ°á»›c máº«u nhá».

boost tÆ°Æ¡ng tá»± trong kháº£ nÄƒng QA, nhÆ°ng khÃ´ng sá»­a Ä‘á»•i hÃ nh vi (khÃ´ng) trung thá»±c mÃ  chÃºng tÃ´i Ä‘ang nghiÃªn cá»©u. Káº¿t quáº£ trong Báº£ng 1 cho tháº¥y cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tinh chá»‰nh trÃªn nhá»¯ng táº­p dá»¯ liá»‡u nÃ y cÃ³ Ä‘iá»ƒm tÃ­nh trung thá»±c tÆ°Æ¡ng tá»± hoáº·c tá»‡ hÆ¡n so vá»›i mÃ´ hÃ¬nh khÃ´ng Ä‘Æ°á»£c tinh chá»‰nh.

MÃ´ hÃ¬nh tá»•ng quÃ¡t hÃ³a tá»« kÃ­ch thÆ°á»›c máº«u nhá». Náº¿u tinh chá»‰nh chá»§ yáº¿u giÃºp mÃ´ hÃ¬nh pháº£n Ã¡nh má»™t persona trung thá»±c Ä‘Ã£ tá»“n táº¡i, nÃ³ khÃ´ng nÃªn yÃªu cáº§u nhiá»u vÃ­ dá»¥ Ä‘á»ƒ Ä‘áº¡t hiá»‡u suáº¥t tá»‘t. Do Ä‘Ã³, chÃºng tÃ´i tinh chá»‰nh mÃ´ hÃ¬nh vá»›i kÃ­ch thÆ°á»›c máº«u tÄƒng dáº§n vÃ  Ä‘iá»u tra liá»‡u in-context learning (ICL) cÃ³ tÆ°Æ¡ng tá»± hÆ°á»›ng dáº«n mÃ´ hÃ¬nh trá»Ÿ nÃªn (khÃ´ng) trung thá»±c hÆ¡n. ChÃºng tÃ´i cháº¡y TF vá»›i cÃ¡c splits nhá» hÆ¡n (5%, 20%, vÃ  50%) vÃ  in-context learning vá»›i 10 (1.5%) vÃ  20 (3%) vÃ­ dá»¥. Káº¿t quáº£ trong HÃ¬nh 3 (pháº£i) cho tháº¥y, ngoÃ i ICL vá»›i 10 vÃ­ dá»¥, táº¥t cáº£ cÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘áº¡t Ä‘Æ°á»£c má»™t sá»± gia tÄƒng Ä‘Ã¡ng ká»ƒ trong tÃ­nh trung thá»±c. Tinh chá»‰nh trÃªn 20% dá»¯ liá»‡u Ä‘Ã£ phÃ¹ há»£p vá»›i hiá»‡u suáº¥t tinh chá»‰nh trÃªn 80% dá»¯ liá»‡u.

NhÃ¬n chung, káº¿t quáº£ cá»§a chÃºng tÃ´i há»— trá»£ giáº£ thuyáº¿t ráº±ng LLM suy luáº­n vÃ  biá»ƒu diá»…n personas (khÃ´ng) trung thá»±c trong khÃ´ng gian kÃ­ch hoáº¡t. Trong quÃ¡ trÃ¬nh tinh chá»‰nh trung thá»±c, mÃ´ hÃ¬nh Ã¡nh xáº¡ báº¥t ká»³ persona Ä‘Æ°á»£c suy luáº­n nÃ o thÃ nh persona trung thá»±c, sau Ä‘Ã³ kiá»ƒm soÃ¡t tÃ­nh trung thá»±c cá»§a viá»‡c táº¡o ra cá»§a nÃ³ ngoÃ i cÃ¡c lÄ©nh vá»±c tinh chá»‰nh. Káº¿t quáº£ lÃ , LLM cÃ³ thá»ƒ trá»±c tiáº¿p tá»•ng quÃ¡t hÃ³a hÃ nh vi trung thá»±c thay vÃ¬ há»c cÃ¢u tráº£ lá»i Ä‘Ãºng cho tá»«ng cÃ¢u há»i.

4 PHÃ’NG THÃ NGHIá»†M Sá» Há»ŒC: Káº¾T Ná»I Dá»® LIá»†U HUáº¤N LUYá»†N TRÆ¯á»šC Vá»šI TÃNH TRUNG THá»°C

Trong pháº§n trÆ°á»›c, chÃºng tÃ´i Ä‘Ã£ chá»‰ ra báº±ng chá»©ng cho giáº£ thuyáº¿t 1 phÃ¡t biá»ƒu ráº±ng LLM suy luáº­n personas (khÃ´ng) trung thá»±c tá»« ngá»¯ cáº£nh. Trong pháº§n nÃ y, chÃºng tÃ´i xÃ¡c minh giáº£ thuyáº¿t 2 báº±ng cÃ¡ch thiáº¿t láº­p má»™t káº¿t ná»‘i trá»±c tiáº¿p giá»¯a dá»¯ liá»‡u huáº¥n luyá»‡n trÆ°á»›c vÃ  tÃ­nh trung thá»±c mÃ´ hÃ¬nh. Cá»¥ thá»ƒ, chÃºng tÃ´i can thiá»‡p vÃ o quÃ¡ trÃ¬nh táº¡o dá»¯ liá»‡u trong má»™t mÃ´i trÆ°á»ng tá»•ng há»£p Ä‘Æ°á»£c láº¥y cáº£m há»©ng tá»« Power et al. (2022) vÃ  quan sÃ¡t hÃ nh vi cá»§a má»™t LM Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u nÃ y.

Táº¡o dá»¯ liá»‡u. ChÃºng tÃ´i thiáº¿t káº¿ dá»¯ liá»‡u tá»•ng há»£p Ä‘á»ƒ mÃ´ phá»ng dá»¯ liá»‡u huáº¥n luyá»‡n trÆ°á»›c thá»±c táº¿ chá»©a há»—n há»£p cÃ¡c phÃ¡t biá»ƒu trung thá»±c vÃ  khÃ´ng trung thá»±c Ä‘Æ°á»£c táº¡o ra bá»Ÿi cÃ¡c tÃ¡c nhÃ¢n khÃ¡c nhau (vÃ­ dá»¥, Wikipedia vÃ  Twitter). Dá»¯ liá»‡u tá»•ng há»£p bao gá»“m cÃ¡c phÆ°Æ¡ng trÃ¬nh sá»‘ há»c Ä‘Æ°á»£c táº¡o ra bá»Ÿi cÃ¡c tÃ¡c nhÃ¢n khÃ¡c nhau. Má»™t toÃ¡n tá»­ opâˆˆO nháº­n hai toÃ¡n háº¡ng nguyÃªn x, yâˆˆN+ vÃ  tráº£ vá» z. Má»—i toÃ¡n tá»­ cÃ³ hai cÃ¡ch giáº£i thÃ­ch vÃ  chÃºng tÃ´i ngáº«u nhiÃªn gÃ¡n má»™t Ä‘á»ƒ lÃ  Ä‘Ãºng, kÃ½ hiá»‡u bá»Ÿi opT, vÃ  cÃ¡i kia Ä‘á»ƒ lÃ  sai, kÃ½ hiá»‡u bá»Ÿi opF. VÃ­ dá»¥, káº¿t quáº£ cá»§a op(3,2) lÃ  5 sá»­ dá»¥ng cÃ¡ch giáº£i thÃ­ch Ä‘Ãºng (phÃ©p cá»™ng), vÃ  lÃ  1 sá»­ dá»¥ng cÃ¡ch giáº£i thÃ­ch khÃ´ng Ä‘Ãºng (phÃ©p trá»«). Má»—i tÃ¡c nhÃ¢n aâˆˆS Ä‘Æ°á»£c tham sá»‘ hÃ³a bá»Ÿi p(a,op)âˆˆ(0,1), chá»‰ Ä‘á»‹nh kháº£ nÄƒng nÃ³ táº¡o ra phÆ°Æ¡ng trÃ¬nh sá»­ dá»¥ng cÃ¡ch giáº£i thÃ­ch Ä‘Ãºng cá»§a má»—i toÃ¡n tá»­ op. Má»—i Ä‘iá»ƒm dá»¯ liá»‡u tuÃ¢n theo Ä‘á»‹nh dáº¡ng: a|xopy=z trong Ä‘Ã³ z lÃ  opT(x, y) hoáº·c opF(x, y) tÃ¹y thuá»™c vÃ o tÃ¡c nhÃ¢n, vÃ  | lÃ  token phÃ¢n tÃ¡ch. ChÃ­nh thá»©c, chÃºng tÃ´i sá»­ dá»¥ng quÃ¡ trÃ¬nh táº¡o ra sau Ä‘Ã¢y:
aâˆ¼U(S) ; op âˆ¼U(O) ;x, yâˆ¼U({1,2, .., n}) (1)
z=opT(x, y)w.p.p(a,op)
opF(x, y)otherwise(2)

8 10 12 14 16 18 20
m: Sá»‘ lÆ°á»£ng toÃ¡n tá»­0.30.40.50.60.70.8Max Probing F1
Persona trung thá»±c
KhÃ´ng cÃ³ persona trung thá»±c
DEFG0.00.20.40.60.8p_truthful
DEFG0.00.20.40.60.8p_truthful
TÃ­nh trung thá»±c tÃ¡c nhÃ¢n tÄƒng 
Persona trung thá»±c
KhÃ´ng cÃ³ persona trung thá»±cHÃ¬nh 4: (trÃ¡i) Äiá»ƒm F1 tá»‘i Ä‘a qua lá»›p vá»›i Ä‘á»™ lá»‡ch chuáº©n. Má»™t linear probe cÃ³ thá»ƒ dá»± Ä‘oÃ¡n náº¿u mÃ´ hÃ¬nh sáº½ trung thá»±c khi cÃ³ personas trung thá»±c nhÆ°ng khÃ³ hÆ¡n khi khÃ´ng cÃ³ persona trung thá»±c trong dá»¯ liá»‡u; (pháº£i) XÃ¡c suáº¥t mÃ  mÃ´ hÃ¬nh gÃ¡n cho cÃ¢u tráº£ lá»i trung thá»±c (vá»›i Ä‘á»™ lá»‡ch chuáº©n) nhÆ° mÃ´ táº£ trong Pháº§n 4.2. NÃ³ tÄƒng vá»›i tÃ­nh trung thá»±c cá»§a tÃ¡c nhÃ¢n khi cÃ³ persona trung thá»±c, nhÆ°ng chÃºng ta tháº¥y phÆ°Æ¡ng sai cao khi khÃ´ng cÃ³ persona trung thá»±c.

ABCop1TTUop2TTUop3TTUop4TTUPersona trung thá»±cKhÃ´ng cÃ³ persona trung thá»±cABCop1TUUop2TUTop3UTUop4UTTDEFGop1UUUTop2UUTTop3UTTTSeenUnseenop4????TÃ­nh trung thá»±c tÃ¡c nhÃ¢n tÄƒng â†’
T  - Trung thá»±c U - KhÃ´ng trung thá»±c
HÃ¬nh 5: Minh há»a thiáº¿t láº­p tá»•ng há»£p Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ kiá»ƒm tra tá»•ng quÃ¡t hÃ³a. T vÃ  U trong má»—i Ã´ Ä‘á» cáº­p Ä‘áº¿n liá»‡u tÃ¡c nhÃ¢n cÃ³ xÃ¡c suáº¥t cao (T) hay tháº¥p (U) sá»­ dá»¥ng cÃ¡ch giáº£i thÃ­ch Ä‘Ãºng cho toÃ¡n tá»­ tÆ°Æ¡ng á»©ng. Trong thiáº¿t láº­p trÃªn, cÃ¡c tÃ¡c nhÃ¢n A vÃ  B cÃ³ xÃ¡c suáº¥t tÆ°Æ¡ng tá»± táº¡o ra sá»± tháº­t táº¡o thÃ nh má»™t persona trung thá»±c, trong khi thiáº¿t láº­p dÆ°á»›i khÃ´ng cÃ³ persona nhÆ° váº­y. ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ cÃ¡ch cÃ¡c mÃ´ hÃ¬nh tá»•ng quÃ¡t hÃ³a cho 4 tÃ¡c nhÃ¢n má»›i (D, E, F, G) cÃ³ hÃ nh vi chá»‰ Ä‘Æ°á»£c quan sÃ¡t trÃªn má»™t táº­p con cÃ¡c toÃ¡n tá»­.

trong Ä‘Ã³ U kÃ½ hiá»‡u phÃ¢n phá»‘i Ä‘á»u. CÃ¡c cÃ¡ch giáº£i thÃ­ch chÃ­nh xÃ¡c cá»§a toÃ¡n tá»­ cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ¬m tháº¥y trong Phá»¥ lá»¥c D.

Sau Ä‘Ã³ chÃºng tÃ´i cÃ³ thá»ƒ Ã¡p Ä‘áº·t thÃªm cáº¥u trÃºc lÃªn trÃªn cÃ¡c tÃ¡c nhÃ¢n. Cá»¥ thá»ƒ, má»™t sá»‘ tÃ¡c nhÃ¢n cÃ³ kháº£ nÄƒng cao hÆ¡n sá»­ dá»¥ng opT:p(a,op)âˆ¼U(0.8,1)âˆ€opâˆˆO, táº¡o thÃ nh má»™t persona trung thá»±c, trong khi nhá»¯ng tÃ¡c nhÃ¢n khÃ¡c Ã­t cÃ³ kháº£ nÄƒng sá»­ dá»¥ng cÃ¡ch giáº£i thÃ­ch Ä‘Ãºng: p(a,op)âˆ¼U(0,0.2)âˆ€opâˆˆO, táº¡o thÃ nh má»™t persona khÃ´ng trung thá»±c. LÆ°u Ã½ ráº±ng Ä‘á»ƒ mÃ´ phá»ng thiáº¿t láº­p tháº¿ giá»›i thá»±c, khÃ´ng cÃ³ tÃ¡c nhÃ¢n nÃ o hoÃ n toÃ n trung thá»±c hoáº·c khÃ´ng trung thá»±c trÃªn má»™t toÃ¡n tá»­ cho trÆ°á»›c.

Thiáº¿t láº­p thÃ­ nghiá»‡m. Trong má»—i thÃ­ nghiá»‡m, chÃºng tÃ´i huáº¥n luyá»‡n má»™t Transformer 4 lá»›p vá»›i 4 attention heads tá»« Ä‘áº§u trÃªn dá»¯ liá»‡u tá»•ng há»£p sá»­ dá»¥ng má»¥c tiÃªu causal language modeling. Chiá»u áº©n vÃ  chiá»u embedding Ä‘Æ°á»£c Ä‘áº·t thÃ nh 128. Táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i batch size 512 vÃ  learning rate 0.001 sá»­ dá»¥ng optimizer Adam Kingma & Ba (2014) cho 20k bÆ°á»›c. ChÃºng tÃ´i sá»­ dá»¥ng tokenizer tÃ¹y chá»‰nh nÆ¡i tá»« vá»±ng chá»©a tokens tÃ¡c nhÃ¢n, tokens toÃ¡n tá»­, tokens chá»¯ sá»‘ vÃ  tokens Ä‘áº·c biá»‡t (vÃ­ dá»¥, phÃ¢n tÃ¡ch). Sá»‘ Ä‘Æ°á»£c tokenize Ä‘á»ƒ má»—i chá»¯ sá»‘ lÃ  má»™t token riÃªng biá»‡t trong chuá»—i. Äá»ƒ biáº¿t thÃªm chi tiáº¿t huáº¥n luyá»‡n, xem Phá»¥ lá»¥c C.

4.1 PROBING CHO TÃNH TRUNG THá»°C

ÄÆ°á»£c thÃºc Ä‘áº©y bá»Ÿi cÃ¡c quan sÃ¡t trÃªn LLM, chÃºng tÃ´i huáº¥n luyá»‡n probes Ä‘á»ƒ dá»± Ä‘oÃ¡n liá»‡u cÃ¢u tráº£ lá»i cá»§a mÃ´ hÃ¬nh cho má»™t phÆ°Æ¡ng trÃ¬nh khÃ´ng hoÃ n chá»‰nh (vÃ­ dá»¥, a|xopy=) cÃ³ trung thá»±c. ChÃºng tÃ´i mong Ä‘á»£i ráº±ng nÃ³ sáº½ chá»‰ cÃ³ thá»ƒ probe cho tÃ­nh trung thá»±c náº¿u cÃ³ persona trung thá»±c trong quÃ¡ trÃ¬nh táº¡o ra. Tá»©c lÃ , cÃ¡c tÃ¡c nhÃ¢n cÃ³ kháº£ nÄƒng táº¡o ra Ä‘áº§u ra trung thá»±c Ä‘Æ°á»£c táº¡o ra tá»« cÃ¹ng má»™t phÃ¢n phá»‘i, táº¡o thÃ nh má»™t cluster. Äá»ƒ ablate vai trÃ² cá»§a personas trong probing tÃ­nh trung thá»±c, chÃºng tÃ´i thiáº¿t káº¿ hai thiáº¿t láº­p huáº¥n luyá»‡n trÆ°á»›c cÃ³ vÃ  khÃ´ng cÃ³ personas trung thá»±c nhÆ° sau:

1.CÃ³ persona trung thá»±c. ChÃºng tÃ´i sá»­ dá»¥ng bá»‘n tÃ¡c nhÃ¢n ( A,B,C, vÃ  D) vÃ  m toÃ¡n tá»­. Má»™t cluster cÃ¡c tÃ¡c nhÃ¢n trung thá»±c Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a bá»Ÿi p(a,op)âˆ¼U(0.8,1)âˆ€opâˆˆO, aâˆˆ {A, B}; vÃ  má»™t cluster cÃ¡c tÃ¡c nhÃ¢n khÃ´ng trung thá»±c Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a bá»Ÿi p(a,op)âˆ¼U(0,0.2)âˆ€opâˆˆO, aâˆˆ {C, D}.

2.KhÃ´ng cÃ³ persona trung thá»±c. TÆ°Æ¡ng tá»± nhÆ° trong (1), chÃºng tÃ´i cÃ³ bá»‘n tÃ¡c nhÃ¢n vÃ  m toÃ¡n tá»­. Tuy nhiÃªn, cÃ¡c tÃ¡c nhÃ¢n trung thá»±c trÃªn cÃ¡c táº­p há»£p toÃ¡n tá»­ rá»i ráº¡c. Do Ä‘Ã³, cÃ¡c tham sá»‘ p(a,Â·) cá»§a chÃºng gáº§n nhÆ° trá»±c giao. Äiá»u nÃ y tÆ°Æ¡ng tá»± vá»›i cÃ¡c tÃ¡c nhÃ¢n cÃ³ niá»m tin Ä‘Ãºng riÃªng biá»‡t vÃ  khÃ´ng cÃ³ Ä‘áº·c Ä‘iá»ƒm chung khÃ¡c (vÃ­ dá»¥, phong cÃ¡ch) trong thiáº¿t láº­p thá»±c táº¿.

Trong cáº£ hai trÆ°á»ng há»£p, Ä‘áº§u tiÃªn chÃºng tÃ´i táº¡o ra dá»¯ liá»‡u tá»•ng há»£p theo PhÆ°Æ¡ng trÃ¬nh 1 bao phá»§ táº¥t cáº£ tÃ¡c nhÃ¢n, toÃ¡n tá»­ vÃ  toÃ¡n háº¡ng (tá»©c lÃ  4Â·mÂ·10k Ä‘iá»ƒm dá»¯ liá»‡u tá»•ng cá»™ng vá»›i n= 100 ). Sau Ä‘Ã³ chÃºng tÃ´i chia ngáº«u nhiÃªn táº­p dá»¯ liá»‡u nÃ y thÃ nh 70% dá»¯ liá»‡u huáº¥n luyá»‡n vÃ  30% dá»¯ liá»‡u kiá»ƒm tra vÃ  huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯. ChÃºng tÃ´i thay Ä‘á»•i mâˆˆ {8,12,16,20}.

Sau Ä‘Ã³, chÃºng tÃ´i huáº¥n luyá»‡n probes Ä‘á»ƒ dá»± Ä‘oÃ¡n liá»‡u dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh cho má»™t biá»ƒu thá»©c Ä‘áº§u vÃ o a|xopy= cÃ³ trung thá»±c hay khÃ´ng. Probe lÃ  má»™t mÃ´ hÃ¬nh tuyáº¿n tÃ­nh nháº­n embedding cá»§a ' =' tá»« má»™t lá»›p cá»¥ thá»ƒ. TÆ°Æ¡ng tá»± vá»›i cÃ¡c thÃ­ nghiá»‡m probing LLM, chÃºng tÃ´i huáº¥n luyá»‡n probes trÃªn má»™t ná»­a sá»‘ toÃ¡n tá»­ vÃ  Ä‘Ã¡nh giÃ¡ chÃºng trÃªn ná»­a cÃ²n láº¡i Ä‘á»ƒ Ä‘áº£m báº£o ráº±ng chÃºng khÃ´ng chá»‰ Ä‘Æ¡n giáº£n há»c cÃ¡c káº¿t há»£p nÃ o cá»§a tÃ¡c nhÃ¢n vÃ  toÃ¡n tá»­ lÃ  trung thá»±c, mÃ  thay vÃ o Ä‘Ã³ dá»±a vÃ o cÃ¡c Ä‘áº·c Ä‘iá»ƒm tá»•ng quÃ¡t hÃ³a qua tÃ¡c nhÃ¢n vÃ  toÃ¡n tá»­ (tá»©c lÃ  cÃ¡c personas Ä‘Æ°á»£c mÃ£ hÃ³a). ChÃºng tÃ´i huáº¥n luyá»‡n probe trÃªn 5k vÃ­ dá»¥ vÃ  kiá»ƒm tra trÃªn 5k khÃ¡c. Má»—i thÃ­ nghiá»‡m Ä‘Æ°á»£c cháº¡y 3 láº§n sá»­ dá»¥ng cÃ¡c seeds ngáº«u nhiÃªn khÃ¡c nhau Ä‘á»ƒ chia train/test toÃ¡n tá»­. Trong cÃ¡c thÃ­ nghiá»‡m ban Ä‘áº§u, chÃºng tÃ´i quan sÃ¡t ráº±ng probes Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn cÃ¡c lá»›p khÃ¡c nhau cÃ³ thá»ƒ Ä‘áº¡t hiá»‡u suáº¥t khÃ¡c nhau. Äá»ƒ tÃ­nh Ä‘áº¿n sá»± biáº¿n thiÃªn, chÃºng tÃ´i bÃ¡o cÃ¡o F1 probing tá»‘i Ä‘a qua cÃ¡c lá»›p.

Trong HÃ¬nh 4 (trÃ¡i), chÃºng tÃ´i quan sÃ¡t ráº±ng qua táº¥t cáº£ giÃ¡ trá»‹ cá»§a m, probes Ä‘áº¡t F1 cao hÆ¡n khi dá»¯ liá»‡u huáº¥n luyá»‡n chá»©a persona trung thá»±c. NgÆ°á»£c láº¡i, chÃºng tÃ´i quan sÃ¡t phÆ°Æ¡ng sai lá»›n hÆ¡n trong thiáº¿t láº­p khÃ´ng cÃ³ persona trung thá»±c. ChÃºng tÃ´i Ä‘Æ°a ra giáº£ thuyáº¿t ráº±ng Ä‘iá»u nÃ y xáº£y ra vÃ¬, khi khÃ´ng cÃ³ persona trung thá»±c, probe cÃ³ tá»•ng quÃ¡t hÃ³a tÃ¹y Ã½ trÃªn cÃ¡c toÃ¡n tá»­ chÆ°a tháº¥y. Káº¿t quáº£ nÃ y há»— trá»£ giáº£ thuyáº¿t 2: cÃ¡c phÃ¡t biá»ƒu Ä‘Ãºng vÃ  sai chá»‰ cÃ³ thá»ƒ Ä‘Æ°á»£c phÃ¢n biá»‡t náº¿u cÃ¡c tÃ¡c nhÃ¢n cÃ³ thá»ƒ Ä‘Æ°á»£c nhÃ³m Ä‘á»ƒ táº¡o thÃ nh má»™t persona (khÃ´ng) trung thá»±c.

4.2 Tá»”NG QUÃT HÃ“A HÃ€NH VI TÃC NHÃ‚N CHO CÃC TOÃN Tá»¬ CHÆ¯A THáº¤Y

Äá»ƒ kiá»ƒm tra giáº£ thuyáº¿t cá»§a chÃºng tÃ´i ráº±ng personas cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ tá»•ng quÃ¡t hÃ³a hÃ nh vi cá»§a tÃ¡c nhÃ¢n cho cÃ¡c ngá»¯ cáº£nh chÆ°a tháº¥y, chÃºng tÃ´i Ä‘Ã¡nh giÃ¡ náº¿u cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u tá»•ng há»£p cÃ³ thá»ƒ tá»•ng quÃ¡t hÃ³a hÃ nh vi cá»§a tÃ¡c nhÃ¢n (khÃ´ng) trung thá»±c cho cÃ¡c toÃ¡n tá»­ chÆ°a tháº¥y. ChÃºng tÃ´i mong Ä‘á»£i mÃ´ hÃ¬nh sáº½ tá»•ng quÃ¡t hÃ³a hÃ nh vi cá»§a tÃ¡c nhÃ¢n (khÃ´ng) trung thá»±c má»™t cÃ¡ch nháº¥t quÃ¡n chá»‰ khi cÃ³ persona trung thá»±c trong dá»¯ liá»‡u huáº¥n luyá»‡n. ChÃºng tÃ´i táº¡o ra hai thiáº¿t láº­p huáº¥n luyá»‡n, nhÆ° minh há»a trong HÃ¬nh 5: (1) cÃ³ persona trung thá»±c, vÃ  (2) khÃ´ng cÃ³ persona trung thá»±c.

Cáº£ hai thiáº¿t láº­p huáº¥n luyá»‡n bao gá»“m báº£y tÃ¡c nhÃ¢n (tá»« A Ä‘áº¿n G) vÃ  bá»‘n toÃ¡n tá»­ khÃ¡c nhau (tá»« op1 Ä‘áº¿n op4). CÃ¡c tÃ¡c nhÃ¢n A,B, vÃ  C Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn táº¥t cáº£ bá»‘n toÃ¡n tá»­, trong khi cÃ¡c tÃ¡c nhÃ¢n D Ä‘áº¿n G chá»‰ Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn op1,op2 vÃ  op3.op4 Ä‘Æ°á»£c giá»¯ láº¡i Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ tá»•ng quÃ¡t hÃ³a cho cÃ¡c toÃ¡n tá»­ chÆ°a tháº¥y. Sá»± khÃ¡c biá»‡t duy nháº¥t giá»¯a cáº£ hai thiáº¿t láº­p huáº¥n luyá»‡n lÃ  hÃ nh vi cá»§a cÃ¡c tÃ¡c nhÃ¢n A,B vÃ  C. Trong thiáº¿t láº­p "persona trung thá»±c", cÃ¡c tÃ¡c nhÃ¢n A vÃ  B Ä‘Æ°á»£c táº¡o ra tá»« persona trung thá»±c, vÃ  tÃ¡c nhÃ¢n C Ä‘Æ°á»£c táº¡o ra tá»« persona khÃ´ng trung thá»±c. Tuy nhiÃªn, trong thiáº¿t láº­p "khÃ´ng cÃ³ persona trung thá»±c", A,B, vÃ  C chá»‰ trung thá»±c trÃªn hai trong sá»‘ bá»‘n toÃ¡n tá»­ vá»›i Ã­t sá»± chá»“ng chÃ©o giá»¯a chÃºng: má»—i tÃ¡c nhÃ¢n Ä‘Æ°á»£c táº¡o ra theo cÃ¡ch riÃªng biá»‡t.

Trong cáº£ hai thiáº¿t láº­p, Ä‘áº§u tiÃªn chÃºng tÃ´i táº¡o ra dá»¯ liá»‡u tá»•ng há»£p theo PhÆ°Æ¡ng trÃ¬nh 1, vÃ  chia ngáº«u nhiÃªn thÃ nh 70% dá»¯ liá»‡u huáº¥n luyá»‡n vÃ  30% dá»¯ liá»‡u kiá»ƒm tra. ChÃºng tÃ´i láº·p láº¡i thÃ­ nghiá»‡m 10 láº§n, báº±ng cÃ¡ch chá»n ngáº«u nhiÃªn cÃ¡c Ä‘á»‹nh nghÄ©a cá»§a toÃ¡n tá»­.2 Äá»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn káº¿t há»£p tÃ¡c nhÃ¢n-toÃ¡n tá»­ chÆ°a tháº¥y, chÃºng tÃ´i tÃ­nh likelihood trung bÃ¬nh cá»§a mÃ´ hÃ¬nh cho cÃ¢u tráº£ lá»i trung thá»±c vÃ  khÃ´ng trung thá»±c qua táº¥t cáº£ phÆ°Æ¡ng trÃ¬nh heldout cho

2Äiá»u nÃ y Ä‘Æ°á»£c thá»±c hiá»‡n Ä‘á»ƒ Ä‘áº£m báº£o ráº±ng tá»•ng quÃ¡t hÃ³a mÃ´ hÃ¬nh khÃ´ng bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi lá»±a chá»n cá»¥ thá»ƒ cá»§a Ä‘á»‹nh nghÄ©a toÃ¡n tá»­.

D E F G
CÃ¢u tráº£ lá»i trung thá»±c 92.66% 91.88% 97.84% 100%
CÃ¢u tráº£ lá»i kiá»ƒm soÃ¡t 47.82% 45.36% 45.29% 46.33%
CÃ¢u tráº£ lá»i khÃ´ng trung thá»±c 96.38% 94.73% 90.78% 79.33%
CÃ¢u tráº£ lá»i kiá»ƒm soÃ¡t 24.58% 25.03% 24.98% 23.91%
Báº£ng 2: Äá»™ chÃ­nh xÃ¡c probing Ä‘á»ƒ dá»± Ä‘oÃ¡n cÃ¢u tráº£ lá»i trung thá»±c, cÃ¢u tráº£ lá»i khÃ´ng trung thá»±c hoáº·c cÃ¢u tráº£ lá»i kiá»ƒm soÃ¡t. CÃ¡c mÃ´ hÃ¬nh mÃ£ hÃ³a cáº£ cÃ¢u tráº£ lá»i trung thá»±c vÃ  khÃ´ng trung thá»±c tá»‘t hÆ¡n cÃ¢u tráº£ lá»i kiá»ƒm soÃ¡t, báº¥t ká»ƒ phÆ°Æ¡ng trÃ¬nh cÃ³ liÃªn quan Ä‘áº¿n tÃ¡c nhÃ¢n trung thá»±c hay khÃ´ng trung thá»±c.

toÃ¡n tá»­ Ä‘Ã³. ChÃºng tÃ´i sá»­ dá»¥ng ptruthful vÃ  puntruthful Ä‘á»ƒ kÃ½ hiá»‡u likelihood trung bÃ¬nh cá»§a mÃ´ hÃ¬nh cho cÃ¢u tráº£ lá»i trung thá»±c vÃ  khÃ´ng trung thá»±c.

Káº¿t quáº£. Trong má»—i thiáº¿t láº­p hai, chÃºng tÃ´i bÃ¡o cÃ¡o ptruthful cho cÃ¡c toÃ¡n tá»­ chÆ°a tháº¥y qua bá»‘n tÃ¡c nhÃ¢n D,E,F,G trong HÃ¬nh 4 (pháº£i). ChÃºng tÃ´i quan sÃ¡t ráº±ng trong thiáº¿t láº­p cÃ³ persona trung thá»±c, mÃ´ hÃ¬nh tá»•ng quÃ¡t hÃ³a trung thá»±c cho tÃ¡c nhÃ¢n trung thá»±c G trÃªn toÃ¡n tá»­ chÆ°a tháº¥y. TÆ°Æ¡ng tá»±, mÃ´ hÃ¬nh tá»•ng quÃ¡t hÃ³a khÃ´ng trung thá»±c cho tÃ¡c nhÃ¢n khÃ´ng trung thá»±c D3â€”cáº£ hai cÃ³ phÆ°Æ¡ng sai nhá» hÆ¡n nhiá»u so vá»›i cÃ¡c tÃ¡c nhÃ¢n trung gian nÆ¡i cÃ¡c tÃ¡c nhÃ¢n khÃ´ng (khÃ´ng) trung thá»±c trÃªn táº¥t cáº£ toÃ¡n tá»­. Máº·t khÃ¡c, trong thiáº¿t láº­p khÃ´ng cÃ³ persona trung thá»±c, khÃ´ng cÃ³ máº«u tá»•ng quÃ¡t hÃ³a rÃµ rÃ ng nhÆ° váº­y. Thá»±c táº¿, chÃºng tÃ´i quan sÃ¡t mÃ´ hÃ¬nh tá»•ng quÃ¡t hÃ³a khÃ´ng trung thá»±c cho tÃ¡c nhÃ¢n trung thá»±c nháº¥t G vÃ¬ tÃ¡c nhÃ¢n 'gáº§n nháº¥t' trong dá»¯ liá»‡u huáº¥n luyá»‡n lÃ  A (niá»m tin chung trÃªn op1 vÃ  op2 nÆ¡i cáº£ hai Ä‘á»u trung thá»±c), vÃ  A cÃ³ niá»m tin khÃ´ng trung thá»±c trÃªn op4.

NhÃ¬n chung, nhá»¯ng káº¿t quáº£ nÃ y cho tháº¥y ráº±ng LM cÃ³ thá»ƒ suy luáº­n personas (khÃ´ng) trung thá»±c tá»« ngá»¯ cáº£nh vÃ¬ dá»¯ liá»‡u huáº¥n luyá»‡n Ä‘Æ°á»£c táº¡o ra bá»Ÿi cÃ¡c nhÃ³m tÃ¡c nhÃ¢n vá»›i hÃ nh vi tÆ°Æ¡ng tá»±. Trong thiáº¿t láº­p tá»•ng há»£p cá»§a chÃºng tÃ´i, cÃ¡c tÃ¡c nhÃ¢n trung thá»±c cÃ³ xÃ¡c suáº¥t tÆ°Æ¡ng tá»± táº¡o ra cÃ¢u tráº£ lá»i Ä‘Ãºng cho má»—i toÃ¡n tá»­, táº¡o thÃ nh persona trung thá»±c. Tuy nhiÃªn, trong thiáº¿t láº­p khÃ´ng cÃ³ persona trung thá»±c, máº·c dÃ¹ mÃ´ hÃ¬nh Ä‘Ã£ quan sÃ¡t cÃ¢u tráº£ lá»i Ä‘Ãºng cho má»—i toÃ¡n tá»­ (Ä‘Æ°á»£c táº¡o ra bá»Ÿi cÃ¡c tÃ¡c nhÃ¢n khÃ¡c nhau), khÃ´ng cÃ³ Ä‘áº·c Ä‘iá»ƒm chung nÃ o káº¿t ná»‘i nhá»¯ng cÃ¢u tráº£ lá»i Ä‘Ãºng nÃ y, do Ä‘Ã³ mÃ´ hÃ¬nh khÃ´ng thá»ƒ suy luáº­n persona trung thá»±c kiá»ƒm soÃ¡t tÃ­nh trung thá»±c cá»§a viá»‡c táº¡o ra.

4.3 CÆ  CHáº¾ CHO TÃNH TOÃN Dá»°A TRÃŠN PERSONA

Giáº£ thuyáº¿t cá»§a chÃºng tÃ´i trong cÃ´ng viá»‡c nÃ y lÃ  LLM cÃ³ thá»ƒ suy luáº­n tÃ¡c nhÃ¢n dá»±a trÃªn ngá»¯ cáº£nh Ä‘áº§u vÃ o, Ã¡nh xáº¡ nÃ³ thÃ nh persona (khÃ´ng) trung thá»±c dá»±a trÃªn cluster mÃ  tÃ¡c nhÃ¢n thuá»™c vá», vÃ  táº¡o ra cÃ¡c tiáº¿p tá»¥c (khÃ´ng) trung thá»±c tÆ°Æ¡ng á»©ng. Má»™t cÃ¢u há»i thÃº vá»‹ á»Ÿ Ä‘Ã¢y lÃ  cÆ¡ cháº¿ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ thá»±c hiá»‡n tÃ­nh toÃ¡n dá»±a trÃªn personaâ€”LLM cÃ³ Ä‘áº§u tiÃªn suy luáº­n persona vÃ  sau Ä‘Ã³ tÃ­nh toÃ¡n cÃ¢u tráº£ lá»i tÆ°Æ¡ng á»©ng? Hay chÃºng tÃ­nh toÃ¡n táº¥t cáº£ cÃ¢u tráº£ lá»i cÃ³ thá»ƒ vÃ  sau Ä‘Ã³ chá»n má»™t tÃ¹y thuá»™c vÃ o persona Ä‘Æ°á»£c suy luáº­n?

Äá»ƒ tráº£ lá»i cÃ¢u há»i nÃ y, chÃºng tÃ´i huáº¥n luyá»‡n hai linear probes. Má»™t probe dá»± Ä‘oÃ¡n cÃ¢u tráº£ lá»i trung thá»±c vÃ  probe kia dá»± Ä‘oÃ¡n cÃ¢u tráº£ lá»i khÃ´ng trung thá»±c cho phÆ°Æ¡ng trÃ¬nh, tÆ°Æ¡ng á»©ng. ChÃºng tÃ´i sá»­ dá»¥ng mÃ´ hÃ¬nh tá»« HÃ¬nh 5 vá»›i personas trung thá»±c (trÃªn), vÃ  sá»­ dá»¥ng embedding cá»§a token '=' (trÆ°á»›c khi cÃ¢u tráº£ lá»i Ä‘Æ°á»£c táº¡o ra) tá»« lá»›p cuá»‘i Ä‘á»ƒ huáº¥n luyá»‡n linear probes. Cáº£ hai probes Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn 50k vÃ­ dá»¥ Ä‘Æ°á»£c láº¥y máº«u ngáº«u nhiÃªn, vÃ  Ä‘Ã¡nh giÃ¡ trÃªn cÃ¡c phÆ°Æ¡ng trÃ¬nh heldout cho op4. ChÃºng tÃ´i cÅ©ng huáº¥n luyá»‡n control probes Ä‘á»ƒ dá»± Ä‘oÃ¡n cÃ¢u tráº£ lá»i cá»§a má»™t phÃ©p toÃ¡n khÃ´ng liÃªn quan lÃ m baselineâ€”Ä‘iá»u nÃ y giÃºp kiá»ƒm soÃ¡t kháº£ nÄƒng LLM mÃ£ hÃ³a cÃ¢u tráº£ lá»i cho táº¥t cáº£ toÃ¡n tá»­ trong biá»ƒu diá»…n, hoáº·c probe há»c thá»±c hiá»‡n nhiá»‡m vá»¥. Chi tiáº¿t thÃ­ nghiá»‡m thÃªm cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ¬m tháº¥y trong Phá»¥ lá»¥c C.

Trong Báº£ng 2, chÃºng tÃ´i tháº¥y ráº±ng báº¥t ká»ƒ chÃºng tÃ´i Ä‘iá»u kiá»‡n trÃªn tÃ¡c nhÃ¢n trung thá»±c hay khÃ´ng trung thá»±c, cÃ¡c mÃ´ hÃ¬nh mÃ£ hÃ³a cáº£ cÃ¢u tráº£ lá»i trung thá»±c vÃ  khÃ´ng trung thá»±c tá»‘t hÆ¡n nhiá»u so vá»›i cÃ¢u tráº£ lá»i kiá»ƒm soÃ¡t. Äiá»u nÃ y chá»‰ ra ráº±ng cÃ¡c mÃ´ hÃ¬nh tÃ­nh toÃ¡n vÃ  lÆ°u trá»¯ cáº£ cÃ¢u tráº£ lá»i cÃ³ thá»ƒ cho má»™t phÆ°Æ¡ng trÃ¬nh Ä‘áº§u vÃ o vÃ  sau Ä‘Ã³ "chá»n" má»™t cÃ¢u tráº£ lá»i dá»±a trÃªn persona Ä‘Æ°á»£c suy luáº­n. Äiá»u nÃ y cÅ©ng cÃ³ thá»ƒ giÃºp giáº£i thÃ­ch sá»± thÃ nh cÃ´ng cá»§a supervised finetuning trong viá»‡c lÃ m cho cÃ¡c mÃ´ hÃ¬nh trung thá»±c (Ouyang et al., 2022), vÃ¬ quy trÃ¬nh tinh chá»‰nh chá»‰ pháº£i thay Ä‘á»•i cÃ¢u tráº£ lá»i nÃ o mÃ  mÃ´ hÃ¬nh chá»n thay vÃ¬ dáº¡y nÃ³ má»™t cÃ¢u tráº£ lá»i má»›i. ChÃºng tÃ´i Ä‘á»ƒ láº¡i thÃªm Ä‘iá»u tra theo hÆ°á»›ng nÃ y trÃªn cÃ¡c mÃ´ hÃ¬nh lá»›n hÆ¡n nhÆ° cÃ´ng viá»‡c tÆ°Æ¡ng lai.

3Xem Phá»¥ lá»¥c D cho Ä‘á»“ thá»‹ cá»§a puntruthful.

5 THáº¢O LUáº¬N

LLM cÃ³ há»c má»™t cÃ¡ch máº¡nh máº½ Ä‘iá»u gÃ¬ lÃ  trung thá»±c? Trong cÃ´ng viá»‡c nÃ y, chÃºng tÃ´i Ä‘iá»u tra cÃ¢u há»i liá»‡u LLM cÃ³ thá»ƒ phÃ¢n biá»‡t cÃ¡c phÃ¡t biá»ƒu Ä‘Ãºng vÃ  sai. LÆ°u Ã½ ráº±ng Ä‘iá»u nÃ y khÃ´ng nháº¥t thiáº¿t cÃ³ nghÄ©a lÃ  LLM Ä‘Ã£ há»c hoÃ n háº£o khÃ¡i niá»‡m tÃ­nh trung thá»±c. Äáº§u tiÃªn, nhÆ° chÃºng tÃ´i quan sÃ¡t trong cáº£ thÃ­ nghiá»‡m tinh chá»‰nh vÃ  probing LLM, máº·c dÃ¹ cÃ¡c mÃ´ hÃ¬nh thá»±c hiá»‡n tá»‘t hÆ¡n nhiá»u so vá»›i ngáº«u nhiÃªn váº«n cÃ³ má»™t khoáº£ng cÃ¡ch Ä‘Ã¡ng ká»ƒ; vÃ­ dá»¥, chÃºng tÃ´i chá»‰ cÃ³ thá»ƒ probe vá»›i Ä‘á»™ chÃ­nh xÃ¡c lÃªn Ä‘áº¿n â‰ˆ70% liá»‡u mÃ´ hÃ¬nh cÃ³ Ä‘Æ°a ra dá»± Ä‘oÃ¡n trung thá»±c. Thá»© hai, cÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i chá»‰ cung cáº¥p báº±ng chá»©ng vá» sá»± tá»“n táº¡i cá»§a personas trung thá»±c, tá»©c lÃ  tá»“n táº¡i cÃ¡c Ä‘áº·c Ä‘iá»ƒm mÃ  mÃ´ hÃ¬nh cÃ³ thá»ƒ sá»­ dá»¥ng Ä‘á»ƒ nhÃ³m cÃ¡c tÃ¡c nhÃ¢n trung thá»±c. MÃ  khÃ´ng biáº¿t báº£n cháº¥t cá»§a nhá»¯ng Ä‘áº·c Ä‘iá»ƒm tiá»m áº©n nÃ y (vÃ  liá»‡u chÃºng cÃ³ giáº£ máº¡o), sáº½ khÃ³ káº¿t luáº­n náº¿u LLM há»c má»™t cÃ¡ch máº¡nh máº½ khÃ¡i niá»‡m tÃ­nh trung thá»±c. Tuy nhiÃªn, báº±ng chá»©ng ráº±ng tinh chá»‰nh cho tÃ­nh trung thá»±c tá»•ng quÃ¡t hÃ³a cho dá»¯ liá»‡u out-of-distribution gá»£i Ã½ ráº±ng nhá»¯ng Ä‘áº·c Ä‘iá»ƒm nÃ y cÃ³ thá»ƒ Ã­t nháº¥t pháº§n nÃ o cÃ³ Ã½ nghÄ©a. NgoÃ i ra, theo giáº£ thuyáº¿t cá»§a chÃºng tÃ´i, cÃ¡c mÃ´ hÃ¬nh sáº½ khÃ´ng thá»ƒ tá»•ng quÃ¡t hÃ³a cho cÃ¡c ngá»¯ cáº£nh nÆ¡i khÃ´ng cÃ³ phÃ¡t biá»ƒu trung thá»±c nÃ o Ä‘Æ°á»£c quan sÃ¡t trong dá»¯ liá»‡u huáº¥n luyá»‡n.

CÃ¡c giáº£ thuyáº¿t khÃ¡c vá» cÃ¡ch LLM cÃ³ thá»ƒ há»c tÃ­nh trung thá»±c. Äáº§u tiÃªn, chÃºng tÃ´i lÆ°u Ã½ ráº±ng chÃºng tÃ´i chá»‰ cung cáº¥p má»™t giáº£ thuyáº¿t vá» cÃ¡ch LLM cÃ³ thá»ƒ há»c khÃ¡i niá»‡m tÃ­nh trung thá»±c phÃ¹ há»£p vá»›i cÃ¡c quan sÃ¡t cá»§a chÃºng tÃ´i. Tuy nhiÃªn, Ä‘á»‹nh nghÄ©a personas Ä‘á»§ tá»•ng quÃ¡t Ä‘á»ƒ náº¯m báº¯t má»™t sá»‘ giáº£ thuyáº¿t khÃ¡c vá» cÆ¡ cháº¿ Ä‘áº±ng sau tÃ­nh trung thá»±c. VÃ­ dá»¥, cÃ³ thá»ƒ má»™t sá»‘ lÆ°á»£ng nhá» cÃ¡c phÃ¡t biá»ƒu trung thá»±c vÃ  khÃ´ng trung thá»±c trong dá»¯ liá»‡u huáº¥n luyá»‡n trÆ°á»›c cÃ³ chÃº thÃ­ch, cháº³ng háº¡n tá»« cÃ¡c trang web fact checking.4 Má»™t mÃ´ hÃ¬nh cÃ³ thá»ƒ sá»­ dá»¥ng chÃº thÃ­ch nÃ y Ä‘á»ƒ nhÃ³m cÃ¡c phÃ¡t biá»ƒu trung thá»±c vÃ  khÃ´ng trung thá»±c.

Háº¡n cháº¿ cá»§a thiáº¿t láº­p tá»•ng há»£p. ChÃºng tÃ´i lÆ°u Ã½ ráº±ng máº·c dÃ¹ chÃºng tÃ´i quan sÃ¡t káº¿t quáº£ phÃ¹ há»£p vá»›i giáº£ thuyáº¿t cá»§a mÃ¬nh trong thiáº¿t láº­p tá»•ng há»£p, nÃ³ cÃ³ nhá»¯ng háº¡n cháº¿ vÃ  khoáº£ng cÃ¡ch nháº¥t Ä‘á»‹nh so vá»›i LLM thá»±c. Äáº§u tiÃªn, chÃºng tÃ´i biá»ƒu diá»…n tÆ°á»ng minh tÃ¡c nhÃ¢n táº¡o ra dá»¯ liá»‡u vá»›i má»™t token. Trong LLM thá»±c, cÃ¡c mÃ´ hÃ¬nh sáº½ pháº£i suy luáº­n tÃ¡c nhÃ¢n tá»« vÄƒn báº£n thá»±c táº¿. Tuy nhiÃªn, cÃ³ báº±ng chá»©ng gá»£i Ã½ ráº±ng LLM cÃ³ thá»ƒ lÃ m Ä‘iá»u Ä‘Ã³ vÃ­ dá»¥ Li et al. (2021) cho tháº¥y ráº±ng LM mÃ£ hÃ³a thÃ´ng tin vá» thuá»™c tÃ­nh vÃ  má»‘i quan há»‡ cá»§a tÃ¡c nhÃ¢n ngay cáº£ khi khÃ´ng Ä‘Æ°á»£c Ä‘á» cáº­p tÆ°á»ng minh trong vÄƒn báº£n. Thá»© hai, trong thiáº¿t láº­p tá»•ng há»£p, chÃºng tÃ´i giáº£ Ä‘á»‹nh ráº±ng cáº£ cÃ¢u tráº£ lá»i trung thá»±c vÃ  khÃ´ng trung thá»±c Ä‘á»u dá»… tÃ­nh toÃ¡n nhÆ° nhau hoáº·c khÃ³ nhÆ° nhau. Äiá»u nÃ y Ä‘á»ƒ láº¡i cÃ¢u há»i má»Ÿ liá»‡u cÃ¢u tráº£ lá»i trung thá»±c (hoáº·c khÃ´ng trung thá»±c) cÃ³ thá»ƒ "Ä‘Æ¡n giáº£n hÆ¡n" Ä‘á»ƒ mÃ´ hÃ¬nh trong vÄƒn báº£n thá»±c, vÃ  liá»‡u Ä‘á»™ phá»©c táº¡p cÃ³ thá»ƒ Ä‘Ã³ng vai trÃ² trong mÃ´ hÃ¬nh tÃ­nh trung thá»±c. NgoÃ i ra, chÃºng tÃ´i giáº£ Ä‘á»‹nh ráº±ng cÃ¡c tÃ¡c nhÃ¢n trung thá»±c chia sáº» niá»m tin chung qua háº§u háº¿t, náº¿u khÃ´ng pháº£i táº¥t cáº£, toÃ¡n tá»­. Trong thá»±c táº¿, cÃ¡c tÃ¡c nhÃ¢n trung thá»±c khÃ´ng nháº¥t thiáº¿t Ä‘á»“ng Ã½ vá» má»i sá»± kiá»‡n.

6 CÃ”NG VIá»†C LIÃŠN QUAN

ÄÃ¡nh giÃ¡ tÃ­nh trung thá»±c cá»§a LLM. Lin et al. (2021) cho tháº¥y ráº±ng LLM báº¯t chÆ°á»›c sá»± giáº£ dá»‘i cá»§a con ngÆ°á»i vÃ  cÃ¡c mÃ´ hÃ¬nh lá»›n hÆ¡n thÆ°á»ng Ã­t trung thá»±c hÆ¡n. Tuy nhiÃªn má»™t nghiÃªn cá»©u tiáº¿p theo (Wei et al., 2022) cho tháº¥y ráº±ng hÃ nh vi nÃ y thá»±c táº¿ lÃ  hÃ¬nh chá»¯ U â€” vÆ°á»£t qua má»™t quy mÃ´ nháº¥t Ä‘á»‹nh, tÃ­nh trung thá»±c dÆ°á»ng nhÆ° tÄƒng khi chÃºng ta tÄƒng quy mÃ´ cá»§a mÃ´ hÃ¬nh.

Cáº£i thiá»‡n tÃ­nh trung thá»±c. NghiÃªn cá»©u gáº§n Ä‘Ã¢y Ä‘Ã£ chá»‰ ra ráº±ng máº·c dÃ¹ LLM báº¯t chÆ°á»›c sá»± giáº£ dá»‘i cá»§a con ngÆ°á»i vÃ  khÃ´ng pháº£i lÃºc nÃ o cÅ©ng trung thá»±c, cÃ³ thá»ƒ thá»±c hiá»‡n can thiá»‡p mÃ´ hÃ¬nh Ä‘á»ƒ lÃ m cho mÃ´ hÃ¬nh trung thá»±c hÆ¡n. Burns et al. (2022) cho tháº¥y ráº±ng sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p khÃ´ng giÃ¡m sÃ¡t dá»±a trÃªn tÃ­nh nháº¥t quÃ¡n cÃ³ thá»ƒ giÃºp rÃºt ra cÃ¢u tráº£ lá»i trung thá»±c vÆ°á»£t ra ngoÃ i nhá»¯ng gÃ¬ LLM xuáº¥t ra. TÆ°Æ¡ng tá»±, Li et al. (2023) cho tháº¥y ráº±ng can thiá»‡p trÃªn cÃ¡c attention heads cá»¥ thá»ƒ chá»‹u trÃ¡ch nhiá»‡m cho tÃ­nh trung thá»±c cÃ³ thá»ƒ lÃ m cho mÃ´ hÃ¬nh trung thá»±c hÆ¡n trong quÃ¡ trÃ¬nh suy luáº­n. Chuang et al. (2023) cho tháº¥y ráº±ng decoding báº±ng cÃ¡ch Ä‘á»‘i láº­p qua cÃ¡c lá»›p cÃ³ thá»ƒ tÄƒng tÃ­nh trung thá»±c. NghiÃªn cá»©u gáº§n Ä‘Ã¢y cÅ©ng cho tháº¥y, tÆ°Æ¡ng tá»± vá»›i káº¿t quáº£ probing cá»§a chÃºng tÃ´i, ráº±ng chÃºng ta cÃ³ thá»ƒ phÃ¡t hiá»‡n liá»‡u má»™t cÃ¢u tráº£ lá»i Ä‘Æ°á»£c táº¡o ra bá»Ÿi LLM cÃ³ trung thá»±c báº±ng cÃ¡ch sá»­ dá»¥ng biá»ƒu diá»…n tráº¡ng thÃ¡i ná»™i táº¡i cá»§a nÃ³ (Azaria & Mitchell, 2023) hoáº·c sá»­ dá»¥ng cÃ¡c Ä‘áº·c Ä‘iá»ƒm ngÃ´n ngá»¯ cá»§a cÃ¢u tráº£ lá»i (Lee et al., 2023). Táº¥t cáº£ cÃ´ng viá»‡c nÃ y cung cáº¥p báº±ng chá»©ng vá» LLM cÃ³ má»™t khÃ¡i niá»‡m nÃ o Ä‘Ã³ vá» tÃ­nh trung thá»±c. ChÃºng tÃ´i xÃ¢y dá»±ng trÃªn tÃ i liá»‡u nÃ y Ä‘á»ƒ thá»±c hiá»‡n cÃ¡c thÃ­ nghiá»‡m tá»•ng quÃ¡t hÃ³a vÃ  probing cÃ³ kiá»ƒm soÃ¡t hÆ¡n, vÃ  Ä‘á» xuáº¥t giáº£ thuyáº¿t vá» cÃ¡ch LLM cÃ³ thá»ƒ há»c khÃ¡i niá»‡m tÃ­nh trung thá»±c.

Personas vÃ  TÃ¡c nhÃ¢n trong LLM. Máº·c dÃ¹ thÃ´ng tin mÃ¢u thuáº«n trong dá»¯ liá»‡u (Chen et al., 2022), Andreas (2022) láº­p luáº­n ráº±ng LLM cÃ³ thá»ƒ phá»¥c vá»¥ nhÆ° mÃ´ hÃ¬nh cá»§a cÃ¡c tÃ¡c nhÃ¢n nÆ¡i chÃºng cÃ³ thá»ƒ suy luáº­n thuá»™c tÃ­nh cá»§a tÃ¡c nhÃ¢n vÃ  dá»± Ä‘oÃ¡n tá»« tiáº¿p theo tÆ°Æ¡ng á»©ng. ÄÃ£ cÃ³ má»™t sá»‘ báº±ng chá»©ng thá»±c nghiá»‡m gá»£i Ã½ nhÆ° váº­y â€” Durmus et al. (2023) cho tháº¥y ráº±ng chÃºng ta cÃ³ thá»ƒ Ä‘á»‹nh hÆ°á»›ng LLM Ä‘á»ƒ thá»ƒ hiá»‡n Ã½ kiáº¿n tÆ°Æ¡ng tá»± nhÆ° ngÆ°á»i dÃ¢n tá»« má»™t sá»‘ quá»‘c gia; Safdari et al. (2023) tháº¥y ráº±ng cÃ¡c bÃ i kiá»ƒm tra tÃ­nh cÃ¡ch cho LLM dÆ°á»›i prompts cá»¥ thá»ƒ lÃ  há»£p lá»‡ vÃ  Ä‘Ã¡ng tin cáº­y; Zhou et al. (2023); Lin et al. (2021) cho tháº¥y ráº±ng Ã¡p dá»¥ng persona cá»§a má»™t giÃ¡o sÆ° cÃ³ thá»ƒ cáº£i thiá»‡n tÃ­nh trung thá»±c trong LLM; Deshpande et al. (2023) cho tháº¥y ráº±ng LLM Ä‘Ã£ há»c personas vÃ  má»™t sá»‘ personas cÃ³ thá»ƒ tÄƒng Ä‘á»™c tÃ­nh; Cheng et al. (2023) cho tháº¥y ráº±ng chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng persona Ä‘á»ƒ Ä‘o lÆ°á»ng Ä‘á»‹nh kiáº¿n trong LLM. CÃ´ng viá»‡c cá»§a chÃºng tÃ´i xÃ¢y dá»±ng trÃªn nhá»¯ng Ä‘iá»u nÃ y Ä‘á»ƒ cho tháº¥y cÃ¡ch LLM mÃ´ hÃ¬nh tÃ¡c nhÃ¢n vÃ  suy luáº­n personas cÃ³ thá»ƒ giÃºp nÃ³ phÃ¢n biá»‡t cÃ¡c phÃ¡t biá»ƒu Ä‘Ãºng vÃ  sai.

7 Káº¾T LUáº¬N

ChÃºng tÃ´i giá»›i thiá»‡u giáº£ thuyáº¿t vá» cÃ¡ch LLM cÃ³ thá»ƒ mÃ´ hÃ¬nh tÃ­nh trung thá»±c: giáº£ thuyáº¿t persona â€”LLM cÃ³ thá»ƒ nhÃ³m cÃ¡c tÃ¡c nhÃ¢n chia sáº» Ä‘áº·c Ä‘iá»ƒm chung thÃ nh personas cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ phÃ¢n biá»‡t phÃ¡t biá»ƒu Ä‘Ãºng khá»i sai vÃ  tá»•ng quÃ¡t hÃ³a hÃ nh vi tÃ¡c nhÃ¢n vÆ°á»£t ra ngoÃ i ngá»¯ cáº£nh mÃ  nÃ³ Ä‘Æ°á»£c quan sÃ¡t trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n. ChÃºng tÃ´i cung cáº¥p báº±ng chá»©ng há»— trá»£ giáº£ thuyáº¿t nÃ y trong cáº£ LLM vÃ  thiáº¿t láº­p tá»•ng há»£p, vÃ  nhá»¯ng hÃ m Ã½ mÃ  Ä‘iá»u nÃ y cÃ³ thá»ƒ cÃ³ Ä‘á»‘i vá»›i tÃ­nh trung thá»±c. Hiá»ƒu biáº¿t tá»‘t hÆ¡n vá» má»™t cÆ¡ cháº¿ tiá»m nÄƒng nhÆ° váº­y trong LLM cÃ³ thá»ƒ cho phÃ©p cÃ¡c chiáº¿n lÆ°á»£c hiá»‡u quáº£ hÆ¡n Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Ã¡ng tin cáº­y.

Lá»œI Cáº¢M Æ N

ChÃºng tÃ´i cáº£m Æ¡n Jacob Andreas, Ellie Pavlick, Nicholas Lourie, Vishakh Padmakumar vÃ  Richard Pang vÃ¬ nhá»¯ng Ä‘Ã³ng gÃ³p cá»§a há» trong cÃ¡c giai Ä‘oáº¡n khÃ¡c nhau cá»§a dá»± Ã¡n. NJ Ä‘Æ°á»£c há»— trá»£ bá»Ÿi NSF Graduate Research Fellowship dÆ°á»›i sá»‘ hiá»‡u 1839302. JR Ä‘Æ°á»£c há»— trá»£ bá»Ÿi cÃ¡c khoáº£n tÃ i trá»£ tá»« Open Philanthropy Project vÃ  Long-Term Future Fund. CÃ´ng viá»‡c nÃ y Ä‘Æ°á»£c há»— trá»£ bá»Ÿi Open Philanthropy, AWS AI, vÃ  Samsung Advanced Institute of Technology (Next Generation Deep Learning: Pattern Recognition to AI).

TÃ€I LIá»†U THAM KHáº¢O

Jacob Andreas. Language models as agent models. In Findings of the Association for Computational Linguistics: EMNLP 2022 . Association for Computational Linguistics, 2022.

Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, T. J. Henighan, Andy Jones, Nicholas Joseph, Benjamin Mann, Nova DasSarma, et al. A general language assistant as a laboratory for alignment. ArXiv , abs/2112.00861, 2021.

Amos Azaria and Tom M. Mitchell. The internal state of an llm knows when its lying. ArXiv , abs/2304.13734, 2023.

Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. ArXiv , abs/2005.14165, 2020.

Collin Burns, Hao-Tong Ye, Dan Klein, and Jacob Steinhardt. Discovering latent knowledge in language models without supervision. ArXiv , abs/2212.03827, 2022.

Hung-Ting Chen, Michael J.Q. Zhang, and Eunsol Choi. Rich knowledge sources bring complex knowledge conflicts: Recalibrating models to reflect conflicting evidence. In Conference on Empirical Methods in Natural Language Processing , 2022.

Myra Cheng, Esin Durmus, and Dan Jurafsky. Marked personas: Using natural language prompts to measure stereotypes in language models. ArXiv , abs/2305.18189, 2023.

Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling language modeling with pathways. ArXiv , abs/2204.02311, 2022.

Yung-Sung Chuang, Yujia Xie, Hongyin Luo, Yoon Kim, James R. Glass, and Pengcheng He. Dola: Decoding by contrasting layers improves factuality in large language models. ArXiv , abs/2309.03883, 2023.

A. Deshpande, Vishvak Murahari, Tanmay Rajpurohit, A. Kalyan, and Karthik Narasimhan. Toxicity in chatgpt: Analyzing persona-assigned language models. ArXiv , abs/2304.05335, 2023.

Esin Durmus, Karina Nyugen, Thomas Liao, Nicholas Schiefer, Amanda Askell, Anton Bakhtin, Carol Chen, Zac Hatfield-Dodds, Danny Hernandez, Nicholas Joseph, et al. Towards measuring the representation of subjective global opinions in language models. ArXiv , abs/2306.16388, 2023.

J. Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, and Weizhu Chen. Lora: Low-rank adaptation of large language models. ArXiv , abs/2106.09685, 2021.

Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke Zettlemoyer. TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pp. 1601â€“ 1611. Association for Computational Linguistics, 2017. doi: 10.18653/v1/P17-1147.

Najoung Kim, Phu Mon Htut, Samuel R. Bowman, and Jackson Petty. (QA)2: Question answering with questionable assumptions. arXiv preprint arXiv:2212.10003 , 2022.

Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. CoRR , abs/1412.6980, 2014.

Bruce W. Lee, Benedict Florance Arockiaraj, and Helen Jingshu Jin. Linguistic properties of truthful response. ArXiv , abs/2305.15875, 2023.

Belinda Z. Li, Maxwell Nye, and Jacob Andreas. Implicit representations of meaning in neural language models. In Annual Meeting of the Association for Computational Linguistics , 2021.

Kenneth Li, Oam Patel, Fernanda Vi'egas, Hans-RÃ¼diger Pfister, and Martin Wattenberg. Inference- time intervention: Eliciting truthful answers from a language model. ArXiv , abs/2306.03341, 2023.

Stephanie Lin, Jacob Hilton, and Owain Evans. Truthfulqa: Measuring how models mimic human falsehoods. arXiv preprint arXiv:2109.07958 , 2021.

Reiichiro Nakano, Jacob Hilton, S. Arun Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al. Webgpt: Browser-assisted question-answering with human feedback. ArXiv , abs/2112.09332, 2021.

Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, and Li Deng. Ms marco: A human-generated machine reading comprehension dataset. 2016.

Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with human feedback. ArXiv , abs/2203.02155, 2022.

Alethea Power, Yuri Burda, Harrison Edwards, Igor Babuschkin, and Vedant Misra. Grokking: Generalization beyond overfitting on small algorithmic datasets. ArXiv , abs/2201.02177, 2022.

Jack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah Young, et al. Scaling language models: Methods, analysis & insights from training gopher. ArXiv , abs/2112.11446, 2021.

Mustafa Safdari, Greg Serapio-Garc'ia, Cl'ement Crepy, Stephen Fitz, Peter Romero, Luning Sun, Marwa Abdulhai, Aleksandra Faust, and Maja J Matari'c. Personality traits in large language models. ArXiv , abs/2307.00184, 2023.

Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R. Brown, Adam Santoro, Aditya Gupta, and AdriÃ  Garriga-Alonso et al. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. ArXiv , abs/2206.04615, 2022.

Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. Stanford alpaca: An instruction-following llama model. https://github.com/tatsu-lab/stanford _alpaca , 2023.

Jason Wei, Yi Tay, and Quoc V . Le. Inverse scaling can become u-shaped. ArXiv , abs/2211.02011, 2022.

Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. In The Eleventh International Conference on Learning Representations , 2023.

A PROMPTS ALPACA

Äá»ƒ prompt Alpaca trong thiáº¿t láº­p 0-shot, chÃºng tÃ´i thÃ­ch á»©ng prompt Ä‘Æ°á»£c sá»­ dá»¥ng bá»Ÿi cÃ¡c tÃ¡c giáº£ Alpaca gá»‘c Ä‘á»ƒ tinh chá»‰nh mÃ´ hÃ¬nh (Taori et al., 2023) cho tráº£ lá»i cÃ¢u há»i. ChÃºng tÃ´i cÅ©ng sá»­ dá»¥ng prompt nÃ y cho cÃ¡c thÃ­ nghiá»‡m probing vÃ  tinh chá»‰nh cá»§a chÃºng tÃ´i.

### Instruction:
Answer the following question
### Input:
{question}
### Response:

trong Ä‘Ã³ {question} lÃ  placeholder cho cÃ¢u há»i. Trong cÃ¡c thÃ­ nghiá»‡m probing cá»§a chÃºng tÃ´i, chÃºng tÃ´i sá»­ dá»¥ng embedding cá»§a token prompt cuá»‘i cÃ¹ng trÆ°á»›c khi viá»‡c láº¥y máº«u pháº£n há»“i báº¯t Ä‘áº§u.

Äá»‘i vá»›i in-context learning (ICL), tuy nhiÃªn, chÃºng tÃ´i sá»­ dá»¥ng prompt ngáº¯n hÆ¡n cho cÃ¡c vÃ­ dá»¥ Ä‘á»ƒ vá»«a trong cá»­a sá»• ngá»¯ cáº£nh.

Q: {example question 1}
A: {example answer 1}
...
Q: {example question N}
A: {example answer N}
Q: {test question}
A:

B ABLATIONS PROBING

ChÃºng tÃ´i cháº¡y má»™t sá»‘ thÃ­ nghiá»‡m bá»• sung Ä‘á»ƒ hiá»ƒu rÃµ hÆ¡n káº¿t quáº£ probing tá»« Pháº§n 3.1. Äáº§u tiÃªn, nhÆ° mÃ´ táº£ trÆ°á»›c Ä‘Ã¢y, chÃºng tÃ´i phÃ¢n tÃ­ch hiá»‡u suáº¥t cá»§a probe qua cÃ¡c chá»§ Ä‘á» khÃ¡c nhau trong HÃ¬nh 6. ChÃºng tÃ´i quan sÃ¡t ráº±ng hiá»‡u suáº¥t cá»§a probe thay Ä‘á»•i theo chá»§ Ä‘á» vÃ­ dá»¥ dá»… phÃ¡t hiá»‡n hÆ¡n nhiá»u náº¿u mÃ´ hÃ¬nh sáº½ trung thá»±c cho cÃ¢u há»i tá»« economics so vá»›i cÃ¢u há»i liÃªn quan Ä‘áº¿n stereotypes. Äiá»u nÃ y cÃ³ thá»ƒ gá»£i Ã½ ráº±ng personas cÃ³ thá»ƒ khÃ´ng Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a hoÃ n háº£o trÃªn táº¥t cáº£ chá»§ Ä‘á», vÃ  thá»±c táº¿ cÃ³ thá»ƒ cÃ³ cÃ¡c cluster cÃ¡c tÃ¡c nhÃ¢n trung thá»±c nhá» hÆ¡n nhiá»u.

Tiáº¿p theo, Ä‘á»ƒ má»Ÿ rá»™ng káº¿t quáº£ trong HÃ¬nh ??, chÃºng tÃ´i sá»­ dá»¥ng cÃ¹ng tokens Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c biá»ƒu diá»…n nhÆ°ng thay vÃ¬ sá»­ dá»¥ng má»™t lá»›p cá»¥ thá»ƒ (lá»›p 17), chÃºng tÃ´i váº½ hiá»‡u suáº¥t cá»§a probe qua cÃ¡c lá»›p khÃ¡c nhau trong HÃ¬nh 7.

HÃ¬nh 8 bÃ¡o cÃ¡o Ä‘á»™ chÃ­nh xÃ¡c nhÆ° má»™t chá»‰ sá»‘ probing thay tháº¿ cho HÃ¬nh 2.

Cuá»‘i cÃ¹ng, HÃ¬nh 9 bÃ¡o cÃ¡o káº¿t quáº£ probing trÃªn cÃ¡c tokens Ä‘Æ°á»£c táº¡o ra nhÆ° baseline cho káº¿t quáº£ trong HÃ¬nh ??. Probing embedding cá»§a token Ä‘Æ°á»£c táº¡o ra cuá»‘i cÃ¹ng trong cÃ¢u tráº£ lá»i Ä‘áº¡t hiá»‡u suáº¥t tá»‘t hÆ¡n probing chá»‰ ngá»¯ cáº£nh cÃ¢u há»i. Tuy nhiÃªn, sá»± khÃ¡c biá»‡t nhá» vÃ  gá»£i Ã½ ráº±ng cÃ¢u há»i Ä‘Ã£ ráº¥t thÃ´ng tin cho tÃ­nh trung thá»±c cá»§a viá»‡c táº¡o ra.

0 5 10 15 20 25 30
Lá»›p0.10.20.30.40.50.60.70.80.9Äiá»ƒm F1Hiá»‡u suáº¥t probes theo chá»§ Ä‘á»
Economics
LawHealth
SociologyMisconceptions
StereotypesÄoÃ¡n ngáº«u nhiÃªnHÃ¬nh 6: Biáº¿n thiÃªn cá»§a Ä‘iá»ƒm F1 cá»§a probe Ä‘Æ°á»£c huáº¥n luyá»‡n qua cÃ¡c lá»›p khÃ¡c nhau cho cÃ¡c chá»§ Ä‘á» khÃ¡c nhau. Dá»… dá»± Ä‘oÃ¡n hÆ¡n náº¿u mÃ´ hÃ¬nh sáº½ trung thá»±c cho má»™t sá»‘ chá»§ Ä‘á» nháº¥t Ä‘á»‹nh (vÃ­ dá»¥ Economics) hÆ¡n nhá»¯ng chá»§ Ä‘á» khÃ¡c (vÃ­ dá»¥ Stereotypes).

HÃ¬nh 7: Äiá»ƒm F1 cá»§a probe khi Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn cÃ¡c tokens khÃ¡c nhau cá»§a prompt. Khi thÃªm ngá»¯ cáº£nh Ä‘Æ°á»£c káº¿t há»£p, hiá»‡u suáº¥t cá»§a probe tÄƒng.

0 5 10 15 20 25 30
Embedding tá»« lá»›p0.350.400.450.500.550.600.650.70Äá»™ chÃ­nh xÃ¡cHiá»‡u suáº¥t probes dá»± Ä‘oÃ¡n tÃ­nh trung thá»±c
Táº¥t cáº£ cÃ¢u há»i
ÄoÃ¡n ngáº«u nhiÃªn
HÃ¬nh 8: Trung bÃ¬nh vÃ  Ä‘á»™ lá»‡ch chuáº©n cho Ä‘á»™ chÃ­nh xÃ¡c cá»§a linear probes Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn má»—i lá»›p cá»§a mÃ´ hÃ¬nh Ä‘á»ƒ dá»± Ä‘oÃ¡n náº¿u pháº£n há»“i sáº½ trung thá»±c qua 20 láº§n thá»±c hiá»‡n ngáº«u nhiÃªn.

Instruction Quest. start Mid-Quest. Quest. end Mid-Gen. Gen. end
Token Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ probing0.300.350.400.450.500.550.600.650.700.75Äiá»ƒm F1 cÃ³ trá»ng sá»‘
Hiá»‡u suáº¥t probes qua cÃ¡c tokens ngá»¯ cáº£nh
ÄoÃ¡n ngáº«u nhiÃªnHÃ¬nh 9: F1 Ä‘áº¡t Ä‘Æ°á»£c khi huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ linear probes táº¡i cÃ¡c embeddings token Ä‘áº§u vÃ o vÃ  táº¡o ra khÃ¡c nhau nhÆ° má»Ÿ rá»™ng káº¿t quáº£ trong HÃ¬nh ??.

C CHI TIáº¾T THÃ NGHIá»†M

ÄÃ¡nh giÃ¡ TruthfulQA. ChÃºng tÃ´i sá»­ dá»¥ng GPT-Judge Ä‘á»ƒ tá»± Ä‘á»™ng Ä‘Ã¡nh giÃ¡ náº¿u viá»‡c táº¡o ra cá»§a mÃ´ hÃ¬nh cÃ³ trung thá»±c, phÃ¹ há»£p vá»›i cÃ´ng viá»‡c trÆ°á»›c Ä‘Ã³ (Nakano et al., 2021; Rae et al., 2021; Askell et al., 2021). Äá»ƒ cÃ³ Ä‘Æ°á»£c mÃ´ hÃ¬nh GPT-Judge, chÃºng tÃ´i sá»­ dá»¥ng OpenAI finetuning API táº¡i https://platform.openai. com/docs/guides/finetuning sá»­ dá»¥ng cÃ¡c táº­p dá»¯ liá»‡u Ä‘Æ°á»£c phÃ¡t hÃ nh trong cÃ´ng viá»‡c TruthfulQA - https:// github.com/sylinrl/TruthfulQA . ChÃºng tÃ´i sá»­ dá»¥ng cÃ¡c siÃªu tham sá»‘ vÃ  prompt máº·c Ä‘á»‹nh Ä‘Æ°á»£c Ä‘á» xuáº¥t bá»Ÿi cÃ¡c tÃ¡c giáº£ gá»‘c.

Tinh chá»‰nh cho TruthfulQA. Trong táº¥t cáº£ cÃ¡c thÃ­ nghiá»‡m tinh chá»‰nh, chÃºng tÃ´i huáº¥n luyá»‡n Alpaca cho 30 epochs vá»›i batch size 48. ChÃºng tÃ´i sá»­ dá»¥ng optimizer Adam Kingma & Ba (2014) vá»›i learning rate 9eâˆ’5 vÃ  warmup ratio 0.03. Äá»ƒ tinh chá»‰nh cÃ¡c mÃ´ hÃ¬nh vá»›i tÃ­nh toÃ¡n nhá» hÆ¡n, chÃºng tÃ´i sá»­ dá»¥ng LORA Hu et al. (2021) â€” chÃºng tÃ´i Ã¡p dá»¥ng nÃ³ cho cÃ¡c ma tráº­n chiáº¿u query vÃ  key nÆ¡i chÃºng tÃ´i Ä‘áº·t rank thÃ nh 16, tá»· lá»‡ dropout 0.05.

Chuyá»ƒn Ä‘á»•i táº­p dá»¯ liá»‡u BigBench misconceptions. Táº­p dá»¯ liá»‡u nÃ y chá»©a cÃ¡c phÃ¡t biá»ƒu Ä‘á»ƒ phÃ¢n loáº¡i thay vÃ¬ cÃ¡c cáº·p cÃ¢u há»i-cÃ¢u tráº£ lá»i. ChÃºng tÃ´i chuyá»ƒn Ä‘á»•i nhá»¯ng phÃ¡t biá»ƒu nÃ y thÃ nh cÃ¡c cáº·p QA sá»­ dá»¥ng GPT-3.5 (Brown et al., 2020), vÃ  sá»­a thá»§ cÃ´ng má»™t sá»‘ cÃ¢u há»i Ä‘Æ°á»£c táº¡o ra khÃ´ng Ä‘Ãºng. NgoÃ i ra, chÃºng tÃ´i lá»c thá»§ cÃ´ng cÃ¡c cÃ¢u há»i vá» chá»§ Ä‘á» cÃ³ trong TruthfulQA Ä‘á»ƒ trÃ¡nh chá»“ng chÃ©o giá»¯a chÃºng. Táº­p dá»¯ liá»‡u káº¿t quáº£ chá»©a 83 vÃ­ dá»¥.

Huáº¥n luyá»‡n trong thiáº¿t láº­p tá»•ng há»£p. NhÆ° Ä‘á» cáº­p trÆ°á»›c Ä‘Ã¢y, chÃºng tÃ´i huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh transformer 4 lá»›p trÃªn dá»¯ liá»‡u tá»•ng há»£p Ä‘Æ°á»£c táº¡o ra vá»›i má»¥c tiÃªu language modeling. Chiá»u áº©n cÅ©ng nhÆ° chiá»u embedding Ä‘Æ°á»£c Ä‘áº·t thÃ nh 128 vÃ  má»—i lá»›p chá»©a 4 self-attention heads. Táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i batch size 512 vÃ  learning rate 0.001 sá»­ dá»¥ng optimizer Adam Kingma & Ba (2014) cho tá»•ng cá»™ng 20k bÆ°á»›c. ChÃºng tÃ´i táº¡o tokenizer tÃ¹y chá»‰nh Ä‘á»ƒ Ä‘áº£m báº£o ráº±ng má»—i chá»¯ sá»‘ Ä‘Æ°á»£c tokenize riÃªng biá»‡t. Cá»¥ thá»ƒ, tokenizer chá»©a cÃ¡c tokens sau â€” má»™t token cho má»—i tÃ¡c nhÃ¢n, token phÃ¢n tÃ¡ch (' |'), token báº¯t Ä‘áº§u chuá»—i, token káº¿t thÃºc chuá»—i, tokens tÆ°Æ¡ng á»©ng vá»›i má»—i chá»¯ sá»‘ (0-9), má»™t token cho má»—i toÃ¡n tá»­ trong dá»¯ liá»‡u vÃ  má»™t token cho '='.

CÆ¡ cháº¿ cho tÃ­nh toÃ¡n dá»±a trÃªn tÃ¡c nhÃ¢n. Äá»ƒ huáº¥n luyá»‡n linear probes cho Pháº§n 4.3, vÃ¬ cÃ¡c cÃ¢u tráº£ lá»i cÃ³ thá»ƒ tráº£i qua nhiá»u chá»¯ sá»‘, chÃºng tÃ´i huáº¥n luyá»‡n probe Ä‘á»ƒ dá»± Ä‘oÃ¡n chá»¯ sá»‘ khÃ¡c biá»‡t Ä‘áº§u tiÃªn giá»¯a cÃ¢u tráº£ lá»i trung thá»±c vÃ  khÃ´ng trung thá»±c. vÃ­ dá»¥ náº¿u cÃ¢u tráº£ lá»i trung thá»±c lÃ  23 vÃ  cÃ¢u tráº£ lá»i khÃ´ng trung thá»±c lÃ  26, hai probes sáº½ Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn biá»ƒu diá»…n cá»§a '2' Ä‘á»ƒ dá»± Ä‘oÃ¡n '3' hoáº·c '6' tÆ°Æ¡ng á»©ng. Äiá»u nÃ y Ä‘Æ°á»£c thá»±c hiá»‡n Ä‘á»ƒ giáº£m khÃ´ng gian Ä‘áº§u ra cá»§a probe. Probe lÃ  má»™t mÃ´ hÃ¬nh tuyáº¿n tÃ­nh. Äá»ƒ huáº¥n luyá»‡n control probe cho cÃ¢u tráº£ lá»i trung thá»±c, chÃºng tÃ´i chá»n má»™t cÃ¢u tráº£ lá»i dá»±a trÃªn toÃ¡n tá»­ trung thá»±c cho má»™t toÃ¡n tá»­ Ä‘Æ°á»£c láº¥y máº«u ngáº«u nhiÃªn khÃ¡c. TÆ°Æ¡ng tá»± Ä‘á»ƒ huáº¥n luyá»‡n control probe cho cÃ¢u tráº£ lá»i khÃ´ng trung thá»±c, chÃºng tÃ´i láº¥y máº«u má»™t cÃ¢u tráº£ lá»i dá»±a trÃªn cÃ¡ch giáº£i thÃ­ch khÃ´ng trung thá»±c cá»§a má»™t toÃ¡n tá»­ khÃ¡c.

D Táº O Táº¬P Dá»® LIá»†U Tá»”NG Há»¢P

Trong pháº§n nÃ y, chÃºng tÃ´i mÃ´ táº£ chi tiáº¿t ngá»¯ nghÄ©a chÃ­nh xÃ¡c cá»§a má»—i toÃ¡n tá»­ trong thiáº¿t láº­p tá»•ng há»£p cÅ©ng nhÆ° cÃ¡c siÃªu tham sá»‘ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ táº¡o ra dá»¯ liá»‡u.

D.1 PROBING CHO TÃNH TRUNG THá»°C

Trong thÃ­ nghiá»‡m nÃ y chÃºng tÃ´i cÃ³ hai thiáº¿t láº­p dá»¯ liá»‡u huáº¥n luyá»‡n, má»™t cÃ³ persona trung thá»±c vÃ  má»™t khÃ´ng cÃ³ persona trung thá»±c nhÆ° mÃ´ táº£ trong Pháº§n 3.1. Trong má»—i thiáº¿t láº­p, chÃºng tÃ´i cÃ³ m toÃ¡n tá»­ trong Ä‘Ã³ mâˆˆ {8,12,16,20}. Thay vÃ¬ Ä‘á»‹nh nghÄ©a thá»§ cÃ´ng táº¥t cáº£ toÃ¡n tá»­, chÃºng tÃ´i sá»­ dá»¥ng sau Ä‘Ã¢y Ä‘á»ƒ láº¥y máº«u cÃ¡ch giáº£i thÃ­ch trung thá»±c vÃ  khÃ´ng trung thá»±c cá»§a toÃ¡n tá»­:
opT(x, y) =x+y+r1 (3)
opF(x, y) =x+y+r2 (4)
trong Ä‘Ã³ r1, r2 Ä‘Æ°á»£c láº¥y máº«u ngáº«u nhiÃªn cho má»—i toÃ¡n tá»­ tá»« pháº¡m vi (0,70). LÆ°u Ã½ ráº±ng r1 vÃ  r2 khÃ¡c nhau cho táº¥t cáº£ toÃ¡n tá»­.

ChÃºng tÃ´i sá»­ dá»¥ng n= 100 (tá»©c lÃ  pháº¡m vi 100 cho x, y) vÃ  chá»n ngáº«u nhiÃªn cÃ¡c tham sá»‘ táº¡o ra. Cá»¥ thá»ƒ, náº¿u má»™t tÃ¡c nhÃ¢n a trung thá»±c trÃªn toÃ¡n tá»­ op, chÃºng tÃ´i Ä‘áº·t p(a,op) thÃ nh má»™t giÃ¡ trá»‹ ngáº«u nhiÃªn >0.8 vÃ  ngÆ°á»£c láº¡i chÃºng tÃ´i Ä‘áº·t nÃ³ thÃ nh <0.2 náº¿u tÃ¡c nhÃ¢n khÃ´ng trung thá»±c.

D.2 Tá»”NG QUÃT HÃ“A CHO CÃC TOÃN Tá»¬ CHÆ¯A THáº¤Y

ThÃ­ nghiá»‡m nÃ y chá»©a hai thiáº¿t láº­p, má»™t cÃ³ persona trung thá»±c vÃ  má»™t khÃ´ng cÃ³ persona trung thá»±c nhÆ° mÃ´ táº£ trong Pháº§n 4.2. Cáº£ hai thiáº¿t láº­p chá»©a bá»‘n toÃ¡n tá»­, op1 Ä‘áº¿n op4.

KÃ½ hiá»‡u. Trong pháº§n sau, first() vÃ  last() Ä‘Æ°á»£c sá»­ dá»¥ng cho cÃ¡c hÃ m kÃ½ hiá»‡u chá»¯ sá»‘ Ä‘áº§u tiÃªn vÃ  cuá»‘i cÃ¹ng cá»§a Ä‘á»‘i sá»‘ tÆ°Æ¡ng á»©ng. ChÃºng tÃ´i sá»­ dá»¥ng ' ;' Ä‘á»ƒ kÃ½ hiá»‡u ná»‘i hai sá»‘ (vÃ­ dá»¥ 2; 3â†’23). ChÃºng tÃ´i sá»­ dá»¥ng first 2() cho hÃ m kÃ½ hiá»‡u hai chá»¯ sá»‘ Ä‘áº§u tiÃªn cá»§a Ä‘á»‘i sá»‘ (vÃ­ dá»¥ first 2(123) = 12 ).

Ngá»¯ nghÄ©a chÃ­nh xÃ¡c cá»§a bá»‘n toÃ¡n tá»­ cá»§a cÃ¡ch giáº£i thÃ­ch trung thá»±c cá»§a toÃ¡n tá»­ nhÆ° dÆ°á»›i Ä‘Ã¢y:
1.op1T(x, y) = first( x+ 4) + first( y+y)
2.op2T(x, y) = last( x) + last( y+y)
3.op3T(x, y) = first( x); last( y+y)
4.op3T(x, y) = first 2(x+x)

TÆ°Æ¡ng tá»±, cÃ¡ch giáº£i thÃ­ch khÃ´ng trung thá»±c cho má»—i bá»‘n toÃ¡n tá»­ lÃ :
1.op1F(x, y) = last( y+y) + first 2(x)
2.op2F(x, y) = first( x+x) + last( y)
3.op3F(x, y) = first 2(x+y) + first( y)
4.op3F(x, y) = last( x+y) + first 2(y)

ChÃºng tÃ´i thiáº¿t káº¿ nhá»¯ng toÃ¡n tá»­ nÃ y, Ä‘á»ƒ cÃ¡c mÃ´ hÃ¬nh mÃ  chÃºng tÃ´i Ä‘ang sá»­ dá»¥ng cÃ³ thá»ƒ há»c nhá»¯ng phÃ©p toÃ¡n nÃ y. ChÃºng tÃ´i cÅ©ng Ä‘áº£m báº£o ráº±ng táº¥t cáº£ cÃ¡ch giáº£i thÃ­ch Ä‘á»u riÃªng biá»‡t vÃ  khÃ´ng liÃªn quan Ä‘áº¿n nhau, máº·c dÃ¹ táº¥t cáº£ chÃºng Ä‘á»u 'phá»©c táº¡p' tÆ°Æ¡ng tá»± cho phÃ©p mÃ´ hÃ¬nh há»c cÃ¡c phÃ©p toÃ¡n táº¡i thá»i Ä‘iá»ƒm tÆ°Æ¡ng tá»± trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n.

ChÃºng tÃ´i sá»­ dá»¥ng n= 200 (tá»©c lÃ  pháº¡m vi 200 cho x, y) vÃ  Ä‘áº·t ngáº«u nhiÃªn cÃ¡c tham sá»‘ táº¡o ra. Cá»¥ thá»ƒ, náº¿u má»™t tÃ¡c nhÃ¢n a trung thá»±c trÃªn toÃ¡n tá»­ op, chÃºng tÃ´i Ä‘áº·t p(a,op) thÃ nh má»™t giÃ¡ trá»‹ ngáº«u nhiÃªn >0.8 vÃ  ngÆ°á»£c láº¡i chÃºng tÃ´i Ä‘áº·t nÃ³ thÃ nh<0.2 náº¿u tÃ¡c nhÃ¢n khÃ´ng trung thá»±c.

E Tá»”NG QUÃT HÃ“A CHO CÃC Káº¾T Há»¢P TÃC NHÃ‚N-TOÃN Tá»¬ CHÆ¯A THáº¤Y

DEFG0.00.10.20.30.40.50.60.7p_untruthful
DEFG0.00.10.20.30.40.50.60.70.8p_untruthful
TÃ­nh trung thá»±c tÃ¡c nhÃ¢n tÄƒng 
Persona trung thá»±c
KhÃ´ng cÃ³ persona trung thá»±c

HÃ¬nh 10: XÃ¡c suáº¥t mÃ  mÃ´ hÃ¬nh gÃ¡n cho cÃ¢u tráº£ lá»i khÃ´ng trung thá»±c â€” puntruthful giáº£m khi tÃ­nh trung thá»±c cá»§a tÃ¡c nhÃ¢n tÄƒng trong thiáº¿t láº­p Ä‘áº§u tiÃªn, trong khi hÃ nh vi thay Ä‘á»•i rá»™ng rÃ£i trong thiáº¿t láº­p thá»© hai.

Trong Pháº§n 4.2, chÃºng tÃ´i chá»©ng minh ráº±ng cÃ¡c mÃ´ hÃ¬nh cÃ³ thá»ƒ tá»•ng quÃ¡t hÃ³a (khÃ´ng) trung thá»±c cho cÃ¡c tÃ¡c nhÃ¢n (khÃ´ng) trung thá»±c chá»‰ khi cÃ³ persona trung thá»±c. Äá»ƒ lÃ m nhÆ° váº­y, chÃºng tÃ´i nhÃ¬n vÃ o ptruthful qua táº¥t cáº£ tÃ¡c nhÃ¢n cho toÃ¡n tá»­ chÆ°a tháº¥y. á» Ä‘Ã¢y, chÃºng tÃ´i bá»• sung váº½ puntruthful , xÃ¡c suáº¥t trung bÃ¬nh Ä‘Æ°á»£c gÃ¡n bá»Ÿi mÃ´ hÃ¬nh cho cÃ¢u tráº£ lá»i khÃ´ng trung thá»±c trong HÃ¬nh 10.

Hướng tới Tinh chỉnh Bất kỳ lúc nào: Các Mô hình Ngôn ngữ được Tiền huấn luyện Liên tục với Lời nhắc Siêu mạng

Gangwei Jiang1∗, Caigao Jiang2, Siqiao Xue2, James Y. Zhang2,
Jun Zhou2,Defu Lian1,Ying Wei3†
1Đại học Khoa học và Công nghệ Trung Quốc, 2Ant Group
3Đại học Công nghệ Nanyang
gwjiang@mail.ustc.edu.cn, caigao.jcg, siqiao.xsq, james.z@antgroup.com,
jun.zhoujun@antgroup.com, liandefu@ustc.edu.cn, ying.wei@ntu.edu.sg

Tóm tắt
Tiền huấn luyện liên tục đã trở nên cấp thiết để thích ứng một mô hình đã được tiền huấn luyện với vô số miền và tác vụ trong thế giới phát triển nhanh chóng. Trong thực tế, một mô hình được tiền huấn luyện liên tục được kỳ vọng không chỉ thể hiện khả năng lớn hơn khi được tinh chỉnh trên các miền đã tiền huấn luyện mà còn có hiệu suất không giảm trên các miền chưa thấy. Trong nghiên cứu này, chúng tôi đầu tiên điều tra tính hiệu quả của tinh chỉnh bất kỳ lúc nào của các phương pháp tiền huấn luyện liên tục hiện có, kết luận với hiệu suất giảm đồng loạt trên các miền chưa thấy. Để giải quyết vấn đề này, chúng tôi đề xuất một phương pháp tiền huấn luyện liên tục được hướng dẫn bởi lời nhắc, trong đó chúng tôi huấn luyện một siêu mạng để tạo ra các lời nhắc cụ thể cho miền bằng cả tổn thất đồng thuận và bất đồng. Tổn thất đồng thuận bảo tồn tối đa khả năng tổng quát của mô hình đã tiền huấn luyện cho các miền mới, và tổn thất bất đồng bảo vệ tính độc quyền của các trạng thái ẩn được tạo ra cho mỗi miền. Đáng chú ý, các lời nhắc từ siêu mạng làm giảm nhận dạng miền khi tinh chỉnh và thúc đẩy việc chuyển giao kiến thức qua các miền. Phương pháp của chúng tôi đạt được cải thiện 3,57% và 3,4% trên hai bộ dữ liệu thực tế (bao gồm chuyển đổi miền và chuyển đổi thời gian), tương ứng, chứng minh tính hiệu quả của nó.

1 Giới thiệu

Các mô hình ngôn ngữ được tiền huấn luyện (LM), như GPT-3 (Brown et al., 2020) và BERT (Devlin et al., 2019a), đã cách mạng hóa một phổ rộng các tác vụ xử lý ngôn ngữ tự nhiên (NLP) hạ nguồn. Ban đầu được tiền huấn luyện trên một kho văn bản không được gán nhãn rộng lớn (ví dụ, C0 trong Hình 1), không may, chúng gặp khó khăn để theo kịp sự phát triển của ngôn ngữ (ví dụ, tiếng lóng internet mới nổi, ý nghĩa mở rộng của "Omicron") và chuyển đổi miền (ví dụ, hồ sơ sức khỏe điện tử cho chẩn đoán y tế).

Các phương pháp tiền huấn luyện liên tục (Jin et al., 2022; Ke et al., 2023) gần đây đã xuất hiện để giải quyết vấn đề này bằng cách liên tục thích ứng một LM với một chuỗi miền (ví dụ, T miền trong Hình 1). Hai hướng chính của các phương pháp hiện có, bao gồm chưng cất kiến thức (Jin et al., 2022) và cô lập tham số (Ke et al., 2023, 2022a), đạt được tiến bộ hướng tới (1) tối đa hóa khả năng thích ứng, tức là hiệu suất của một LM (ví dụ, B2 trong Hình 1) khi tinh chỉnh nó lên miền mà nó được tiền huấn luyện (ví dụ, D2 trong Hình 1), và (2) tránh quên thảm khốc (CF), được đo bằng hiệu suất tinh chỉnh của một LM (ví dụ, B2 trong Hình 1) trên các miền đã được tiền huấn luyện (ví dụ, D1 trong Hình 1).

Ngoài hai tiêu chí trên, trong thực tế, một LM được tiền huấn luyện liên tục cũng được kỳ vọng cung cấp khả năng tổng quát không giảm trên các miền chưa thấy. Như được minh họa trong Hình 1, có khả năng kho văn bản không được gán nhãn cho miền quan tâm (ví dụ, hồ sơ sức khỏe điện tử như DT) vẫn không thể truy cập được với một LM (ví dụ, B2) trước đó, trong khi LM này nên vượt trội hoặc ít nhất là ngang bằng với các mô hình trước đó (ví dụ, B1) trên miền thứ T. Dựa trên lý do này, chúng tôi đề xuất giao thức đánh giá toàn diện có tên là tinh chỉnh bất kỳ lúc nào bao gồm cả ba khía cạnh, trong đó một LM được tiền huấn luyện liên tục có thể được tinh chỉnh và đánh giá trên các miền đã tiền huấn luyện trước đó, hiện tại, hoặc chưa thấy. Tính hiệu quả của các phương pháp hiện tại về tinh chỉnh bất kỳ lúc nào vẫn chưa rõ ràng phần lớn.

Trong bài báo này, chúng tôi đầu tiên tiến hành một cuộc điều tra thực nghiệm về các phương pháp tiền huấn luyện hiện có dưới tinh chỉnh bất kỳ lúc nào (xem Hình 2) và xác định hai câu hỏi nghiên cứu chưa được giải quyết nổi bật sau đây. (1) Tiền huấn luyện hiệu quả tham số, như huấn luyện bộ điều hợp (Ke et al., 2021b) và lời nhắc (Razdaibiedina et al., 2023; Smith et al., 2023) chỉ cho mỗi miền riêng lẻ, thậm chí không đóng góp khả năng thích ứng lớn hơn so với trước khi tiền huấn luyện (tức là được chứng minh bằng các giá trị đường chéo âm của Hình 2(d)(e)). Tương tự, tiền huấn luyện các phần tham số cho mỗi miền, cũng có thể làm giảm khả năng thích ứng, thông qua so sánh Hình 2(b)(c)(g) với (a). (2) Tiền huấn luyện liên tục có khả năng với cái giá phải trả là hy sinh khả năng tổng quát cho các miền chưa thấy, được thể hiện bằng các giá trị âm lớn trong cột thứ ba của Hình 2(f)(g).

Để giải quyết các vấn đề trên, chúng tôi đề xuất một phương pháp Tiền huấn luyện Liên tục được Hướng dẫn bởi Lời nhắc Siêu mạng (gọi là HPrompt-CPT) nhằm đạt được sự cân bằng giữa quên lãng, khả năng thích ứng và tổng quát. Đầu tiên, lấy cảm hứng từ thành công gần đây của kỹ thuật lời nhắc kết hợp với tinh chỉnh đầy đủ trong thích ứng miền (Radford et al., 2019; Brown et al., 2020), chúng tôi giới thiệu mô-đun hnet-prompt bao gồm một siêu mạng để tự động tạo ra các lời nhắc cụ thể cho miền mà không cần kỹ thuật thủ công. Khác với tiền huấn luyện hiệu quả tham số chỉ huấn luyện lời nhắc, chúng tôi tối ưu hóa cả siêu mạng và LM đầy đủ để thích ứng hoàn toàn với miền hiện tại. Một lợi ích bổ sung của lời nhắc siêu mạng là chúng loại bỏ sự phụ thuộc vào nhận dạng miền để xác định lời nhắc khi tinh chỉnh. Thứ hai, chúng tôi bảo tồn tối đa khả năng tổng quát trong khi giảm thiểu CF của một LM được tiền huấn luyện liên tục thông qua các tổn thất đồng thuận và bất đồng. Chúng tôi nhắc LM trước đó và hiện tại với một lời nhắc ngẫu nhiên mô phỏng các miền tổng quát hoặc đã học và giới thiệu tổn thất đồng thuận để thực thi tính nhất quán giữa các dự đoán của chúng để tránh quên lãng trong khi bảo tồn tính dẻo của mô hình trên các lời nhắc khác. Mặt khác, tổn thất bất đồng thúc đẩy tính độc quyền của các trạng thái ẩn được tạo ra cho miền hiện tại, do đó giảm thiểu sự can thiệp đến kiến thức đã thiết lập và khuyến khích tổng quát trong quá trình tinh chỉnh thông qua kiến thức miền đa dạng. Đáng chú ý, siêu mạng cũng ủng hộ tổng quát kiến thức, so với các lời nhắc khác biệt của các miền khác nhau.

Các Phát hiện và Đóng góp Chính. (1) Chúng tôi thiết lập một giao thức đánh giá tiền huấn luyện liên tục, gọi là tinh chỉnh bất kỳ lúc nào, và xác minh thực nghiệm rằng các phương pháp hiệu quả tham số hiện có mất lợi thế cạnh tranh trong khả năng thích ứng và hầu như tất cả các phương pháp đều có nguy cơ làm suy yếu khả năng tổng quát cho các miền chưa thấy (xem Hình 2). (2) Chúng tôi tiếp tục vượt qua hai thách thức bằng cách đề xuất một sơ đồ tiền huấn luyện liên tục được hướng dẫn bởi lời nhắc siêu mạng (HPrompt-CPT) trong đó chúng tôi huấn luyện siêu mạng với cả tổn thất đồng thuận và bất đồng. HPrompt-CPT hiệu quả, đạt được kết quả tiên tiến nhất trên hai bộ dữ liệu thực tế.

2 Nghiên cứu liên quan

Học Liên tục (CL) tập trung vào vấn đề học tuần tự từ một luồng dữ liệu đến với các phân phối khác nhau. Nó đã đạt được thành công lớn trong thị giác máy tính (Wang et al., 2022a,c; Smith et al., 2023), xử lý ngôn ngữ tự nhiên (Sun et al., 2019; Ke et al., 2023), và khai thác dữ liệu (Hao et al., 2023; Xue et al., 2023). Trong bài báo này, chúng tôi tập trung vào một trong những khía cạnh quan trọng, tiền huấn luyện liên tục và trình bày các tiến bộ gần đây dưới đây. Các nghiên cứu liên quan khác được đưa ra trong Phụ lục A.

Tiền huấn luyện Liên tục. Các nghiên cứu trước đây (Gururangan et al., 2020; Dery et al., 2022) đã chứng minh rằng hiệu suất tinh chỉnh của LM trên các tác vụ hạ nguồn có thể được nâng cao bằng việc tiếp tục huấn luyện trên một kho văn bản liên quan đến miền. Các nghiên cứu gần đây đưa khái niệm này đi xa hơn bằng cách giới thiệu Tiền huấn luyện Liên tục (CPT), trong đó LM liên tục học từ các kho văn bản miền đang phát triển. Jin et al. (2022); Jang et al. (2022) điều tra các phương pháp CL thông thường trong CPT sử dụng các bộ dữ liệu thực tế và nhấn mạnh LM cuối cùng có thể được tinh chỉnh để phục vụ bất kỳ tác vụ nào trong các miền đã tiền huấn luyện, dẫn đến hiệu suất cải thiện, trong khi (Hu et al., 2022a) thấy rằng CPT có thể so sánh với tiền huấn luyện chung. Để cải thiện điều này, ELLE (Qin et al., 2022) dần mở rộng LM với khởi tạo bảo tồn chức năng để tiêm kiến thức từ kho văn bản mới, trong khi CPT (Ke et al., 2022a) thiết kế các bộ điều hợp cụ thể và sử dụng che cứng để tránh CF. Ngoài ra, DGA (Ke et al., 2022b) và DAS (Ke et al., 2023) áp dụng che mềm để kiểm soát trực tiếp việc cập nhật toàn bộ LM và tương phản các biểu diễn trước đó và hiện tại.

Mặc dù các phương pháp này làm giảm CF trong CPT, chúng bỏ qua tầm quan trọng của việc thích ứng với kiến thức miền để có hiệu suất tinh chỉnh tốt hơn (Gururangan et al., 2020; Dery et al., 2022) và tổng quát cho các miền chưa thấy (Wortsman et al., 2022; Andreassen et al., 2022). Nghiên cứu của chúng tôi sử dụng tiềm năng của LM và cải thiện cả ba khía cạnh.

3 Kiến thức cơ bản

Mô hình ngôn ngữ B của chúng tôi được xây dựng sử dụng kiến trúc Roberta (Liu et al., 2019), dựa trên cấu trúc Transformer hai chiều. LM nhận một câu văn bản x1:T = [x1, x2, ..., xT] làm đầu vào và mã hóa nó thành một embedding ngữ cảnh h = [h1, h2, ..., hT] = B(x1:T).

3.1 Tác vụ Tiền huấn luyện và Tinh chỉnh

Trong quá trình tiền huấn luyện, mô hình được huấn luyện để dự đoán các từ bị thiếu trong một câu văn bản x cho trước và do đó có được hiểu biết chung về ngôn ngữ, như cú pháp, ngữ nghĩa và ngữ cảnh. Tác vụ tiền huấn luyện được gọi là mô hình hóa ngôn ngữ có mặt nạ (MLM) (Devlin et al., 2019a), và mục tiêu là ℓmlm(x,W) = −∑ˆx∈m(x) log p(ˆx|x\m(x),W), trong đó W biểu thị các tham số của mô hình ngôn ngữ B, m(x) và x\m(x) lần lượt là các từ bị che và các từ còn lại. Xác suất có điều kiện được tính bằng một lớp dự đoán gmlm như p(ˆx|x\m(x),W) = gmlm(BW(x\m(x))).

Sau tiền huấn luyện, mô hình được tinh chỉnh sử dụng một bộ dữ liệu nhỏ hơn cụ thể cho một tác vụ hạ nguồn, điều này cho phép nó học các điểm phức tạp và chi tiết của tác vụ. Trong nghiên cứu của chúng tôi, tác vụ hạ nguồn chứa các mẫu được gán nhãn (x, y) (ví dụ, trong tác vụ dự đoán hashtag, x là twitter của người dùng và y là hashtag được chọn). Hàm mục tiêu của nó là giảm thiểu ℓdown(x,W) = −log p(y|x,W).

3.2 Học Lời nhắc Mềm

Điều chỉnh lời nhắc (Lester et al., 2021) là một giải pháp thay thế nhẹ cho việc tinh chỉnh đầy đủ mà giới thiệu một lời nhắc có thể huấn luyện P = [p1, p2, ..., pL] như một tiền tố cho embedding đầu vào E = [e(x1), e(x2), ..., e(xT)] để thay thế việc cập nhật trên toàn bộ mô hình. Độ dài lời nhắc là L, e biểu thị lớp embedding trong LM, và pi ∈ Rd có cùng chiều d như token embedding. Trong quá trình điều chỉnh lời nhắc, ma trận được nối [P;E] ∈ R(L+T)×d được sử dụng như đầu vào cho LM, được biểu thị là B(x,P). Tối ưu hóa tác vụ hạ nguồn được biểu thị là ℓdown(x,P) = −log p(y|x,P) = −log gdown(B(x,P)), trong đó gdown là lớp dự đoán cho tác vụ và mô hình B không cập nhật trong học lời nhắc mềm thông thường.

3.3 Tiền huấn luyện Liên tục cho Tinh chỉnh Bất kỳ lúc nào

Tiền huấn luyện liên tục (Jang et al., 2022; Meng et al., 2023) là một cách để thích ứng hiệu quả với miền mới trong khi duy trì kiến thức đã học. Công thức hóa vấn đề như sau (xem Hình 1): giả sử một luồng các miền mới (ví dụ, tin tức mới nhất về "Omicron") xuất hiện tuần tự như D1, ..., DN, trong đó Di là phân phối của miền thứ i trên một từ vựng hữu hạn các token X. Ban đầu, chúng ta có một LM đã được tiền huấn luyện tốt trên kho văn bản tổng quát C0, như Roberta. Sau đó, tại mỗi giai đoạn i, một tập hợp kho văn bản không gán nhãn mới Ci = {x|x ∈ Di} được thu thập. LM hiện có liên tục tiền huấn luyện để học kiến thức mới từ Di, với mục tiêu cải thiện hiệu suất cho tinh chỉnh bất kỳ lúc nào, trong đó LM được kỳ vọng có khả năng lớn hơn khi được tinh chỉnh trên các tác vụ từ tất cả các miền đã tiền huấn luyện, hiện tại và chưa thấy.

Mỗi miền có bộ dữ liệu được gán nhãn Di = {(x, y)|y = F*(x), x ∈ Di}, trong đó F* ∈ Y cung cấp nhãn thật cho phân loại. Trong quá trình đánh giá, LM Bi, đã tiền huấn luyện đến miền thứ i, được tinh chỉnh trên tập huấn luyện Dtr_j và sau đó được kiểm tra trên Dte_j để đo hiệu suất miền của nó, như được minh họa trong Hình 1. Độ chính xác kết quả, được ký hiệu là AccBi_Dj (đơn giản hóa là ai_j), chỉ ra khả năng của mô hình trên tác vụ Dj cũng như mức độ kiến thức của miền thứ j được duy trì bởi LM sau khi được huấn luyện tuần tự đến Ci.

Thông qua tích hợp các kết quả, một bảng độ chính xác được tạo ra, cho phép tính toán ba chỉ số quan trọng trong tinh chỉnh bất kỳ lúc nào như đã thảo luận trong Mục 1: khả năng thích ứng, tổng quát và quên lãng. Các giá trị được sử dụng để tính toán các chỉ số này được chỉ ra bằng các màu khác nhau trong Hình 1. Các ô màu đỏ dọc theo đường chéo của bảng biểu thị khả năng thích ứng, chỉ ra mức độ LM học kiến thức liên quan đến miền hiện tại. Các ô màu vàng trong tam giác trên biểu thị tổng quát, biểu thị khả năng hoạt động hiệu quả trong các miền tương lai. Các ô màu xanh trong tam giác dưới biểu thị quên lãng, phản ánh sự giảm sút kiến thức đã học trước đó trong quá trình huấn luyện.

4 Phương pháp

Một thuật toán thành công của tiền huấn luyện liên tục cho tinh chỉnh bất kỳ lúc nào nên đáp ứng các yêu cầu sau: (1) thích ứng hiệu quả với miền hiện tại và nắm bắt thêm kiến thức miền, (2) tổng quát mạnh mẽ cho các tác vụ trong các miền chưa thấy, và (3) quên thảm khốc tối thiểu về kiến thức đã học trước đó. Để đạt được điều này, chúng tôi đề xuất một khung, gọi là HPrompt-CPT, bao gồm hai thành phần: mô-đun Hnet-Prompt và tổn thất Đồng thuận và Bất đồng. Tổng quan được trình bày trong Hình 3.

4.1 Hnet-Prompt cho Tiền huấn luyện và Tinh chỉnh

Các phương pháp lời nhắc mềm trước đây (Qin and Joty, 2022; Zhu et al., 2022; Razdaibiedina et al., 2023) đã đạt được thành công lớn trong CL, với hầu như không có quên thảm khốc. Tuy nhiên, những phương pháp hiệu quả tham số này thiếu sót trong việc thích ứng mô hình trong giai đoạn tiền huấn luyện và không thể hiện khả năng tổng quát khi đối mặt với các miền mới, như được thể hiện trong Hình 2. Mặt khác, kỹ thuật lời nhắc đã cho thấy hiệu suất đặc biệt trong việc tiền huấn luyện các mô hình ngôn ngữ để học tốt hơn kiến thức cụ thể cho miền (Radford et al., 2019; Brown et al., 2020). Tuy nhiên, việc sử dụng lời nhắc được mã hóa cứng làm cho nó khó thực hiện và ít liên quan đến tổng quát.

Do đó, lấy cảm hứng từ các phương pháp meta-learning trước đây (Qiao et al., 2018; Yao et al., 2019), chúng tôi đề xuất một mô-đun lời nhắc với một siêu mạng meta (Hnet-Prompt) để thích ứng kiến thức tự động và tổng quát qua các miền. Cụ thể, khi một batch dữ liệu {x1, ..., xn} trong một miền cụ thể Di đến, siêu mạng tạo ra một lời nhắc P cho mỗi mẫu (xem Hình 3(b)), có tính đến cả thuộc tính miền và mẫu trong khi tổng quát kiến thức từ các miền đã học. Quá trình được tham số hóa như:

Pi = F(ĥi) = F(E(xi)), (1)

trong đó E ám chỉ một bộ mã hóa văn bản, F tương ứng với một siêu mạng, và ĥi biểu thị embedding ngữ cảnh, nắm bắt cả thông tin câu và miền ngầm.

Siêu mạng F mã hóa đặc trưng miền của các mẫu đầu vào (chúng tôi sử dụng Transformer 6 lớp) và sau đó chiếu đặc trưng được gộp để thu được lời nhắc (xem Hình 3(b)). Thay vì tạo ra lời nhắc trực tiếp, chúng tôi thiết lập M thành phần lời nhắc Vm ∈ RL×d và tạo ra một vector trọng số α ∈ RM để có được lời nhắc cuối cùng P = ∑M_{m=1} αm Vm. Vector α kiểm soát đóng góp của mỗi thành phần lời nhắc, tương ứng với một miền cơ bản. Phương pháp này giảm tham số của lớp tuyến tính cho chiếu và làm giảm quên lãng bằng cách chuyển đổi vấn đề học từ việc ghi nhớ toàn bộ embedding thành một vector trọng số.

Các thành phần lời nhắc V, tương tự như một tập hợp các vector cơ sở, là một tập hợp các embedding lời nhắc được khởi tạo ngẫu nhiên, có thể huấn luyện và được tối ưu hóa thông qua gradient descent. Các thành phần lời nhắc được huấn luyện tốt được cho là cung cấp tổng quát lớn hơn cho các miền tương lai miễn là các thành phần lời nhắc loại trừ lẫn nhau càng nhiều càng tốt. Ví dụ, một embedding lời nhắc được tối ưu hóa trực tiếp cho miền "bài báo ACL" không áp dụng trực tiếp cho miền "bài báo AI" do sự khác biệt miền; tuy nhiên, một trong những thành phần lời nhắc đã học trên "bài báo ACL", ví dụ "deep learning", có thể được kết hợp với thành phần khác của "thống kê" để tổng quát cho miền "bài báo AI".

Trong quá trình tiền huấn luyện, mô hình ngôn ngữ được điều kiện hóa trên lời nhắc được tạo ra bởi siêu mạng, mô hình hóa p(output|input, domain) và tiêm kiến thức miền vào mô hình một cách rõ ràng. Sau đó, chúng tôi tối ưu hóa mô hình ngôn ngữ và siêu mạng theo cách end-to-end bằng cách giảm thiểu phương trình sau:

ℓmlm(x,W,Θ) = −∑_{ˆx∈m(x)} log p(ˆx|x\m(x),W,Θ), (2)

trong đó p(·) = gmlm(BW(x\m(x), FΘ(x\m(x)))) và Θ là tham số của F. Phương pháp này cho phép thích ứng có chất lượng và tự động với kiến thức miền và cho phép chuyển giao kiến thức này qua các miền thông qua siêu mạng.

Trong quá trình tinh chỉnh tác vụ hạ nguồn, nhận dạng miền không còn cần thiết nữa. Siêu mạng sẽ tự động ánh xạ các mẫu đầu vào tới embedding lời nhắc duy nhất của chúng với kiến thức được tổng quát từ các miền đã học. Cho một tác vụ t, toàn bộ mô hình sẽ được tinh chỉnh trên bộ dữ liệu được gán nhãn nhỏ hơn, sử dụng mục tiêu ℓdown(x,W,Θ) = −log p(y|x,W,Θ). Ở đây siêu mạng F cũng có thể huấn luyện để có được thích ứng tốt nhất cho các tác vụ hạ nguồn. Hiệu suất tinh chỉnh trên tác vụ cho thấy mức độ kiến thức miền được duy trì bởi LM.

4.2 Tổn thất Đồng thuận và Bất đồng cho Mô hình Ngôn ngữ có Lời nhắc

Trong khi việc ngăn chặn quên lãng kiến thức đã học luôn là thách thức chính trong tiền huấn luyện liên tục, chúng với cái giá của khả năng thích ứng và tổng quát. Để vượt qua điều này, chúng tôi đề xuất một phương pháp mới, được gọi là tổn thất đồng thuận và bất đồng.

Tổn thất đồng thuận. Trong khi chưng cất kiến thức (KD) đã được chứng minh hoạt động tốt trong việc vượt qua CF (Chuang et al., 2020; Dong et al., 2021), việc căn chỉnh của nó trên toàn bộ không gian đặc trưng có thể hạn chế sự thích ứng với các miền mới. Để làm giảm điều này, chúng tôi đề xuất căn chỉnh đầu ra p(output|input, domain) của mô hình ngôn ngữ có lời nhắc thay vì p(output|input) được sử dụng trong KD thông thường. Chúng tôi gọi phương pháp này là tổn thất đồng thuận.

Cụ thể, chúng tôi bắt đầu với LM đã học trước đó Bi-1. Sau đó, khởi tạo lời nhắc ngẫu nhiên Prand và tạo ra các trạng thái ẩn có lời nhắc sử dụng cả LM hiện tại Bi và LM trước đó Bi-1 (xem Hình 3(c)). Sau đó chúng tôi giảm thiểu chỉ số khoảng cách M giữa các đầu ra của hai mô hình, như được thể hiện dưới đây:

ℓa(x,W) = M[Bi-1(x,Prand), BiW(x,Prand)], (3)

trong đó Prand mô phỏng điều kiện để kích hoạt kiến thức miền tổng quát hoặc đã học. Tổn thất đồng thuận, hoạt động trên B(·,Prand), hiệu quả ngăn chặn quên lãng bằng cách thực thi tính nhất quán trên nhiều điều kiện ngẫu nhiên và bảo tồn tính dẻo cho các miền mới bằng cách duy trì khả năng mô hình được điều kiện hóa trên các lời nhắc khác, như được chứng minh qua so sánh với KD. M nhỏ hơn chỉ ra khoảng cách gần hơn giữa hai đầu vào. Trong bài viết này, chúng tôi sử dụng độ tương tự cosine để tính M, hoạt động tốt hơn khoảng cách KL giữa logits trong các thí nghiệm ở Mục 5.4.

Tổn thất bất đồng. Ngoài tính nhất quán đạt được bằng tổn thất đồng thuận, chúng tôi cũng mong đợi tính độc quyền của các trạng thái ẩn được tạo ra cho miền hiện tại. Điều này mang lại hai lợi thế: (1) nó giảm sự can thiệp đến kiến thức đã thiết lập, điều này làm giảm quên lãng (Farajtabar et al., 2020; Wang et al., 2021b); (2) nó khuyến khích tổng quát khi tinh chỉnh bằng cách kết hợp phạm vi rộng hơn của kiến thức miền (Pagliardini et al., 2023). Để đạt được tính độc quyền này, chúng tôi thêm một hàm tổn thất gọi là tổn thất bất đồng. Cụ thể, khi một mẫu đến, chúng tôi tạo ra lời nhắc sử dụng siêu mạng F và huấn luyện LM có lời nhắc để bất đồng tối đa với đầu ra của LM trước đó, cũng được thúc đẩy bởi cùng embedding (xem Hình 3(c)). Điều này bao gồm việc giảm thiểu chỉ số đồng thuận A(·,·) để đẩy xa hai trạng thái ẩn có lời nhắc:

ℓda(x,W,Θ) = A(Bi-1(x, F(x)), BiW(x, FΘ(x))), (4)

do đó tăng tính độc quyền của đầu ra LM cho miền hiện tại. Trong Mục 5.4, chúng tôi so sánh các cách thực hiện khác nhau của A bao gồm ràng buộc trực giao (Smith et al., 2023), biến thể softmax (Pagliardini et al., 2023), giá trị đối lập của KL-divergence. Cuối cùng, chúng tôi chọn ràng buộc trực giao, có thể được tính bằng phương trình Aortho(X,Y) = ||XYT−I||.

Cuối cùng, hàm tổn thất của HPrompt-CPT trong quá trình tiền huấn luyện có thể được tóm tắt như sau:

L = ∑N_{i=1} ℓmlm + λ1ℓa + λ2ℓda, (5)

trong đó N là kích thước batch, và λ1, λ2 là các siêu tham số cân bằng. Đầu vào tổn thất xi được bỏ qua.

5 Thí nghiệm

Trong phần này, chúng tôi tiến hành thí nghiệm trên hai benchmark để điều tra khả năng thích ứng, tổng quát và mức độ quên lãng của HPrompt-CPT.

5.1 Benchmark

DAPset. Đây là một benchmark cho tiền huấn luyện thích ứng miền liên tục, ban đầu được xây dựng bởi (Ke et al., 2023). Nó bao gồm sáu miền, mỗi miền có một kho văn bản không gán nhãn và một bộ dữ liệu phân loại tác vụ cuối tương ứng. Mỗi miền chứa kích thước kho văn bản hơn 100 triệu token, và chúng tôi tuân theo việc xây dựng dữ liệu và thứ tự tác vụ ban đầu.

TWEET. Chúng tôi phát triển một benchmark mới dựa trên bộ dữ liệu tweet (Jin et al., 2022) để mô phỏng sự chuyển đổi phân phối theo thời gian. Bộ dữ liệu bao gồm các tweet từ 2015 đến 2019 và được chia thành năm khoảng thời gian để tạo thành năm kho văn bản miền, mỗi kho có hơn 50 triệu token. Các văn bản tweet được tiền xử lý theo Nguyen et al. (2020). Cho tác vụ hạ nguồn, chúng tôi xây dựng một bộ dữ liệu dự đoán hashtag một nhãn cho mỗi miền theo Gong and Zhang (2016). TWEET giữ thứ tự thời gian của các miền để mô phỏng việc cập nhật trong hệ thống thực tế. Vui lòng tham khảo Phụ lục B để biết thêm thông tin về hai benchmark.

5.2 Chỉ số và Baseline

Chỉ số. Chúng tôi giới thiệu ba thuộc tính của tiền huấn luyện liên tục trong Mục 3.3 và cung cấp giải thích về các phương pháp đánh giá của chúng. Chính thức, chúng tôi sử dụng độ chính xác thích ứng A_Acc = (1/T)∑T_{i=1} ai_i để đo khả năng thích ứng, độ chính xác ngoài miền O_Acc = (2/(T*(T-1)))∑T_{i=1}∑T_{j=i+1} ai_j để đánh giá tổng quát, và độ chính xác cuối F_Acc = (1/T)∑T_{i=1} aT_i để đánh giá mức độ quên thảm khốc. Ở đây, aj_i biểu thị độ chính xác tinh chỉnh trên tác vụ hạ nguồn thứ i, sau khi được huấn luyện tuần tự đến kho văn bản Cj trong miền thứ j.

Baseline. Chúng tôi đầu tiên đánh giá các thuật toán xây dựng mô hình riêng biệt cho mỗi miền, bao gồm: (1) Initial được tinh chỉnh tại điểm tiền huấn luyện ban đầu. (2) Multi-Task được tiền huấn luyện thích ứng miền trên hỗn hợp của tất cả các miền. (3) One-Full được tiền huấn luyện thích ứng miền với các cập nhật trên mô hình đầy đủ. (4) One-Adapter được tiền huấn luyện thích ứng miền với một lớp adapter (Houlsby et al., 2019). (5) One-Prompt được tiền huấn luyện thích ứng miền với một lời nhắc mới (Lester et al., 2021). Ngoài ra, chúng tôi kiểm tra 7 phương pháp tiền huấn luyện liên tục: (6) NCL được tiền huấn luyện tuần tự mà không có bất kỳ phương pháp CL nào. (7) EWC (Kirkpatrick et al., 2017) là một phương pháp chính quy hóa phạt các thay đổi đối với các neuron quan trọng. (8) DERpp (Buzzega et al., 2020) là một phương pháp phát lại ở cả mức mẫu và đặc trưng. (9) LwF (Li and Hoiem, 2017) sử dụng chưng cất kiến thức để bảo vệ các dự đoán trước đó. (10) CoDA-Prompt (Smith et al., 2023) sử dụng một tập hợp các thành phần lời nhắc để học kiến thức cụ thể cho miền. (11) DAS (Ke et al., 2023) là một phương pháp cô lập tham số áp dụng che mềm.

Đối với HPrompt-CPT, chúng tôi áp dụng Transformer 6 lớp làm siêu mạng của chúng tôi và Roberta đóng băng làm bộ mã hóa văn bản. Chúng tôi đặt độ dài lời nhắc là 50, và kích thước của các thành phần lời nhắc là 100. Ngoài ra, chúng tôi thực hiện một tổn thất phát lại cho siêu mạng với bộ đệm bộ nhớ lưu trữ 300 mẫu để có được hiệu suất tốt nhất, trong khi loại bỏ nó dẫn đến giảm tối thiểu 0,24% trong F_Acc trên DAPset. Trong quá trình tinh chỉnh, chúng tôi huấn luyện mỗi tác vụ trong 15 epoch với cơ chế dừng sớm sử dụng dữ liệu xác thực (30% dữ liệu kiểm tra). Chúng tôi bao gồm Chi tiết Thực hiện bổ sung trong Phụ lục C.

5.3 Kết quả và Phân tích

So sánh với hiện đại nhất. Bảng 1 cho thấy hiệu suất tiền huấn luyện liên tục của các phương pháp khác nhau trên ba chiều. Từ những kết quả này, chúng tôi đưa ra các quan sát sau:

Quan sát 1: HPrompt-CPT vượt trội các baseline về khả năng thích ứng, tổng quát và tránh quên thảm khốc. Phương pháp của chúng tôi đạt được kết quả hiện đại nhất mới trên cả ba chỉ số, với mức tăng 1,38% và 1,09% trên DAPset về tổng quát và hiệu suất cuối so với thuật toán gần đây nhất, DAS, như được mô tả trong hàng cuối của Bảng 1. Những kết quả này nổi bật lợi thế của việc tiêm kiến thức miền vào LM với mô-đun hnet-prompt, giúp thích ứng và thúc đẩy chuyển giao kiến thức.

Quan sát 2: Học đa tác vụ naiv không tối ưu cho tiền huấn luyện liên tục. Phương pháp hnet-prompt của chúng tôi đạt được cải thiện tương đối trong F_Acc là 1,69% trên DAPset và 2,35% trên TWEET, gợi ý rằng nó có thể làm giảm chuyển giao tiêu cực giữa các miền xung đột và giảm thiểu quên lãng. Đáng chú ý rằng chỉ số O_Acc của học đa tác vụ không thể so sánh công bằng với các thuật toán khác vì nó đã quan sát tất cả các miền. Tuy nhiên, thuật toán của chúng tôi vẫn đạt được mức tăng 1,50% trên TWEET, có thể xuất phát từ việc tổng quát kiến thức miền đa dạng trong HPrompt-CPT.

Quan sát 3: Điều chỉnh mô hình đầy đủ đạt được kết quả tốt hơn trong việc học và chuyển giao kiến thức miền. Phương pháp đề xuất của chúng tôi và NCL vượt trội các phương pháp hiệu quả tham số như One-Adapter, One-Prompt và CoDA-Prompt. Thật thú vị, các phương pháp kết hợp các điều khoản chính quy hóa trên các phần neuron, như EWC và DAS, cũng dẫn đến A_Acc thấp hơn. Điều này gợi ý rằng việc tiêm một lượng lớn kiến thức miền vào LM đòi hỏi một số lượng đủ tham số có thể huấn luyện. LM có lời nhắc của chúng tôi, với tất cả tham số có thể huấn luyện và không có ràng buộc thực nghiệm về cập nhật, cho thấy hiệu suất thích ứng tốt nhất.

Tiền huấn luyện hiệu quả dữ liệu. Lưu ý rằng chúng tôi giả thuyết HPrompt-CPT đặc biệt hiệu quả trong thiết lập tinh chỉnh bất kỳ lúc nào. Hiệu suất của nó trên một tập con nhỏ của kho văn bản đáng tham khảo, vì mô hình có thể được sử dụng để tinh chỉnh trong các trường hợp mà một miền chưa hoàn thành huấn luyện. Hình 4 minh họa hiệu suất được huấn luyện trên các kích thước bộ dữ liệu khác nhau và nổi bật tính hiệu quả của phương pháp chúng tôi trong môi trường ít tài nguyên, đặc biệt về khả năng tổng quát. Thiết kế mô-đun hnet-prompt của chúng tôi thành công thúc đẩy chuyển giao kiến thức qua các miền, và bên cạnh đó chúng tôi quan sát rằng cấu trúc của siêu mạng quan trọng trong các thiết lập như vậy. Transformer có thể underfitting khi đối mặt với các bộ dữ liệu nhỏ hơn, dẫn đến hiệu suất kém so với cấu trúc tuyến tính.

Phân tích về phân phối của embedding hnet-prompt và trạng thái ẩn. Chúng tôi thực hiện phân tích định tính về lời nhắc và trạng thái ẩn được tạo ra bởi HPrompt-CPT để điều tra xem siêu mạng có thể tổng quát thông tin miền hay không. Như được mô tả trong Hình 5, chúng tôi sử dụng bản đồ t-sne (van der Maaten and Hinton, 2008) để hình dung đầu ra mô hình trước và sau khi huấn luyện trên tất cả sáu miền trong DAPset. Đối với lời nhắc, chúng tôi quan sát rằng các embedding lời nhắc được tạo ra có thể hiệu quả nhóm các miền tương tự lại với nhau (ví dụ, embedding chồng chéo cho kho văn bản C2, C3 và C5 từ cùng bộ dữ liệu giấy tờ) trong khi cũng đạt được sự khác biệt cho các miền không tương tự (ví dụ, embedding xa cho C1 (nhà hàng) và C5 (hóa sinh)). Đây là một kết quả ấn tượng, tức là nó chuyển giao thông tin qua các miền, giúp LM thích ứng hiệu quả và tổng quát kiến thức.

Đối với các trạng thái ẩn, mô hình của chúng tôi tạo ra các trạng thái ẩn có thể phân biệt cho tác vụ hạ nguồn dựa trên thông tin miền đã tiền huấn luyện, tức là biểu diễn hạ nguồn ban đầu bị trộn lẫn (D1-D6 trong Hình 5 trên bên phải) được tách thành công trong Hình 5 trên bên trái. Ví dụ, mô hình gán biểu diễn chồng chéo cho các tác vụ tương tự D2 và D3 (thuộc về ACL và AI, tương ứng), trong khi cung cấp sự khác biệt hiệu quả cho các tác vụ không liên quan D1 (nhà hàng) và D5 (sinh học).

5.4 Nghiên cứu Loại bỏ

Bảng 2 và 3 trình bày kết quả của các thiết kế khác nhau của HPrompt-CPT trên DAPset, trong đó các siêu tham số được cố định qua tất cả các thiết lập.

Tính hiệu quả của các thành phần chính. Để đánh giá tác động của siêu mạng, chúng tôi thay thế hnet-prompt bằng progprompt (Razdaibiedina et al., 2023), tạo ra một lời nhắc mềm mới cho mỗi miền và nối nó với các lời nhắc đã học trước đó trong khi yêu cầu domain-id trong quá trình tinh chỉnh. Như được thể hiện trong Bảng 2 (hàng 1 và 3), nó dẫn đến giảm đáng kể trong hiệu suất, đặc biệt trong khả năng thích ứng, với giảm gần 1,77%. Điều này nổi bật tính hiệu quả của hnet-prompt trong việc thích ứng và tổng quát kiến thức miền, cung cấp khả năng lớn cho tinh chỉnh.

Để kiểm tra tác động của tổn thất đồng thuận và bất đồng, chúng tôi so sánh kết quả của việc huấn luyện lời nhắc tiến bộ và hnet-prompt có và không có chúng. Nó cho thấy việc kết hợp tổn thất đồng thuận và bất đồng dẫn đến cải thiện 1,15% và 1,20% trong F_Acc cho hai mô hình, tương ứng, chứng minh tính hiệu quả của nó trong việc ngăn chặn CF. Hơn nữa, chúng tôi quan sát rằng việc giới thiệu tổn thất bất đồng dẫn đến mức tăng 1,33% trong O_Acc, được cho là do việc kết hợp phạm vi rộng hơn của kiến thức miền để thích ứng, như đã thảo luận trong Mục 4.2.

Cấu trúc siêu mạng. Chúng tôi tiếp tục điều tra các thiết kế khác nhau của siêu mạng và trình bày kết quả trong Bảng 3 (trên). Đầu tiên, chúng tôi so sánh cấu trúc mạng với lớp Linear hoặc Multilayer Perceptron (MLP) (hai hàng trên), nhưng chúng cho thấy khả năng thích ứng kém và mức độ CF cao hơn. Thật thú vị, chúng tôi thấy rằng cấu trúc tuyến tính ổn định hơn khi đối mặt với thiết lập ít tài nguyên. Bên cạnh đó, chúng tôi kiểm tra hiệu suất của việc tạo ra embedding lời nhắc trực tiếp để cho thấy tầm quan trọng của phương pháp dựa trên thành phần được giới thiệu trong Mục 4.1. Kết quả tiết lộ rằng phương pháp dựa trên thành phần vượt trội trong tổng quát và ngăn chặn quên lãng, được hưởng lợi từ việc chuyển đổi vấn đề học từ việc ghi nhớ lời nhắc thành vector trọng số là một tác vụ đơn giản.

Mục tiêu tổn thất đồng thuận và bất đồng. Chúng tôi đầu tiên thay thế tổn thất đồng thuận bằng KD thông thường và kết quả được trình bày trong hàng đầu của Bảng 3 (giữa). Nó cho thấy tổn thất đồng thuận dẫn đến cải thiện 1,06% trong khả năng thích ứng trong khi duy trì khả năng tránh quên lãng, chứng minh lợi thế của nó trong việc đạt được sự cân bằng giữa ổn định và tính dẻo cho LM. Sau đó, vì không rõ loại mục tiêu nào phù hợp nhất để vượt qua quên lãng, chúng tôi kiểm tra các hàm mục tiêu khác nhau cho tổn thất đồng thuận và bất đồng trong Bảng 3 (giữa). Cuối cùng, việc giảm thiểu KL-divergence của các trạng thái ẩn có lời nhắc ngẫu nhiên (tổn thất đồng thuận) và giảm thiểu khoảng cách trực giao của các trạng thái ẩn hiện tại (tổn thất bất đồng) mang lại hiệu suất cuối tốt nhất là 83,41%.

6 Kết luận

Bài báo này giới thiệu HPrompt-CPT, một phương pháp tiền huấn luyện liên tục được hướng dẫn bởi lời nhắc mới hướng tới tinh chỉnh bất kỳ lúc nào, cho phép hiệu suất tốt hơn khi được tinh chỉnh trên các miền đã thấy và chưa thấy. Bằng cách huấn luyện một siêu mạng để tạo ra các lời nhắc cụ thể cho miền với tổn thất đồng thuận và bất đồng, nó dẫn đến (i) khả năng lớn hơn trên các miền đã tiền huấn luyện bằng cách học kiến thức miền với các lời nhắc được tạo ra trong khi bảo tồn kiến thức trước đó với lời nhắc ngẫu nhiên, (ii) hiệu suất cải thiện trên các miền chưa thấy bằng cách duy trì tính dẻo của mô hình với tổn thất đồng thuận và khả năng chuyển giao kiến thức với siêu mạng, và (iii) không cần domain-id trong quá trình tinh chỉnh. Chúng tôi thiết lập SOTA mới trên cả benchmark được thiết lập tốt và benchmark chuyển đổi thời gian.

7 Hạn chế

Trong khi chúng tôi đã đánh giá phương pháp của mình trên hai benchmark tiền huấn luyện liên tục, vẫn chưa biết phương pháp của chúng tôi sẽ hoạt động như thế nào trên các benchmark với xung đột miền nghiêm trọng. Các miền trong các benchmark được sử dụng trong bài báo của chúng tôi chủ yếu có thể chuyển giao cho nhau. Ví dụ, miền "ACL" và "AI" trong DAPset có liên quan cao. Chúng tôi không chắc phương pháp của chúng tôi sẽ hoạt động như thế nào trong một chuỗi các miền có ít hoặc không có kiến thức chung hoặc thậm chí xung đột. Ngoài ra, chúng tôi hiện tại chỉ kiểm tra phương pháp của mình trên tác vụ phân loại, trong khi việc khám phá thêm các loại tác vụ hạ nguồn cũng quan trọng. Nghiên cứu tương lai của chúng tôi sẽ mở rộng benchmark để bao gồm các trường hợp như vậy.

Một vấn đề khác cho HPrompt-CPT là việc lựa chọn siêu mạng. Các thí nghiệm của chúng tôi trong Mục 5.3 chứng minh rằng việc giảm kích thước kho văn bản không gán nhãn có thể khiến cấu trúc Transformer bị underfitting, trong khi cấu trúc Linear không thể nắm bắt tất cả thông tin từ một kho văn bản lớn. Ngoài ra, chúng tôi thấy việc tinh chỉnh siêu mạng nhạy cảm với learning rate và weight decay. Chúng tôi hướng tới việc nâng cao khả năng và tính ổn định của siêu mạng. Hơn nữa, tốt nhất là có một siêu mạng có thể tổng quát tốt trên các tác vụ hạ nguồn mà không cần tinh chỉnh.

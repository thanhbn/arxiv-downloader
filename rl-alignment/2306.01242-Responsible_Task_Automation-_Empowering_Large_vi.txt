# 2306.01242.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/rl-alignment/2306.01242.pdf
# Kích thước tệp: 1988471 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Tự động hóa Nhiệm vụ Có Trách nhiệm: Trao quyền cho Mô hình Ngôn ngữ Lớn 
như những Bộ tự động hóa Nhiệm vụ Có Trách nhiệm
Zhizheng Zhang∗Xiaoyi Zhang∗Wenxuan Xie Yan Lu
Microsoft Research Asia
{zhizzhang, xiaoyizhang, wenxie, yanlu}@microsoft.com
Tóm tắt
Thành công gần đây của các Mô hình Ngôn ngữ Lớn (LLM) đánh dấu một bước tiến ấn tượng 
hướng tới trí tuệ nhân tạo tổng quát. Chúng đã cho thấy triển vọng đầy hứa hẹn trong việc 
tự động hoàn thành các nhiệm vụ theo hướng dẫn của người dùng, hoạt động như những bộ 
điều phối giống như bộ não. Các rủi ro liên quan sẽ được tiết lộ khi chúng ta ủy thác ngày 
càng nhiều nhiệm vụ cho máy móc để hoàn thành tự động. Một câu hỏi lớn nổi lên: làm thế 
nào chúng ta có thể khiến máy móc hành xử có trách nhiệm khi giúp con người tự động hóa 
các nhiệm vụ như những copilot cá nhân? Trong bài báo này, chúng tôi khám phá câu hỏi 
này một cách sâu sắc từ các góc độ khả thi, đầy đủ và bảo mật. Cụ thể, chúng tôi trình bày 
Tự động hóa Nhiệm vụ Có Trách nhiệm (ResponsibleTA) như một framework cơ bản để tạo 
điều kiện cho sự hợp tác có trách nhiệm giữa các bộ điều phối dựa trên LLM và các bộ thực 
thi cho việc tự động hóa nhiệm vụ với ba khả năng được trao quyền: 1) dự đoán tính khả thi 
của các lệnh cho bộ thực thi; 2) xác minh tính đầy đủ của bộ thực thi; 3) tăng cường bảo 
mật (ví dụ, bảo vệ quyền riêng tư của người dùng). Chúng tôi tiếp tục đề xuất và so sánh 
hai mô hình để thực hiện hai khả năng đầu tiên. Một là tận dụng kiến thức chung của chính 
LLM thông qua kỹ thuật prompt engineering trong khi cái khác là áp dụng các mô hình có 
thể học được đặc thù cho từng lĩnh vực. Hơn nữa, chúng tôi giới thiệu một cơ chế bộ nhớ 
cục bộ để đạt được khả năng thứ ba. Chúng tôi đánh giá ResponsibleTA được đề xuất trên 
việc tự động hóa nhiệm vụ UI và hy vọng nó có thể mang lại nhiều sự chú ý hơn để đảm bảo 
LLM có trách nhiệm hơn trong các tình huống đa dạng.

1 Giới thiệu
Các Mô hình Ngôn ngữ Lớn (LLM) tiên tiến gần đây [3,28,27,6,7,10,32,40] thể hiện khả năng 
hiểu ngôn ngữ, lý luận, tạo sinh, tổng quát hóa và điều chỉnh mạnh mẽ trong một loạt các 
tình huống thực tế. LLM thu được kiến thức chung về các nhiệm vụ miền mở bằng cách mở 
rộng quy mô deep learning, điều này đánh dấu một cột mốc quan trọng trong tiến bộ hướng 
tới trí tuệ nhân tạo tổng quát. Ngoài các nhiệm vụ ngôn ngữ, LLM được trao quyền với khả 
năng nhận thức và tạo sinh đa phương thức thông qua sự hợp tác với các mô hình đặc thù 
theo lĩnh vực [39,30,36]. Chúng đã cách mạng hóa lĩnh vực tự động hóa nhiệm vụ bằng cách 
kết nối LLM với các mô hình hoặc API đặc thù theo lĩnh vực khác nhau, trong đó LLM phục 
vụ như những bộ điều phối giống như bộ não trong khi các mô hình hoặc API đặc thù theo 
lĩnh vực hoạt động như những bộ thực thi hành động [18, 33, 10].

Áp dụng LLM để xây dựng một copilot đa mục đích cho việc tự động hóa các nhiệm vụ đa 
dạng vẫn đang trong giai đoạn khám phá sơ khai. Lấy ví dụ về tương tác với UI, việc duyệt 
web và tương tác với các trang web cũng như ứng dụng khác nhau để đạt được những ý định 
đa dạng của họ (ví dụ, tìm kiếm trên trang web, mua sắm trực tuyến, thay đổi cài đặt, v.v.) 
gần như không thể thiếu đối với cuộc sống hàng ngày của nhiều người. Một số trong số đó 
yêu cầu một kiến trúc hành động phân cấp [2,1] trong đó một hướng dẫn cấp cao từ con 
người được gọi là mục tiêu cấp nhiệm vụ cần được phân tách thành một loạt các hướng dẫn 
từng bước cấp thấp để thực thi thực tế. Những nhiệm vụ đa bước phức tạp như vậy yêu cầu 
mỗi bước phải được lập kế hoạch hợp lý và thực hiện đáng tin cậy phù hợp với ý định của 
con người. Điều này thực sự đặt ra những thách thức đáng kể về tính tương thích giữa các 
bộ điều phối dựa trên LLM và các bộ thực thi của chúng mà không can thiệp vào quá trình 
đào tạo. Sự hợp tác đáng tin cậy của chúng yêu cầu các bộ điều phối dựa trên LLM phải rất 
quen thuộc với khả năng của các bộ thực thi, và lập lại kế hoạch thực thi nhiệm vụ khi cần 
thiết dựa trên tính đầy đủ lệnh của các bộ thực thi. Các công trình hiện tại [36,39,30,18] chỉ 
nói với LLM về sức mạnh của các bộ thực thi với các mô tả mô hình/API thông qua kỹ thuật 
prompt engineering nặng. Tuy nhiên, những mô tả này thường được viết thủ công và giống 
như tóm tắt, không đầy đủ để mô tả khả năng của các bộ thực thi và không thể phản ánh 
tính đầy đủ thực thi cho LLM. Ngoài ra, LLM cũng có thể thiếu nhận thức đầy đủ về các mục 
tiêu nhiệm vụ và môi trường, do đó đưa ra các hướng dẫn không hợp lý cho các bộ thực thi.

Khi ngày càng nhiều nhiệm vụ được ủy thác cho máy móc để hoàn thành tự động, việc tiếp 
xúc với rủi ro sẽ tăng lên, điều này đòi hỏi phải giải quyết vấn đề độ tin cậy với ý thức cấp 
bách.

Trong công trình này, chúng tôi đề xuất ResponsibleTA như một framework đa phương thức 
cơ bản để trao quyền cho LLM như những bộ tự động hóa nhiệm vụ có trách nhiệm trong ba 
khía cạnh: 1) Tính khả thi: ResponsibleTA dự đoán tính khả thi của các lệnh cấp thấp được 
tạo ra bởi bộ điều phối dựa trên LLM và trả về kết quả cho LLM để lập lại kế hoạch trước 
khi thực thi hành động. Khả năng này nhằm giảm thiểu rủi ro và tiêu thụ thời gian khi để 
các bộ thực thi thực hiện các hướng dẫn không thể đạt được, làm cho việc tự động hóa nhiệm 
vụ trở nên có thể kiểm soát và hiệu quả hơn. 2) Tính đầy đủ: ResponsibleTA kiểm tra kết 
quả thực thi của các lệnh cấp thấp từng bước và cung cấp phản hồi kịp thời cho bộ điều 
phối dựa trên LLM để cho phép nó lên lịch lại các bước tiếp theo một cách hợp lý hơn. Khả 
năng này có thể cải thiện tỷ lệ thành công của việc hoàn thành nhiệm vụ tự động. 3) Bảo 
mật: ResponsibleTA tăng cường LLM với bộ nhớ triển khai ở edge, cho phép thông tin nhạy 
cảm của người dùng được ẩn trong quá trình tương tác với LLM triển khai trên cloud và chỉ 
được lưu trữ và sử dụng cục bộ trên thiết bị của người dùng. Khả năng này giảm hoặc tránh 
việc truyền thông tin nhạy cảm của người dùng giữa LLM triển khai trên cloud và các bộ 
thực thi triển khai ở edge, do đó giảm nguy cơ rò rỉ quyền riêng tư của người dùng. Trao 
quyền cho LLM với những khả năng này, ResponsibleTA đạt được xác minh tự động trước 
và sau mỗi bước thực thi, điều này cải thiện không chỉ tỷ lệ thành công mà còn hiệu quả 
hoàn thành với đảm bảo bảo mật chu đáo cho người dùng.

Ngoài thiết kế framework của ResponsibleTA, chúng tôi điều tra việc thực hiện ba chức năng 
cốt lõi của ResponsibleTA như một nghiên cứu thực nghiệm trong một tình huống ứng dụng 
thực tế (tức là tự động hóa nhiệm vụ UI). Mục tiêu của nó là tự động định vị các phần tử UI 
mục tiêu và tương tác với chúng thông qua các hoạt động nhấp chuột và gõ phím tự động 
dựa trên hướng dẫn nhiệm vụ từ người dùng, điều này có nhu cầu cao trong cả học thuật 
và công nghiệp. Đối với tính khả thi và tính đầy đủ, chúng tôi đề xuất và so sánh hai mô 
hình kỹ thuật để thực hiện chúng. Một mô hình là tận dụng kiến thức chung của chính LLM 
thông qua kỹ thuật prompt engineering. Mô hình khác là đào tạo các mô hình đặc thù theo 
lĩnh vực chịu trách nhiệm cụ thể cho hai chức năng này như những trợ lý bên ngoài của các 
bộ điều phối và bộ thực thi. Chúng tôi quan sát thấy việc tận dụng chính LLM kém hơn so 
với việc áp dụng các mô hình đặc thù theo lĩnh vực, cho thấy rằng kiến thức đặc thù theo 
lĩnh vực là rất quan trọng để tăng cường độ tin cậy của LLM trong tự động hóa nhiệm vụ. 
Đối với bảo mật, chúng tôi giới thiệu một bộ nhớ cục bộ và đề xuất một thiết kế cơ chế để 
sử dụng nó nhằm trao cho ResponsibleTA những đảm bảo bảo mật.

Các đóng góp của công trình này có thể được tóm tắt như sau:
• Chúng tôi trình bày một framework đa phương thức cơ bản, được gọi là ResponsibleTA, 
trao quyền cho LLM với khả năng dự đoán tính khả thi, xác minh tính đầy đủ và bảo vệ 
bảo mật để tự động hoàn thành các nhiệm vụ một cách có trách nhiệm.
• Chúng tôi đề xuất và so sánh hai mô hình kỹ thuật để thực hiện các chức năng dự đoán 
tính khả thi và xác minh tính đầy đủ của ResponsibleTA trong các tình huống tự động hóa 
nhiệm vụ UI. Một là tận dụng kiến thức nội bộ của chính LLM trong khi cái khác là đào 
tạo các mô hình đặc thù theo lĩnh vực như những trợ lý bên ngoài.
• Chúng tôi giới thiệu một cơ chế bộ nhớ cục bộ để trao cho ResponsibleTA khả năng bảo 
vệ bảo mật cho quyền riêng tư người dùng, và trình bày hiệu quả của nó trong một số 
trường hợp thực tế đại diện.

2 Các Công trình Liên quan

2.1 Phát triển của Mô hình Ngôn ngữ Lớn
Bắt đầu từ mô hình ngôn ngữ Bert [9], scheme pretraining-finetuning là một thực hành phổ 
biến trong nhiều bài toán xử lý ngôn ngữ tự nhiên (NLP) và thị giác máy tính (CV). Bằng 
cách đưa dữ liệu và mô hình lên quy mô lớn hơn, GPT-3 [3] chứng minh rằng LLM có được 
khả năng học trong ngữ cảnh, trong đó LLM có thể nhanh chóng thích ứng với một nhiệm vụ 
mới chỉ với một vài ví dụ như prompts. Hơn nữa,

--- TRANG 2 ---
InstructGPT [29] tinh chỉnh GPT-3 với một bộ dữ liệu minh họa của con người để làm cho 
LLM tuân theo ý định của người dùng. Gần đây, ChatGPT [28] và GPT-4 [27] thể hiện khả 
năng xuất sắc trong việc tạo ra những câu trả lời hoàn chỉnh cho các câu hỏi ngôn ngữ tự 
nhiên của người dùng. Xem xét rằng những LLM này chỉ xử lý các token ngôn ngữ, Kosmos-1 
[12] mở rộng tập dữ liệu đào tạo của nó thành dữ liệu hình ảnh-văn bản và cho thấy khả 
năng trong việc trả lời câu hỏi thị giác và đối thoại đa phương thức. Trong khi đó, có những 
LLM đồng thời như PaLM [6,7] và PaLM-E [10], và những nỗ lực mã nguồn mở như LLaMA 
[32] và OPT [40]. Mặc dù có hiệu suất mạnh mẽ, những câu trả lời được tạo ra bởi LLM không 
phải lúc nào cũng đáng tin cậy. Công trình của chúng tôi nhằm trao quyền cho LLM để đáng 
tin cậy trong lĩnh vực tự động hóa nhiệm vụ.

2.2 Mô hình Ngôn ngữ Lớn cho Tự động hóa Nhiệm vụ
LLM có thể phục vụ như những actor hoặc coordinator/planner cho việc tự động hóa nhiệm 
vụ AI kỹ thuật số hoặc vật lý. Khi hoạt động như actor, các đầu ra của LLM là những hành 
động có thể thực thi [25,1], điều này bị giới hạn trong các nhiệm vụ xử lý ngôn ngữ tự nhiên. 
Hướng tới các ứng dụng rộng lớn hơn trong môi trường vật lý [13,1,20,10,18], mô phỏng vật 
lý [34,35] và kỹ thuật số [30,36,39,18], LLM thường hoạt động như một bộ điều phối giống 
như bộ não để xử lý các hướng dẫn cấp cao của con người thành các lệnh máy có thể thực 
thi từng bước và chuyển chúng cho các mô hình/API đặc thù theo lĩnh vực để thực thi thực 
tế. Theo hướng này, LLM đã mở ra những khả năng vô hạn cho việc tự động hóa nhiệm vụ 
và đồng thời đặt ra những yêu cầu cao hơn về độ tin cậy của các hệ thống tự động. Những 
khiếm khuyết kiến thức hoặc thiên lệch của LLM và khoảng cách giữa LLM và các bộ thực 
thi đều có thể dẫn đến những rủi ro tiềm ẩn trong việc thất bại hoàn thành nhiệm vụ hoặc 
thậm chí gây hại cho người dùng [11]. Công trình trước đây [1] cố gắng giải quyết vấn đề 
khả năng thực thi bằng cách đào tạo một mô hình bên ngoài để phê bình các đầu ra của 
LLM. Nó đạt được thành công trong các môi trường robot đơn giản [1] nhưng được chứng 
minh là khó áp dụng vào các môi trường phức tạp với nhiều đối tượng và hành động đa dạng 
hơn [31,37]. Bên cạnh đó, [35,37] theo dõi kết quả thực thi cho việc lập kế hoạch tiếp theo 
của LLM. Theo hiểu biết tốt nhất của chúng tôi, chúng tôi là những người đầu tiên nghiên 
cứu có hệ thống về độ tin cậy của việc tự động hóa nhiệm vụ dựa trên LLM từ các góc độ 
tính khả thi, tính đầy đủ và bảo mật.

3 Phương pháp

3.1 Framework ResponsibleTA
ResponsibleTA là một framework đa phương thức cơ bản để trao quyền cho LLM như những 
bộ tự động hóa nhiệm vụ có trách nhiệm. Mục tiêu là tăng cường toàn diện độ tin cậy của 
việc sử dụng LLM như những bộ điều phối, trong khi áp dụng các mô hình/API đặc thù theo 
lĩnh vực như những bộ thực thi, để tự động hoàn thành các nhiệm vụ theo hướng dẫn của 
con người. Nó đạt được việc tăng cường độ tin cậy với ba khả năng được trao quyền: dự 
đoán tính khả thi, xác minh tính đầy đủ và bảo vệ bảo mật.

Như được hiển thị trong Hình 1, ResponsibleTA nhận các hướng dẫn cấp cao (tức là mục 
tiêu nhiệm vụ) từ con người làm đầu vào và phân tích chúng thành các lệnh cấp thấp (tức 
là từng bước) với một LLM được đào tạo trước để lập kế hoạch hành động

--- TRANG 3 ---
Hướng dẫn cấp cao
không khả thi Lập lại kế hoạch
khả thi khả thi
Bộ điều phối dựa trên LLM
Bộ thực thi đặc thù theo lĩnh vực
Lập kế hoạch
hoàn thành hay không
Đầu vào thị giác Đầu vào ngôn ngữ
Bộ nhớ
Bộ xác minh tính đầy đủ
Lệnh cấp thấp
Bộ dự đoán tính khả thi
Kết quả thực thi Placeholder → Thông tin người dùng
Bộ bảo vệ bảo mật
Thông tin người dùng → Placeholder
Bộ bảo vệ bảo mật

Hình 1: Framework của ResponsibleTA được đề xuất. Nó tăng cường bộ điều phối dựa trên 
LLM triển khai trên cloud với bộ bảo vệ tính khả thi, bộ xác minh tính đầy đủ và một bộ 
nhớ cục bộ, đạt được sự hợp tác có trách nhiệm với bộ thực thi đặc thù theo lĩnh vực. Tất 
cả đều được mô tả chi tiết trong văn bản chính.

3. Để đảm bảo lệnh cấp thấp được tạo ra một cách hợp lý và được thực thi đúng ở mỗi bước, 
chúng tôi giới thiệu một bộ dự đoán tính khả thi và một bộ xác minh tính đầy đủ trong 
ResponsibleTA. Trước mỗi lần thực thi, bộ dự đoán tính khả thi đánh giá xem lệnh cấp thấp 
được tạo ra có thể thực thi trong thực tế hay không dựa trên ảnh chụp màn hình hiện tại 
và chính lệnh này. Nó sẽ yêu cầu bộ điều phối dựa trên LLM lập lại kế hoạch thông qua 
kỹ thuật prompt engineering khi lệnh được đánh giá là không khả thi, nếu không sẽ cung 
cấp lệnh cho bộ thực thi khi khả thi. Khi đạt đến số lần cố gắng lập lại kế hoạch tối đa được 
đặt trước, LLM sẽ chấm dứt nhiệm vụ hiện tại và cung cấp phản hồi cho người dùng. Sau 
mỗi lần thực thi, bộ xác minh tính đầy đủ kiểm tra xem kết quả thực thi có phù hợp với 
mục tiêu của lệnh cấp thấp đã cho hay không. Việc lập lại kế hoạch sẽ được khởi động bởi 
LLM một khi phát hiện một lần thực thi không hợp lệ hoặc không hoàn thành. Lưu ý rằng 
chúng tôi chỉ nhập thông tin phần tử UI trên màn hình cho LLM dưới dạng ngôn ngữ thông 
qua một mô hình phân tích màn hình được đào tạo chỉ khi cần lập lại kế hoạch, để bảo vệ 
thông tin cá nhân trên màn hình của người dùng càng nhiều càng tốt. (Xem phần bổ sung 
để biết thêm chi tiết.) Hơn nữa, chúng tôi tích hợp một bộ bảo vệ bảo mật vào ResponsibleTA 
để cho phép thông tin nhạy cảm của người dùng được lưu trữ cục bộ. Với mô-đun này, 
người dùng được phép thay thế tất cả thông tin nhạy cảm bằng những placeholder được 
định nghĩa trước của họ, và dịch chúng ngược lại khi gửi các lệnh cho các bộ thực thi triển 
khai ở edge để thực thi cục bộ. Kết quả là, ResponsibleTA tăng cường sự liên kết nội bộ 
giữa bộ điều phối và các bộ thực thi, và cung cấp đảm bảo bảo mật cho người dùng như 
một framework tự động hóa nhiệm vụ có trách nhiệm.

Chúng tôi sử dụng tự động hóa nhiệm vụ UI như một tình huống ứng dụng thực tế để điều 
tra và thí nghiệm sâu, nhằm 1) trình bày hiệu quả của ResponsibleTA một cách trực quan 
và 2) nêu rõ việc thực hiện ba mô-đun cốt lõi trong ResponsibleTA. Mục tiêu của nó là tự 
động hóa các nhiệm vụ tương tác giữa con người và UI (ví dụ, tìm kiếm trên trang web, 
phát media, mua sắm trực tuyến, thay đổi cài đặt, v.v.). Chúng tôi đào tạo một bộ thực thi 
đặc thù theo lĩnh vực để tự động định vị phần tử UI mục tiêu bằng cách dự đoán tọa độ 
không gian của nó để nhấp chuột hoặc gõ phím, với một lệnh cấp thấp đã cho và ảnh chụp 
màn hình tương ứng làm đầu vào. Vì đây không phải là điểm nhấn trong công trình này, 
chúng tôi đặt thiết kế mô hình chi tiết và việc đào tạo bộ thực thi trong phần thí nghiệm 
và phần bổ sung.

3.2 Bộ dự đoán tính khả thi
Bộ dự đoán tính khả thi nhận lệnh cấp thấp và ảnh chụp màn hình hiện tại làm đầu vào 
để dự đoán tính khả thi của lệnh này. Nó góp phần tránh việc thực thi một lệnh không khả 
thi hoặc nguy hiểm bằng cách yêu cầu lập lại kế hoạch một khi không khả thi. Ở đây, chúng 
tôi giới thiệu hai mô hình kỹ thuật để thực hiện nó, và so sánh hiệu quả của chúng trong 
phần thí nghiệm tiếp theo.

--- TRANG 4 ---
Vâng, tôi hiểu kỳ vọng của bạn và tôi đã sẵn sàng bắt đầu. [System Prompt]:
Bạn là một bộ dự đoán tính khả thi cho tự động hóa nhiệm vụ trong Windows. Cho một lệnh cần được thực thi và các mô tả cho tất cả các phần tử trên màn hình hiện tại, bạn trả về Có hoặc Không để dự đoán tính khả thi của lệnh này.
Ví dụ, bạn được cho:
Lệnh: "Nhấp vào biểu tượng chi tiết của tin tức tài chính."
Các phần tử UI trên màn hình hiện tại:
[{ID: 0, Nội dung: "Trang chủ BBC", Vị trí: [100, 100] # tọa độ trung tâm [ngang, dọc] của phần tử này},
 {ID: 1, Nội dung: "Hậu vệ Anh Bronze phẫu thuật đầu gối qua lỗ khóa.", Vị trí: [100, 200]},
 {ID: 2, Nội dung: "Cầu thủ Spurs hoàn tiền cho người hâm mộ sau trận thua thảm.", Vị trí: [100, 300]}, ……]
Bạn nên trả về:
{Suy nghĩ: "Không có phần tử nào trong danh sách đã cho liên quan đến 'chi tiết tin tức tài chính'. Vậy nên, truy vấn hành động không khả thi, câu trả lời nên là không.", Khả thi: "Không".}
Bạn có hiểu kỳ vọng của tôi không? Và bạn đã sẵn sàng bắt đầu chưa?
[User Query]:
Lệnh: "*** *** ***."
Các phần tử UI trên màn hình hiện tại: [{ID: *, Nội dung: "*** ***", Vị trí: [*, *]}, ……]
{Suy nghĩ: "∗∗∗ ∗∗∗ ∗∗∗.", Khả thi: "Có (hoặc Không)".}

Hình 2: Minh họa mô hình dựa trên kỹ thuật prompt engineering của chúng tôi để thực hiện 
bộ dự đoán tính khả thi trong ResponsibleTA được đề xuất.

Mô hình dựa trên kỹ thuật prompt engineering. Mô hình này được thiết kế để tận dụng kiến 
thức chung nội bộ của LLM để đạt được dự đoán tính khả thi. Đầu tiên chúng tôi thiết kế 
một system prompt như prompt khởi động để nói với LLM mục tiêu nhiệm vụ và đầu ra mong 
đợi của chúng tôi cùng với một số minh họa cụ thể. Xem xét rằng hầu hết các LLM tiên tiến 
(ví dụ, ChatGPT, GPT-4) chưa tích hợp hoặc phát hành giao diện đầu vào của chúng cho 
các phương thức khác (ví dụ, thị giác) ngoại trừ ngôn ngữ, chúng tôi đào tạo một mô hình 
phân tích màn hình để dịch các ảnh chụp màn hình thành một loạt các phần tử UI trong 
đó mỗi phần tử được biểu diễn dưới dạng mô tả ngôn ngữ với chỉ số, nội dung văn bản, vị 
trí và loại của nó. Thêm chi tiết về mô hình này có thể tìm thấy trong Phần A.2 của tài liệu 
bổ sung. Chúng tôi tổ chức các mô tả ngôn ngữ của tất cả các phần tử UI tại ảnh chụp màn 
hình hiện tại dưới dạng có cấu trúc (tức là từ điển), và nhập nó cùng với lệnh cấp thấp 
tại bước hiện tại như các truy vấn người dùng cho mỗi instance nhiệm vụ. System prompt 
và các minh họa của truy vấn người dùng của bộ dự đoán tính khả thi được đề xuất được 
minh họa chi tiết trong Hình 2.

Mô hình dựa trên mô hình đặc thù theo lĩnh vực. Mô hình này nhằm giải quyết dự đoán 
tính khả thi bằng cách đào tạo một mô hình đặc thù theo lĩnh vực, tức là một chuyên gia 
bên ngoài. Ở đây, chúng tôi thiết kế một mô hình đa phương thức end-to-end với kiến trúc 
được lấy cảm hứng từ ý tưởng mô hình hóa Pix2Seq [4]. Như được hiển thị trong Hình 3, 
Bộ dự đoán tính khả thi đặc thù theo lĩnh vực của chúng tôi, được gọi là DSFP, bao gồm 
một bộ mã hóa thị giác dựa trên transformer và một bộ giải mã ngôn ngữ dựa trên transformer. 
Cho một hình ảnh X∈RH×W×C, bộ mã hóa thị giác nắm bắt các đặc trưng của X và nhúng 
nó thành nv token d-chiều được ký hiệu bởi {vi|vi∈Rd,1≤i≤nv}. Lệnh cấp thấp được tokenize 
thành nt token văn bản d-chiều được ký hiệu bởi {ti|ti∈Rd,1≤i≤nt}. Sau đó các tập {v} và 
{t} được đưa vào bộ giải mã ngôn ngữ để tạo ra kết quả dự đoán dưới dạng ngôn ngữ.

Bộ mã hóa thị giác
Bộ giải mã ngôn ngữ
Lệnh cấp thấp
"Đăng nhập vào web này với tài khoản {account_name} và mật khẩu {password}."
<s_feasibility>
"0"
</s_feasibility>
Khả thi: 0

Hình 3: Minh họa mô hình dựa trên mô hình đặc thù theo lĩnh vực của chúng tôi để thực 
hiện bộ dự đoán tính khả thi trong ResponsibleTA.

Để làm cho thiết kế kiến trúc trên thống nhất với các nhiệm vụ khác, như xác minh tính đầy 
đủ được giới thiệu tiếp theo, chúng tôi mô hình hóa các đầu ra của bộ giải mã dưới dạng 
ngôn ngữ có cấu trúc như "<task_prompt> {results} </task_prompt>" theo [14,38]. Ở đây, 
"<task_prompt>" và "</task_prompt>" ký hiệu cho điểm bắt đầu và kết thúc trong chuỗi 
ngôn ngữ cho kết quả, tương ứng. Và "{results}" ký hiệu cho nội dung thực tế của kết quả. 
Đối với bộ dự đoán tính khả thi của ResponsibleTA, "<task_prompt>" và "</task_prompt>" 
được khởi tạo thành "<s_feasibility>" và "</s_feasibility>", tương ứng. "{results}" có thể 
là 0 hoặc 1 trong đó 0 đại diện cho "không khả thi" trong khi 1 ký hiệu "khả thi".

3.3 Bộ xác minh tính đầy đủ
Bộ xác minh tính đầy đủ trong ResponsibleTA nhận lệnh đã thực thi và ảnh chụp màn hình 
sau khi thực thi làm đầu vào để đánh giá tính đầy đủ của lệnh này. Nó thực tế đóng vai 
trò xử lý sự liên kết nội bộ giữa bộ điều phối dựa trên LLM và bộ thực thi để đảm bảo độ 
tin cậy của sự hợp tác của chúng. Cho mỗi bước, bộ xác minh cung cấp một phản hồi cho 
bộ điều phối dựa trên LLM để cho biết liệu kết quả thực thi của bộ thực thi có phù hợp với 
kỳ vọng của nó ở bước này hay không để nó có thể khắc phục việc thực thi sai lầm hoặc 
thiên lệch kịp thời thông qua hoạt động lập lại kế hoạch. Nó tạo thành một vòng lặp để trao 
cho ResponsibleTA khả năng tự sửa chữa. Chúng tôi trình bày hiệu quả của nó trong nghiên 
cứu trường hợp trong phần thí nghiệm.

Chúng tôi cũng đề xuất và so sánh hai mô hình kỹ thuật để thực hiện mô-đun này, tương 
tự như những mô hình của bộ dự đoán tính khả thi được giới thiệu ở trên. Để ngắn gọn, 
chúng tôi chỉ nêu những khác biệt với bộ dự đoán tính khả thi ở đây và đặt thêm chi tiết 
trong phần bổ sung của chúng tôi. Đối với mô hình dựa trên kỹ thuật prompt engineering, 
chúng tôi chia sẻ mô hình phân tích màn hình với mô hình trong bộ dự đoán tính khả thi, 
và cập nhật system prompt và truy vấn người dùng phù hợp với mục tiêu xác minh tính đầy 
đủ. Nội dung của chúng được chi tiết trong phần bổ sung. Đối với mô hình dựa trên mô hình 
đặc thù theo lĩnh vực, chúng tôi áp dụng cùng kiến trúc mô hình và định dạng đầu ra với 
những mô hình của bộ dự đoán tính khả thi, nhưng cung cấp lệnh đã thực thi và ảnh chụp 
màn hình sau khi thực thi làm đầu vào. Ở đây, "<task_prompt>" và "</task_prompt>" được 
khởi tạo thành "<s_completeness>" và

--- TRANG 5 ---
"</s_completeness>", tương ứng. "{results}" có thể là 0 hoặc 1 trong đó 0 đại diện cho 
"không đầy đủ" trong khi 1 ký hiệu "đầy đủ".

3.4 Bộ bảo vệ bảo mật
Nhiều nhiệm vụ mà người dùng cần được tự động hóa liên quan đến thông tin riêng tư của họ. 
Ví dụ, mua sắm trực tuyến hoặc cấu hình máy tính có thể yêu cầu thông tin thẻ tín dụng, 
tài khoản và mật khẩu của người dùng. Bộ bảo vệ bảo mật trong ResponsibleTA được thiết 
kế để cho phép thông tin nhạy cảm từ người dùng được lưu trữ và sử dụng cục bộ, loại bỏ 
việc truyền chúng đến LLM triển khai trên cloud và giảm rủi ro rò rỉ thông tin. Để đạt được 
điều này, bộ bảo vệ bảo mật sử dụng một mô hình NER (ví dụ, Bert-NER [19]) để tự động 
phát hiện thông tin nhạy cảm trong hướng dẫn của người dùng, và thay thế chúng bằng 
một placeholder thông tin được ký hiệu bởi "{info_name}". Sau đó, nó lưu trữ "{info_name}" 
và nội dung thực tương ứng bằng cấu trúc từ điển vào một bộ nhớ triển khai ở edge. Khi 
nhận được một lệnh từ LLM, bộ bảo vệ bảo mật dịch placeholder thông tin ngược lại thành 
nội dung gốc, sau đó gửi lệnh đã dịch cho các bộ thực thi để thực thi cục bộ. Ví dụ, khi 
người dùng yêu cầu ResponsibleTA thay đổi địa chỉ giao hàng trong một trang web mua sắm, 
địa chỉ cũ và mới của họ được biểu diễn như "{old_address}" và "{new_address}", tương 
ứng, khi tương tác với LLM triển khai trên cloud, và được dịch ngược lại cho các bộ thực 
thi cục bộ.

4 Thí nghiệm

4.1 Bộ dữ liệu và Chi tiết thực hiện
Bộ dữ liệu dự đoán tính khả thi. Chúng tôi thu thập dữ liệu cho dự đoán tính khả thi từ 
Common Crawl2, một kho lưu trữ mở về dữ liệu web crawl. Chúng tôi lấy mẫu khoảng 40K 
trang web từ kho lưu trữ mở này, cho ra 1,1M cặp hình ảnh-văn bản. Trong số đó, 1M cặp 
được sử dụng để đào tạo trong khi 100K cặp còn lại để kiểm tra. Đối với mỗi trang web, 
chúng tôi trích xuất các phần tử lá và gán chú thích cho chúng từ các mục HTML như inner-text, 
value, alt, aria-label, label-for, và placeholder. Tiếp theo, chúng tôi sử dụng một thuật toán 
ngẫu nhiên để tạo ra các lệnh cấp thấp cho các phần tử bằng cách tận dụng chú thích của 
chúng. Các lệnh ví dụ bao gồm "chọn mục {element_caption}", "nhấp vào mục bên phải 
của {element_caption}", "nhập {words} vào {element_caption}", "cuộn cho đến {element_caption}", 
v.v. Tất cả những lệnh này được coi là khả thi. Các lệnh không khả thi được tạo ra dựa 
trên chú thích phần tử giả không xuất hiện trong trang web hiện tại.

Bộ dữ liệu xác minh tính đầy đủ. Bộ dữ liệu này cũng dựa trên các trang web có sẵn công 
khai. Bộ dữ liệu này tận dụng các chuyển đổi giữa hai trang web, tức là nó chuyển đến trang 
B bằng cách nhấp vào một phần tử trong trang A. Dựa trên các chuyển đổi, chúng tôi có 
thể định nghĩa một ví dụ tích cực về tính đầy đủ như một bộ ba [ảnh chụp màn hình A, 
{element_caption}, ảnh chụp màn hình B]. Chúng tôi tạo ra các ví dụ tiêu cực bằng cách 
thay thế bộ ba bằng các mục giả. Tổng thể, bộ dữ liệu này bao gồm 113K trang web với 
1,2M cặp hình ảnh-văn bản để đào tạo và 6K trang web với 60K cặp hình ảnh-văn bản để 
kiểm tra.

Dữ liệu cho bộ thực thi tự động hóa nhiệm vụ dựa trên bộ dữ liệu dự đoán tính khả thi. 
Chúng tôi đặt thêm chi tiết về cấu hình bộ dữ liệu và thực hiện mô hình trong phần bổ 
sung.

4.2 Kết quả định lượng
Chúng tôi đánh giá hai mô hình kỹ thuật được giới thiệu trước đây để thực hiện bộ dự đoán 
tính khả thi và bộ xác minh tính đầy đủ trong ResponsibleTA. Kết quả thí nghiệm được 
trình bày trong Bảng 1. Do chi phí nặng nề và hiệu quả của việc kiểm tra với LLM, chúng 
tôi lấy mẫu ngẫu nhiên 5K cặp hình ảnh-văn bản từ các phần kiểm tra về dự đoán tính khả 
thi và xác minh tính đầy đủ để đánh giá các mô hình dựa trên kỹ thuật prompt engineering. 
Đối với các mô hình dựa trên mô hình đặc thù theo lĩnh vực, chúng tôi đánh giá chúng trên 
cùng 5K cặp hình ảnh-văn bản (viết tắt là DSM trong Bảng 1) cũng như trên toàn bộ phần 
kiểm tra (viết tắt là DSM+ trong Bảng 1). Như được hiển thị trong Bảng 1, chúng ta có thể 
thấy rằng DSM-based và DSM-based+ có hiệu suất rất gần nhau dưới hai cài đặt kiểm tra 
này. Điều này cho thấy 5K cặp hình ảnh-văn bản được lấy mẫu của chúng tôi đủ đa dạng 
và đại diện để cung cấp kết quả đánh giá thuyết phục.

2https://commoncrawl.org/the-data/

--- TRANG 6 ---
Bảng 1: Kết quả đánh giá định lượng cho các mô-đun dự đoán tính khả thi và xác minh tính 
đầy đủ được đề xuất. "AP", "Acc" và "F1" là viết tắt của các chỉ số average precision, accuracy 
và F1 score, tương ứng. Chỉ số trên "+" ký hiệu kết quả được đánh giá trên bộ dữ liệu kiểm 
tra lớn hơn.

Mô hình    Dự đoán tính khả thi    Xác minh tính đầy đủ
           Acc (%)  AP    F1      Acc (%)  AP    F1
LLM-based (ChatGPT)  65.7   0.631  0.546   61.1   0.564  0.704
LLM-based (GPT-4)    68.9   0.669  0.583   62.9   0.575  0.721
DSM-based           74.8   0.818  0.671   83.8   0.803  0.833
DSM-based+          75.3   0.823  0.678   83.5   0.804  0.829

Độ chính xác của dự đoán tính khả thi. Như được hiển thị trong Bảng 1, GPT-4 mạnh hơn 
ChatGPT cho dự đoán tính khả thi. Và bộ dự đoán tính khả thi dựa trên DSM vượt trội 
hơn bộ dựa trên LLM (GPT-4) lần lượt 5,9%, 0,149, 0,088 trong accuracy, average precision 
và F1 score về dự đoán tính khả thi. Những kết quả này chứng minh hiệu suất vượt trội 
của mô hình dựa trên mô hình đặc thù theo lĩnh vực so với mô hình dựa trên kỹ thuật prompt 
engineering về dự đoán tính khả thi.

Độ chính xác của xác minh tính đầy đủ. Từ Bảng 1, chúng tôi quan sát thấy bộ dự đoán 
tính khả thi dựa trên DSM vượt trội hơn bộ dựa trên LLM (GPT-4) lần lượt 20,9%, 0,228, 
0,112 trong accuracy, average precision và F1 score về xác minh tính đầy đủ, cho thấy xu 
hướng tương tự như trong dự đoán tính khả thi. Nó cũng cho thấy ưu thế hiệu suất của 
việc áp dụng một mô hình đặc thù theo lĩnh vực như bộ xác minh tính đầy đủ trong ResponsibleTA.

Như trên, chúng ta có thể thấy các mô hình dựa trên mô hình đặc thù theo lĩnh vực thực 
hiện tốt hơn một cách nhất quán so với các mô hình dựa trên kỹ thuật prompt engineering 
trong việc thực hiện hai chức năng này của ResponsibleTA. Mặc dù vậy, ưu điểm của các 
mô hình dựa trên kỹ thuật prompt engineering là chúng không yêu cầu thu thập dữ liệu 
cụ thể để đào tạo, mang lại tính linh hoạt tốt hơn trong triển khai thực tế.

4.3 Nghiên cứu trường hợp và Minh họa
Chúng tôi phân tích hiệu suất và hành vi của ResponsibleTA được đề xuất thông qua nghiên 
cứu trường hợp thực tế trên 12 nhiệm vụ, xem xét rằng chưa có các benchmark trưởng 
thành trong lĩnh vực nghiên cứu này. Bên cạnh đó, chúng tôi tiến hành nghiên cứu ablation 
trên những nhiệm vụ này bằng cách so sánh Baseline, Baseline+Fea. và Baseline+Fea.+Com. 
trong đó Baseline+Fea.+Com. là phiên bản đầy đủ của ResponsibleTA. Cấu hình của chúng 
được chi tiết trong chú thích của Bảng 2. Bộ dự đoán bảo mật được cài đặt trong tất cả 
các mô hình.

Nghiên cứu ablation và phân tích. Chúng tôi báo cáo tiến độ hoàn thành cụ thể và trạng 
thái thành công cuối cùng trên tất cả 12 nhiệm vụ thực tế trong Bảng 2. Về tỷ lệ thành 
công, chúng ta có thể thấy rằng Baseline không đạt được thành công cuối cùng trên 9 trong 
số 12 nhiệm vụ. Đối với 9 nhiệm vụ này, 5 trong số chúng được khắc phục thành công bởi 
bộ dự đoán tính khả thi một mình. Trên cơ sở đó, bộ xác minh tính đầy đủ giúp chuyển 
thêm 2 trong số chúng thành thành công cuối cùng. Có thể thấy rằng bộ dự đoán tính khả 
thi và bộ xác minh tính đầy đủ trong ResponsibleTA có thể cải thiện đáng kể tỷ lệ thành 
công của tự động hóa nhiệm vụ bằng cách cung cấp phản hồi cho bộ điều phối dựa trên 
LLM để nó có thể lập lại kế hoạch kịp thời. Cách ResponsibleTA của chúng tôi đạt được 
điều này sẽ được mô tả chi tiết trong văn bản tiếp theo.

Bên cạnh lợi ích của việc cải thiện tỷ lệ thành công, ResponsibleTA được đề xuất có thể 
giảm hiệu quả số lượng lần thực thi hướng dẫn không hợp lệ nhờ bộ dự đoán tính khả thi 
của nó. Kết luận này được rút ra bằng cách so sánh các bước hợp lệ và tổng số bước thực 
thi cho các mô hình Baseline và Baseline+Fea. Do đó, ResponsibleTA của chúng tôi có thể 
tránh các rủi ro khi thực thi những bước không hợp lệ đó.

Hơn nữa, chúng tôi tiếp tục xác minh vai trò của ResponsibleTA về bảo vệ bảo mật bằng 
cách so sánh việc sử dụng placeholder và thông tin người dùng thực trên nhiệm vụ số 7 và 
số 10. Chúng tôi thấy rằng việc khởi động bộ bảo vệ bảo mật không ảnh hưởng đến tỷ lệ 
thành công nhiệm vụ cũng không tăng số lượng lần thực thi không hợp lệ trên hai trường 
hợp này cho cả ba mô hình. Nó có thể loại bỏ hiệu quả nhu cầu tải lên thông tin nhạy cảm 
của người dùng lên cloud.

ResponsibleTA khắc phục các trường hợp thất bại như thế nào? Ở đây, chúng tôi xem xét 
kỹ một trường hợp cụ thể để phân tích chi tiết về cách ResponsibleTA khắc phục một trường 
hợp thất bại để đạt được thành công cuối cùng. Chúng tôi minh họa các quy trình thực thi 
cụ thể của 4 bước đầu tiên cho nhiệm vụ số 9 trong Hình 4. Việc thực thi

--- TRANG 7 ---
Bảng 2: Kết quả nghiên cứu trường hợp của tự động hóa nhiệm vụ trong thế giới thực. 
"Baseline" ký hiệu mô hình bao gồm một bộ điều phối dựa trên LLM và một bộ thực thi 
tự động hóa nhiệm vụ, không có các mô-đun dự đoán tính khả thi và xác minh tính đầy 
đủ được đề xuất. "+Fea." và "+Com." đề cập đến việc thêm mô-đun dự đoán tính khả thi 
và thêm mô-đun tính đầy đủ, tương ứng. Chúng tôi biểu diễn mỗi kết quả thực thi với 
"Tiến độ" và "Trạng thái kết thúc". Ở đây, "Tiến độ" được hiển thị dưới dạng số "bước 
hợp lệ / tổng số bước thực thi (bước chuyên gia con người)", trong đó "bước chuyên gia 
con người" đề cập đến số bước hoàn thành hướng dẫn đã cho bởi một chuyên gia con người. 
Đối với "Trạng thái kết thúc", ✓ có nghĩa là mục tiêu nhiệm vụ đã được đạt được cuối cùng 
trong khi ✗ cho biết nó chưa được đạt.

Số   Hướng dẫn cấp cao                                Baseline         Baseline+Fea.    Baseline+Fea.+Com.
                                                      Tiến độ  Trạng   Tiến độ  Trạng    Tiến độ  Trạng
                                                               thái            thái             thái
1    Mở tin tức bóng đá trong bbc.com.              4/4 (4)   ✓      4/4 (4)   ✓      4/4 (4)   ✓
2    Tìm trang cài đặt xem trong Outlook.          4/4 (4)   ✓      4/4 (4)   ✓      4/4 (4)   ✓
3    Điều hướng đến cài đặt ngôn ngữ trong        3/3 (3)   ✓      3/3 (3)   ✓      3/3 (3)   ✓
     Windows11 của tôi.
4    Tìm cài đặt hệ thống cho kích thước văn       1/3 (3)   ✗      3/3 (3)   ✓      3/3 (3)   ✓
     bản trong Windows11 của tôi.
5    Giúp tôi mở email nhận được mới nhất          2/3 (3)   ✗      3/3 (3)   ✓      3/3 (3)   ✓
     trong Outlook của tôi.
6    Đi đến github.com và kiểm tra các vấn đề      2/5 (4)   ✗      4/4 (4)   ✓      4/5 (4)   ✓
     đã đề cập tôi, đã đăng nhập.
7    Đăng nhập Instacart với tên người dùng        5/6 (6)   ✗      6/6 (6)   ✓      6/6 (6)   ✓
     {username} và mật khẩu {password}.
8    Đi đến Amazon và thêm một đôi găng tay        4/6 (6)   ✗      6/6 (6)   ✓      6/6 (6)   ✓
     vào giỏ hàng.
9    Đi đến Amazon và thêm bộ sạc rẻ nhất          4/7 (9)   ✗      5/5 (9)   ✗      9/9 (9)   ✓
     vào giỏ hàng.
10   Thêm số thẻ khách hàng thân thiết             2/6 (6)   ✗      3/3 (6)   ✗      6/7 (6)   ✓
     Costco {card_num} của tôi trong trang web {web_url}.
11   Tạo một cuộc họp vào 2023/04/15 14:00-       3/6 (8)   ✗      3/3 (8)   ✗      3/3 (8)   ✗
     14:30 trong Outlook.
12   Tìm kiếm repo Cpython và tải xuống tệp        5/7 (8)   ✗      6/6 (8)   ✗      6/6 (8)   ✗
     zip của nó trong github.com.

cho các bước còn lại và các prompt tương ứng được bỏ qua ở đây để ngắn gọn. Như được 
hiển thị trong Hình 4, bộ điều phối dựa trên LLM tạo ra các lệnh cấp thấp khả thi cho 4 
bước đầu tiên, và việc thực thi tương ứng diễn ra suôn sẻ cho những bước này. Đối với bước 
thứ 5, bộ điều phối ban đầu nghĩ chúng ta nên nhấp vào nút có nội dung "sắp xếp theo 
giá". Có vẻ như đây là một lệnh hợp lý nhưng thực tế không khớp với trang web hiện tại, 
vì không có nút phù hợp. Tại thời điểm này, mô hình Baseline thực thi lệnh không khả thi 
này một cách dường như ngẫu nhiên, dẫn đến tổng cộng 4 bước hợp lệ. Khi ResponsibleTA 
có bộ dự đoán tính khả thi, mô-đun này sẽ trả về tín hiệu "không khả thi" cho bộ điều 
phối để nó có thể lập lại kế hoạch dựa trên thông tin trang màn hình được cung cấp thêm. 
Sau khi lập lại kế hoạch, bộ điều phối đưa ra một lệnh khả thi, tức là nhấp vào nút "Sort 
by: Featured", và tạo ra thêm một bước hợp lệ. Mặc dù vậy, Baseline+Fea. vẫn thất bại 
ở bước tiếp theo vì nó không nhận ra rằng một hoạt động nhấp chuột khác cần thiết để 
đạt được mục tiêu sắp xếp theo giá. Điều này có thể được khắc phục hiệu quả bởi phiên 
bản đầy đủ của ResponsibleTA nhờ bộ xác minh tính đầy đủ của nó. Với sự hỗ trợ của mô-
đun này, ResponsibleTA thêm hoạt động nhấp chuột như vậy cho nút "Price: Low to High" 
trước khi thực thi các bước tiếp theo thông qua một lần lập lại kế hoạch khác. Bằng cách 
này, nó điều chỉnh các hành động được lập kế hoạch kịp thời và góp phần vào thành công 
cuối cùng.

5 Hạn chế
Chúng tôi phải thừa nhận rằng rất khó, thậm chí không thể, bao gồm tất cả các khía cạnh 
của một hệ thống mới được thiết kế trong một bài báo học thuật duy nhất. Bài báo này 
đóng góp và mang lại những hiểu biết từ các góc độ thiết kế framework và so sánh mô hình 
kỹ thuật. Những hạn chế còn lại của nó nằm ở hai khía cạnh: 1) xây dựng benchmark; 2) 
thiết kế/lặp lại mô hình cụ thể nhằm theo đuổi hiệu suất cao cho lĩnh vực mới này. Chúng 
tôi ở đây kêu gọi cộng đồng giải quyết chúng với công trình của chúng tôi như một điểm 
khởi đầu.

--- TRANG 8 ---
[ResponsibleTA –Điều phối viên]: (# lập lại kế hoạch)
[Bước-5] {Suy nghĩ: "Nhiệm vụ là về việc sắp xếp kết quả theo giá. Phần tử số 128 có
nội dung 'Sort by:Featured', có vẻ như là nút sắp xếp. Tôi nên nhấp vào nó.",
Hành động: "Nhấp", Loại phần tử: "Nút", Nội dung phần tử: "sort by:featured"}.

[Người dùng]: Đi đến Amazon và thêm bộ sạc rẻ nhất vào giỏ hàng.
[ResponsibleTA –Hệ thống]: Đã nhận! Đang gọi GPT-4 để lập kế hoạch nhiệm vụ…
[ResponsibleTA –Điều phối viên]:
[Bước-1] {Suy nghĩ: "Chúng ta nên mở trình duyệt Edge để truy cập trang web.",
Hành động: "Mở ứng dụng", Tên ứng dụng: "Edge"}.
[Bước-2] {Suy nghĩ: "Chúng ta nên viết url để truy cập trang web.",
Hành động: "Nhập", Nội dung nhập: "amazon.com \n"}.
[Bước-3] {Suy nghĩ: "Chúng ta nên nhấp vào trường nhập tìm kiếm.",
Hành động: "Nhấp", Loại phần tử: "Trường nhập", Nội dung phần tử: "search"}.
[Bước-4] {Suy nghĩ: "Chúng ta nên nhập truy vấn tìm kiếm.",
Hành động: "Nhập", Nội dung nhập: "charger \n"}.
[Bước-5] {Suy nghĩ: "Chúng ta nên sắp xếp kết quả theo giá.",
Hành động: "Nhấp", Loại phần tử: "Nút", Nội dung phần tử: "sort by price"}.

[ResponsibleTA –Bộ dự đoán tính khả thi]: {Khả thi: "Không"} (# trước khi thực thi)
(# Lý do: Không có phần tử hợp lệ "sort by price" trong trang hiện tại.)

[ResponsibleTA –Bộ xác minh tính đầy đủ]: {Hoàn thành: "Không"} (# sau khi thực thi)
(# Lý do: Cần thêm một bước để đạt được mục tiêu của bước-5 đã lập kế hoạch.)

Hình 4: Nghiên cứu trường hợp chi tiết về cách bộ dự đoán tính khả thi và bộ xác minh 
tính đầy đủ được đề xuất trong ResponsibleTA khắc phục trường hợp thất bại để đạt được 
thành công trên nhiệm vụ số 9 trong Bảng 2. Các bước từ 6 đến 9 được bỏ qua để ngắn 
gọn. GPT-4 [27] được sử dụng như bộ điều phối dựa trên LLM.

6 Kết luận và Tác động rộng lớn hơn
Trong bài báo này, chúng tôi trình bày một framework đa phương thức cơ bản, ResponsibleTA, 
để trao quyền cho LLM như những bộ tự động hóa nhiệm vụ có trách nhiệm. Cụ thể, chúng 
tôi tăng cường LLM với ba khả năng cốt lõi, tức là dự đoán tính khả thi, xác minh tính đầy 
đủ và bảo vệ bảo mật. Hơn nữa, chúng tôi đề xuất và so sánh các mô hình kỹ thuật khác 
nhau để thực hiện những chức năng cốt lõi này. Chúng tôi quan sát thực nghiệm thấy các 
mô hình đặc thù theo lĩnh vực mang lại hiệu suất vượt trội so với các giải pháp dựa trên 
kỹ thuật prompt engineering trong việc thực hiện chúng, trong khi cái sau không yêu cầu 
thu thập dữ liệu đặc thù theo lĩnh vực để đào tạo mô hình. Bên cạnh đó, chúng tôi cũng 
chứng minh hiệu quả của ResponsibleTA được đề xuất và cung cấp giải thích về cách ResponsibleTA 
của chúng tôi hoạt động một cách trực quan thông qua nghiên cứu trường hợp. Về tác động 
rộng lớn hơn, chúng tôi hy vọng công trình của chúng tôi có thể truyền cảm hứng cho nhiều 
công trình xuất sắc hơn về việc xây dựng benchmark liên quan, thiết kế phương pháp và 
mở rộng chức năng dựa trên công trình này trong tương lai.

Tài liệu tham khảo
[1]Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David,
Chelsea Finn, Keerthana Gopalakrishnan, Karol Hausman, Alex Herzog, et al. Do as i can, not
as i say: Grounding language in robotic affordances. arXiv preprint arXiv:2204.01691, 2022.
[2]Pierre-Luc Bacon, Jean Harb, and Doina Precup. The option-critic architecture. In Proceedings
of the AAAI conference on artificial intelligence, volume 31, 2017.
[3]Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,
Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are
few-shot learners. In NeurIPS, volume 33, pages 1877–1901, 2020.
[4]Ting Chen, Saurabh Saxena, Lala Li, David J Fleet, and Geoffrey Hinton. Pix2seq: A language
modeling framework for object detection. ICLR, 2022.
[5]Ting Chen, Saurabh Saxena, Lala Li, Tsung-Yi Lin, David J Fleet, and Geoffrey E Hinton. A
unified sequence interface for vision tasks. Advances in Neural Information Processing Systems,
35:31333–31346, 2022.
[6]Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam
Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm:
Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022.
[7]Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li,
Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. Scaling instruction-finetuned
language models. arXiv preprint arXiv:2210.11416, 2022.
[8]MDN contributors. Dom, 2021. https://developer.mozilla.org/en-US/docs/Web/
API/Document_Object_Model/Introduction.
[9]Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep
bidirectional transformers for language understanding. In NAACL, pages 4171–4186, 2019.
[10] Danny Driess, Fei Xia, Mehdi SM Sajjadi, Corey Lynch, Aakanksha Chowdhery, Brian Ichter,
Ayzaan Wahid, Jonathan Tompson, Quan Vuong, Tianhe Yu, et al. Palm-e: An embodied
multimodal language model. arXiv preprint arXiv:2303.03378, 2023.
[11] Kai Greshake, Sahar Abdelnabi, Shailesh Mishra, Christoph Endres, Thorsten Holz, and Mario
Fritz. More than you've asked for: A comprehensive analysis of novel prompt injection threats
to application-integrated large language models. arXiv preprint arXiv:2302.12173, 2023.
[12] Shaohan Huang, Li Dong, Wenhui Wang, Yaru Hao, Saksham Singhal, Shuming Ma, Tengchao
Lv, Lei Cui, Owais Khan Mohammed, Qiang Liu, et al. Language is not all you need: Aligning
perception with language models. arXiv preprint arXiv:2302.14045, 2023.
[13] Wenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch. Language models as
zero-shot planners: Extracting actionable knowledge for embodied agents. In International
Conference on Machine Learning, pages 9118–9147. PMLR, 2022.
[14] Geewook Kim, Teakgyu Hong, Moonbin Yim, JeongYeon Nam, Jinyoung Park, Jinyeong Yim,
Wonseok Hwang, Sangdoo Yun, Dongyoon Han, and Seunghyun Park. Ocr-free document
understanding transformer. In Computer Vision–ECCV 2022: 17th European Conference, Tel
Aviv, Israel, October 23–27, 2022, Proceedings, Part XXVIII, pages 498–517. Springer, 2022.
[15] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.

--- TRANG 10 ---
[16] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed,
Omer Levy, Ves Stoyanov, and Luke Zettlemoyer. Bart: Denoising sequence-to-sequence
pre-training for natural language generation, translation, and comprehension. arXiv preprint
arXiv:1910.13461, 2019.
[17] Chenxia Li, Weiwei Liu, Ruoyu Guo, Xiaoting Yin, Kaitao Jiang, Yongkun Du, Yuning Du,
Lingfeng Zhu, Baohua Lai, Xiaoguang Hu, Dianhai Yu, and Yanjun Ma. Pp-ocrv3: More
attempts for the improvement of ultra lightweight ocr system, 2022.
[18] Yaobo Liang, Chenfei Wu, Ting Song, Wenshan Wu, Yan Xia, Yu Liu, Yang Ou, Shuai Lu, Lei
Ji, Shaoguang Mao, et al. Taskmatrix.ai: Completing tasks by connecting foundation models
with millions of apis. arXiv preprint arXiv:2303.16434, 2023.
[19] David Lim. dslim/bert-base-ner, 2023. https://huggingface.co/dslim/bert-base-NER.
[20] Bill Yuchen Lin, Chengsong Huang, Qian Liu, Wenda Gu, Sam Sommerer, and Xiang Ren. On
grounded planning for embodied tasks with language models. AAAI, 2023.
[21] Thomas F. Liu, Mark Craft, Jason Situ, Ersin Yumer, Radomir Mech, and Ranjitha Kumar.
Learning design semantics for mobile apps. In The 31st Annual ACM Symposium on User
Interface Software and Technology, UIST '18, pages 569–579, New York, NY, USA, 2018.
ACM.
[22] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining
Guo. Swin transformer: Hierarchical vision transformer using shifted windows. In Proceedings
of the IEEE/CVF international conference on computer vision, pages 10012–10022, 2021.
[23] Chengqi Lyu, Wenwei Zhang, Haian Huang, Yue Zhou, Yudong Wang, Yanyi Liu, Shilong
Zhang, and Kai Chen. Rtmdet: An empirical study of designing real-time object detectors,
2022.
[24] Ningning Ma, Xiangyu Zhang, Hai-Tao Zheng, and Jian Sun. Shufflenet v2: Practical guidelines
for efficient cnn architecture design. In Proceedings of the European conference on computer
vision (ECCV), pages 116–131, 2018.
[25] Vincent Micheli and François Fleuret. Language models are few-shot butlers. arXiv preprint
arXiv:2104.07972, 2021.
[26] Microsoft. Microsoft ui automation, 2023. https://learn.microsoft.com/en-us/
dotnet/framework/ui-automation/ui-automation-overview.
[27] OpenAI. Gpt-4, 2023. https://openai.com/research/gpt-4.
[28] OpenAI. Introducing chatgpt, 2023. https://openai.com/blog/chatgpt.
[29] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin,
Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Gray, et al. Training language models
to follow instructions with human feedback. In NeurIPS, 2022.
[30] Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang.
Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface. arXiv preprint
arXiv:2303.17580, 2023.
[31] Mohit Shridhar, Xingdi Yuan, Marc-Alexandre Côté, Yonatan Bisk, Adam Trischler, and
Matthew Hausknecht. Alfworld: Aligning text and embodied environments for interactive
learning. arXiv preprint arXiv:2010.03768, 2020.
[32] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timo-
thée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open
and efficient foundation language models. arXiv preprint arXiv:2302.13971, 2023.
[33] Sai Vemprala, Rogerio Bonatti, Arthur Bucker, and Ashish Kapoor. Chatgpt for robotics: Design
principles and model abilities. Technical Report MSR-TR-2023-8, Microsoft, February 2023.

--- TRANG 11 ---
[34] Ryan Volum, Sudha Rao, Michael Xu, Gabriel DesGarennes, Chris Brockett, Benjamin
Van Durme, Olivia Deng, Akanksha Malhotra, and William B Dolan. Craft an iron sword: Dy-
namically generating interactive game characters by prompting large language models tuned on
code. In Proceedings of the 3rd Wordplay: When Language Meets Games Workshop (Wordplay
2022), pages 25–43, 2022.
[35] Zihao Wang, Shaofei Cai, Anji Liu, Xiaojian Ma, and Yitao Liang. Describe, explain, plan and
select: Interactive planning with large language models enables open-world multi-task agents.
arXiv preprint arXiv:2302.01560, 2023.
[36] Chenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, and Nan Duan.
Visual chatgpt: Talking, drawing and editing with visual foundation models. arXiv preprint
arXiv:2303.04671, 2023.
[37] Yue Wu, So Yeon Min, Yonatan Bisk, Ruslan Salakhutdinov, Amos Azaria, Yuanzhi Li, Tom
Mitchell, and Shrimai Prabhumoye. Plan, eliminate, and track–language models are good
teachers for embodied agents. arXiv preprint arXiv:2305.02412, 2023.
[38] Zhengyuan Yang, Zhe Gan, Jianfeng Wang, Xiaowei Hu, Faisal Ahmed, Zicheng Liu, Yumao
Lu, and Lijuan Wang. Unitab: Unifying text and box outputs for grounded vision-language
modeling. In Computer Vision–ECCV 2022: 17th European Conference, Tel Aviv, Israel,
October 23–27, 2022, Proceedings, Part XXXVI, pages 521–539. Springer, 2022.
[39] Zhengyuan Yang, Linjie Li, Jianfeng Wang, Kevin Lin, Ehsan Azarnasab, Faisal Ahmed,
Zicheng Liu, Ce Liu, Michael Zeng, and Lijuan Wang. Mm-react: Prompting chatgpt for
multimodal reasoning and action. arXiv preprint arXiv:2303.11381, 2023.
[40] Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen,
Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, et al. Opt: Open pre-trained
transformer language models. arXiv preprint arXiv:2205.01068, 2022.

--- TRANG 12 ---
[Tài liệu Bổ sung]
A Giới thiệu thêm về Mô hình
Chúng tôi mô tả chi tiết ba mô-đun cốt lõi trong ResponsibleTA được đề xuất, tức là bộ 
dự đoán tính khả thi, bộ xác minh tính đầy đủ và bộ bảo vệ bảo mật, với việc mô hình 
hóa chúng trong Phần 3 và các bộ dữ liệu được sử dụng trong Phần 4 trong phần chính 
của bài báo. Bên cạnh ba mô-đun cốt lõi này, trong ResponsibleTA, chúng tôi cũng đào 
tạo một bộ thực thi lệnh đặc thù theo lĩnh vực và một mô hình phân tích màn hình. Bộ 
thực thi lệnh đặc thù theo lĩnh vực nhằm định vị phần tử UI mục tiêu bằng cách dự đoán 
tọa độ không gian của nó để tự động hóa các hoạt động nhấp chuột hoặc gõ phím theo 
các lệnh đã cho. Và mô hình phân tích màn hình chuyển đổi một ảnh chụp màn hình đã 
cho thành một loạt các mô tả theo từng phần tử dưới dạng ngôn ngữ, đóng vai trò nhập 
thông tin của một ảnh chụp màn hình dưới dạng ngôn ngữ cho bộ điều phối dựa trên LLM 
trong hai tình huống: 1) khi lập lại kế hoạch; 2) khi sử dụng các mô hình dựa trên kỹ 
thuật prompt engineering để thực hiện bộ dự đoán tính khả thi hoặc bộ xác minh tính đầy 
đủ, như được đề xuất. Mô hình này cần thiết xem xét rằng hầu hết LLM hiện tại chưa phát 
triển hoặc phát hành API đầu vào thị giác của chúng. Hai mô-đun này không phải là điểm 
nổi bật của công trình này. Do đó chúng tôi chi tiết chúng trong tài liệu bổ sung này.

A.1 Bộ thực thi đặc thù theo lĩnh vực
Bộ thực thi đặc thù theo lĩnh vực là một mô hình đa phương thức chấp nhận cả ảnh chụp 
màn hình và một lệnh làm đầu vào. Nó tương tự như mô hình dựa trên mô hình đặc thù 
theo lĩnh vực được giới thiệu để thực hiện bộ dự đoán tính khả thi hoặc bộ xác minh tính 
đầy đủ trong văn bản chính. Lấy cảm hứng từ mô hình hóa Pix2Seq [4,5], chúng tôi sử 
dụng cùng thiết kế kiến trúc cho mô hình này với mô hình của bộ dự đoán tính khả thi như 
được minh họa trong Hình 2 của văn bản chính. Nó yêu cầu các khởi tạo khác nhau cho 
định dạng đầu ra có cấu trúc, tức là "<task_prompt> {results} </task_prompt>". Trong mô 
hình này, "<task_prompt>" và "</task_prompt>" được khởi tạo bởi "<locate_element>" và 
"</locate_element>", tương ứng. Và "{results}" được tổ chức như "<x_min> {xmin} </x_min> 
<y_min> {ymin} </y_min> <x_max> {xmax} </x_max> <y_max> {ymax} </y_max>" trong đó 
[xmin, ymin, xmax, ymax] ký hiệu tọa độ của các điểm trên-trái và dưới-phải của hộp giới 
hạn tương ứng với phần tử UI mục tiêu. Nó đạt được 0.51 mIoU cho việc định vị các phần 
tử UI mục tiêu trong các lệnh đã cho.

A.2 Mô hình phân tích màn hình
Mô hình phân tích màn hình nhằm phát hiện tất cả các phần tử UI trong một ảnh chụp 
màn hình đã cho và nhận dạng các thuộc tính của chúng, tức là vị trí, nội dung văn bản 
và loại. Về thuộc tính loại, chúng tôi phân loại mỗi phần tử UI thành một trong button, 
input và icon. Mô hình này là một hỗn hợp của các mô hình chuyên gia bao gồm bộ phát 
hiện phần tử, bộ phát hiện văn bản, bộ nhận dạng văn bản và bộ nhận dạng biểu tượng. 
Đối với một ảnh chụp màn hình UI đã cho, bộ phát hiện phần tử đầu tiên định vị tất cả 
các phần tử UI. Sau đó, đối với các phần tử button và input, bộ phát hiện văn bản định 
vị các vùng văn bản của chúng khi có văn bản, và bộ nhận dạng văn bản trích xuất nội 
dung văn bản của chúng. Đối với các phần tử icon, bộ nhận dạng biểu tượng nhận dạng 
các danh mục của chúng như nội dung văn bản. Cụ thể, đối với bộ phát hiện phần tử, 
chúng tôi áp dụng kiến trúc kiểu RTMDet [23] với backbone ShuffleNetv2-1.0x [24]. Nó 
đạt được 0.710 mAP trên tập kiểm tra được giới thiệu như sau. Đối với bộ phát hiện văn 
bản và bộ nhận dạng văn bản, chúng tôi sử dụng các mô hình có sẵn từ PaddleOCRv3 [17]. 
Đối với nhận dạng biểu tượng, chúng tôi sử dụng ShuffleNetv2-1.0x [24] như backbone 
của bộ phân loại biểu tượng và sử dụng một lớp được kết nối đầy đủ như head phân loại. 
Bộ nhận dạng biểu tượng của chúng tôi đạt được 95.7% độ chính xác trung bình trên tập 
kiểm tra.

B Giới thiệu thêm về Bộ dữ liệu
Chúng tôi mô tả chi tiết các bộ dữ liệu được sử dụng cho bộ dự đoán tính khả thi và bộ 
xác minh tính đầy đủ đặc thù theo lĩnh vực trong văn bản chính. Trong phần này, chúng 
tôi tiếp tục giới thiệu dữ liệu cho bộ thực thi đặc thù theo lĩnh vực và mô hình phân tích 
màn hình được đề cập trước đây.

Bộ dữ liệu cho bộ thực thi đặc thù theo lĩnh vực bao gồm tất cả các cặp ảnh chụp màn 
hình-hướng dẫn khả thi từ bộ dữ liệu dự đoán tính khả thi được giới thiệu trong Phần 
4.1 của văn bản chính. Phần đào tạo của nó chứa 0.5M mẫu từ 38K ảnh chụp màn hình 
desktop, và phần kiểm tra của nó chứa 27K mẫu từ 2K ảnh chụp màn hình desktop. Đối 
với bộ phát hiện phần tử trong mô hình phân tích màn hình, chúng tôi thu thập một bộ 
dữ liệu dựa trên các trang web và ứng dụng windows có sẵn công khai, bao gồm khoảng 
1.5M ảnh chụp màn hình với 1.2M trong số chúng là

--- TRANG 13 ---
phần đào tạo và 0.3M trong số chúng là phần kiểm tra. Đối với những dữ liệu này, chúng 
tôi có được các chú thích của các phần tử UI, tức là loại và hộp giới hạn của chúng, từ 
metadata cấu trúc cây của chúng, tức là DOM [8] và UIA [26]. Chỉ có các nút lá được sử 
dụng. Đối với bộ phân loại biểu tượng trong mô hình phân tích màn hình, chúng tôi xây 
dựng một bộ dữ liệu dựa trên một bộ công khai (Rico [21]), chứa 14,043 hình ảnh biểu 
tượng với 14 danh mục biểu tượng được sử dụng thường xuyên. Phần đào tạo của nó chứa 
12,637 mẫu trong khi phần kiểm tra chứa 1,405 mẫu.

C Thêm chi tiết thực hiện

C.1 Chi tiết đào tạo
Như được giới thiệu, trong ResponsibleTA, bộ dự đoán tính khả thi, bộ xác minh tính đầy 
đủ và bộ thực thi đặc thù theo lĩnh vực chia sẻ cùng thiết kế kiến trúc mô hình như được 
hiển thị trong Hình 3 của văn bản chính. Đối với kiến trúc này, chúng tôi sử dụng Swin 
Transformer [22] và mô hình BART [16] như bộ mã hóa thị giác và bộ giải mã ngôn ngữ, 
tương ứng. Đối với tất cả chúng, đầu tiên chúng tôi pretrain toàn bộ mô hình trên các 
nhiệm vụ hiểu tài liệu được giới thiệu trong [14] và sau đó finetune nó trên những bộ dữ 
liệu cho dự đoán tính khả thi, xác minh tính đầy đủ và thực thi lệnh. Trừ khi được nêu 
cụ thể, chúng tôi thực hiện finetune trên mỗi nhiệm vụ trong 20 epoch sử dụng 8 GPU 
NVIDIA V100, với batch size là 2 trên mỗi card GPU. Chiều cao và chiều rộng của ảnh 
chụp màn hình được thay đổi kích thước thành 960 và 1280, tương ứng. Chúng tôi sử dụng 
optimizer Adam [15] và đặt learning rate ban đầu là 1×10−4. Bên cạnh đó, chúng tôi áp 
dụng lịch trình cosine learning rate annealing và kỹ thuật gradient clipping với norm 
gradient tối đa là 1.0.

C.2 Chi tiết thiết kế Prompt
Tương tự như các mô hình được đề xuất để thực hiện bộ dự đoán tính khả thi, chúng tôi 
cũng giới thiệu hai mô hình tương tự để thực hiện bộ xác minh tính đầy đủ trong ResponsibleTA 
được đề xuất. Về mô hình dựa trên kỹ thuật prompt engineering, chúng tôi chi tiết thiết 
kế prompt liên quan như được minh họa trong Hình 5 để giới thiệu rõ ràng hơn và tái 
tạo tốt hơn.

D Thêm kết quả thí nghiệm
Trong Hình 4 của văn bản chính, chúng tôi đã mô tả quy trình tự động hóa của năm bước 
đầu tiên trên một nhiệm vụ cụ thể (tức là Nhiệm vụ 9 trong Bảng 2 của văn bản chính) 
để hiển thị cách bộ dự đoán tính khả thi và bộ xác minh tính đầy đủ được đề xuất đóng 
vai trò của chúng trong việc chuyển một trường hợp ban đầu thất bại thành một trường 
hợp thành công. Ở đây, trong Phần D.1, chúng tôi cung cấp phiên bản đầy đủ của nó với 
phần-1 (từ đầu đến bước thứ 6) được minh họa trong Hình 6 và phần-2 (từ bước thứ 7 
đến cuối) được minh họa trong Hình 7. Hơn nữa, chúng tôi cung cấp một trường hợp thất 
bại (được minh họa trong Hình 8) và phân tích của nó trong Phần D.2.

D.1 Một trường hợp thành công và Phân tích của nó
Lưu ý rằng phân tích sâu cho phần-1 của trường hợp này có trong Phần 4.3 của văn bản 
chính. Chúng tôi cung cấp phân tích chi tiết về phần-2 của nó ở đây. Như được hiển thị 
trong Hình 7, bộ điều phối dựa trên GPT-4 trong ResponsibleTA ban đầu lập kế hoạch nhấp 
vào nút có nội dung "cheapest charger". Tuy nhiên, trong trang web thực tế, không có 
phần tử phù hợp trên trang hiện tại. Lúc này, bộ dự đoán tính khả thi coi lệnh được lập 
kế hoạch này là không khả thi trước khi thực thi, và yêu cầu bộ điều phối lệnh được lập 
lại kế hoạch dựa trên thông tin của trang hiện tại. Sau đó, bộ điều phối nghĩ chúng ta 
nên nhấp vào phần tử chứa thông tin sạc với tọa độ y nhỏ nhất để bước này được xử lý 
đúng. Bộ điều phối lập kế hoạch cho bước tiếp theo, tức là thêm mục đã chọn vào giỏ 
hàng. Nó đưa ra một lệnh không khả thi một lần nữa vì không có mục "add to chart" trên 
trang hiện tại. Mục tiêu được lập kế hoạch này yêu cầu hai hoạt động thực thi để hoàn 
thành trong thực tế. Với sự giúp đỡ của bộ dự đoán tính khả thi và bộ xác minh tính đầy 
đủ, ResponsibleTA của chúng tôi cuối cùng đạt được mục đích thêm mục vào giỏ hàng bằng 
cách nhấp vào nút "See All Buying Options" tiếp theo là nút "Add to Cart". Như vậy, hướng 
dẫn của con người "Đi đến Amazon và thêm bộ sạc rẻ nhất vào giỏ hàng." được tự động 
hóa thành công.

Từ phân tích chi tiết của trường hợp này, chúng ta có thể hiểu trực quan các chức năng 
của bộ dự đoán tính khả thi và bộ xác minh tính đầy đủ trong ResponsibleTA. Cụ thể, bộ 
dự đoán tính khả thi có thể chặn các lệnh được lập kế hoạch không hợp lý. Và bộ xác minh 
tính đầy đủ kiểm tra xem các hoạt động thực thi thực tế có đạt được mục tiêu dự định 
từng bước hay không. Chúng phục vụ như một đảm bảo kép cho ResponsibleTA để đạt được 
tự động hóa nhiệm vụ có trách nhiệm trước và sau khi thực thi lệnh, bằng cách cung cấp 
phản hồi cho bộ điều phối để nó có thể thực hiện lập lại kế hoạch kịp thời.

D.2 Một trường hợp thất bại và Phân tích của nó
Chúng tôi mô tả một trường hợp thất bại (tức là nhiệm vụ số 12 trong Bảng 2 của văn 
bản chính) mà bộ dự đoán tính khả thi và bộ xác minh tính đầy đủ không thể khắc phục, 
như được minh họa trong Hình 8. Thất bại này xảy ra trong việc tự động hóa hướng dẫn 
của con người "Tìm kiếm repo Cpython và tải xuống tệp zip của nó trong github.com.". 
Trong hầu hết các kho GitHub, chúng ta có thể đạt được mục đích tải xuống bằng cách trực 
tiếp nhấp vào nút "Download ZIP". Tuy nhiên, trong một số kho GitHub, như trong trường 
hợp thất bại được minh họa, nút "Download ZIP" được ẩn trong một menu thứ cấp. Trong 
trường hợp này, chúng ta cần phải hoàn thành việc tải xuống tệp ZIP thông qua hai hoạt 
động: đầu tiên nhấp vào nút "Local", và sau đó nhấp vào nút "Download ZIP". Như được 
hiển thị trong Hình 8, mặc dù mô-đun được đề xuất phát hiện chính xác rằng các lệnh 
được đưa ra bởi bộ điều phối là không khả thi, bộ điều phối đã không thể cung cấp các 
lệnh đúng và khả thi thông qua lập lại kế hoạch của nó. Nhiệm vụ này cuối cùng bị chấm 
dứt khi đạt đến số lần cố gắng lập lại kế hoạch tối đa được đặt trước. Trường hợp thất 
bại này ngụ ý rằng kiến thức của LLM hiện tại là chung chung nhưng có thể không hoàn 
hảo, và có chỗ cho ResponsibleTA được đề xuất trở nên mạnh mẽ hơn khi khả năng của 
LLM được cải thiện.

Vâng, tôi hiểu kỳ vọng của bạn và tôi đã sẵn sàng bắt đầu. [System Prompt]:
Bạn là một bộ xác minh tính đầy đủ cho tự động hóa nhiệm vụ trong Windows. Cho một lệnh đã được thực thi và các mô tả cho tất cả các phần tử trên màn hình hiện tại, bạn cần trả về Có hoặc Không để nhận dạng tính đầy đủ của lệnh đã cho, tức là liệu mục tiêu lệnh có được đạt thành công hay không.
Ví dụ, bạn được cho:
Lệnh: "Mở tin tức thể thao."
Các phần tử UI trên màn hình hiện tại:
[{ID:0, Loại: "Button", Nội dung: "Trang chủ BBC"}, # Loại có thể là "button", "icon" hoặc "input".
{ID:1, Loại: "Button", Nội dung: "Hậu vệ Anh Bronze phẫu thuật đầu gối qua lỗ khóa."},
{ID:2, Loại: "Button", Nội dung: "Cầu thủ Spurs hoàn tiền cho người hâm mộ sau trận thua thảm."}, ……]
Bạn nên trả về:
{Suy nghĩ: "Có các nội dung phần tử liên quan đến truy vấn hành động: tin tức thể thao, vậy nên lệnh đã cho đã được hoàn thành, câu trả lời nên là có.", Tính đầy đủ: "Có".}
Bạn có hiểu kỳ vọng của tôi không? Và bạn đã sẵn sàng bắt đầu chưa?
[User Query]:
Lệnh: "*** *** ***."
Các phần tử UI trên màn hình hiện tại: [{ID: *, Loại: *, Nội dung: "*** ***"}, ……]
{Suy nghĩ: "∗∗∗∗∗∗∗∗∗.", Tính đầy đủ: "Có (hoặc Không)".}

Hình 5: Minh họa mô hình dựa trên kỹ thuật prompt engineering của chúng tôi để thực 
hiện bộ xác minh tính đầy đủ trong ResponsibleTA được đề xuất.

--- TRANG 14 ---
[ResponsibleTA – Điều phối viên]: (# lập lại kế hoạch cho bước-7)
[Bước-7] {Suy nghĩ: "Nhiệm vụ là về việc chọn bộ sạc rẻ nhất. Các phần tử ID 138, ID 152, và ID 164 là ba phần tử chứa thông tin bộ sạc. Bộ sạc rẻ nhất nên là phần tử có tọa độ y nhỏ nhất trong số các phần tử bộ sạc. Phần tử ID 138 là phần tử có tọa độ y nhỏ nhất trong số chúng.",
Hành động: "Nhấp", Loại phần tử: "Nút", Nội dung phần tử: "new battery charger"}.

[ResponsibleTA – Điều phối viên]:
[Bước-8] {Suy nghĩ: "Tôi nên thêm bộ sạc vào giỏ hàng.",
Hành động: "Nhấp", Loại phần tử: "Nút", Nội dung phần tử: "add to chart"}.

[ResponsibleTA – Điều phối viên]:
[Bước-7] {Suy nghĩ: "Tôi nên chọn bộ sạc rẻ nhất.",
Hành động: "Nhấp", Loại phần tử: "Nút", Nội dung phần tử: "cheapest charger"}.

[ResponsibleTA – Bộ dự đoán tính khả thi]: {Khả thi: "Không"} (# trước khi thực thi)
(# Lý do: Không tìm thấy phần tử hợp lệ "cheapest charger" trên trang hiện tại.)

[ResponsibleTA – Điều phối viên]: (# lập lại kế hoạch cho bước-8)
[Bước-8] {Suy nghĩ: "Nhiệm vụ là về việc thêm bộ sạc rẻ nhất vào giỏ hàng. Phần tử ID 147 là bộ sạc, và phần tử ID 148 là nút 'See All Buying Options' nên được nhấp để thêm bộ sạc vào giỏ.",
Hành động: "Nhấp", Loại phần tử: "Nút", Nội dung phần tử: "see all buying options"}.

[ResponsibleTA – Bộ dự đoán tính khả thi]: {Khả thi: "Không"} (# trước khi thực thi)
(# Lý do: Không tìm thấy phần tử hợp lệ "add to chart" trên trang hiện tại.)

[ResponsibleTA – Bộ xác minh tính đầy đủ]: {Tính đầy đủ: "Không"} (# sau khi thực thi)
(# Lý do: Cần thêm một bước để đạt được mục tiêu của bước-8 đã lập kế hoạch.)

[ResponsibleTA – Điều phối viên]: (# lập lại kế hoạch cho bước-9)
[Bước-9] {Suy nghĩ: "Nhiệm vụ là thêm bộ sạc rẻ nhất vào giỏ hàng. Và phần tử ID 138 là nút 'add to chart'.",
Hành động: "Nhấp", Loại phần tử: "Nút", Nội dung phần tử: "add to chart"}.

Hình 7: Tiếp tục từ Hình 6 trong tài liệu bổ sung này, hình này mô tả phần-2 của quy 
trình tự động hóa hoàn chỉnh của nhiệm vụ số 9, tức là từ bước thứ 7 đến cuối.

--- TRANG 15 ---
[ResponsibleTA – Điều phối viên]: (# lập lại kế hoạch cho bước-7)
[Bước-5] {Suy nghĩ: "Nhiệm vụ là tải xuống repo Cpython dưới dạng zip trong github.com bằng cách nhấp vào tùy chọn 'Download ZIP'. Phần tử có nội dung 'Download ZIP' là phần tử chúng ta cần nhấp.",
Hành động: "Nhấp", Loại phần tử: "Nút", Nội dung phần tử: "Download ZIP"}.

[Người dùng]: Tìm kiếm repo Cpython và tải xuống tệp zip của nó trong github.com.
[ResponsibleTA – Hệ thống]: Đã nhận! Đang gọi GPT-4 để lập kế hoạch nhiệm vụ…
[ResponsibleTA – Điều phối viên]:
[Bước-1⋯6] ⋯⋯
[Bước-7] {Suy nghĩ: "Chúng ta nên nhấp vào tùy chọn 'Download ZIP'.",
Hành động: "Nhấp", Loại phần tử: "Nút", Nội dung phần tử: "Download ZIP"}.

[ResponsibleTA – Bộ dự đoán tính khả thi]: {Khả thi: "Không"} (# trước khi thực thi)
(# Lý do: Không có phần tử hợp lệ "Download ZIP" trên trang hiện tại.)

[ResponsibleTA – Bộ dự đoán tính khả thi]: {Khả thi: "Không"} (# trước khi thực thi)
# Lý do: Không có phần tử hợp lệ "Download ZIP" trên trang hiện tại.

# Các hành động ground-truth (từ con người) cho các bước còn lại:
Bước-7: Nhấp vào nút "Local"
Bước-8: Nhấp vào nút "Download ZIP"

Hình 8: Minh họa một trường hợp thất bại (tức là nhiệm vụ số 12 trong Bảng 2 của văn 
bản chính). Sáu bước đầu tiên được bỏ qua trong hình này để ngắn gọn. GPT-4 [27] được 
sử dụng như bộ điều phối dựa trên LLM.

--- TRANG 16 ---
[ResponsibleTA – Điều phối viên]: (# lập lại kế hoạch)
[Bước-5] {Suy nghĩ: "Nhiệm vụ là về việc sắp xếp kết quả theo giá. Phần tử số 128 có nội dung 'Sort by:Featured', có vẻ như là nút sắp xếp. Tôi nên nhấp vào nó.",
Hành động: "Nhấp", Loại phần tử: "Nút", Nội dung phần tử: "sort by: featured"}.

[Người dùng]: Đi đến Amazon và thêm bộ sạc rẻ nhất vào giỏ hàng.
[ResponsibleTA – Hệ thống]: Đã nhận! Đang gọi GPT-4 để lập kế hoạch nhiệm vụ…
[ResponsibleTA – Điều phối viên]:
[Bước-1] {Suy nghĩ: "Chúng ta nên mở trình duyệt Edge để truy cập trang web.",
Hành động: "Mở ứng dụng", Tên ứng dụng: "Edge"}.
[Bước-2] {Suy nghĩ: "Chúng ta nên viết url để truy cập trang web.",
Hành động: "Nhập", Nội dung nhập: "amazon.com \n"}.
[Bước-3] {Suy nghĩ: "Chúng ta nên nhấp vào trường nhập tìm kiếm.",
Hành động: "Nhấp", Loại phần tử: "Trường nhập", Nội dung phần tử: "search"}.
[Bước-4] {Suy nghĩ: "Chúng ta nên nhập truy vấn tìm kiếm.",
Hành động: "Nhập", Nội dung nhập: "charger \n"}.
[Bước-5] {Suy nghĩ: "Chúng ta nên sắp xếp kết quả theo giá.",
Hành động: "Nhấp", Loại phần tử: "Nút", Nội dung phần tử: "sort by price"}.

[ResponsibleTA – Bộ dự đoán tính khả thi]: {Khả thi: "Không"} (# trước khi thực thi)
(# Lý do: Không có phần tử hợp lệ "sort by price" trên trang hiện tại.)

[ResponsibleTA – Bộ xác minh tính đầy đủ]: {Hoàn thành: "Không"} (# sau khi thực thi)
(# Lý do: Cần thêm một bước để đạt được mục tiêu của bước-5 đã lập kế hoạch.)

[ResponsibleTA – Điều phối viên]: (# lập lại kế hoạch cho bước-6)
[Bước-6] {Suy nghĩ: "Nhiệm vụ là sắp xếp kết quả theo giá. Phần tử số 132 có nội dung 'Price: Low to High', đây là nút để sắp xếp kết quả theo giá.",
Hành động: "Nhấp", Loại phần tử: "Nút", Nội dung phần tử: "price: low to high"}.

Hình 6: Minh họa một trường hợp thành công (tức là nhiệm vụ số 9 trong Bảng 2 của văn 
bản chính) về cách bộ dự đoán tính khả thi và bộ xác minh tính đầy đủ được đề xuất trong 
ResponsibleTA khắc phục trường hợp thất bại để đạt được thành công. Hình này mô tả 
phần-1 của phiên bản đầy đủ, tức là từ bước thứ 1 đến bước thứ 6. GPT-4 [27] được sử 
dụng như bộ điều phối dựa trên LLM.

--- TRANG 17 ---

--- TRANG 18 ---

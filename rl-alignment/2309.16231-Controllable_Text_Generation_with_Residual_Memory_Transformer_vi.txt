# Tạo Văn Bản Có Thể Kiểm Soát với Residual Memory Transformer

Hanqing Zhang1∗, Si Sun2∗, Haiming Wu1, Dawei Song1†
1Trường Khoa học Máy tính & Công nghệ, Viện Công nghệ Bắc Kinh
2Khoa Kỹ thuật Điện tử, Đại học Thanh Hoa
zhanghanqing@bit.edu.cn s-sun17@mails.tsinghua.edu.cn
haimming@bit.edu.cn dwsong@bit.edu.cn
∗Đóng góp ngang nhau†Tác giả liên hệ

## Tóm tắt

Các Mô hình Ngôn ngữ Nhân quả Quy mô Lớn (CLM), ví dụ như GPT3 và ChatGPT, đã mang lại thành công tuyệt vời trong việc tạo văn bản. Tuy nhiên, việc kiểm soát quá trình tạo sinh của CLM trong khi cân bằng tính linh hoạt, độ chi tiết kiểm soát và hiệu quả tạo sinh vẫn là một thách thức mở. Trong bài báo này, chúng tôi đề xuất một phương án thay thế mới cho việc tạo văn bản có thể kiểm soát (CTG), bằng cách thiết kế một plugin kiểm soát không xâm nhập, nhẹ để đồng hành với quá trình tạo sinh của CLM tại các bước thời gian tùy ý. Plugin kiểm soát được đề xuất, gọi là Residual Memory Transformer (RMT), có cấu trúc encoder-decoder, có thể chấp nhận mọi loại điều kiện kiểm soát và hợp tác với CLM thông qua mô hình học tồn dư, để đạt được CTG linh hoạt, tổng quát và hiệu quả hơn. Các thí nghiệm mở rộng được thực hiện trên nhiều nhiệm vụ kiểm soát khác nhau, dưới dạng đánh giá tự động và đánh giá của con người. Kết quả cho thấy sự vượt trội của RMT so với một loạt các phương pháp tiên tiến hiện tại, chứng minh tính hiệu quả và tính linh hoạt của phương pháp chúng tôi.

## 1. Giới thiệu

Tạo văn bản có thể kiểm soát (CTG) tập trung vào việc tạo văn bản trong khi tuân thủ các ràng buộc cụ thể (Hu và Li, 2021; Zhang et al., 2022). Các ràng buộc này có thể từ các yếu tố ngữ nghĩa cấp cao, như cảm xúc, chủ đề và tránh độc hại, đến nội dung chi tiết hơn, ví dụ như bao gồm các khái niệm cụ thể hoặc các yếu tố quan trọng trong văn bản được tạo. Với sự phát triển của AI tạo sinh dựa trên các mô hình ngôn ngữ lớn, mạng xã hội sẽ bị ngập tràn với nội dung do AI tạo ra. Do đó, CTG sẽ rất quan trọng trong các ứng dụng Web thực tế để thiết lập các hệ thống xã hội do AI điều khiển an toàn, đáng tin cậy và thực tế hơn (Krause et al., 2021; Liu et al., 2021a; Zhang et al., 2022).

Các phương pháp CTG tiên tiến hiện tại dựa trên Mô hình Ngôn ngữ Lớn (LLM) được xây dựng trên cấu trúc Transformer (Vaswani et al., 2017) và đã thu hút sự chú ý đáng kể do khả năng hiểu và tạo văn bản xuất sắc. Gần đây, các Mô hình Ngôn ngữ nhân quả quy mô lớn (CLM), tức là các mô hình ngôn ngữ chỉ có decoder, cho thấy những ưu điểm đặc biệt trong các tình huống zero/few-shot (Brown et al., 2020), dẫn đến một loạt các mô hình kế thừa như ChatGPT và GPT4. Điều này được xem là một cột mốc quan trọng hướng tới việc hiện thực hóa Trí tuệ Tạo sinh Nhân tạo. Mặc dù thành công của các mô hình này, CLM vẫn đang đối mặt với những thách thức nhất định, đặc biệt trong CTG.

Xem xét quy mô đáng kể của CLM và chi phí đáng kể để huấn luyện các mô hình như vậy, các phương pháp CTG dựa trên CLM chính hiện tại thuộc hai loại, tức là các phương pháp dựa trên prompt và xử lý hậu kỳ. Các phương pháp dựa trên prompt (Zhang và Song, 2022; Yang et al., 2022; Qian et al., 2022; Lu et al., 2022a; Zhou et al., 2023) nối control-prompt với đầu vào của mô hình tạo sinh để hướng dẫn tạo văn bản có thể kiểm soát hơn. Như các nghiên cứu trước đây đã tiết lộ (Zou et al., 2021; Carlsson et al., 2022), hiệu quả kiểm soát có xu hướng giảm sút với khoảng cách tăng từ prompt. Ngoài ra, việc chèn control-prompt vào một mô hình được huấn luyện tốt có thể làm hại dòng tạo sinh ban đầu của mô hình, do đó mất đi tính linh hoạt của kiểm soát (Carlsson et al., 2022). Mặt khác, hầu hết các phương pháp xử lý hậu kỳ tận dụng một mô-đun phụ trợ để điều chỉnh xác suất tự nhiên tạo ra một token bởi mô hình tạo sinh tại giai đoạn giải mã (Krause et al., 2021; Liu et al., 2021a; Yang và Klein, 2021; Lu et al., 2022b), cản trở khả năng lập kế hoạch nội dung của mô hình và do đó hạn chế việc kiểm soát chi tiết. Hơn nữa, các phương pháp decode-time gần đây hơn (Li et al., 2022; Mireshghallah et al., 2022; Qin et al., 2022) cải thiện độ chi tiết kiểm soát thông qua lấy mẫu hoặc chỉnh sửa lặp lại, nhưng với cái giá của hiệu quả tạo sinh. Do đó, tính linh hoạt, độ chi tiết kiểm soát và hiệu quả tạo sinh cần được cân bằng tốt hơn, điều này đòi hỏi một khung CTG dựa trên CLM linh hoạt hơn.

Trong bài báo này, chúng tôi đề xuất một plugin CTG mới có tên Residual Memory Transformer (RMT), tận dụng mô hình học tồn dư (He et al., 2016; Zhang et al., 2020a) và chỉ thực hiện late fusion với CLM đông lạnh để điều khiển quá trình tạo sinh một cách không xâm nhập. Không như các phương pháp dựa trên prompt, mô hình này không làm rối loạn dòng tạo sinh ban đầu của mô hình CLM cơ sở, cho phép tính linh hoạt tốt hơn của CTG (tức là kiểm soát theo cách plug-and-play). Ngoài ra, kiến trúc RMT bao gồm cấu trúc encoder-decoder, trong đó encoder xử lý các loại thông tin kiểm soát khác nhau và ảnh hưởng đến quá trình tạo sinh, để đạt được kiểm soát chi tiết. Trong khi đó, RMT sử dụng cross-attention để áp dụng đồng nhất các điều kiện kiểm soát cho mỗi token được tạo, tránh tác động tiêu cực thay đổi theo độ dài ngữ cảnh. Đặc biệt, khác với decoder vanilla của Transformer, một causal attention bổ sung được giới thiệu để trích xuất kiến thức tiên nghiệm từ dòng tạo sinh của CLM, cho phép RMT không lệch quá xa khỏi mô hình tạo sinh ban đầu trong khi ngữ nghĩa cấp cao ngầm của nó được tận dụng. Việc tái sử dụng đầu ra của base-CLM cho phép RMT đạt được kiểm soát hiệu quả với một mạng nhỏ, dẫn đến hiệu quả tạo sinh được cải thiện.

Việc huấn luyện RMT bao gồm hai giai đoạn: pre-training và fine-tuning. Pre-training của RMT nhằm tái tạo văn bản nhiễu thành một câu hoàn chỉnh, tạo điều kiện cho RMT hiểu ngữ nghĩa của các điều kiện kiểm soát khác nhau, trong khi căn chỉnh với quá trình tạo sinh của CLM. Trong giai đoạn fine-tuning (tức là học tồn dư), logit của RMT được cộng trực tiếp vào logit của CLM cố định, và mục tiêu huấn luyện là học các tham số của RMT sao cho phân phối mô hình kết hợp gần với phân phối văn bản mong muốn. Vì gradient không cần backpropagate về base-CLM, việc huấn luyện RMT rất hiệu quả. Ví dụ, trong các thí nghiệm của chúng tôi dựa trên GPT2-large, toàn bộ giai đoạn pre-training của RMT với 4M mẫu có thể hoàn thành trong khoảng 30 giờ, sử dụng một GPU NVIDIA A6000 duy nhất.

Chúng tôi thực hiện các thí nghiệm mở rộng để khám phá sự vượt trội của phương pháp chúng tôi trong ba khía cạnh. (1) Tính linh hoạt: Về mặt lý thuyết, RMT được đề xuất có khả năng can thiệp vào quá trình tạo sinh tại bất kỳ bước nào. Về mặt thực nghiệm, nó duy trì cùng mức độ hiệu quả kiểm soát trong cả hai cài đặt có ngữ cảnh và không có ngữ cảnh, cho thấy RMT cho phép kiểm soát tầm xa trong suốt quá trình tạo sinh. (2) Độ chi tiết kiểm soát: Chúng tôi kiểm tra phương pháp của mình trên một loạt các nhiệm vụ CTG có mức độ chi tiết khác nhau (tức là các nhiệm vụ kiểm soát chi tiết bao gồm bao hàm từ và kiểm soát độ dài câu; và kiểm soát thuộc tính dựa trên tình cảm). RMT đạt được hiệu quả kiểm soát có thể so sánh với các phương pháp tiên tiến hiện tại, trong khi đảm bảo chất lượng văn bản. (3) Hiệu quả: Kết quả cho thấy ba block layer của RMT là đủ để đạt được hiệu quả CTG cạnh tranh, và chi phí thời gian tạo văn bản gần như tương đương với CLM ban đầu.

## 2. Khái niệm cơ bản

### 2.1 Attention trong Transformer

Cơ chế Self-Attention là một thành phần quan trọng trong Transformer (Vaswani et al., 2017), được sử dụng để nắm bắt hiệu quả các phụ thuộc tầm xa giữa các từ trong chuỗi đầu vào. Cụ thể, nó được định nghĩa là một ánh xạ giữa một query và một tập hợp các cặp key-value. Các giá trị được cân nhắc theo một hàm tương thích giữa query và mỗi key tương ứng, sau đó được tổng hợp, cuối cùng thu được vector đầu ra. Cơ chế self-attention có thể được biểu diễn như sau:

Att(Q, K, V) = softmax(QK^T/√dk)V, (1)

trong đó Q, K, V đại diện cho các biểu diễn được biến đổi của chuỗi sử dụng ma trận có thể học tương ứng, và √dk là hệ số tỷ lệ. Trong mô hình Transformer, các vector key, query và value luôn được tạo ra từ một chuỗi chung.

Causal Attention là một nhánh đặc biệt của self-attention, còn được gọi là masked self-attention, thường được áp dụng trong mô-đun decoder của Transformer. Khác với self-attention thường, các query trong causal attention chỉ bị hạn chế đối với các vị trí cặp key-value trước đó và vị trí hiện tại của chúng để duy trì tính chất auto-regressive. Thường thì nó có thể được thực hiện bằng một cơ chế che các vị trí không hợp lệ và đặt chúng thành âm vô cùng:

Att(Q, K, V) = softmax(QAK^T/√dk)V, (2)

Aij = {1 nếu i≥j, -∞ ngược lại. (3)

Cross Attention là một nhánh khác của self-attention trong phần decoder của Transformer, nhằm nắm bắt sự tương tác giữa encoder và decoder. Cụ thể, các phần key và value được lấy từ đầu ra bước trước của encoder, và query từ decoder, cho phép encoder chú ý đến từng vị trí trong mô-đun decoder cùng lúc.

### 2.2 Mô hình Ngôn ngữ Nhân quả

Mô hình Ngôn ngữ Nhân quả (CLM) loại bỏ nhu cầu về một thành phần encoder riêng biệt và thường tận dụng Transformer chỉ có decoder (Vaswani et al., 2017), trong đó chỉ có causal attention được sử dụng để thực hiện ước lượng mật độ từng bước, tức là dự đoán token tiếp theo. Giả sử một CLM được tham số hóa với θ. Cho một chuỗi một phần x<t, nó gán một xác suất Pθ(xt|x<t) trên từ vựng V cho việc tạo token tiếp theo xt. Khi tạo một chuỗi văn bản Xn={x1, x2, ..., xn}, nó có thể được biểu thức hóa bởi quy tắc chuỗi như dưới đây:

Pθ(Xn) = ∏(t=1 đến n) Pθ(xt|x<t). (4)

Toàn bộ quá trình tạo sinh được thực hiện lặp lại. Đầu tiên, một token được lấy mẫu từ phân phối Pθ(xt|x<t). Sau đó token được chọn được nối với đầu vào cho bước tạo sinh tiếp theo.

## 3. Phương pháp

Phần này giới thiệu Residual Memory Transformer (RMT) được đề xuất để kiểm soát việc tạo văn bản với mô hình ngôn ngữ nhân quả (CLM). Chúng tôi đầu tiên cung cấp một cái nhìn tổng quan về khung tạo văn bản có thể kiểm soát (CTG) được tăng cường bởi RMT, tiếp theo là mô tả chi tiết về RMT, và cuối cùng là các phương pháp pre-training và fine-tuning chuyên dụng cho khung được đề xuất.

### 3.1 Khung CTG với RMT

Như biểu đồ nét đứt trong Hình 1 minh họa, RMT hoạt động trong chế độ kiểm soát không xâm nhập như một plug-in CLM, trong đó tín hiệu kiểm soát đi qua RMT độc lập và ảnh hưởng đến phân phối đầu ra của CLM đông lạnh thông qua học tồn dư (yt=yg_t+yc_t) mà không can thiệp vào lối đi tạo sinh tự do của CLM. So với các mô hình có thể kiểm soát xâm nhập, ví dụ như các phương pháp dựa trên prompt, RMT cho phép tính linh hoạt cao hơn trong việc chuyển đổi giữa chế độ tạo sinh tự do và chế độ tạo sinh có thể kiểm soát. Mô hình kiểm soát không xâm nhập được đề xuất được coi là thách thức hơn. Cụ thể, RMT được tách rời khỏi quá trình tạo sinh của base-CLM có tiềm năng can thiệp kiểm soát động. Trong khi đó, nó cũng tránh việc điều chỉnh base-CLM thành một mô hình cụ thể cho nhiệm vụ, đảm bảo tính phổ quát của base-CLM. Do đó, nó linh hoạt và đầy hứa hẹn hơn.

Chính thức, cho một văn bản được tạo một phần x<t và một chuỗi hướng dẫn kiểm soát C, khung được đề xuất nhằm tạo văn bản đủ điều kiện Xn={x1, ..., xn} đáp ứng các điều kiện kiểm soát:

PΘ(Xn) = ∏(t=1 đến n) PΘ(xt|x<t;C), (5)

trong đó Θ={θ̃;φ} đại diện cho các tham số của mô hình CTG, bao gồm cả các tham số đông lạnh được thừa kế từ CLM (θ̃) và các tham số có thể điều chỉnh được lấy từ RMT (φ). Toàn bộ quá trình tạo sinh của phương pháp chúng tôi bao gồm bốn bước sau:

**Tạo sinh thô của CLM.** Tại bước tạo sinh t, CLM đầu tiên ánh xạ văn bản được tạo x<t={x1, ..., xt-1} thành các trạng thái ẩn hg_<t={hg_1, ..., hg_{t-1}}. Sau đó, một lớp linear và chuẩn hóa softmax được sử dụng để chiếu trạng thái ẩn của token cuối cùng hg_{t-1} thành phân phối xác suất yg_t trên từ vựng:

yg_t = Pθ̃(xt|x<t) = softmax(Linear(hg_{t-1})), (6)

trong đó CLM tự nhiên tạo token tiếp theo xt cho ngữ cảnh x<t như trong huấn luyện của nó.

**Mã hóa kiểm soát của RMT.** Tiếp theo, encoder của RMT chịu trách nhiệm mã hóa hướng dẫn kiểm soát C={c1, ..., cm} thành bộ nhớ kiểm soát C̃={c̃1, ..., c̃m}, được sử dụng để hướng dẫn việc tạo văn bản có thể kiểm soát trong decoder của RMT:

C̃ = RMT-Enc(C;φenc). (7)

**Giải mã kiểm soát của RMT.** Sau khi mã hóa tín hiệu kiểm soát, decoder của RMT ánh xạ văn bản được tạo x<t thành các trạng thái ẩn mới hc_<t={hc_1, ..., hc_{t-1}} bằng cách xem xét cả bộ nhớ kiểm soát C̃ và các trạng thái ẩn vanilla của CLM hg_<t, và dự đoán tổng hợp phân phối xác suất token tiếp theo yc_t trên từ vựng:

hc_<t = {hc_1..., hc_{t-1}} = RMT-Dec(x<t, hg_<t, C̃; φdec),
yc_t = Pφ(xt|x<t;C) = softmax(Linear(hc_{t-1})). (8)

**Học tồn dư để tạo sinh.** Chúng tôi sử dụng học tồn dư để kết hợp các phân phối đầu ra từ CLM (Eq. 6) và RMT (Eq. 8), cho phép khung thu được các dự đoán kết hợp cho token tiếp theo và đạt được CTG không xâm nhập:

yt = PΘ(xt|x<t;C) = yg_t + yc_t. (9)

### 3.2 Residual Memory Transformer (RMT)

Cấu trúc chi tiết của RMT được hiển thị trong Hình 1. Cụ thể, RMT áp dụng kiến trúc encoder-decoder và tái sử dụng bộ word và position embedding của CLM.

**Encoder RMT.** Encoder RMT chịu trách nhiệm mã hóa mô tả kiểm soát C thành bộ nhớ kiểm soát C̃ (Eq. 7). Encoder bao gồm một chồng M block giống hệt nhau. Mỗi block bao gồm một lớp self-attention (Eq. 1) và một lớp feed-forward kết nối đầy đủ. Ngoài ra, nó kết hợp các kết nối tồn dư xung quanh mỗi lớp trên, và được theo sau bởi một layer normalization.

**Decoder RMT.** Decoder RMT nhằm dự đoán phân phối xác suất của token tiếp theo yc_t (Eq. 8) trong chế độ kiểm soát. Decoder cũng bao gồm một chồng M block giống hệt nhau. Mỗi block chứa ba lớp attention được thiết kế cẩn thận và một mạng feed-forward kết nối đầy đủ. Tương tự như encoder, các kết nối tồn dư và layer normalization cũng được áp dụng. Ba lớp attention hướng đến văn bản đã được tạo x<t, các trạng thái ẩn đầu ra của CLM hg_<t, và bộ nhớ kiểm soát C̃, tương ứng:

• **Causal Self Attention.** Lớp attention đầu tiên sử dụng một thao tác causal attention (Eq. 2), trong đó Q, K và V đều được ánh xạ đầu tiên từ chính văn bản được tạo ban đầu x<t. Cơ chế attention này tạo điều kiện cho việc nhận dạng và nắm bắt các đặc trưng ngữ cảnh của chuỗi được tạo từ đầu.

• **Causal CLM Attention.** Lớp attention thứ hai cũng sử dụng causal attention (Eq. 2), nhưng với một khác biệt quan trọng: Q được lấy từ đầu ra của lớp causal self-attention trước đó, trong khi K và V được lấy từ các trạng thái ẩn cuối cùng của CLM hg_<t. Thiết kế này thiết lập một kết nối tồn dư bên trong với CLM, cho phép RMT xem xét các đặc trưng ngữ cảnh cấp cao và tương tác tối đa với dòng tạo sinh của CLM.

• **Cross Control Attention.** Lớp attention thứ ba là một cross-attention cho bộ nhớ kiểm soát từ encoder RMT. Cụ thể, Q được lấy từ lớp causal CLM attention trước đó, trong khi K và V được lấy từ bộ nhớ kiểm soát C̃. Lớp cross-attention này kết nối encoder và decoder của RMT, đưa các tín hiệu kiểm soát vào việc tạo sinh.

### 3.3 Huấn luyện mô hình

**Pre-training.** Để cho phép khả năng hiểu ngữ nghĩa của RMT và cho phép nó căn chỉnh với quá trình tạo sinh của CLM, chúng tôi sử dụng phương pháp pre-training denoising auto-encoder, trong đó encoder xử lý văn bản bị hỏng X̂ và decoder tái tạo văn bản gốc X.

Cụ thể, chúng tôi làm hỏng văn bản pre-training (X→X̂) theo bốn cách tham khảo (Lewis et al., 2020): (1) Token Masking: che ngẫu nhiên các token bằng các token đặc biệt. (2) Token Deletion: xóa ngẫu nhiên các token trong văn bản. (3) Span Replacing: thay thế ngẫu nhiên các span văn bản có độ dài khác nhau bằng các token đặc biệt. Khác với token masking, mỗi span được thay thế bằng một token đặc biệt duy nhất. (4) Text Rotation: chọn ngẫu nhiên một token và xoay văn bản xung quanh nó, tức là văn bản bắt đầu bằng token đó và kết thúc bằng token trước đó.

**Fine-tuning.** Khi pre-training hoàn thành, RMT có thể được fine-tune để thực hiện các nhiệm vụ tạo văn bản có thể kiểm soát khác nhau. Điều này cho phép CLM tạo các chuỗi đáp ứng các yêu cầu kiểm soát cụ thể theo cách auto-regressive. Mục tiêu cụ thể có thể thay đổi theo các nhiệm vụ khác nhau: chúng tôi sử dụng Maximum Likelihood Estimation (MLE) cho các nhiệm vụ bao hàm từ và kiểm soát độ dài; và sử dụng chiến lược huấn luyện unlikelihood (Zhang và Song, 2022) cho nhiệm vụ kiểm soát thuộc tính.

Đáng chú ý là RMT có đặc điểm hiệu quả huấn luyện. Thứ nhất, RMT tái sử dụng hiệu quả đầu ra của base CLM, điều này làm cho RMT cần ít dataset pre-training hơn và đẩy nhanh quá trình pre-training. Ngoài ra, RMT nhẹ và được xây dựng trên lớp trên cùng của base CLM. Do đó, gradient không cần lan truyền vào base CLM trong quá trình backpropagation, có thể tiết kiệm đáng kể thời gian huấn luyện và bộ nhớ GPU.

## 4. Thí nghiệm

### 4.1 Thí nghiệm bao hàm từ

Hai cài đặt khác nhau được thí nghiệm trong phần này. Cài đặt đầu tiên là cài đặt không có ngữ cảnh, tức là điều khiển CLM tạo một câu duy nhất chứa các từ khóa mà không có ngữ cảnh. Cài đặt thứ hai là cài đặt tạo sinh có ngữ cảnh, yêu cầu CLM tiếp tục tạo văn bản mục tiêu dưới một ngữ cảnh mở rộng. Việc xem xét hai chế độ này nhằm kiểm tra tính linh hoạt của CTG, có khả năng kiểm soát việc tạo sinh của CLM theo cách độc lập với vị trí.

**Cài đặt thí nghiệm.** Theo NRP (Carlsson et al., 2022), chúng tôi sử dụng GPT2-large làm CLM xương sống, và dữ liệu huấn luyện cho pre-training và fine-tuning cũng đến từ Wikipedia. Chúng tôi kiểm tra phương pháp của mình trên CommonGen (Lin et al., 2020) (cho cài đặt không có ngữ cảnh), và C2Gen (Carlsson et al., 2022) (cho cài đặt có ngữ cảnh).

**Baseline.** Đối với cài đặt không có ngữ cảnh, chúng tôi đầu tiên chọn những phương pháp được huấn luyện cụ thể cho các nhiệm vụ ràng buộc từ vựng. Đó là KG-BART (Liu et al., 2021b), fine-tune toàn bộ tham số của BART trong khi được tăng cường bởi knowledge graph; và POINT (Zhang et al., 2020b), là phương pháp dựa trên insertion và lặp lại chèn từ xung quanh các từ mục tiêu. Cuối cùng, chúng tôi cũng sử dụng phương pháp decode-time thuần túy cho ràng buộc từ vựng, gọi là NeuroLogic (Lu et al., 2022b), làm baseline. Các phương pháp CTG tổng quát cũng được so sánh, bao gồm Non-Residual Prompt (Carlsson et al., 2022) (tức là phương pháp tiên tiến gần đây sử dụng mô hình prompting độc lập với vị trí để hướng dẫn việc tạo sinh).

**Đánh giá.** Theo NRP (Carlsson et al., 2022), chúng tôi sử dụng coverage (Cov), đo tỷ lệ bao phủ trung bình của văn bản được tạo đối với các từ mục tiêu, để đánh giá khả năng kiểm soát. Perplexity (PPL) được sử dụng để đánh giá độ trôi chảy. Chúng tôi tính PPL sử dụng mô hình GPT2-large có sẵn. Ngoài ra, chúng tôi sử dụng Self-Bleu-5 để đánh giá sự đa dạng của văn bản được tạo, với giá trị Self-Bleu thấp hơn cho thấy sự đa dạng cú pháp lớn hơn. Chúng tôi cũng thực hiện đánh giá của con người để đánh giá sự phù hợp của văn bản được tạo với common sense (CS) và Fluency từ góc độ con người.

**Kết quả và phân tích.** Như được hiển thị trong Bảng 1, trong cài đặt không có ngữ cảnh, coverage của phương pháp chúng tôi vượt trội đáng kể so với phương pháp prompt vanilla (tức là Prompt+GPT2) và phương pháp decode-time thuần túy (tức là NeuroLogit) với cùng thuật toán decode được RMT sử dụng. Nó cho thấy những ưu điểm nhỏ so với ChatGPT và NRP. So với các mô hình cụ thể cho nhiệm vụ (tức là POINT, KG-BART), coverage của RMT gần với chúng, nhưng với PPL thấp hơn. Đáng chú ý là, trong cài đặt có ngữ cảnh, các baseline mạnh, bao gồm ChatGPT và NRP, tương ứng chịu sự suy giảm 12.0% và 8.0% khả năng kiểm soát so với cài đặt không có ngữ cảnh. Tuy nhiên, RMT duy trì cùng mức khả năng kiểm soát với cài đặt không có ngữ cảnh, và vượt trội hơn NRP và ChatGPT, cho thấy sự vượt trội của RMT ở chỗ khả năng kiểm soát sẽ không giảm sút theo độ dài ngữ cảnh.

### 4.2 Thí nghiệm kiểm soát độ dài câu

Chúng tôi kiểm tra khả năng kiểm soát độ dài của RMT, tức là hướng dẫn CLM tạo một câu đáp ứng mục tiêu bao hàm từ dưới một số từ chính xác. Cài đặt này tăng thách thức của nhiệm vụ bao hàm từ, hiệu quả chứng minh khả năng kiểm soát chi tiết. Chúng tôi quan sát thấy RMT có thể lập kế hoạch phù hợp theo hướng dẫn về số lượng token yêu cầu và từ mục tiêu.

Để đo lường khả năng kiểm soát độ dài câu một cách định lượng, chúng tôi tiến hành các thử nghiệm trên tập validation CommonGen để phân tích hiệu quả kiểm soát của phương pháp được đề xuất. Một số ví dụ được trình bày trong Bảng 2, cho thấy RMT hiệu quả điều khiển CLM tạo văn bản với các từ khóa cụ thể và độ dài câu yêu cầu.

### 4.3 Thí nghiệm kiểm soát thuộc tính

**Cài đặt và Baseline.** Chúng tôi theo DisCup (Zhang và Song, 2022), và sử dụng chiến lược huấn luyện có liên quan đến discriminator để fine-tune RMT. Khác với DisCup, tối ưu hóa prompt duy nhất cho mỗi thuộc tính, chúng tôi sử dụng mô-đun RMT để mã hóa trực tiếp các hướng dẫn thuộc tính khác nhau một cách thống nhất. GPT2-large được sử dụng làm CLM xương sống, và dữ liệu huấn luyện là Stanford Sentiment Tree (SST-5) được sử dụng rộng rãi.

**Đánh giá.** Theo công việc trước đây (Krause et al., 2021; Zhang và Song, 2022; Lu et al., 2022a), chúng tôi sử dụng một classifier tình cảm bên ngoài để phân loại các văn bản được tạo, và nhận được độ chính xác kiểm soát tình cảm (tức là Correctness). PPL và Dist-1/2/3 được báo cáo để kiểm tra độ trôi chảy và sự đa dạng của chúng, tương ứng.

**Kết quả và phân tích.** Như được hiển thị trong Bảng 3, RMT trong cài đặt top-k thể hiện hiệu suất kiểm soát vượt trội so với tất cả baseline, trong khi duy trì chất lượng văn bản và sự đa dạng có thể so sánh. Và RMT trong cài đặt top-p cho thấy chất lượng văn bản tốt hơn nhưng hiệu suất kiểm soát yếu hơn. Những người thực hiện gần nhất với phương pháp của chúng tôi là DEXPERT và DisCup. Tuy nhiên, DEXPERT yêu cầu fine-tuning một cặp CLM bên ngoài, dẫn đến việc điều chỉnh gấp hai lần số tham số của base CLM. Ngược lại, RMT tiết kiệm tham số, chỉ yêu cầu điều chỉnh các tham số liên quan chỉ khoảng 16% tham số của base CLM.

### 4.4 Phân tích thêm

**Block layer và kích thước base-CLM.** Để kiểm tra khả năng mở rộng theo số lượng block layer và base-clm, chúng tôi điều tra ảnh hưởng của số lượng block layer đến hiệu suất kiểm soát của RMT trên các mô hình base-CLM có kích thước khác nhau. Kết quả được hiển thị trong Hình 3 cho thấy giá trị M=3 được coi là phù hợp để đạt được kiểm soát bao hàm từ và độ dài câu hiệu quả.

**Nghiên cứu Ablation.** Để đánh giá hiệu quả của Residual Memory Transformer (RMT), chúng tôi tiến hành nghiên cứu ablation. Nghiên cứu bao gồm ba cài đặt: loại bỏ causal self-attention, loại trừ causal CLM attention, và đánh giá hiệu suất của RMT mà không có pre-training. Kết quả được trình bày trong Bảng 5. Thú vị là, dưới cả ba cài đặt, chúng tôi quan sát thấy sự suy giảm hiệu suất đáng kể. Phát hiện này phục vụ như bằng chứng thuyết phục rằng mọi thành phần trong RMT, cũng như giai đoạn pre-training, đều quan trọng và không thể thiếu để đạt được kết quả tối ưu.

**Hiệu quả tạo sinh.** RMT là một plugin nhẹ, cho phép tốc độ suy luận hiệu quả có thể so sánh với CLM gốc. Bảng 6 cho thấy RMT vượt trội hơn các phương pháp CTG điển hình về tốc độ tạo sinh hiệu quả, tiến gần đến tốc độ của CLM thuần túy (GPT2-large).

## 5. Công trình liên quan

Như được tóm tắt bởi (Zhang et al., 2022), các phương pháp CTG có thể được chia thành ba loại, tức là retraining/refactoring, fine-tuning và post-process. Hai loại đầu tiên đề cập đến các phương pháp huấn luyện, nhằm fine-tune hoặc retrain một PLM để tạo văn bản đáp ứng điều kiện kiểm soát mong muốn. Các phương pháp này đã cho thấy những cải thiện hiệu suất đáng kể trong lĩnh vực này. Tuy nhiên, với kích thước ngày càng tăng của PLM, chúng đã trở nên tốn kém tài nguyên để fine-tune hoặc retrain. Kết quả là, các phương pháp post-process đã trở nên phổ biến hơn trong cộng đồng nghiên cứu.

Các phương pháp post-process dành riêng cho việc hướng dẫn mô hình ngôn ngữ hướng tới các văn bản mong muốn trong giai đoạn decode-time sử dụng một mô-đun phụ trợ. Nhằm đạt được mục tiêu tạo văn bản cụ thể theo thuộc tính, PPLM (Dathathri et al., 2020) tận dụng một classifier thuộc tính đơn giản để cập nhật lớp ẩn đầu của LM bằng gradient feedback. Hầu hết các phương pháp decoder-time hoặc chỉ can thiệp với LM trong giai đoạn lựa chọn token của việc tạo sinh, thiếu khả năng lập kế hoạch, hoặc yêu cầu nhiều lần lặp, dẫn đến thời gian tạo sinh quá mức. Phương pháp của chúng tôi chia sẻ đặc điểm plug-and-play với các phương pháp decoder-time. Tuy nhiên, điểm khác biệt chính là chúng tôi sử dụng một mô hình tồn dư nhẹ để tích hợp thông tin kiểm soát và các dòng ngữ cảnh đa cấp từ CLM, cho phép lập kế hoạch nội dung chi tiết và tạo văn bản hiệu quả.

## 6. Thảo luận và hướng nghiên cứu tương lai

RMT vẫn gặp phải một số hạn chế. (1) Thách thức trong việc áp dụng RMT cho các CLM đóng. Hiện tại, việc áp dụng RMT cần có được các trạng thái ẩn cuối cùng hoặc logit của CLM, do đó việc áp dụng RMT cho một số CLM thương mại, ví dụ như GPT-4, vẫn gặp thách thức. Đây cũng là vấn đề chung của tất cả CTG kiểu plugin. (2) RMT không tập trung vào common sense, có thể dẫn đến việc tạo ra các văn bản đôi khi không phù hợp với common sense. Vấn đề này có thể được giảm thiểu bằng cách đưa knowledge graph bên ngoài vào công việc tương lai.

Cho đến nay, việc tránh các lỗi thực tế xuất hiện trong văn bản được tạo ra đối với các mô hình ngôn ngữ nhân quả quy mô lớn vẫn là thách thức, mà RMT cũng không giải quyết được. Một hướng nghiên cứu tương lai đầy hứa hẹn là kết hợp RMT và các hệ thống truy xuất thông tin để tăng cường độ chính xác thực tế của những mô hình tạo sinh đó. Hơn nữa, RMT cũng có thể được sử dụng để mã hóa hồ sơ cá nhân và xây dựng chatbot cá nhân hóa, hoặc kết hợp với thông tin hình ảnh để áp dụng vào các tình huống đa phương thức.

## 7. Kết luận

Trong bài báo này, chúng tôi đã đề xuất một phương án CTG mới, tận dụng một mô hình tồn dư để điều khiển CLM tạo văn bản mong muốn một cách không xâm nhập. Ngoài ra, chúng tôi đề xuất residual memory transformer, một kiến trúc encoder-decoder mới, để kết hợp văn bản ngữ cảnh thô, dòng tạo sinh của CLM và thông tin kiểm soát trong một lần, do đó hợp tác và kiểm soát việc tạo sinh của CLM tốt hơn. Các thí nghiệm cho thấy RMT thể hiện hiệu suất tốt hơn về tính linh hoạt, độ chi tiết kiểm soát và hiệu quả, làm cho nó trở thành một giải pháp hấp dẫn cho việc tạo văn bản có thể kiểm soát.

# 2305.06474.pdf
# Chuyá»ƒn Ä‘á»•i tá»« PDF sang TXT
# ÄÆ°á»ng dáº«n nguá»“n: /home/admin88/arxiv-downloader/rl-alignment/2305.06474.pdf
# KÃ­ch thÆ°á»›c tá»‡p: 2374106 byte

===============================================
Ná»˜I DUNG Tá»†P PDF
===============================================


--- TRANG 1 ---
Liá»‡u LLM cÃ³ hiá»ƒu sá»Ÿ thÃ­ch ngÆ°á»i dÃ¹ng khÃ´ng? ÄÃ¡nh giÃ¡ LLM vá» dá»± Ä‘oÃ¡n xáº¿p háº¡ng ngÆ°á»i dÃ¹ng
WANG-CHENG KANG*, Google Research, Brain Team, Hoa Ká»³
JIANMO NI*, Google Research, Brain Team, Hoa Ká»³
NIKHIL MEHTA, Google Research, Brain Team, Hoa Ká»³
MAHESWARAN SATHIAMOORTHY, Google Research, Brain Team, Hoa Ká»³
LICHAN HONG, Google Research, Brain Team, Hoa Ká»³
ED CHI, Google Research, Brain Team, Hoa Ká»³
DEREK ZHIYUAN CHENG, Google Research, Brain Team, Hoa Ká»³
CÃ¡c MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n (LLM) Ä‘Ã£ thá»ƒ hiá»‡n kháº£ nÄƒng Ä‘áº·c biá»‡t trong viá»‡c tá»•ng quÃ¡t hÃ³a sang cÃ¡c nhiá»‡m vá»¥ má»›i theo cÃ¡ch zero-shot hoáº·c few-shot.
Tuy nhiÃªn, má»©c Ä‘á»™ LLM cÃ³ thá»ƒ hiá»ƒu sá»Ÿ thÃ­ch ngÆ°á»i dÃ¹ng dá»±a trÃªn hÃ nh vi trÆ°á»›c Ä‘Ã³ cá»§a há» váº«n lÃ  má»™t cÃ¢u há»i nghiÃªn cá»©u má»›i ná»•i vÃ  chÆ°a rÃµ rÃ ng. Theo truyá»n thá»‘ng, Lá»c Cá»™ng tÃ¡c (CF) Ä‘Ã£ lÃ  phÆ°Æ¡ng phÃ¡p hiá»‡u quáº£ nháº¥t cho cÃ¡c nhiá»‡m vá»¥ nÃ y,
chá»§ yáº¿u dá»±a vÃ o khá»‘i lÆ°á»£ng lá»›n dá»¯ liá»‡u xáº¿p háº¡ng. NgÆ°á»£c láº¡i, LLM thÆ°á»ng yÃªu cáº§u Ã­t dá»¯ liá»‡u hÆ¡n nhiá»u trong khi duy trÃ¬ kiáº¿n thá»©c toÃ n diá»‡n vá» tháº¿ giá»›i vá» tá»«ng má»¥c, cháº³ng háº¡n nhÆ° phim hoáº·c sáº£n pháº©m. Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i tiáº¿n hÃ nh kiá»ƒm tra ká»¹ lÆ°á»¡ng cáº£ CF vÃ  LLM trong nhiá»‡m vá»¥ cá»• Ä‘iá»ƒn dá»± Ä‘oÃ¡n xáº¿p háº¡ng ngÆ°á»i dÃ¹ng, bao gá»“m viá»‡c dá»± Ä‘oÃ¡n xáº¿p háº¡ng cá»§a ngÆ°á»i dÃ¹ng cho má»™t má»¥c á»©ng viÃªn dá»±a trÃªn cÃ¡c xáº¿p háº¡ng trong quÃ¡ khá»© cá»§a há». ChÃºng tÃ´i Ä‘iá»u tra cÃ¡c LLM khÃ¡c nhau vá»›i nhiá»u kÃ­ch thÆ°á»›c khÃ¡c nhau, tá»« 250M Ä‘áº¿n 540B tham sá»‘ vÃ 
Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a chÃºng trong cÃ¡c tÃ¬nh huá»‘ng zero-shot, few-shot vÃ  fine-tuning. ChÃºng tÃ´i tiáº¿n hÃ nh phÃ¢n tÃ­ch toÃ n diá»‡n Ä‘á»ƒ so sÃ¡nh giá»¯a
LLM vÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p CF máº¡nh, vÃ  tháº¥y ráº±ng LLM zero-shot tá»¥t háº­u so vá»›i cÃ¡c mÃ´ hÃ¬nh gá»£i Ã½ truyá»n thá»‘ng cÃ³ quyá»n truy cáº­p vÃ o dá»¯ liá»‡u tÆ°Æ¡ng tÃ¡c ngÆ°á»i dÃ¹ng, cho tháº¥y táº§m quan trá»ng cá»§a dá»¯ liá»‡u tÆ°Æ¡ng tÃ¡c ngÆ°á»i dÃ¹ng. Tuy nhiÃªn, thÃ´ng qua fine-tuning, LLM Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t tÆ°Æ¡ng Ä‘Æ°Æ¡ng hoáº·c tháº­m chÃ­ tá»‘t hÆ¡n chá»‰ vá»›i má»™t pháº§n nhá» dá»¯ liá»‡u huáº¥n luyá»‡n, thá»ƒ hiá»‡n tiá»m nÄƒng cá»§a chÃºng thÃ´ng qua hiá»‡u quáº£ dá»¯ liá»‡u.
Äá»‹nh dáº¡ng tham chiáº¿u ACM:
Wang-Cheng Kang*, Jianmo Ni*, Nikhil Mehta, Maheswaran Sathiamoorthy, Lichan Hong, Ed Chi, vÃ  Derek Zhiyuan Cheng. 2023.
Liá»‡u LLM cÃ³ hiá»ƒu sá»Ÿ thÃ­ch ngÆ°á»i dÃ¹ng khÃ´ng? ÄÃ¡nh giÃ¡ LLM vá» dá»± Ä‘oÃ¡n xáº¿p háº¡ng ngÆ°á»i dÃ¹ng. 1, 1 (ThÃ¡ng 5 2023), 11 trang. https://doi.org/10.
1145/nnnnnnn.nnnnnnn
1 GIá»šI THIá»†U
CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) Ä‘Ã£ cho tháº¥y kháº£ nÄƒng ká»³ láº¡ trong viá»‡c xá»­ lÃ½ nhiá»u nhiá»‡m vá»¥ Ä‘a dáº¡ng nhÆ° táº¡o vÄƒn báº£n
[1,2,6,26], dá»‹ch thuáº­t [36,42], vÃ  tÃ³m táº¯t [19]. Viá»‡c fine-tuning gáº§n Ä‘Ã¢y cá»§a LLM trÃªn cÃ¡c cuá»™c há»™i thoáº¡i vÃ 
viá»‡c sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t nhÆ° instruction fine-tuning [4] vÃ  há»c tÄƒng cÆ°á»ng tá»« pháº£n há»“i con ngÆ°á»i (RLHF) [3] Ä‘Ã£ dáº«n Ä‘áº¿n
*Hai tÃ¡c giáº£ Ä‘Ã£ Ä‘Ã³ng gÃ³p báº±ng nhau cho cÃ´ng trÃ¬nh nÃ y.
Äá»‹a chá»‰ tÃ¡c giáº£: Wang-Cheng Kang*, wckang@google.com, Google Research, Brain Team, Hoa Ká»³; Jianmo Ni*, jianmon@google.com, Google Research,
Brain Team, Hoa Ká»³; Nikhil Mehta, nikhilmehta@google.com, Google Research, Brain Team, Hoa Ká»³; Maheswaran Sathiamoorthy, nlogn@google.com, Google
Research, Brain Team, Hoa Ká»³; Lichan Hong, lichan@google.com, Google Research, Brain Team, Hoa Ká»³; Ed Chi, edchi@google.com, Google Research, Brain
Team, Hoa Ká»³; Derek Zhiyuan Cheng, zcheng@google.com, Google Research, Brain Team, Hoa Ká»³.
ÄÆ°á»£c phÃ©p táº¡o báº£n sao ká»¹ thuáº­t sá»‘ hoáº·c báº£n cá»©ng cá»§a toÃ n bá»™ hoáº·c má»™t pháº§n cÃ´ng trÃ¬nh nÃ y Ä‘á»ƒ sá»­ dá»¥ng cÃ¡ nhÃ¢n hoáº·c lá»›p há»c mÃ  khÃ´ng máº¥t phÃ­ vá»›i Ä‘iá»u kiá»‡n cÃ¡c báº£n sao khÃ´ng
Ä‘Æ°á»£c táº¡o hoáº·c phÃ¢n phá»‘i Ä‘á»ƒ thu lá»£i nhuáº­n hoáº·c lá»£i tháº¿ thÆ°Æ¡ng máº¡i vÃ  cÃ¡c báº£n sao pháº£i ghi rÃµ thÃ´ng bÃ¡o nÃ y vÃ  trÃ­ch dáº«n Ä‘áº§y Ä‘á»§ trÃªn trang Ä‘áº§u tiÃªn. Báº£n quyá»n cho cÃ¡c thÃ nh pháº§n
cá»§a cÃ´ng trÃ¬nh nÃ y thuá»™c sá»Ÿ há»¯u cá»§a ngÆ°á»i khÃ¡c ngoÃ i ACM pháº£i Ä‘Æ°á»£c tÃ´n trá»ng. Viá»‡c trÃ­ch dáº«n cÃ³ ghi cÃ´ng nguá»“n Ä‘Æ°á»£c phÃ©p. Äá»ƒ sao chÃ©p khÃ¡c, hoáº·c tÃ¡i xuáº¥t báº£n, Ä‘á»ƒ Ä‘Äƒng trÃªn mÃ¡y chá»§ hoáº·c
phÃ¢n phá»‘i láº¡i danh sÃ¡ch, yÃªu cáº§u sá»± cho phÃ©p cá»¥ thá»ƒ trÆ°á»›c vÃ /hoáº·c phÃ­. YÃªu cáº§u quyá»n tá»« permissions@acm.org.
Â©2023 Association for Computing Machinery.
Báº£n tháº£o gá»­i Ä‘áº¿n ACM
Báº£n tháº£o gá»­i Ä‘áº¿n ACM 1arXiv:2305.06474v1 [cs.IR] 10 ThÃ¡ng 5 2023

--- TRANG 2 ---
2 W.-C. Kang, et al.
HÃ¬nh 1. Hiá»‡u suáº¥t zero-shot cho dá»± Ä‘oÃ¡n xáº¿p háº¡ng cá»§a LLM vá»›i cÃ¡c kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh khÃ¡c nhau, bao gá»“m Flan-T5 (base Ä‘áº¿n XXL), GPT3 (Curie,
Davinci) vÃ  Flan-U-PaLM. ChÃºng ta tháº¥y cáº£i thiá»‡n hiá»‡u suáº¥t khi tÄƒng kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh. Trong sá»‘ Ä‘Ã³, cÃ¡c mÃ´ hÃ¬nh lá»›n hÆ¡n 100B
(Flan-U-PaLM 540B vÃ  text-davinci-003 175B) vÆ°á»£t trá»™i hoáº·c ngang báº±ng vá»›i baseline xáº¿p háº¡ng trung bÃ¬nh toÃ n cá»¥c trÃªn cáº£ RMSE vÃ 
AUC-ROC.
thÃ nh cÃ´ng to lá»›n trong viá»‡c mang cÃ¡c chatbot giá»‘ng con ngÆ°á»i (vÃ­ dá»¥ ChatGPT [23], vÃ  Bard [10]) Ä‘áº¿n há»™ gia Ä‘Ã¬nh bÃ¬nh thÆ°á»ng.
CÃ³ ba yáº¿u tá»‘ chÃ­nh trá»±c tiáº¿p Ä‘Ã³ng gÃ³p vÃ o tÃ­nh linh hoáº¡t vÃ  hiá»‡u quáº£ cá»§a LLM:
(1)Kiáº¿n thá»©c tá»« thÃ´ng tin tháº¿ giá»›i thá»±c á»Ÿ quy mÃ´ internet: LLM Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn cÃ¡c bá»™ dá»¯ liá»‡u vÄƒn báº£n khá»•ng lá»“, cung cáº¥p
quyá»n truy cáº­p vÃ o kho thÃ´ng tin tháº¿ giá»›i thá»±c phong phÃº. ThÃ´ng tin nÃ y Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i thÃ nh kiáº¿n thá»©c cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ
tráº£ lá»i cÃ¢u há»i, viáº¿t sÃ¡ng táº¡o (vÃ­ dá»¥: thÆ¡ vÃ  bÃ i viáº¿t), vÃ  dá»‹ch giá»¯a cÃ¡c ngÃ´n ngá»¯.
(2)Kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a Ä‘Ã¡ng kinh ngáº¡c thÃ´ng qua há»c few-shot hiá»‡u quáº£: trong bá»‘i cáº£nh nháº¥t Ä‘á»‹nh, LLM cÃ³ thá»ƒ
há»c cÃ¡c nhiá»‡m vá»¥ má»›i tá»« má»™t sá»‘ lÆ°á»£ng cá»±c ká»³ nhá» cÃ¡c vÃ­ dá»¥ (a.k.a., há»c few-shot). Kháº£ nÄƒng há»c few-shot máº¡nh máº½
trang bá»‹ cho LLM kháº£ nÄƒng thÃ­ch á»©ng cao vá»›i cÃ¡c nhiá»‡m vá»¥ má»›i.
(3)Kháº£ nÄƒng lÃ½ luáº­n máº¡nh máº½: LLM cÃ³ thá»ƒ lÃ½ luáº­n thÃ´ng qua quÃ¡ trÃ¬nh chuá»—i suy nghÄ© [40,41], cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ
hiá»‡u suáº¥t cá»§a chÃºng trÃªn nhiá»u nhiá»‡m vá»¥ [37].
Gáº§n Ä‘Ã¢y, Ä‘Ã£ cÃ³ má»™t sá»‘ cÃ´ng trÃ¬nh khÃ¡m phÃ¡ sÆ¡ bá»™ Ä‘á»ƒ sá»­ dá»¥ng LLM cho TÃ¬m kiáº¿m [20], Há»c xáº¿p háº¡ng [11,45],
vÃ  Há»‡ thá»‘ng Gá»£i Ã½ [5,8,18]. Cá»¥ thá»ƒ cho há»‡ thá»‘ng gá»£i Ã½, P5 [8] fine-tune T5-small (60M)
vÃ  T5-base(220M) [27], thá»‘ng nháº¥t cáº£ xáº¿p háº¡ng, truy xuáº¥t vÃ  cÃ¡c nhiá»‡m vá»¥ khÃ¡c nhÆ° giáº£i thÃ­ch tÃ³m táº¯t vÃ o má»™t mÃ´ hÃ¬nh.
M6-Rec [5] giáº£i quyáº¿t nhiá»‡m vá»¥ dá»± Ä‘oÃ¡n CTR báº±ng cÃ¡ch fine-tune má»™t LLM gá»i lÃ  M6 (300M) [17]. Liu et al. [18] tÃ¬m hiá»ƒu
liá»‡u cÃ¡c agent há»™i thoáº¡i nhÆ° ChatGPT cÃ³ thá»ƒ phá»¥c vá»¥ nhÆ° má»™t mÃ´ hÃ¬nh gá»£i Ã½ sáºµn cÃ³ vá»›i prompt lÃ m
giao diá»‡n vÃ  bÃ¡o cÃ¡o hiá»‡u suáº¥t zero-shot trÃªn dá»± Ä‘oÃ¡n xáº¿p háº¡ng so vá»›i cÃ¡c baseline nhÆ° MF vÃ  MLP. Tuy nhiÃªn, cÃ³
sá»± thiáº¿u váº¯ng Ä‘Ã¡ng chÃº Ã½ cá»§a má»™t nghiÃªn cá»©u toÃ n diá»‡n Ä‘Ã¡nh giÃ¡ tá»‰ má»‰ cÃ¡c LLM vá»›i kÃ­ch thÆ°á»›c khÃ¡c nhau vÃ  Ä‘á»‘i chiáº¿u chÃºng
vá»›i cÃ¡c baseline máº¡nh Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a cáº©n tháº­n.
Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i khÃ¡m phÃ¡ viá»‡c sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) sáºµn cÃ³ cho há»‡ thá»‘ng gá»£i Ã½. ChÃºng tÃ´i
nghiÃªn cá»©u nhiá»u LLM vá»›i kÃ­ch thÆ°á»›c khÃ¡c nhau tá»« 250M Ä‘áº¿n 540B tham sá»‘. ChÃºng tÃ´i táº­p trung vÃ o nhiá»‡m vá»¥ cá»¥ thá»ƒ cá»§a
dá»± Ä‘oÃ¡n xáº¿p háº¡ng ngÆ°á»i dÃ¹ng, vÃ  Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a cÃ¡c LLM nÃ y dÆ°á»›i ba cháº¿ Ä‘á»™ khÃ¡c nhau: 1. zero-shot 2. few-shot,
vÃ  3. fine-tuning. Sau Ä‘Ã³ chÃºng tÃ´i so sÃ¡nh cáº©n tháº­n chÃºng vá»›i cÃ¡c mÃ´ hÃ¬nh gá»£i Ã½ tiÃªn tiáº¿n trÃªn hai
bá»™ dá»¯ liá»‡u benchmark gá»£i Ã½ Ä‘Æ°á»£c Ã¡p dá»¥ng rá»™ng rÃ£i. ÄÃ³ng gÃ³p cá»§a chÃºng tÃ´i gá»“m ba pháº§n:
â€¢ChÃºng tÃ´i nghiÃªn cá»©u thá»±c nghiá»‡m hiá»‡u suáº¥t zero-shot vÃ  few-shot cá»§a cÃ¡c LLM sáºµn cÃ³ vá»›i má»™t phá»• rá»™ng
kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh. ChÃºng tÃ´i tháº¥y ráº±ng cÃ¡c mÃ´ hÃ¬nh lá»›n hÆ¡n (trÃªn 100B tham sá»‘) cÃ³ thá»ƒ cung cáº¥p cÃ¡c gá»£i Ã½ há»£p lÃ½ dÆ°á»›i
tÃ¬nh huá»‘ng cold-start, Ä‘áº¡t hiá»‡u suáº¥t tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i cÃ¡c baseline dá»±a trÃªn heuristic tá»­ táº¿.
Báº£n tháº£o gá»­i Ä‘áº¿n ACM

--- TRANG 3 ---
Liá»‡u LLM cÃ³ hiá»ƒu sá»Ÿ thÃ­ch ngÆ°á»i dÃ¹ng khÃ´ng? ÄÃ¡nh giÃ¡ LLM vá» dá»± Ä‘oÃ¡n xáº¿p háº¡ng ngÆ°á»i dÃ¹ng 3
â€¢ChÃºng tÃ´i cho tháº¥y LLM zero-shot váº«n tá»¥t háº­u so vá»›i cÃ¡c mÃ´ hÃ¬nh gá»£i Ã½ truyá»n thá»‘ng sá»­ dá»¥ng dá»¯ liá»‡u tÆ°Æ¡ng tÃ¡c con ngÆ°á»i.
LLM zero-shot chá»‰ Ä‘áº¡t hiá»‡u suáº¥t tÆ°Æ¡ng Ä‘Æ°Æ¡ng hai baseline táº§m thÆ°á»ng Ä‘Ã¡ng ngáº¡c nhiÃªn luÃ´n dá»± Ä‘oÃ¡n
xáº¿p háº¡ng má»¥c hoáº·c ngÆ°á»i dÃ¹ng trung bÃ¬nh. HÆ¡n ná»¯a, chÃºng cÃ³ hiá»‡u suáº¥t kÃ©m Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c mÃ´ hÃ¬nh gá»£i Ã½
cÃ³ giÃ¡m sÃ¡t truyá»n thá»‘ng, cho tháº¥y táº§m quan trá»ng cá»§a dá»¯ liá»‡u tÆ°Æ¡ng tÃ¡c ngÆ°á»i dÃ¹ng.
â€¢ThÃ´ng qua nhiá»u thÃ­ nghiá»‡m fine-tune LLM trÃªn dá»¯ liá»‡u tÆ°Æ¡ng tÃ¡c con ngÆ°á»i, chÃºng tÃ´i chá»©ng minh ráº±ng LLM Ä‘Æ°á»£c
fine-tune cÃ³ thá»ƒ Ä‘áº¡t hiá»‡u suáº¥t tÆ°Æ¡ng Ä‘Æ°Æ¡ng hoáº·c tháº­m chÃ­ tá»‘t hÆ¡n cÃ¡c mÃ´ hÃ¬nh truyá»n thá»‘ng chá»‰ vá»›i má»™t pháº§n nhá»
dá»¯ liá»‡u huáº¥n luyá»‡n, thá»ƒ hiá»‡n tiá»m nÄƒng trong hiá»‡u quáº£ dá»¯ liá»‡u.
2 CÃ”NG TRÃŒNH LIÃŠN QUAN
2.1 Sá»­ dá»¥ng NgÃ´n ngá»¯ Tá»± nhiÃªn trong Há»‡ thá»‘ng Gá»£i Ã½
Má»™t trong nhá»¯ng cÃ´ng trÃ¬nh sá»›m nháº¥t khÃ¡m phÃ¡ viá»‡c cÃ´ng thá»©c hÃ³a váº¥n Ä‘á» gá»£i Ã½ nhÆ° má»™t nhiá»‡m vá»¥ ngÃ´n ngá»¯ tá»± nhiÃªn lÃ  [44]. Há»
sá»­ dá»¥ng BERT [6] vÃ  GPT-2 [25] trÃªn bá»™ dá»¯ liá»‡u Movielens [12] Ä‘á»ƒ cho tháº¥y cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ nhÆ° váº­y hoáº¡t Ä‘á»™ng tá»‘t Ä‘Ã¡ng ngáº¡c nhiÃªn,
máº·c dÃ¹ khÃ´ng tá»‘t báº±ng cÃ¡c baseline Ä‘Æ°á»£c tinh chá»‰nh tá»‘t nhÆ° GRU4Rec [15].
P5 [8] fine-tune mÃ´ hÃ¬nh T5 [27] mÃ£ nguá»“n má»Ÿ phá»• biáº¿n, thá»‘ng nháº¥t cáº£ xáº¿p háº¡ng, truy xuáº¥t vÃ  cÃ¡c nhiá»‡m vá»¥ khÃ¡c nhÆ° giáº£i thÃ­ch tÃ³m táº¯t vÃ o má»™t mÃ´ hÃ¬nh. M6-Rec [5] lÃ  má»™t cÃ´ng trÃ¬nh liÃªn quan khÃ¡c, nhÆ°ng há» giáº£i quyáº¿t nhiá»‡m vá»¥ dá»± Ä‘oÃ¡n CTR báº±ng cÃ¡ch fine-tune
má»™t LLM gá»i lÃ  M6 [17].
Hai cÃ´ng trÃ¬nh gáº§n Ä‘Ã¢y khÃ¡m phÃ¡ viá»‡c sá»­ dá»¥ng LLM cho dá»± Ä‘oÃ¡n zero-shot. ChatRec [7] xá»­ lÃ½ dá»± Ä‘oÃ¡n zero-shot cÅ©ng nhÆ°
tÆ°Æ¡ng tÃ¡c vÃ  cung cáº¥p giáº£i thÃ­ch. [35] Ã¡p dá»¥ng phÆ°Æ¡ng phÃ¡p prompting ba giai Ä‘oáº¡n Ä‘á»ƒ táº¡o gá»£i Ã½ má»¥c tiáº¿p theo
trong bá»™ dá»¯ liá»‡u Movielens vÃ  Ä‘áº¡t Ä‘Æ°á»£c cÃ¡c chá»‰ sá»‘ cáº¡nh tranh, máº·c dÃ¹ khÃ´ng thá»ƒ Ä‘Ã¡nh báº¡i cÃ¡c baseline gá»£i Ã½ tuáº§n tá»± máº¡nh
nhÆ° SASRec [16].
2.2 MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n
Khi má»i ngÆ°á»i nháº­n ra ráº±ng viá»‡c má»Ÿ rá»™ng quy mÃ´ dá»¯ liá»‡u vÃ  mÃ´ hÃ¬nh giÃºp Ã­ch cho cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯, Ä‘Ã£ cÃ³ má»™t loáº¡t
mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n Ä‘Æ°á»£c Ä‘á» xuáº¥t vÃ  xÃ¢y dá»±ng: vÃ­ dá»¥ PaLM [2], GPT-3 [1] vÃ  nhá»¯ng mÃ´ hÃ¬nh gáº§n Ä‘Ã¢y nhÆ° OPT [43] vÃ  LLaMA [33]. Má»™t
trong nhá»¯ng kháº£ nÄƒng Ä‘á»™c Ä‘Ã¡o cá»§a LLM lÃ  kháº£ nÄƒng lÃ½ luáº­n vá» má»i thá»©, Ä‘Æ°á»£c cáº£i thiá»‡n thÃªm bá»Ÿi cÃ¡c ká»¹ thuáº­t
nhÆ° prompting chuá»—i suy nghÄ© [41], tá»± nháº¥t quÃ¡n [38] vÃ  tá»± pháº£n Ã¡nh [30].
Má»™t kháº£ nÄƒng máº¡nh máº½ chÃ­nh khÃ¡c cá»§a LLM lÃ  tuÃ¢n theo hÆ°á»›ng dáº«n mÃ  cÃ¡c mÃ´ hÃ¬nh cÃ³ thá»ƒ tá»•ng quÃ¡t hÃ³a sang cÃ¡c nhiá»‡m vá»¥ chÆ°a tháº¥y báº±ng cÃ¡ch
tuÃ¢n theo cÃ¡c hÆ°á»›ng dáº«n ngÃ´n ngá»¯ tá»± nhiÃªn Ä‘Ã£ cho. CÃ¡c nhÃ  nghiÃªn cá»©u Ä‘Ã£ phÃ¡t hiá»‡n ráº±ng cÃ¡c ká»¹ thuáº­t nhÆ° instruction fine-tuning
[4] vÃ  RLHF [3] cÃ³ thá»ƒ cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ kháº£ nÄƒng cá»§a LLM thá»±c hiá»‡n cÃ¡c nhiá»‡m vá»¥ Ä‘Æ°á»£c Ä‘Æ°a ra cÃ¡c mÃ´ táº£ ngÃ´n ngá»¯ tá»± nhiÃªn
phÃ¹ há»£p vá»›i sá»Ÿ thÃ­ch cá»§a con ngÆ°á»i. LÃ  má»™t trong nhá»¯ng nhiá»‡m vá»¥ cÃ³ thá»ƒ Ä‘Æ°á»£c mÃ´ táº£ báº±ng ngÃ´n ngá»¯ tá»± nhiÃªn, 'gá»£i Ã½'
Ä‘Ã£ trá»Ÿ thÃ nh má»™t kháº£ nÄƒng má»›i Ä‘áº§y há»©a háº¹n cho LLM. Trong cÃ´ng trÃ¬nh nÃ y, chÃºng tÃ´i táº­p trung vÃ o cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c fine-tune Ä‘á»ƒ
cáº£i thiá»‡n kháº£ nÄƒng tuÃ¢n theo hÆ°á»›ng dáº«n nhÆ° ChatGPT [23], GPT-3 (text-davinci-003 [22]), Flan-U-PaLM vÃ 
Flan-T5 [4].
3 PHÆ¯Æ NG PHÃP
3.1 CÃ´ng thá»©c hÃ³a váº¥n Ä‘á»
ChÃºng tÃ´i nghiÃªn cá»©u nhiá»‡m vá»¥ dá»± Ä‘oÃ¡n xáº¿p háº¡ng ngÆ°á»i dÃ¹ng, Ä‘Æ°á»£c cÃ´ng thá»©c hÃ³a nhÆ°: Cho má»™t ngÆ°á»i dÃ¹ng ğ‘¢âˆˆU, má»™t chuá»—i
tÆ°Æ¡ng tÃ¡c lá»‹ch sá»­ cá»§a ngÆ°á»i dÃ¹ng ğ‘¢ lÃ  ğ¸ğ‘¢={ğ‘’ğ‘¢1,ğ‘’ğ‘¢2,...,ğ‘’ğ‘¢ğ‘›} vÃ  má»™t má»¥c ğ‘–âˆˆI, dá»± Ä‘oÃ¡n xáº¿p háº¡ng mÃ  ngÆ°á»i dÃ¹ng ğ‘¢ sáº½ Ä‘Æ°a ra cho má»¥c ğ‘–, trong Ä‘Ã³
chuá»—i tÆ°Æ¡ng tÃ¡c lá»‹ch sá»­ ngÆ°á»i dÃ¹ng ğ¸ğ‘¢ Ä‘Æ°á»£c sáº¯p xáº¿p theo thá»i gian (ğ‘’ğ‘¢ğ‘› lÃ  má»¥c gáº§n nháº¥t mÃ  ngÆ°á»i dÃ¹ng tiÃªu dÃ¹ng), vÃ  má»—i
Báº£n tháº£o gá»­i Ä‘áº¿n ACM

--- TRANG 4 ---
4 W.-C. Kang, et al.
tÆ°Æ¡ng tÃ¡c ğ‘’ğ‘¢ğ‘˜ Ä‘Æ°á»£c Ä‘áº¡i diá»‡n bá»Ÿi thÃ´ng tin vá» má»¥c (vÃ­ dá»¥: ID, tiÃªu Ä‘á», metadata, v.v.) mÃ  ngÆ°á»i dÃ¹ng Ä‘Ã£ tiÃªu dÃ¹ng cÅ©ng nhÆ°
xáº¿p háº¡ng ngÆ°á»i dÃ¹ng Ä‘Ã£ Ä‘Æ°a ra cho má»¥c Ä‘Ã³.
3.2 LLM Zero-shot vÃ  Few-shot cho Dá»± Ä‘oÃ¡n Xáº¿p háº¡ng
HÃ¬nh 2. Prompt LLM zero vÃ  few shot cho dá»± Ä‘oÃ¡n xáº¿p háº¡ng.
ChÃºng tÃ´i trÃ¬nh bÃ y cÃ¡c prompt zero-shot vÃ  few-shot Ä‘Æ°á»£c sá»­ dá»¥ng cho nhiá»‡m vá»¥ dá»± Ä‘oÃ¡n xáº¿p háº¡ng trÃªn bá»™ dá»¯ liá»‡u MovieLens trong
hÃ¬nh 2. NhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong hÃ¬nh, cÃ¡c prompt Ä‘áº§u vÃ o mÃ´ táº£ má»™t sá»‘ tÃ­nh nÄƒng quan trá»ng Ä‘Æ°á»£c Ä‘áº¡i diá»‡n dÆ°á»›i dáº¡ng vÄƒn báº£n, bao gá»“m
lá»‹ch sá»­ xáº¿p háº¡ng trong quÃ¡ khá»© cá»§a ngÆ°á»i dÃ¹ng vÃ  cÃ¡c tÃ­nh nÄƒng má»¥c á»©ng viÃªn (tiÃªu Ä‘á» vÃ  thá»ƒ loáº¡i). Cuá»‘i cÃ¹ng, Ä‘á»ƒ rÃºt ra má»™t xáº¿p háº¡ng sá»‘ tá»« mÃ´ hÃ¬nh
vá»›i thang xáº¿p háº¡ng, prompt Ä‘áº§u vÃ o chá»‰ Ä‘á»‹nh má»™t thang xáº¿p háº¡ng sá»‘. Pháº£n há»“i cá»§a mÃ´ hÃ¬nh Ä‘Æ°á»£c phÃ¢n tÃ­ch Ä‘á»ƒ trÃ­ch xuáº¥t
Ä‘áº§u ra xáº¿p háº¡ng tá»« mÃ´ hÃ¬nh. Tuy nhiÃªn, chÃºng tÃ´i phÃ¡t hiá»‡n ráº±ng LLM cÃ³ thá»ƒ ráº¥t nháº¡y cáº£m vá»›i cÃ¡c prompt Ä‘áº§u vÃ o vÃ  khÃ´ng
luÃ´n tuÃ¢n theo hÆ°á»›ng dáº«n Ä‘Æ°á»£c cung cáº¥p. VÃ­ dá»¥, chÃºng tÃ´i tháº¥y ráº±ng má»™t sá»‘ LLM cÃ³ thá»ƒ Ä‘Æ°a ra lÃ½ luáº­n bá»• sung hoáº·c
khÃ´ng cung cáº¥p xáº¿p háº¡ng sá»‘ nÃ o cáº£. Äá»ƒ giáº£i quyáº¿t Ä‘iá»u nÃ y, chÃºng tÃ´i thá»±c hiá»‡n ká»¹ thuáº­t prompt bá»• sung báº±ng cÃ¡ch thÃªm
hÆ°á»›ng dáº«n bá»• sung nhÆ° "ÄÆ°a ra má»™t sá»‘ duy nháº¥t lÃ m xáº¿p háº¡ng mÃ  khÃ´ng cÃ³ giáº£i thÃ­ch" vÃ  "KhÃ´ng Ä‘Æ°a ra lÃ½ luáº­n" vÃ o
prompt Ä‘áº§u vÃ o.
3.3 Fine-tuning LLM cho Dá»± Ä‘oÃ¡n Xáº¿p háº¡ng
Trong nghiÃªn cá»©u há»‡ thá»‘ng gá»£i Ã½ truyá»n thá»‘ng, Ä‘Ã£ Ä‘Æ°á»£c chá»©ng minh rá»™ng rÃ£i ráº±ng viá»‡c huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh vá»›i dá»¯ liá»‡u tÆ°Æ¡ng tÃ¡c con ngÆ°á»i
lÃ  hiá»‡u quáº£ vÃ  quan trá»ng Ä‘á»ƒ cáº£i thiá»‡n kháº£ nÄƒng hiá»ƒu sá»Ÿ thÃ­ch ngÆ°á»i dÃ¹ng cá»§a há»‡ thá»‘ng gá»£i Ã½.
á» Ä‘Ã¢y, chÃºng tÃ´i khÃ¡m phÃ¡ viá»‡c huáº¥n luyá»‡n LLM vá»›i tÆ°Æ¡ng tÃ¡c con ngÆ°á»i vÃ  nghiÃªn cá»©u cÃ¡ch nÃ³ cÃ³ thá»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t mÃ´ hÃ¬nh.
ChÃºng tÃ´i táº­p trung vÃ o fine-tuning má»™t há» LLM, cá»¥ thá»ƒ lÃ  Flan-T5, vÃ¬ chÃºng cÃ³ sáºµn cÃ´ng khai vÃ  cÃ³ hiá»‡u suáº¥t cáº¡nh tranh trÃªn
nhiá»u benchmark. Nhiá»‡m vá»¥ dá»± Ä‘oÃ¡n xáº¿p háº¡ng cÃ³ thá»ƒ Ä‘Æ°á»£c cÃ´ng thá»©c hÃ³a thÃ nh má»™t trong hai nhiá»‡m vá»¥: (1)
phÃ¢n loáº¡i Ä‘a lá»›p; hoáº·c (2) há»“i quy, nhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 3b.
PhÃ¢n loáº¡i Äa lá»›p. LLM (kiáº¿n trÃºc chá»‰ Decoder hoáº·c Encoder-Decoder) vá» cÆ¡ báº£n Ä‘Æ°á»£c pre-train
vá»›i nhiá»‡m vá»¥ phÃ¢n loáº¡i ğ¾-way dá»± Ä‘oÃ¡n token tá»« má»™t tá»« vá»±ng cá»‘ Ä‘á»‹nh vá»›i kÃ­ch thÆ°á»›c ğ¾. NhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 3b,
cÃ³ má»™t lá»›p projection chiáº¿u cÃ¡c Ä‘áº§u ra tá»« lá»›p cuá»‘i cÃ¹ng Ä‘áº¿n kÃ­ch thÆ°á»›c tá»« vá»±ng sau Ä‘Ã³ quÃ¡ trÃ¬nh pre-training
tá»‘i Æ°u hÃ³a cross-entropy loss cho phÃ¢n loáº¡i token. Logits Ä‘áº§u ra Ä‘Æ°á»£c tÃ­nh nhÆ° logitsdec=ğ‘Šprojâ„dec,
trong Ä‘Ã³ ğ‘Šproj lÃ  ma tráº­n projection cÃ³ kÃ­ch thÆ°á»›c (ğ‘‘,|ğ‘‰|), â„dec lÃ  Ä‘áº§u ra tá»« lá»›p transformer cuá»‘i cÃ¹ng cá»§a decoder, ğ‘‘ lÃ 
kÃ­ch thÆ°á»›c chiá»u áº©n cá»§a decoder vÃ  |ğ‘‰| lÃ  tá»« vá»±ng.
Báº£n tháº£o gá»­i Ä‘áº¿n ACM

--- TRANG 5 ---
Liá»‡u LLM cÃ³ hiá»ƒu sá»Ÿ thÃ­ch ngÆ°á»i dÃ¹ng khÃ´ng? ÄÃ¡nh giÃ¡ LLM vá» dá»± Ä‘oÃ¡n xáº¿p háº¡ng ngÆ°á»i dÃ¹ng 5
(a) MÃ´ hÃ¬nh chá»‰ Decoder.
(b) MÃ´ hÃ¬nh Encoder-Decoder.
HÃ¬nh 3. Hai loáº¡i LLM cho nhiá»‡m vá»¥ dá»± Ä‘oÃ¡n xáº¿p háº¡ng.
Theo [4,26], chÃºng tÃ´i cÃ´ng thá»©c hÃ³a nhiá»‡m vá»¥ há»“i quy xáº¿p háº¡ng nhÆ° má»™t nhiá»‡m vá»¥ phÃ¢n loáº¡i 5-way, trong Ä‘Ã³ chÃºng tÃ´i láº¥y xáº¿p háº¡ng 1
Ä‘áº¿n 5 nhÆ° 5 lá»›p. Trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n, chÃºng tÃ´i sá»­ dá»¥ng cross-entropy loss nhÆ° cÃ¡c nhiá»‡m vá»¥ phÃ¢n loáº¡i khÃ¡c, nhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ dÆ°á»›i Ä‘Ã¢y:
ğ¿cross_entropy =âˆ’ğ‘âˆ‘ï¸ğ‘–=1ğ‘Ÿğ‘–log(logitsğ‘–dec), (1)
trong Ä‘Ã³ ğ‘Ÿğ‘– lÃ  xáº¿p háº¡ng ground-truth cho má»¥c thá»© ğ‘– vÃ  ğ‘ lÃ  sá»‘ lÆ°á»£ng tá»•ng vÃ­ dá»¥ huáº¥n luyá»‡n.
Trong quÃ¡ trÃ¬nh suy luáº­n, chÃºng tÃ´i tÃ­nh log-likelihood cho Ä‘áº§u ra mÃ´ hÃ¬nh má»—i lá»›p vÃ  chá»n lá»›p cÃ³
xÃ¡c suáº¥t lá»›n nháº¥t lÃ m dá»± Ä‘oÃ¡n cuá»‘i cÃ¹ng.
Há»“i quy. Äá»ƒ cho phÃ©p LLM thá»±c hiá»‡n cÃ¡c nhiá»‡m vá»¥ há»“i quy, chÃºng tÃ´i Ä‘áº·t hÃ¬nh dáº¡ng cá»§a ma tráº­n projection ğ‘Šproj thÃ nh (ğ‘‘,1), Ä‘á»ƒ
nÃ³ chá»‰ xuáº¥t ra logits 1 chá»¯ sá»‘. NhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong PhÆ°Æ¡ng trÃ¬nh 2, trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n chÃºng tÃ´i Ã¡p dá»¥ng mean-squared-error (MSE) loss
dá»±a trÃªn logits Ä‘áº§u ra vÃ  xáº¿p háº¡ng ground-truth.
ğ¿regression =1|ğ‘|ğ‘âˆ‘ï¸ğ‘–=1(logitsğ‘–decâˆ’ğ‘Ÿğ‘–)2. (2)
4 THÃ NGHIá»†M
ChÃºng tÃ´i tiáº¿n hÃ nh cÃ¡c thÃ­ nghiá»‡m má»Ÿ rá»™ng Ä‘á»ƒ tráº£ lá»i cÃ¡c cÃ¢u há»i nghiÃªn cá»©u sau:
RQ1: CÃ¡c LLM sáºµn cÃ³ cÃ³ hoáº¡t Ä‘á»™ng tá»‘t cho cÃ¡c gá»£i Ã½ zero-shot vÃ  few-shot khÃ´ng?
RQ2: LLM so sÃ¡nh nhÆ° tháº¿ nÃ o vá»›i cÃ¡c há»‡ thá»‘ng gá»£i Ã½ truyá»n thá»‘ng trong má»™t mÃ´i trÆ°á»ng cÃ´ng báº±ng
RQ3: KÃ­ch thÆ°á»›c mÃ´ hÃ¬nh quan trá»ng nhÆ° tháº¿ nÃ o Ä‘á»‘i vá»›i LLM khi Ä‘Æ°á»£c sá»­ dá»¥ng cho cÃ¡c há»‡ thá»‘ng gá»£i Ã½?
RQ4: LLM cÃ³ há»™i tá»¥ nhanh hÆ¡n cÃ¡c mÃ´ hÃ¬nh gá»£i Ã½ truyá»n thá»‘ng khÃ´ng?
4.1 Bá»™ dá»¯ liá»‡u vÃ  Thiáº¿t láº­p ÄÃ¡nh giÃ¡
4.1.1 Bá»™ dá»¯ liá»‡u. Äá»ƒ Ä‘Ã¡nh giÃ¡ nhiá»‡m vá»¥ dá»± Ä‘oÃ¡n xáº¿p háº¡ng ngÆ°á»i dÃ¹ng, chÃºng tÃ´i sá»­ dá»¥ng hai bá»™ dá»¯ liá»‡u benchmark Ä‘Æ°á»£c Ã¡p dá»¥ng rá»™ng rÃ£i Ä‘á»ƒ
Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t mÃ´ hÃ¬nh trÃªn cÃ¡c gá»£i Ã½. Cáº£ hai bá»™ dá»¯ liá»‡u Ä‘á»u bao gá»“m xáº¿p háº¡ng Ä‘Ã¡nh giÃ¡ ngÆ°á»i dÃ¹ng tá»« 1 Ä‘áº¿n 5.
â€¢MovieLens [13]: ChÃºng tÃ´i sá»­ dá»¥ng phiÃªn báº£n MovieLens-1M bao gá»“m 1 triá»‡u xáº¿p háº¡ng ngÆ°á»i dÃ¹ng cho phim.
â€¢Amazon-Books [21]: ChÃºng tÃ´i sá»­ dá»¥ng danh má»¥c "Books" cá»§a Bá»™ dá»¯ liá»‡u ÄÃ¡nh giÃ¡ Amazon vá»›i xáº¿p háº¡ng ngÆ°á»i dÃ¹ng trÃªn cÃ¡c má»¥c. ChÃºng tÃ´i
sá»­ dá»¥ng phiÃªn báº£n 5-core lá»c ra ngÆ°á»i dÃ¹ng vÃ  má»¥c cÃ³ Ã­t hÆ¡n 5 tÆ°Æ¡ng tÃ¡c.
Báº£n tháº£o gá»­i Ä‘áº¿n ACM

--- TRANG 6 ---
6 W.-C. Kang, et al.
Báº£ng 1. Thá»‘ng kÃª cá»§a bá»™ dá»¯ liá»‡u
Bá»™ dá»¯ liá»‡u #NgÆ°á»i dÃ¹ng #Má»¥c # VÃ­ dá»¥ Huáº¥n luyá»‡n # VÃ­ dá»¥ Kiá»ƒm tra TÃ­nh nÄƒng
Movielens-1M 6,040 3,689 882,002 2,000 (75,880) TiÃªu Ä‘á», Thá»ƒ loáº¡i
Amazon-Books 1,850,187 483,579 17,566,711 2,000 (2,324,503) TiÃªu Ä‘á», ThÆ°Æ¡ng hiá»‡u
4.1.2 PhÃ¢n chia Huáº¥n luyá»‡n / Kiá»ƒm tra. Äá»ƒ táº¡o cÃ¡c táº­p huáº¥n luyá»‡n vÃ  kiá»ƒm tra, chÃºng tÃ´i tuÃ¢n theo phÃ¢n chia thá»i Ä‘iá»ƒm Ä‘Æ¡n [32]. Äáº§u tiÃªn chÃºng tÃ´i lá»c ra
cÃ¡c xáº¿p háº¡ng liÃªn quan Ä‘áº¿n cÃ¡c má»¥c khÃ´ng cÃ³ metadata, sau Ä‘Ã³ sáº¯p xáº¿p táº¥t cáº£ xáº¿p háº¡ng ngÆ°á»i dÃ¹ng theo thá»© tá»± thá»i gian. Cuá»‘i cÃ¹ng,
chÃºng tÃ´i láº¥y 90% xáº¿p háº¡ng Ä‘áº§u tiÃªn lÃ m táº­p huáº¥n luyá»‡n vÃ  pháº§n cÃ²n láº¡i lÃ m táº­p kiá»ƒm tra. Má»—i vÃ­ dá»¥ huáº¥n luyá»‡n lÃ  má»™t tuple
<ğ‘¢ğ‘ ğ‘’ğ‘Ÿ_ğ‘–ğ‘‘,ğ‘–ğ‘¡ğ‘’ğ‘š_ğ‘–ğ‘‘,ğ‘–ğ‘¡ğ‘’ğ‘š_ğ‘šğ‘’ğ‘¡ğ‘ğ‘‘ğ‘ğ‘¡ğ‘,ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘›ğ‘”>, trong Ä‘Ã³ nhÃ£n lÃ  xáº¿p háº¡ng thang Likert 5 Ä‘iá»ƒm. CÃ¡c tÃ­nh nÄƒng Ä‘áº§u vÃ o lÃ  ğ‘¢ğ‘ ğ‘’ğ‘Ÿ_ğ‘–ğ‘‘,
ğ‘–ğ‘¡ğ‘’ğ‘š_ğ‘–ğ‘‘, vÃ  danh sÃ¡ch cÃ¡c tÃ­nh nÄƒng item_metadata. Thá»‘ng kÃª cá»§a cÃ¡c bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Báº£ng 1. Do chi phÃ­ tÃ­nh toÃ¡n cao
cá»§a cÃ¡c thÃ­ nghiá»‡m zero-shot vÃ  few-shot dá»±a trÃªn LLM, chÃºng tÃ´i láº¥y máº«u ngáº«u nhiÃªn tá»« táº­p kiá»ƒm tra cá»§a má»—i
bá»™ dá»¯ liá»‡u thÃ nh 2,000 tuple lÃ m táº­p kiá»ƒm tra nhá» hÆ¡n. Äá»‘i vá»›i táº¥t cáº£ cÃ¡c thÃ­ nghiá»‡m, chÃºng tÃ´i bÃ¡o cÃ¡o káº¿t quáº£ trÃªn táº­p kiá»ƒm tra Ä‘Æ°á»£c láº¥y máº«u. VÃ  chÃºng tÃ´i
cáº¯t bá»›t chuá»—i ngÆ°á»i dÃ¹ng Ä‘áº¿n 10 tÆ°Æ¡ng tÃ¡c gáº§n nháº¥t trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡.
4.1.3 Chá»‰ sá»‘ ÄÃ¡nh giÃ¡. ChÃºng tÃ´i sá»­ dá»¥ng cÃ¡c chá»‰ sá»‘ Ä‘Æ°á»£c Ã¡p dá»¥ng rá»™ng rÃ£i RMSE (Root Mean Squared Error) vÃ  MAE (Mean
Average Error) Ä‘á»ƒ Ä‘o hiá»‡u suáº¥t mÃ´ hÃ¬nh trÃªn dá»± Ä‘oÃ¡n xáº¿p háº¡ng. HÆ¡n ná»¯a, chÃºng tÃ´i sá»­ dá»¥ng ROC-AUC Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh
trÃªn xáº¿p háº¡ng, trong Ä‘Ã³ cÃ¡c xáº¿p háº¡ng lá»›n hÆ¡n hoáº·c báº±ng 4 Ä‘Æ°á»£c coi lÃ  dÆ°Æ¡ng vÃ  pháº§n cÃ²n láº¡i lÃ  Ã¢m.
Trong trÆ°á»ng há»£p nÃ y, AUC Ä‘o xem mÃ´ hÃ¬nh cÃ³ xáº¿p háº¡ng cÃ¡c má»¥c dÆ°Æ¡ng cao hÆ¡n cÃ¡c má»¥c Ã¢m khÃ´ng.
4.2 Baseline vÃ  LLM
4.2.1 Baseline.
â€¢Há»‡ thá»‘ng Gá»£i Ã½ Truyá»n thá»‘ng: ChÃºng tÃ´i xem xÃ©t má»™t sá»‘ mÃ´ hÃ¬nh gá»£i Ã½ truyá»n thá»‘ng nhÆ° baseline máº¡nh, bao gá»“m
1. Matrix Factorization (MF) [29], vÃ  2. Multi-layer Perceptrons (MLP) [14]. Äá»‘i vá»›i MF vÃ  MLP, chá»‰ cÃ³ user ID vÃ  item
ID Ä‘Æ°á»£c sá»­ dá»¥ng lÃ m tÃ­nh nÄƒng Ä‘áº§u vÃ o.
â€¢Bá»™ Dá»± Ä‘oÃ¡n Xáº¿p háº¡ng Tuáº§n tá»± Nháº­n biáº¿t Thuá»™c tÃ­nh vÃ  Xáº¿p háº¡ng: Trong cÃ¡c thÃ­ nghiá»‡m, chÃºng tÃ´i cung cáº¥p cho LLM
metadata má»¥c lá»‹ch sá»­, nhÆ° tiÃªu Ä‘á» vÃ  danh má»¥c, cÃ¹ng vá»›i xáº¿p háº¡ng lá»‹ch sá»­. Tuy nhiÃªn, theo hiá»ƒu biáº¿t tá»‘t nháº¥t cá»§a chÃºng tÃ´i, khÃ´ng cÃ³
phÆ°Æ¡ng phÃ¡p hiá»‡n táº¡i nÃ o Ä‘Æ°á»£c thiáº¿t káº¿ cho thiáº¿t láº­p nÃ yÂ¹. Äá»ƒ Ä‘áº£m báº£o so sÃ¡nh cÃ´ng báº±ng, chÃºng tÃ´i xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh
Transformer-MLP Ä‘á»ƒ xá»­ lÃ½ hiá»‡u quáº£ cÃ¹ng thÃ´ng tin Ä‘áº§u vÃ o Ä‘Æ°á»£c cung cáº¥p cho LLM.
CÃ³ ba lá»±a chá»n thiáº¿t káº¿ chÃ­nh: (i) xá»­ lÃ½ tÃ­nh nÄƒng: ChÃºng tÃ´i xem táº¥t cáº£ tÃ­nh nÄƒng nhÆ° tÃ­nh nÄƒng thÆ°a thá»›t, vÃ  há»c embedding cá»§a chÃºng
end-to-end. VÃ­ dá»¥, chÃºng tÃ´i sá»­ dá»¥ng one-hot encoding cho thá»ƒ loáº¡i, vÃ  táº¡o má»™t báº£ng embedding, trong Ä‘Ã³
hÃ ng thá»© i lÃ  embedding cá»§a thá»ƒ loáº¡i i. TÆ°Æ¡ng tá»±, chÃºng tÃ´i cÃ³ Ä‘Æ°á»£c bag-of-words encodings thÃ´ng qua viá»‡c Ã¡p dá»¥ng tokenizerÂ² trÃªn tiÃªu Ä‘á»,
vÃ  sau Ä‘Ã³ tra cá»©u embedding tÆ°Æ¡ng á»©ng. (ii) mÃ´ hÃ¬nh hÃ³a ngÆ°á»i dÃ¹ng: Ä‘á»‘i vá»›i má»—i hÃ nh vi ngÆ°á»i dÃ¹ng, chÃºng tÃ´i sá»­ dá»¥ng AddorConcat
Ä‘á»ƒ tá»•ng há»£p táº¥t cáº£ embedding (vÃ­ dá»¥ item ID, tiÃªu Ä‘á», thá»ƒ loáº¡i/danh má»¥c, xáº¿p háº¡ng) thÃ nh má»™t, vÃ  sau Ä‘Ã³ Ã¡p dá»¥ng cÃ¡c lá»›p bi-directional
self-attention [34] vá»›i position embedding Ä‘Ã£ há»c Ä‘á»ƒ mÃ´ hÃ¬nh hÃ³a hÃ nh vi trong quÃ¡ khá»© cá»§a ngÆ°á»i dÃ¹ng. TÆ°Æ¡ng tá»± nhÆ° SASRec, chÃºng tÃ´i sá»­ dá»¥ng
embedding Ä‘áº§u ra cá»§a hÃ nh vi gáº§n nháº¥t nhÆ° tÃ³m táº¯t ngÆ°á»i dÃ¹ng; (iii) Káº¿t há»£p ngÆ°á»i dÃ¹ng vÃ  á»©ng viÃªn cho dá»± Ä‘oÃ¡n xáº¿p háº¡ng:
chÃºng tÃ´i Ã¡p dá»¥ng má»™t MLP trÃªn embedding ngÆ°á»i dÃ¹ng cÃ¹ng vá»›i cÃ¡c tÃ­nh nÄƒng má»¥c á»©ng viÃªn khÃ¡c Ä‘á»ƒ táº¡o ra dá»± Ä‘oÃ¡n xáº¿p háº¡ng cuá»‘i cÃ¹ng,
vÃ  tá»‘i Æ°u hÃ³a Ä‘á»ƒ giáº£m thiá»ƒu MSE.
Â¹CÃ¡c cÃ´ng trÃ¬nh liÃªn quan nháº¥t lÃ  SASRec [16] vÃ  CARCA [28], tuy nhiÃªn chÃºng Ä‘Æ°á»£c thiáº¿t káº¿ cho dá»± Ä‘oÃ¡n má»¥c tiáº¿p theo thay vÃ¬ dá»± Ä‘oÃ¡n xáº¿p háº¡ng, vÃ  do Ä‘Ã³ khÃ´ng
trá»±c tiáº¿p Ã¡p dá»¥ng Ä‘Æ°á»£c cho trÆ°á»ng há»£p cá»§a chÃºng tÃ´i.
Â²https://www.tensorflow.org/text/api_docs/python/text/WhitespaceTokenizer
Báº£n tháº£o gá»­i Ä‘áº¿n ACM

--- TRANG 7 ---
Liá»‡u LLM cÃ³ hiá»ƒu sá»Ÿ thÃ­ch ngÆ°á»i dÃ¹ng khÃ´ng? ÄÃ¡nh giÃ¡ LLM vá» dá»± Ä‘oÃ¡n xáº¿p háº¡ng ngÆ°á»i dÃ¹ng 7
Báº£ng 2. Káº¿t quáº£ dá»± Ä‘oÃ¡n xáº¿p háº¡ng ngÆ°á»i dÃ¹ng. PhÆ°Æ¡ng phÃ¡p hoáº¡t Ä‘á»™ng tá»‘t nháº¥t Ä‘Æ°á»£c in Ä‘áº­m trong má»—i cá»™t, vÃ  gáº¡ch chÃ¢n trong má»—i nhÃ³m.
MÃ´ hÃ¬nh MovieLens Amazon-Books
RMSEâ†“MAEâ†“ AUCâ†‘ RMSEâ†“MAEâ†“ AUCâ†‘
LLM Zero-Shot
Flan-U-PALM 1.0677 0.7740 0.7084 0.9565 0.5569 0.7676
ChatGPT 1.0081 0.8193 0.6794 1.0081 0.8093 0.6778
text-davinci-003 1.0460 0.7850 0.6951 0.8890 0.5442 0.7416
LLM Few-Shot
Flan-U-PALM 1.0721 0.7605 0.7094 1.0712 0.5855 0.7439
ChatGPT 1.0862 0.8203 0.6930 1.0618 0.7760 0.7470
text-davinci-003 1.0867 0.8119 0.6963 1.0716 0.7753 0.7739
Thá»‘ng kÃª Bá»™ dá»¯ liá»‡u ÄÆ¡n giáº£n
Xáº¿p háº¡ng Trung bÃ¬nh ToÃ n cá»¥c 1.1564 0.9758 0.5 0.9482 0.7609 0.5
Xáº¿p háº¡ng Trung bÃ¬nh Má»¥c á»¨ng viÃªn 0.9749 0.7778 0.7395 0.9342 0.7078 0.6041
Xáº¿p háº¡ng Trung bÃ¬nh QuÃ¡ khá»© NgÆ°á»i dÃ¹ng 1.0196 0.7959 0.7266 0.8527 0.5502 0.8047
PhÆ°Æ¡ng phÃ¡p Gá»£i Ã½ CÃ³ giÃ¡m sÃ¡t
MF 0.9552 0.7436 0.7734 1.7960 1.1070 0.7638
MLP 0.9689 0.7452 0.7393 0.8607 0.6384 0.6932
Transformer+MLP 0.8848 0.7036 0.7979 0.8143 0.5541 0.8042
LLM Fine-tuned
Flan-T5-Base (phÃ¢n loáº¡i) 1.0110 0.6805 0.7590 0.9856 0.4685 0.6292
Flan-T5-Base (há»“i quy) 0.9187 0.7092 0.7949 0.8413 0.5317 0.8182
Flan-T5-XXL (há»“i quy) 0.8979 0.6986 0.8042 0.8301 0.5122 0.8312
Äá»ƒ tinh chá»‰nh Ä‘Ãºng cÃ¡ch cÃ¡c mÃ´ hÃ¬nh baseline, chÃºng tÃ´i Ä‘á»‹nh nghÄ©a má»™t khÃ´ng gian tÃ¬m kiáº¿m siÃªu tham sá»‘ (vÃ­ dá»¥ cho chiá»u embedding,
learning rate, kÃ­ch thÆ°á»›c máº¡ng, tá»•ng há»£p AddorConcat, v.v.), vÃ  thá»±c hiá»‡n hÆ¡n 100 thá»­ nghiá»‡m tÃ¬m kiáº¿m báº±ng Vizier
[9], má»™t cÃ´ng cá»¥ tá»‘i Æ°u hÃ³a siÃªu tham sá»‘ black-box.
â€¢Heuristics: ChÃºng tÃ´i cÅ©ng bao gá»“m ba baseline dá»±a trÃªn heuristic: (1) xáº¿p háº¡ng trung bÃ¬nh toÃ n cá»¥c: (2) xáº¿p háº¡ng trung bÃ¬nh má»¥c á»©ng viÃªn,
vÃ  (3) xáº¿p háº¡ng trung bÃ¬nh quÃ¡ khá»© ngÆ°á»i dÃ¹ng, cÃ³ nghÄ©a lÃ  dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh phá»¥ thuá»™c vÃ o (1) xáº¿p háº¡ng trung bÃ¬nh trong sá»‘
táº¥t cáº£ xáº¿p háº¡ng ngÆ°á»i dÃ¹ng-má»¥c, (2) xáº¿p háº¡ng trung bÃ¬nh tá»« má»¥c á»©ng viÃªn hoáº·c (3) xáº¿p háº¡ng trung bÃ¬nh cá»§a ngÆ°á»i dÃ¹ng trong quÃ¡ khá»©.
4.2.2 LLM cho Há»c Zero-shot vÃ  Few-shot.: ChÃºng tÃ´i sá»­ dá»¥ng cÃ¡c LLM Ä‘Æ°á»£c liá»‡t kÃª dÆ°á»›i Ä‘Ã¢y cho há»c zero-shot vÃ  few-shot.
ChÃºng tÃ´i sá»­ dá»¥ng nhiá»‡t Ä‘á»™ 0.1 cho táº¥t cáº£ LLM, vÃ¬ Ä‘áº§u ra cá»§a LLM trong trÆ°á»ng há»£p cá»§a chÃºng tÃ´i Ä‘Æ¡n giáº£n lÃ  má»™t dá»± Ä‘oÃ¡n xáº¿p háº¡ng. ChÃºng tÃ´i sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh GPT-3
tá»« OpenAI [24]: (i)text-davinci-003 (175B): MÃ´ hÃ¬nh GPT-3 cÃ³ kháº£ nÄƒng nháº¥t vá»›i Reinforcement Learning
from Human Feedback (RLHF) [31]; (ii) ChatGPT: mÃ´ hÃ¬nh máº·c Ä‘á»‹nh lÃ  gpt-3.5-turbo, Ä‘Æ°á»£c fine-tune trÃªn cáº£
cuá»™c trÃ² chuyá»‡n do con ngÆ°á»i viáº¿t vÃ  RLHF, vÃ  Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a thÃªm cho cuá»™c há»™i thoáº¡i. Flan-U-PaLM (540B) lÃ  mÃ´ hÃ¬nh lá»›n nháº¥t vÃ  máº¡nh nháº¥t
trong [4], nÃ³ Ã¡p dá»¥ng cáº£ FLAN instruction tuning [39] vÃ  má»¥c tiÃªu huáº¥n luyá»‡n UL2 [4] trÃªn PaLM [2].
4.2.3 LLM cho Fine-tuning. Äá»‘i vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p fine-tuning, chÃºng tÃ´i sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh Flan-T5-Base (250M) vÃ  Flan-T5-XXL (11B) trong
cÃ¡c thÃ­ nghiá»‡m. ChÃºng tÃ´i Ä‘áº·t learning rate thÃ nh 5e-5, batch size thÃ nh 64, tá»· lá»‡ drop out thÃ nh 0.1 vÃ  huáº¥n luyá»‡n 50k bÆ°á»›c trÃªn táº¥t cáº£ bá»™ dá»¯ liá»‡u.
4.3 LLM Zero-Shot vÃ  Few-shot (RQ1)
NhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Báº£ng 2, chÃºng tÃ´i tiáº¿n hÃ nh thÃ­ nghiá»‡m trÃªn má»™t sá»‘ LLM sáºµn cÃ³ trong thiáº¿t láº­p zero-shot. ChÃºng tÃ´i quan sÃ¡t tháº¥y ráº±ng
LLM dÆ°á»ng nhÆ° hiá»ƒu nhiá»‡m vá»¥ tá»« mÃ´ táº£ prompt, vÃ  dá»± Ä‘oÃ¡n xáº¿p háº¡ng há»£p lÃ½. LLM vÆ°á»£t trá»™i hÆ¡n xáº¿p háº¡ng trung bÃ¬nh toÃ n cá»¥c trong háº§u háº¿t trÆ°á»ng há»£p,
vÃ  hoáº¡t Ä‘á»™ng tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i xáº¿p háº¡ng trung bÃ¬nh má»¥c hoáº·c ngÆ°á»i dÃ¹ng. VÃ­ dá»¥, text-davinci-003
hoáº¡t Ä‘á»™ng hÆ¡i kÃ©m hÆ¡n xáº¿p háº¡ng trung bÃ¬nh má»¥c á»©ng viÃªn trÃªn Movielens nhÆ°ng vÆ°á»£t trá»™i trÃªn Amazon-Books. Äá»‘i vá»›i
Báº£n tháº£o gá»­i Ä‘áº¿n ACM

--- TRANG 8 ---
8 W.-C. Kang, et al.
(a) MovieLens
(b) Amazon Books
HÃ¬nh 4. Hiá»‡u quáº£ dá»¯ liá»‡u: Ä‘Æ°á»ng cong há»™i tá»¥.
cÃ¡c thÃ­ nghiá»‡m few-shot, chÃºng tÃ´i cung cáº¥p 3 vÃ­ dá»¥ trong prompt (3-shot). So vá»›i zero-shot, chÃºng tÃ´i tháº¥y ráº±ng
AUC cho LLM few-shot Ä‘Æ°á»£c cáº£i thiá»‡n, trong khi khÃ´ng cÃ³ máº«u rÃµ rÃ ng trong RMSE vÃ  MAE.
HÆ¡n ná»¯a, chÃºng tÃ´i tháº¥y ráº±ng cáº£ LLM zero-shot vÃ  few-shot Ä‘á»u kÃ©m hiá»‡u suáº¥t so vá»›i cÃ¡c mÃ´ hÃ¬nh gá»£i Ã½ truyá»n thá»‘ng
Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i dá»¯ liá»‡u tÆ°Æ¡ng tÃ¡c. NhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Báº£ng 2, cÃ¡c mÃ´ hÃ¬nh GPT-3 vÃ  Flan-U-PaLM Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t
tháº¥p hÆ¡n Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c mÃ´ hÃ¬nh cÃ³ giÃ¡m sÃ¡t. Hiá»‡u suáº¥t kÃ©m cÃ³ thá»ƒ lÃ  do thiáº¿u dá»¯ liá»‡u tÆ°Æ¡ng tÃ¡c ngÆ°á»i dÃ¹ng-má»¥c
trong pre-training cá»§a LLM, vÃ  do Ä‘Ã³ chÃºng khÃ´ng cÃ³ kiáº¿n thá»©c vá» sá»Ÿ thÃ­ch con ngÆ°á»i cho cÃ¡c nhiá»‡m vá»¥ gá»£i Ã½ khÃ¡c nhau. HÆ¡n ná»¯a, cÃ¡c nhiá»‡m vá»¥ gá»£i Ã½
ráº¥t phá»¥ thuá»™c vÃ o bá»™ dá»¯ liá»‡u: (vÃ­ dá»¥) cÃ¹ng má»™t bá»™ phim cÃ³ thá»ƒ cÃ³ xáº¿p háº¡ng trung bÃ¬nh khÃ¡c nhau trÃªn cÃ¡c ná»n táº£ng khÃ¡c nhau. Do Ä‘Ã³, khÃ´ng biáº¿t thá»‘ng kÃª cá»¥ thá»ƒ cá»§a bá»™ dá»¯ liá»‡u,
LLM khÃ´ng thá»ƒ cung cáº¥p dá»± Ä‘oÃ¡n phá»• quÃ¡t phÃ¹ há»£p vá»›i má»i bá»™ dá»¯ liá»‡u.
4.4 LLM so vá»›i MÃ´ hÃ¬nh Gá»£i Ã½ Truyá»n thá»‘ng (RQ2)
Fine-tuning LLM lÃ  má»™t cÃ¡ch hiá»‡u quáº£ Ä‘á»ƒ Ä‘Æ°a thá»‘ng kÃª bá»™ dá»¯ liá»‡u vÃ o LLM, vÃ  chÃºng tÃ´i tháº¥y hiá»‡u suáº¥t cá»§a LLM Ä‘Æ°á»£c fine-tune
tá»‘t hÆ¡n nhiá»u so vá»›i LLM zero/few-shot. NgoÃ i ra, khi fine-tuning mÃ´ hÃ¬nh Flan-T5-base vá»›i classification
loss, hiá»‡u suáº¥t kÃ©m hÆ¡n nhiá»u so vá»›i fine-tuning vá»›i regression loss trÃªn cáº£ ba chá»‰ sá»‘. Äiá»u nÃ y cho tháº¥y
táº§m quan trá»ng cá»§a viá»‡c chá»n má»¥c tiÃªu tá»‘i Æ°u hÃ³a phÃ¹ há»£p cho fine-tuning LLM.
So sÃ¡nh vá»›i baseline máº¡nh nháº¥t Transformer-MLP, chÃºng tÃ´i tháº¥y Flan-T5-XXL Ä‘Æ°á»£c fine-tune cÃ³ MAE vÃ 
AUC tá»‘t hÆ¡n, ngá»¥ Ã½ ráº±ng LLM Ä‘Æ°á»£c fine-tune cÃ³ thá»ƒ phÃ¹ há»£p hÆ¡n cho cÃ¡c nhiá»‡m vá»¥ xáº¿p háº¡ng.
4.5 áº¢nh hÆ°á»Ÿng cá»§a KÃ­ch thÆ°á»›c MÃ´ hÃ¬nh (RQ3)
Äá»‘i vá»›i táº¥t cáº£ LLM chÃºng tÃ´i nghiÃªn cá»©u vá»›i kÃ­ch thÆ°á»›c khÃ¡c nhau tá»« 250M Ä‘áº¿n 500B tham sá»‘, chÃºng tÃ´i cÃ³ thá»ƒ sá»­ dá»¥ng prompt zero-shot
hoáº·c few-shot Ä‘á»ƒ cho chÃºng xuáº¥t ra dá»± Ä‘oÃ¡n xáº¿p háº¡ng tá»« 1 Ä‘áº¿n 5. Äiá»u nÃ y cho tháº¥y hiá»‡u quáº£ cá»§a instruction
tuning cho phÃ©p cÃ¡c LLM nÃ y (Flan-T5, Flan-U-PaLM, GPT-3) tuÃ¢n theo prompt. ChÃºng tÃ´i cÅ©ng tháº¥y ráº±ng chá»‰ cÃ³ LLM
vá»›i kÃ­ch thÆ°á»›c lá»›n hÆ¡n 100B má»›i hoáº¡t Ä‘á»™ng tá»‘t há»£p lÃ½ trÃªn dá»± Ä‘oÃ¡n xáº¿p háº¡ng trong thiáº¿t láº­p zero-shot, nhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 1.
Äá»‘i vá»›i cÃ¡c thÃ­ nghiá»‡m fine-tuning, chÃºng tÃ´i cÅ©ng tháº¥y ráº±ng Flan-T5-XXL vÆ°á»£t trá»™i Flan-T5-Base trÃªn cáº£ hai bá»™ dá»¯ liá»‡u, nhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong
hai hÃ ng cuá»‘i cá»§a Báº£ng 2.
4.6 Hiá»‡u quáº£ Dá»¯ liá»‡u cá»§a LLM (RQ4)
VÃ¬ LLM Ä‘Ã£ há»c Ä‘Æ°á»£c lÆ°á»£ng lá»›n kiáº¿n thá»©c tháº¿ giá»›i trong quÃ¡ trÃ¬nh pre-training, trong khi cÃ¡c mÃ´ hÃ¬nh gá»£i Ã½ truyá»n thá»‘ng
Ä‘Æ°á»£c huáº¥n luyá»‡n tá»« Ä‘áº§u, chÃºng tÃ´i so sÃ¡nh Ä‘Æ°á»ng cong há»™i tá»¥ cá»§a chÃºng trong HÃ¬nh 4 Ä‘á»ƒ kiá»ƒm tra xem LLM cÃ³ hiá»‡u quáº£ dá»¯ liá»‡u tá»‘t hÆ¡n khÃ´ng.
ChÃºng ta cÃ³ thá»ƒ tháº¥y ráº±ng Ä‘á»‘i vá»›i RMSE, cáº£ hai phÆ°Æ¡ng phÃ¡p Ä‘á»u cÃ³ thá»ƒ há»™i tá»¥ Ä‘áº¿n hiá»‡u suáº¥t há»£p lÃ½ vá»›i má»™t pháº§n nhá»
Báº£n tháº£o gá»­i Ä‘áº¿n ACM

--- TRANG 9 ---
Liá»‡u LLM cÃ³ hiá»ƒu sá»Ÿ thÃ­ch ngÆ°á»i dÃ¹ng khÃ´ng? ÄÃ¡nh giÃ¡ LLM vá» dá»± Ä‘oÃ¡n xáº¿p háº¡ng ngÆ°á»i dÃ¹ng 9
dá»¯ liá»‡u. Äiá»u nÃ y cÃ³ láº½ lÃ  do ngay cáº£ xáº¿p háº¡ng trung bÃ¬nh cá»§a táº¥t cáº£ má»¥c cÅ©ng cÃ³ RMSE tÆ°Æ¡ng Ä‘á»‘i tháº¥p, vÃ  do Ä‘Ã³ miá»…n lÃ  má»™t
mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c cÃ¡ch dá»± Ä‘oÃ¡n xáº¿p háº¡ng gáº§n vá»›i xáº¿p háº¡ng trung bÃ¬nh, nÃ³ cÃ³ thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t há»£p lÃ½. Äá»‘i vá»›i AUC xu hÆ°á»›ng
rÃµ rÃ ng hÆ¡n, vÃ¬ viá»‡c Ä‘Æ¡n giáº£n dá»± Ä‘oÃ¡n xáº¿p háº¡ng trung bÃ¬nh dáº«n Ä‘áº¿n AUC lÃ  0.5. ChÃºng tÃ´i tháº¥y ráº±ng má»™t pháº§n nhá» dá»¯ liá»‡u lÃ 
cáº§n thiáº¿t Ä‘á»ƒ LLM Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t tá»‘t, trong khi Transformer+MLP cáº§n nhiá»u dá»¯ liá»‡u huáº¥n luyá»‡n hÆ¡n (Ã­t nháº¥t 1
epoch) Ä‘á»ƒ há»™i tá»¥.
5 Káº¾T LUáº¬N
Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£ cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n nhÆ° má»™t há»‡ thá»‘ng gá»£i Ã½ cho dá»± Ä‘oÃ¡n xáº¿p háº¡ng ngÆ°á»i dÃ¹ng
trong ba thiáº¿t láº­p: 1. zero-shot; 2. few-shot; vÃ  3. fine-tuning. So vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p gá»£i Ã½ truyá»n thá»‘ng,
káº¿t quáº£ cá»§a chÃºng tÃ´i tiáº¿t lá»™ ráº±ng LLM trong zero-shot vÃ  few-shot tá»¥t háº­u so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p cÃ³ giÃ¡m sÃ¡t Ä‘áº§y Ä‘á»§, ngá»¥ Ã½
táº§m quan trá»ng cá»§a viá»‡c káº¿t há»£p phÃ¢n phá»‘i bá»™ dá»¯ liá»‡u má»¥c tiÃªu vÃ o LLM. Máº·t khÃ¡c, LLM Ä‘Æ°á»£c fine-tune cÃ³ thá»ƒ
thu háº¹p khoáº£ng cÃ¡ch vá»›i cÃ¡c baseline Ä‘Æ°á»£c thiáº¿t káº¿ cáº©n tháº­n trong cÃ¡c chá»‰ sá»‘ chÃ­nh. CÃ¡c há»‡ thá»‘ng gá»£i Ã½ dá»±a trÃªn LLM cÃ³ má»™t sá»‘ lá»£i Ã­ch: (i) hiá»‡u quáº£ dá»¯ liá»‡u tá»‘t hÆ¡n;
(ii) Ä‘Æ¡n giáº£n cho xá»­ lÃ½ tÃ­nh nÄƒng vÃ  mÃ´ hÃ¬nh hÃ³a: chÃºng tÃ´i chá»‰ cáº§n chuyá»ƒn Ä‘á»•i thÃ´ng tin thÃ nh prompt
mÃ  khÃ´ng cáº§n thiáº¿t káº¿ thá»§ cÃ´ng cÃ¡c chiáº¿n lÆ°á»£c xá»­ lÃ½ tÃ­nh nÄƒng, phÆ°Æ¡ng phÃ¡p embedding, vÃ  kiáº¿n trÃºc máº¡ng Ä‘á»ƒ xá»­ lÃ½
nhiá»u loáº¡i thÃ´ng tin khÃ¡c nhau; (iii) tiá»m nÄƒng má»Ÿ khÃ³a kháº£ nÄƒng gá»£i Ã½ há»™i thoáº¡i. CÃ´ng trÃ¬nh cá»§a chÃºng tÃ´i lÃ m sÃ¡ng tá»
tÃ¬nh tráº¡ng hiá»‡n táº¡i cá»§a cÃ¡c há»‡ thá»‘ng gá»£i Ã½ dá»±a trÃªn LLM, vÃ  trong tÆ°Æ¡ng lai chÃºng tÃ´i sáº½ tiáº¿p tá»¥c tÃ¬m hiá»ƒu cáº£i thiá»‡n
hiá»‡u suáº¥t thÃ´ng qua cÃ¡c phÆ°Æ¡ng phÃ¡p nhÆ° prompt tuning, vÃ  khÃ¡m phÃ¡ cÃ¡c á»©ng dá»¥ng gá»£i Ã½ má»›i Ä‘Æ°á»£c há»— trá»£ bá»Ÿi LLM.
TÃ€I LIá»†U THAM KHáº¢O
[1]Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877â€“1901.
[2]Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles
Sutton, Sebastian Gehrmann, et al. 2022. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311 (2022).
[3]Paul Francis Christiano, Jan Leike, Tom B. Brown, Miljan Martic, Shane Legg, and Dario Amodei. 2017. Deep Reinforcement Learning from Human
Preferences. ArXiv abs/1706.03741 (2017).
[4]Hyung Won Chung, Le Hou, S. Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert
Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Dasha Valter, Sharan Narang, Gaurav Mishra,
Adams Wei Yu, Vincent Zhao, Yanping Huang, Andrew M. Dai, Hongkun Yu, Slav Petrov, Ed Huai hsin Chi, Jeff Dean, Jacob Devlin, Adam Roberts,
Denny Zhou, Quoc V. Le, and Jason Wei. 2022. Scaling Instruction-Finetuned Language Models. ArXiv abs/2210.11416 (2022).
[5]Zeyu Cui, Jianxin Ma, Chang Zhou, Jingren Zhou, and Hongxia Yang. 2022. M6-Rec: Generative Pretrained Language Models are Open-Ended
Recommender Systems. arXiv preprint arXiv:2205.08084 (2022).
[6]Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language
understanding. arXiv preprint arXiv:1810.04805 (2018).
[7]Yunfan Gao, Tao Sheng, Youlin Xiang, Yun Xiong, Haofen Wang, and Jiawei Zhang. 2023. Chat-REC: Towards Interactive and Explainable
LLMs-Augmented Recommender System. arXiv preprint arXiv:2303.14524 (2023).
[8]Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, and Yongfeng Zhang. 2022. Recommendation as Language Processing (RLP): A Unified
Pretrain, Personalized Prompt & Predict Paradigm (P5). arXiv preprint arXiv:2203.13366 (2022).
[9]Daniel Golovin, Benjamin Solnik, Subhodeep Moitra, Greg Kochanski, John Karro, and D. Sculley. 2017. Google Vizier: A Service for Black-Box
Optimization. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Halifax, NS, Canada,
August 13 - 17, 2017 . ACM, 1487â€“1495. https://doi.org/10.1145/3097983.3098043
[10] Google. 2023. Bard: A Large Language Model from Google AI. https://bard.google.com/
[11] Shuguang Han, Xuanhui Wang, Mike Bendersky, and Marc Najork. 2020. Learning-to-Rank with BERT in TF-Ranking. arXiv:2004.08476 [cs.IR]
[12] F Maxwell Harper and Joseph A Konstan. 2015. The movielens datasets: History and context. Acm transactions on interactive intelligent systems (tiis)
5, 4 (2015), 1â€“19.
[13] F. Maxwell Harper and Joseph A. Konstan. 2016. The MovieLens Datasets: History and Context. ACM Trans. Interact. Intell. Syst. 5 (2016), 19:1â€“19:19.
[14] Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural Collaborative Filtering. In Proceedings of the 26th
International Conference on World Wide Web, WWW 2017, Perth, Australia, April 3-7, 2017 , Rick Barrett, Rick Cummings, Eugene Agichtein, and
Evgeniy Gabrilovich (Eds.). ACM, 173â€“182. https://doi.org/10.1145/3038912.3052569
Báº£n tháº£o gá»­i Ä‘áº¿n ACM

--- TRANG 10 ---
10 W.-C. Kang, et al.
[15] BalÃ¡zs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2015. Session-based recommendations with recurrent neural networks.
arXiv preprint arXiv:1511.06939 (2015).
[16] Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recommendation. In 2018 IEEE international conference on data mining
(ICDM) . IEEE, 197â€“206.
[17] Junyang Lin, Rui Men, An Yang, Chang Zhou, Ming Ding, Yichang Zhang, Peng Wang, Ang Wang, Le Jiang, Xianyan Jia, et al .2021. M6: A chinese
multimodal pretrainer. arXiv preprint arXiv:2103.00823 (2021).
[18] Junling Liu, Chao Liu, Renjie Lv, Kang Zhou, and Yan Zhang. 2023. Is ChatGPT a Good Recommender? A Preliminary Study. arXiv:2304.10149 [cs.IR]
[19] Yang Liu and Mirella Lapata. 2019. Text Summarization with Pretrained Encoders. arXiv:1908.08345 [cs.CL]
[20] Microsoft. 2023. Reinventing search with a new AI-powered Bing and Edge, your copilot for the web. https://news.microsoft.com/the-new-Bing/
[21] Jianmo Ni, Jiacheng Li, and Julian McAuley. 2019. Justifying Recommendations using Distantly-Labeled Reviews and Fine-Grained Aspects. In
Conference on Empirical Methods in Natural Language Processing .
[22] OpenAI. 2022. Aligning language models to follow instructions. https://openai.com/research/instruction-following.
[23] OpenAI. 2022. Introducing ChatGPT. https://openai.com/blog/chatgpt.
[24] OpenAI. 2023. GPT Models Documentation. https://platform.openai.com/docs/models/overview
[25] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al .2019. Language models are unsupervised multitask learners.
OpenAI blog 1, 8 (2019), 9.
[26] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the
Limits of Transfer Learning with a Unified Text-to-Text Transformer. J. Mach. Learn. Res. 21, 1, Article 140 (jan 2020), 67 pages.
[27] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020. Exploring the
limits of transfer learning with a unified text-to-text transformer. The Journal of Machine Learning Research 21, 1 (2020), 5485â€“5551.
[28] Ahmed Rashed, Shereen Elsayed, and Lars Schmidt-Thieme. 2022. CARCA: Context and Attribute-Aware Next-Item Recommendation via Cross-
Attention. arXiv preprint arXiv:2204.06519 (2022).
[29] Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2012. BPR: Bayesian personalized ranking from implicit feedback.
arXiv preprint arXiv:1205.2618 (2012).
[30] Noah Shinn, Beck Labash, and Ashwin Gopinath. 2023. Reflexion: an autonomous agent with dynamic memory and self-reflection. arXiv preprint
arXiv:2303.11366 (2023).
[31] Nisan Stiennon, Long Ouyang, Jeff Wu, Daniel M. Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, Dario Amodei, and Paul F. Christiano. 2020.
Learning to summarize from human feedback. CoRR abs/2009.01325 (2020). arXiv:2009.01325 https://arxiv.org/abs/2009.01325
[32] Aixin Sun. 2022. Take a Fresh Look at Recommender Systems from an Evaluation Standpoint.
[33] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, TimothÃ©e Lacroix, Baptiste RoziÃ¨re, Naman Goyal, Eric
Hambro, Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971 (2023).
[34] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Åukasz Kaiser, and Illia Polosukhin. 2017. Attention is
all you need. Advances in neural information processing systems 30 (2017).
[35] Lei Wang and Ee-Peng Lim. 2023. Zero-Shot Next-Item Recommendation using Large Pretrained Language Models. arXiv preprint arXiv:2304.03153
(2023).
[36] Qiang Wang, Bei Li, Tong Xiao, Jingbo Zhu, Changliang Li, Derek F. Wong, and Lidia S. Chao. 2019. Learning Deep Transformer Models for Machine
Translation. arXiv:1906.01787 [cs.CL]
[37] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2023. Self-Consistency
Improves Chain of Thought Reasoning in Language Models. arXiv:2203.11171 [cs.CL]
[38] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. 2022. Self-consistency improves chain of thought reasoning in
language models. arXiv preprint arXiv:2203.11171 (2022).
[39] Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, and Quoc V. Le. 2022. Finetuned
Language Models are Zero-Shot Learners. In The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29,
2022. OpenReview.net. https://openreview.net/forum?id=gEZrGCozdqR
[40] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler,
Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William Fedus. 2022. Emergent Abilities of Large Language Models.
arXiv:2206.07682 [cs.CL]
[41] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and Denny Zhou. 2022. Chain of thought prompting elicits reasoning
in large language models. arXiv preprint arXiv:2201.11903 (2022).
[42] Jiacheng Yang, Mingxuan Wang, Hao Zhou, Chengqi Zhao, Weinan Zhang, Yong Yu, and Lei Li. 2020. Towards making the most of bert in neural
machine translation. In Proceedings of the AAAI conference on artificial intelligence , Vol. 34. 9378â€“9385.
[43] Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin,
et al. 2022. Opt: Open pre-trained transformer language models. arXiv preprint arXiv:2205.01068 (2022).
[44] Yuhui Zhang, Hao Ding, Zeren Shui, Yifei Ma, James Zou, Anoop Deoras, and Hao Wang. 2021. Language models as recommender systems:
Evaluations and limitations. (2021).
Báº£n tháº£o gá»­i Ä‘áº¿n ACM

--- TRANG 11 ---
Liá»‡u LLM cÃ³ hiá»ƒu sá»Ÿ thÃ­ch ngÆ°á»i dÃ¹ng khÃ´ng? ÄÃ¡nh giÃ¡ LLM vá» dá»± Ä‘oÃ¡n xáº¿p háº¡ng ngÆ°á»i dÃ¹ng 11
[45] Lixin Zou, Shengqiang Zhang, Hengyi Cai, Dehong Ma, Suqi Cheng, Shuaiqiang Wang, Daiting Shi, Zhicong Cheng, and Dawei Yin. 2021. Pre-Trained
Language Model Based Ranking in Baidu Search. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining (Virtual
Event, Singapore) (KDD '21) . Association for Computing Machinery, New York, NY, USA, 4014â€“4022. https://doi.org/10.1145/3447548.3467147
Báº£n tháº£o gá»­i Ä‘áº¿n ACM

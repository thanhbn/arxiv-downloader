# 2206.00059.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/rl-alignment/2206.00059.pdf
# File size: 1373428 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
A Mixture-of-Expert Approach
to RL-based Dialogue Management
Yinlam Chow Aza Tulepbergenov Oﬁr Nachum
Moonkyung Ryu Mohammad Ghavamzadeh Craig Boutilier
Google Research
{yinlamchow, atulep, ofirnachum, mkryu, ghavamza, cboutilier}@google.com
Abstract
Despite recent advancements in language models (LMs), their application to di-
alogue management (DM) problems and ability to carry on rich conversations
remain a challenge. We use reinforcement learning (RL) to develop a dialogue
agent that avoids being short-sighted (outputting generic utterances) and maxi-
mizes overall user satisfaction. Most existing RL approaches to DM train the agent
at the word-level, and thus, have to deal with a combinatorially complex action
space even for a medium-size vocabulary. As a result, they struggle to produce a
successful and engaging dialogue even if they are warm-started with a pre-trained
LM. To address this issue, we develop a RL-based DM using a novel mixture of
expert language model (MoE-LM) that consists of (i) a LM capable of learning
diverse semantics for conversation histories, (ii) a number of specialized LMs (or
experts ) capable of generating utterances corresponding to a particular attribute
or personality, and (iii) a RL-based DM that performs dialogue planning with the
utterances generated by the experts. Our MoE approach provides greater ﬂexibility
to generate sensible utterances with different intents and allows RL to focus on
conversational-level DM. We compare it with SOTA baselines on open-domain
dialogues and demonstrate its effectiveness both in terms of the diversity and
sensibility of the generated utterances and the overall DM performance.
1 Introduction
With the tremendous advancements in natural language understanding and generation, increasing
attention has been directed to construct intelligent dialogue agents that can carry out rich and engaging
conversations with human users. Such interactions can be quite open-ended, contain many different
topics, and often involve an underlying task, such as building a rapport, negotiation, information
exchange, and recommendation. Therefore, to satisfy the user, a good dialogue agent should not only
generate natural responses, but also be capable of pursuing the task’s objectives and adapting to the
user’s feedback on-the-ﬂy.
A standard solution is to train the dialogue agent using behavioral cloning, where the agent is a
language model (LM) that imitates the utterances in the training set [Gaši ´c et al., 2011, Fatemi et al.,
2016]. By leveraging deep neural networks, e.g., RNNs [Sutskever et al., 2014] and Transform-
ers [Vaswani et al., 2017], a LM encodes the conversation to a low-dimensional dialogue state and
predicts an utterance, but steering such generation for particular purposes remains an open question.
Several works studied ways to ﬁne-tune a LM to generate texts with speciﬁc contexts [Ziegler et al.,
2019, Ficler and Goldberg, 2017]. Other results learned a single steerable LM that is capable of
Preprint. Under review.arXiv:2206.00059v1  [cs.CL]  31 May 2022

--- PAGE 2 ---
generating utterances for multiple speciﬁc intents [Gu et al., 2017, Chen et al., 2018, Subramani et al.,
2019, Dathathri et al., 2019]. While these LMs produce ﬂuent and relevant responses, it is unclear
how to control them to systematically pursue goals during multi-turn dialogue conversations.
Another popular approach is to view dialogue management (DM) as a control problem and use
reinforcement learning (RL) to optimize the agent’s policy (which is often a LM itself). Using
RL for dialogue systems has a long history. Earlier work relies on speciﬁc, hand-crafted semantic
states [Levin and Pieraccini, 1997, Singh et al., 2002, Walker, 2000] or partially observable belief
states [Williams and Young, 2007, Young et al., 2010], in which the agent chooses the best hand-
crafted dialogue act at each turn, with the goal of either satisfying the user [Shah et al., 2018],
completing the task [Shi and Yu, 2018], or responding to the user’s query [Serban et al., 2017a].
However, the application of these approaches is limited to problems whose action space can be
captured by hand-crafted representations, and they cannot handle complex conversations. On the
other hand, more recent approaches use deep learning to extract semantic representations from
conversation histories, treat these representations as dialogue belief states, and apply RL to learn
a word-level generative DM agent [Jaques et al., 2019, Li et al., 2016, 2017, Shin et al., 2020].
However, since there are innumerable possibilities of language utterances, and thus, the action
space of the RL problem is extremely large, the agent often performs planning poorly and generates
incomprehensible utterances [Zhao et al., 2019]. Another issue is that RL only optimizes a scalar
reward, while the aforementioned methods often need to optimize for both the quality of the generated
utterance, e.g., ease of answering [Li et al., 2016] and ﬂuency [Li et al., 2017, 2019], and the goal,
e.g., conversation length [Zhou et al., 2020], user’s sentiment [Hancock et al., 2019], and task
completion [Verma et al., 2022]. Moreover, deﬁning the reward as weighted combination of these
metrics is not ideal, since the hand-picked weights do not often reﬂect the underlying success criteria.
To address the above issues related to using RL in dialogue management (DM) systems, we propose
an RL-based DM agent using a novel mixture of expert (MoE) approach. Our MoE approach is based
on a mixture of expert language model (MoE-LM), which consists of three main components: 1)a
LM (a probabilistic encoder and a decoder) capable of learning diverse semantics for conversation
histories, and as a result generating diverse utterances, which we refer to as the primitive LM or LM0,
2)a number of specialized LMs (or experts ),fLMigm
i=1, that each is constructed using the latent space
learned by LM0, but has been trained such that it is capable of generating utterances corresponding to
a certain intent or personality, and 3)an RL-based dialogue manager (DM) that at each turn, given
the latent state shared by the experts fLMigm
i=0and the utterance action(s) they suggest, chooses one
among them for the agent to execute. Our MoE-LM can be seen as a special case of hierarchical
LMs (e.g., Serban et al. 2017a, Zhao et al. 2019, Saleh et al. 2020), but it is different than them
because it learns both the LMs (experts) and the DM. Moreover, the DM in MoE-LM is a policy
conditioned on both the latent state and the actions suggested by the experts, and not just the state
as it is common in hierarchical RL. The primitive LM ( LM0) plays an important role in this model
because it learns diverse semantics for conversation histories and allows the agent to generate a wide
variety of utterances. This diversity is also shared with the specialized LMs (experts) and gives them
ﬂexibility in generating their (more) specialized utterances. Another important feature of MoE-LM
is its modularity that facilitates adding and removing specialized LMs (experts). Moreover, this
hierarchical architecture allows us to solve an RL problem with much smaller state and action spaces,
which is quite important in the quality of the learned policy. Finally, since the candidate utterances
are generated by experts with different intents, instead of combining all agent-user signals into a
single RL reward, our DM agent can focus on optimizing the speciﬁc goal of the conversation task.
We start the paper with a brief introduction of LMs and the use of Markov decision processes
(MDPs) in modeling dialogue management problems in Section 2. We then describe the overall
architecture of our MoE-LM in Section 3, followed by the detailed implementation of each of its
three main components (described in the above paragraph) in Sections 4 to 6. Finally, in Section 7,
we demonstrate the effectiveness of our MoE-LM in open-domain dialogues, in terms of both its
ability to generate diverse and sensible utterances and its overall DM performance.
2 Preliminaries
Language Models (LMs) In this work, we employ seq2seq LMs to generate the next utterances
in a dialogue. We assume access to a dataset of the form D=f(X(k);Y(k))gjDj
k=1, where each
X=X(k)is aL-turn conversation history X=fXlgL 1
l=0andYis its next utterance. We denote
2

--- PAGE 3 ---
byNX, an upper-bound on the length (number of tokens) of each utterance XlinX.1The role of
a LM is to predict the probability of the next utterance Y, consisting of Ntokens, conditioned on
the conversation history X, i.e.,p 
Y=fyngN
n=1jX
. In the transformer architecture [Wolf et al.,
2019], the LM ﬁrst encodes the conversation history Xusing an encoder to a(LNX)-length
sequence of embeddings f(zl;0;:::;zl;NX 1)gL 1
l=0, where each zl;nis a vector in the latent space.
For notational convenience, we concatenate these embeddings into a single embedding z2Z Rd
and denote the overall dimension of the latent space as d. In the RNN architecture [Serban et al.,
2016], the LM’s encoder directly maps the conversation history Xto a latent state z2Z Rd. In
both architectures, the next utterance bY=fbyngN
n=1is sampled token-by-token from the decoder 	,
i.e.,bY	 
jz
=QN
n=1	 
bynjby0;:::;byn 1;z
, whereby0is a ﬁxed initial (start-of-sentence)
token [Chien and Kuo, 2019], and the latent state is denoted as z= (X).2
Markov Decision Processes (MDPs) have been used to model dialogue management problems
in a variety of settings [Li et al., 2016, Asadi and Williams, 2016, Jaques et al., 2019]. In such
MDPs, denoted by M= (S;A;P;r;s 0;), the state spaceSrepresents the tokenized conversation
history and the initial state s02 S is the initial user’s query. The action space Ais also the
tokenized language space with each action a2A being the agent’s next utterance (which is a
ﬁxed-length, NX, sequence of tokens). The transition kernel Pmodels the user’s response to the
action taken by the agent (bot). Finally, the reward function rmeasures the user’s satisfaction.
In these MDPs, we can think of the entire LM as a policy that maps conversation histories to
next utterances, and solve them by ﬁnding a policy with maximum expected discounted return,
i.e.,2arg maxJ:=E[P1
k=0trtjP;s0;]. Note that the size of the tokenized state and
action spaces grow exponentially with the size of the vocabulary. This makes it intractable to solve
the MDP even for a medium-size vocabulary. As a result, it would quite desirable to develop a novel
MDP paradigm that is more amendable to RL-based DM systems.
3 Mixture of Experts (MoE) Language Model
We start by explaining how a MoE language model (MoE-LM) can enrich the bot’s utterances
and improve the overall performance of the DM. While our approach is applicable to any DM
system, we use open-domain dialogue [Sankar et al., 2019] as a running example to show how
MoE-LM-based agents can improve user satisfaction measured by an improvement on a sentiment
or engagement. Intuitively a good DM agent should possess different behaviors (e.g., inquisitive,
explorative, relevant, soothing, empathetic, complimentary, provoking) and swiftly decide which
intent to use to pivot a conversation, build rapport, pique the user’s interests, improve their mood, etc.
To achieve this goal, we require the LM to have a language representation (primitive discovery) that
captures different semantics, in order to encode different conversations and avoid generating dull and
repetitive responses. We also need a machinery (expert construction) to embed different intents into
sub-models of this LM, so that they can behave accordingly when prompted, and respond efﬁciently.
Finally, with various candidate utterances available, the DM module of this LM should understand
the current level of user satisfaction and determine which response is the most appropriate. Motivated
by these observations, we construct our MoE-LM in three steps as shown in Figure 1. We give the
main idea behind each step here and leave their detailed descriptions to Sections 4, 5, and 6.
Step 1: Primitive Discovery. We ﬁrst employ the dataset D, introduced in Section 2, and learn a
language model LM0= (;G0;	)consisting of a stochastic encoder (i.e., an encoder and a latent
space distributionG0that maps the encoded conversation into a latent distribution), and a decoder 	.
The stochastic encoder (;G0)comprises an encoder that maps tokenized conversation histories X
to a latent spaceZRd, i.e.,z= (X)2Z, which is then used to construct a parameterized d-
dimensional Gaussian distribution G0(z0jz) =N 
0(z);2
0(z)Idd
overRd. The decoder predicts
the next utterance bY0(token-by-token) conditioned on the point z0sampled from the latent distribu-
tion, i.e., 	(bY0jz0)3; z0G 0(jz). We denote by LM0(YjX) :=Ez0G0(jz);z=(X)[	(Yjz0)], the
primitive and learn it using a loss function that in addition to predicting the next utterance accurately,
encourages diversity and generalization in the learned latent space Z(see Eq. 1 and Fig. 2). As we
will explain in Section 4, our loss function is inspired by those in prior work, and more speciﬁcally by
1If the actual utterance Xlhas fewer tokens than NX, it will be padded by a speciﬁc token and masked.
2Note that we use Yas the next utterance in the dataset and ^Yas the one predicted by the LM.
3In practice, we can use both latent states as the input to the decoder model 	(bY0jz0;z).
3

--- PAGE 4 ---
<latexit sha1_base64="vXrCpQE7bIqHA3pzUtWhaecwsVQ=">AAACPnicfZDNSsNAFIUn/ht/q0s3wSqISElE1GVRF27EClaFJpSb6W07dDIJMxOxhL6CW30cX8MXcCduXTqpEdSKFwY+zj0zc+8JE86Udt1na2x8YnJqembWnptfWFxaLq1cqTiVFOs05rG8CUEhZwLrmmmON4lEiEKO12HvOO9f36JULBaXup9gEEFHsDajoHPJr3VZc7nsVtxhOaPgFVAmRdWaJWvDb8U0jVBoykGphucmOshAakY5Dmw/VZgA7UEHGwYFRKiCbDjswNk0Sstpx9IcoZ2h+v1GBpFS/Sg0zgh0V/3u5eJfvUaq24dBxkSSahT086N2yh0dO/nmTotJpJr3DQCVzMzq0C5IoNrkY/snaHaReGbePU9Qgo7lduaD7ERwNzC7dfydnP4zMvFlNGSbXL3fKY7C1W7F26/sXeyVq0dFwjNkjayTLeKRA1Ilp6RG6oSSLrknD+TRerJerFfr7dM6ZhV3VsmPst4/AA34rus=</latexit> 
<latexit sha1_base64="tjHbOgrf4ho9DvviQX3BPsA5tPU=">AAACQ3icfZDLSgMxFIYz3q13XboJVkFEyoyIuhR0oQtRwWqlU+RMeqYNJpkhyYhl6FO41cfxIXwGd+JWMFMreMMDgY///EnO+aNUcGN9/8kbGBwaHhkdGy9NTE5Nz8zOzZ+bJNMMqywRia5FYFBwhVXLrcBaqhFkJPAiut4r+hc3qA1P1JntpNiQ0FI85gysky5DCbYdxbR2NVv2K36v6G8I+lAm/Tq5mvOWw2bCMonKMgHG1AM/tY0ctOVMYLcUZgZTYNfQwrpDBRJNI+9N3KUrTmnSONHuKEt76tcbOUhjOjJyzmJC87NXiH/16pmNdxo5V2lmUbGPj+JMUJvQYn3a5BqZFR0HwDR3s1LWBg3MupBK4T66XTQeuXePU9RgE72Wh6BbEm67brdWuF7Qf0auPo2OSi7X4GeKv+F8oxJsVTZPN8u7h/2Ex8giWSKrJCDbZJcckBNSJYxIckfuyYP36D17L97rh3XA699ZIN/Ke3sHH16w7Q==</latexit>X<latexit sha1_base64="mPpLqvfiTr3sYUH3/8vodE3xifA=">AAACPHicfZDLSgMxFIYzXmu969JNsAoiUmakqMuCLnQhXrC10ClyJj3ThmYyQ5IR69A3cKuP43u4dyduXZvWCt7wQODjP3+Sc/4gEVwb131yRkbHxicmc1P56ZnZufmFxaWqjlPFsMJiEataABoFl1gx3AisJQohCgReBp39fv/yGpXmsbww3QQbEbQkDzkDY6XzW3q1UHCL7qDob/CGUCDDOr1adNb8ZszSCKVhArSue25iGhkow5nAXt5PNSbAOtDCukUJEepGNhi1R9et0qRhrOyRhg7UrzcyiLTuRoF1RmDa+mevL/7Vq6cm3GtkXCapQck+PgpTQU1M+3vTJlfIjOhaAKa4nZWyNihgxqaT9w/Q7qLw2L57kqACE6vNzAfViuCmZ3dr+Vt9+s/I5afRUt7m6v1M8TdUt4veTrF0ViqUj4YJ58gKWSUbxCO7pEwOySmpEEZCckfuyYPz6Dw7L87rh3XEGd5ZJt/KeXsHIjqt+w==</latexit>z<latexit sha1_base64="+t0/fCT+bwdn8UYzdjxaOo9NJME=">AAACPHicfZDLSsNAFIYn9V6v1aWbYBVFpCQi6rKgC12IF2wrNKWcTE/SoZNJmJmINfQN3Orj+B7u3Ylb105rBW94YODjP//MnPP7CWdKO86TlRsZHRufmJzKT8/Mzs0vFBarKk4lxQqNeSyvfFDImcCKZprjVSIRIp9jze8c9Pu1a5SKxeJSdxNsRBAKFjAK2kgXt+vNhaJTcgZl/wZ3CEUyrLNmwVr1WjFNIxSaclCq7jqJbmQgNaMce3kvVZgA7UCIdYMCIlSNbDBqz14zSssOYmmO0PZA/Xojg0ipbuQbZwS6rX72+uJfvXqqg/1GxkSSahT046Mg5baO7f7edotJpJp3DQCVzMxq0zZIoNqkk/cO0ewi8cS8e5qgBB3LzcwDGUZw0zO7hd5Wn/4zMvFpNJQ3ubo/U/wN1e2Su1vaOd8plo+HCU+SZbJCNohL9kiZHJEzUiGUBOSO3JMH69F6tl6s1w9rzhreWSLfynp7By8brgI=</latexit>z0
<latexit sha1_base64="PmwWrbsHQqqrqct+03DAPOgnz4Y=">AAACPnicfVDBThsxEPXS0kKAAu2Ri0VAIIRW3pA26Q1BD72gUqkBpGwUzTqTxML2rmxv1XSVX+AKn9Pf6A9wq3rtsd4QJEDAkyw9vXkznnlJJoV1jP0OZl68nH31em6+srC49GZ5ZfXtiU1zw7HFU5maswQsSqGx5YSTeJYZBJVIPE3OD8v66Xc0VqT6mxtl2FEw0KIvOLhS+rnVVd2VKgsbtShq1ikLI7YXNT56wprva6xBo5BNUCVTHHdXg424l/JcoXZcgrXtiGWuU4BxgkscV+LcYgb8HAbY9lSDQtspJsuO6aZXerSfGv+0oxP1bkcBytqRSrxTgRvah7VSfKzWzl2/2SmEznKHmt981M8ldSktL6c9YZA7OfIEuBF+V8qHYIA7n08l/oT+FoNHfu6XDA241OwUMZiBgh9jf9sg3i3Zc0ahb42eVXyut+HRp8lJLYw+hPWv9er+wTThObJG1sk2iUiD7JPP5Ji0CCdDckEuyVXwK7gO/gR/b6wzwbTnHbmH4N9/ZVivHQ==</latexit>z0m
<latexit sha1_base64="O7NQF5PRKNqjJUlhRpMqc7MMXTM=">AAACPnicfVBNTxsxEPVCPyCU8tEjF4uAqCq0skPapDcEPXBBpVIDSNkomnUmiYXXu7K9FWGVv8AVfk7/Rv8At4orR7whSG1VeJKlpzdvxjMvzpS0jrFfwczsi5evXs/NVxbeLL5dWl5ZPbZpbgS2RKpScxqDRSU1tpx0Ck8zg5DECk/is/2yfvIDjZWp/u5GGXYSGGjZlwJcKV1sdXl3ucrCRo3zZp2ykLMd3vjsCWt+rLEG5SGboEqmOOquBBtRLxV5gtoJBda2OctcpwDjpFA4rkS5xQzEGQyw7amGBG2nmCw7ppte6dF+avzTjk7UPzsKSKwdJbF3JuCG9t9aKf6v1s5dv9kppM5yh1o8fNTPFXUpLS+nPWlQODXyBISRflcqhmBAOJ9PJfqC/haDh37u1wwNuNR8KCIwgwTOx/62QbRdsueMUj8aPav4XB/Do0+T41rIP4X1b/Xq7t404TmyRtbJe8JJg+ySA3JEWkSQIbkkV+Q6+BncBL+D2wfrTDDteUf+QnB3D/blruE=</latexit>z01
<latexit sha1_base64="L5Vl11zRP3oJrUNfhcgBJUpG4hc=">AAACRnicfVBdaxNBFL2bVq3xq62PvgyNgogsMzE28a2oUF+kFUxbyIZwd3KTDp2dXWZmi2HJ3/DV/pz+Bf+Eb6WvnU1TqKIeGDice+6de09aaOU85z+jxsrqnbv31u43Hzx89PjJ+sbmgctLK6kvc53boxQdaWWo75XXdFRYwizVdJiefKjrh6dkncrNVz8raJjh1KiJkuiDlCQZ+mOJmu2OxGi9xeNuW4heh/FY8Dei+y4Q3nvb5l0mYr5AC5bYH21Ez5NxLsuMjJcanRsIXvhhhdYrqWneTEpHBcoTnNIgUIMZuWG1WHrOXgRlzCa5Dc94tlBvd1SYOTfL0uCsl3R/1mrxb7VB6Se9YaVMUXoy8vqjSamZz1mdABsrS9LrWSAorQq7MnmMFqUPOTWTjxRusfQ5zN0ryKLP7asqQTvN8Ns83DZNXtfsf0ZlboyBNUOuN+Gxf5ODdiy2486XTmvn/TLhNXgGW/ASBHRhBz7BPvRBQgHf4QecRefRr+giury2NqJlz1P4DQ24ArVEsS4=</latexit>G1
<latexit sha1_base64="6CFy4sEr48HlSd8MTpBCL2k1yXc=">AAACRnicfVBdaxNBFL2bVq3xq62PvgyNgogsszE28a2oUF+kFUxbyIZwd3KTDp2ZXWZmi2HJ3/DV/pz+Bf+Eb6WvnU1TqKIeGDice+6de09WKOk85z+jxsrqnbv31u43Hzx89PjJ+sbmgctLK6gvcpXbowwdKWmo76VXdFRYQp0pOsxOPtT1w1OyTubmq58VNNQ4NXIiBfogpalGfyxQsd2RHq23eNxtJ0mvw3ic8DdJ910gvPe2zbssifkCLVhif7QRPU/HuSg1GS8UOjdIeOGHFVovhaJ5My0dFShOcEqDQA1qcsNqsfScvQjKmE1yG57xbKHe7qhQOzfTWXDWS7o/a7X4t9qg9JPesJKmKD0Zcf3RpFTM56xOgI2lJeHVLBAUVoZdmThGi8KHnJrpRwq3WPoc5u4VZNHn9lWVop1q/DYPt03T1zX7n1GaG2NgzZDrTXjs3+SgHSfbcedLp7XzfpnwGjyDLXgJCXRhBz7BPvRBQAHf4QecRefRr+giury2NqJlz1P4DQ24AiO3sWo=</latexit>Gm
<latexit sha1_base64="rODIjbgl+1AbQU4DQzfN+yZaqbc=">AAACQHicfVBNTxsxEPVS2tL0C8qRi9W0UlVVK28aSLghwYEeUEFqAlI2QrPOJLh47ZU9i4hW+Q9c6c/pv+g/4Ia49oQTgtRWbZ9k6enNm/HMywqtPAnxI1p4sPjw0eOlJ7Wnz56/eLm88qrrbekkdqTV1h1l4FErgx1SpPGocAh5pvEwO92e1g/P0HllzRcaF9jPYWTUUEmgIHXTs4Elf7xcF3GrkSTtJhdxIj4mrc1ARHu9IVo8icUMdTbH/vFK9CYdWFnmaEhq8L6XiIL6FThSUuOklpYeC5CnMMJeoAZy9P1qtu6Evw3KgA+tC88Qn6m/dlSQez/Os+DMgU78n7Wp+Ldar6Rhu18pU5SERt59NCw1J8unt/OBcihJjwMB6VTYlcsTcCApJFRLdzDc4nAvzP1coAOy7n2VghvlcD4Jt43SD1P2P6My98bAaiHX+/D4v0m3EScbcfOgWd/6NE94ia2x1+wdS1iLbbFdts86TLKv7IJdsm/R9+gquo5u7qwL0bxnlf2G6Octxh2wVw==</latexit>...<latexit sha1_base64="rtd53eRvdjXL7aJ/XJ2AToV2vfk=">AAACR3icfVBNbxMxEPWGAm34auHIxWpAQgit7BCacKugBy6IVmraouwqmnUmiVWvd2vPAtEqv4Mr/Tn9CfwKbogjTppKgIAnWXp682Y887LSaE9CfI0a19au37i5vtG8dfvO3XubW/ePfFE5hX1VmMKdZODRaIt90mTwpHQIeWbwODt9vagff0DndWEPaVZimsPE6rFWQEFKk496hFOg+v18KIebLRF321L2OlzEUjyX3ZeBiN6LtuhyGYslWmyF/eFW9CgZFarK0ZIy4P1AipLSGhxpZXDeTCqPJahTmOAgUAs5+rRebj3nj4My4uPChWeJL9VfO2rIvZ/lWXDmQFP/Z20h/q02qGjcS2tty4rQqsuPxpXhVPBFBHykHSoys0BAOR125WoKDhSFoJrJHoZbHL4Nc9+V6IAK97ROwE1y+DQPt02SZwv2P6O2V8bAmiHXq/D4v8lRO5Y7ceeg09p9tUp4nT1k2+wJk6zLdtkbts/6TLEz9pl9YefRRfQt+h79uLQ2olXPA/YbGtFPpeOyLg==</latexit>bY1
<latexit sha1_base64="Uvry7M7d/1+yNOnfr0h+vfaieXU=">AAACR3icfVBNbxMxEPWGAm34auHIxWpAQgitvCE04VZBD1wQrdS0RdlVNOtMEqu2d2vPAtEqv4Mr/Tn9CfwKbogjTppKgIAnWXp682Y88/JSK09CfI0a19au37i5vtG8dfvO3XubW/ePfFE5iX1Z6MKd5OBRK4t9UqTxpHQIJtd4nJ++XtSPP6DzqrCHNCsxMzCxaqwkUJCy9KMa4RSofj8fmuFmS8TddpL0OlzEiXiedF8GInov2qLLk1gs0WIr7A+3okfpqJCVQUtSg/eDRJSU1eBISY3zZlp5LEGewgQHgVow6LN6ufWcPw7KiI8LF54lvlR/7ajBeD8zeXAaoKn/s7YQ/1YbVDTuZbWyZUVo5eVH40pzKvgiAj5SDiXpWSAgnQq7cjkFB5JCUM10D8MtDt+Gue9KdECFe1qn4CYGPs3DbZP02YL9z6jslTGwZsj1Kjz+b3LUjpOduHPQae2+WiW8zh6ybfaEJazLdtkbts/6TLIz9pl9YefRRfQt+h79uLQ2olXPA/YbGtFPFFayag==</latexit>bYm
<latexit sha1_base64="eow8BoOVgK6gRUw64Z0JIyLW5ro=">AAACPnicfZDNSsNAFIUn/ht/q0s3wSqISElE1GVRF27EClaFJpSb6W07dDIJMxOxhL6CW30cX8MXcCduXTqpEdSKFwY+zj0zc+8JE86Udt1na2x8YnJqembWnptfWFxaLq1cqTiVFOs05rG8CUEhZwLrmmmON4lEiEKO12HvOO9f36JULBaXup9gEEFHsDajoHPJrynWXC67FXdYzih4BZRJUbVmydrwWzFNIxSaclCq4bmJDjKQmlGOA9tPFSZAe9DBhkEBEaogGw47cDaN0nLasTRHaGeofr+RQaRUPwqNMwLdVb97ufhXr5Hq9mGQMZGkGgX9/KidckfHTr6502ISqeZ9A0AlM7M6tAsSqDb52P4Jml0knpl3zxOUoGO5nfkgOxHcDcxuHX8np/+MTHwZDdkmV+93iqNwtVvx9it7F3vl6lGR8AxZI+tki3jkgFTJKamROqGkS+7JA3m0nqwX69V6+7SOWcWdVfKjrPcPIkCu9g==</latexit> <latexit sha1_base64="rODIjbgl+1AbQU4DQzfN+yZaqbc=">AAACQHicfVBNTxsxEPVS2tL0C8qRi9W0UlVVK28aSLghwYEeUEFqAlI2QrPOJLh47ZU9i4hW+Q9c6c/pv+g/4Ia49oQTgtRWbZ9k6enNm/HMywqtPAnxI1p4sPjw0eOlJ7Wnz56/eLm88qrrbekkdqTV1h1l4FErgx1SpPGocAh5pvEwO92e1g/P0HllzRcaF9jPYWTUUEmgIHXTs4Elf7xcF3GrkSTtJhdxIj4mrc1ARHu9IVo8icUMdTbH/vFK9CYdWFnmaEhq8L6XiIL6FThSUuOklpYeC5CnMMJeoAZy9P1qtu6Evw3KgA+tC88Qn6m/dlSQez/Os+DMgU78n7Wp+Ldar6Rhu18pU5SERt59NCw1J8unt/OBcihJjwMB6VTYlcsTcCApJFRLdzDc4nAvzP1coAOy7n2VghvlcD4Jt43SD1P2P6My98bAaiHX+/D4v0m3EScbcfOgWd/6NE94ia2x1+wdS1iLbbFdts86TLKv7IJdsm/R9+gquo5u7qwL0bxnlf2G6Octxh2wVw==</latexit>...
<latexit sha1_base64="H/zPQBHbEU+inRtdEtB/PMWdxBg=">AAACRnicfZDPSiNBEMZr4u6q2XX9s0cvzWYFEQkzEtSjuAt6ERWMETIh1HQqSZOenqG7RwxDXmOv+ji+gi/hTbzaEyOoEQsafnz1dXfVF6VSGOv7d15p5svXb7Nz8+XvPxZ+Li4tr5ybJNOc6jyRib6I0JAUiupWWEkXqSaMI0mNaPC36DcuSRuRqDM7TKkVY0+JruBonRSGMdo+R8kO2n57qeJX/XGxaQgmUIFJnbSXvT9hJ+FZTMpyicY0Az+1rRy1FVzSqBxmhlLkA+xR06HCmEwrHw89YmtO6bBuot1Rlo3V1zdyjI0ZxpFzFkOa971C/KjXzGx3t5ULlWaWFH/+qJtJZhNWJMA6QhO3cugAuRZuVsb7qJFbl1M5/EduF01H7t3jlDTaRG/kIepejFcjt1sv3CzoM6NQL0ZHZZdr8D7FaTjfqgbb1dpprbK3P0l4DlbhN6xDADuwB4dwAnXgkMJ/uIYb79a79x68x2dryZvc+QVvqgRPPpyw6w==</latexit>G0<latexit sha1_base64="JjAfhP4R8Kdx4+VQdQPYW4DRyJM=">AAACR3icfZDLSsNAFIYn9V7vunQTrIKIlEREXYq6cCMqWC80oZxMT9vBySTOnKgl9Dnc6uP4CD6FO3HptFbwhgcGPv7zz8w5f5RKYcjznp3CwODQ8MjoWHF8YnJqemZ27swkmeZY4YlM9EUEBqVQWCFBEi9SjRBHEs+jq71u//wGtRGJOqV2imEMTSUaggNZKQxuRR1bQPllp+bVZkpe2euV+xv8PpRYv45rs85SUE94FqMiLsGYqu+lFOagSXCJnWKQGUyBX0ETqxYVxGjCvDd1x122St1tJNoeRW5P/Xojh9iYdhxZZwzUMj97XfGvXjWjxnaYC5VmhIp/fNTIpEuJ243ArQuNnGTbAnAt7Kwub4EGTjaoYrCPdheNh/bdoxQ1UKJX8wB0M4a7jt2tGax16T+jUJ9GS0Wbq/8zxd9wtl72N8sbJxulnd1+wqNsgS2yFeazLbbDDtgxqzDOrtk9e2CPzpPz4rw6bx/WgtO/M8++VcF5By87ses=</latexit>bY0<latexit sha1_base64="KqzGpleD13x0G7Vrlw5EMNlUH1U=">AAACRXicfVBNb9NAEF2Xr5JSaOmxlxUpEqoqyzZWEm4V9NALokikLYqjaryZJKusd63dMRBZ+Rm9ws/hN/AjekNcYZOmEkUtT1rp6c2b2ZmXl0o6iqIfwcqdu/fuP1h92Fh7tP74ycbm02NnKiuwK4wy9jQHh0pq7JIkhaelRShyhSf55M28fvIJrZNGf6Bpif0CRloOpQDyUi/7LAc4Bqo/zs42mlGYJmn8ssWjsJO0X7VST5J2q5MkPA6jBZpsiaOzzWAnGxhRFahJKHCuF0cl9WuwJIXCWSOrHJYgJjDCnqcaCnT9erHzjD/3yoAPjfVPE1+of3fUUDg3LXLvLIDG7t/aXLyp1qto2OnXUpcVoRaXHw0rxcnweQB8IC0KUlNPQFjpd+ViDBYE+Zga2QH6Wyy+9XPflWiBjN2tM7CjAr7M/G2jbG/O/meU+sroWcPnehUev50cJ2HcCtP3aXP/9TLhVbbNnrEXLGZtts8O2RHrMsEMO2df2bfge3AR/Ax+XVpXgmXPFruG4PcfZ8Kymg==</latexit>bY
Step 1Step 2Step 3deterministic transitionstochastic transition<latexit sha1_base64="espj5Jd4DP6QlfdMdutbPiataE4=">AAACPXicfVDLShxBFK32kZjJw9cym8IxECQ03Z1mZtyJunAjUXRUmB7kds2dtrCquqmqFodmPsFt8jl+hx/gTty6Tc04ghHNgYLDuefeuvekheDGBsGNNzU9M/vu/dyH2sdPn7/MLywuHZm81AzbLBe5PknBoOAK25ZbgSeFRpCpwOP0fGtUP75AbXiuDu2gwK6ETPE+Z2CddJDI8nShHvhxFIc/GzTwW1FzvRE7EjUbrSiioR+MUScT7J0ueqtJL2elRGWZAGM6YVDYbgXaciZwWEtKgwWwc8iw46gCiaZbjXcd0m9O6dF+rt1Tlo7V5x0VSGMGMnVOCfbMvKyNxNdqndL2W92Kq6K0qNjjR/1SUJvT0eG0xzUyKwaOANPc7UrZGWhg1sVTS7bR3aJx1839VaAGm+u1KgGdSbgcutuy5MeI/c/I1ZPRsZrL9Sk8+jY5ivyw4cf7cX1jc5LwHPlKVsh3EpIm2SA7ZI+0CSMZuSK/yR/v2rv17rz7R+uUN+lZJv/Ae/gLBquu9Q==</latexit>µ
Figure 1: (Left) MoE-LM Architecture. (Right) Sample utterance workﬂow generated by an MoE-
LM trained with Reddit data. Step 1: encodes conversation history. Step 2: 	Gi,8i, generate
candidate bot utterances. Step 3: selects the bot response by Q-score ranking & post-processing.
the one in OPAL [Ajay et al., 2020], i.e., an unsupervised learning method for discovering primitive
skills in trajectories that are used by some downstream RL tasks.
Step 2: Expert Construction. Given the latent space Z, encoder (;G0), and decoder 	
learned in Step 1, we now learn mlatent distributions fGigm
i=1, each deﬁned as Gi(z0jz) =
N 
i(z);2
i(z)Idd
. Intuitively, eachGicorresponds to an attribute, e.g., an intent or a personality
(in case of a chatbot) and generates samples in speciﬁc parts of the latent space Z. This results in
havingmLMs,fLMigm
i=1;LMi= (;Gi;	), each of them corresponds to a specialized version of
the original LM, LM0, and serves as an expert in our MoE-LM. Upon receiving a conversation history
X, each expert LMigenerates a candidate (or more) for the next utterance bYiin certain parts of the
language space that are compatible with its attribute (personality). As we will explain in Section 5,
eachGiis learned using a loss function that encourages its corresponding LM, LMi, to generate
utterances consistent with its attribute (see Eq. 2).
Step 3: Dialogue Manager (DM). Thedialogue manager , denoted by , takes as input the encoded
conversation history z= (X)and the candidate action utterances generated by the experts fbYigm
i=0,
and selects one of them as the action for the bot to execute, i.e., bY(jz;fbYigm
i=0). We will
describe how DM is trained using reinforcement learning (RL) in Section 6.
4 Primitive Discovery in MoE-LM
Motivated by literature in the reinforcement and imitation learning ﬁelds [Ajay et al., 2020], we
propose to learn the primitive LM, LM0, in our MoE-LM by solving the following KL-constrained
optimization problem that aims at capturing diverse semantics:
min
(;G0;	);bEz0(jz;Y);z=(X)
 log 	(Yjz0)
;s.t.bEz=(X)
KL 
(z0jz;Y)jjG0(z0jz)
KL;(1)
wherebEis the empirical expectation over (X;Y)in the datasetD,is a distribution over the latent
space conditioned on the encoded conversation history zand the target utterance Y, andKLis a posi-
tive real-valued threshold. Using (1), we learn LM0= (;G0;	)by maximizing the log-likelihood,
while enforcing consistency between the latent variable z0predicted byG0(jz)and(jz;Y)via
the KL constraint. The distribution (jz;Y)is a GaussianN 
(z;(Y));2
(z;(Y))Idd
in
which is a pre-trained encoder for the target utterance Y, and mean(;)and variance 2
(;)
are trainable models. One reason for using a separate encoder for the target utterance Yis to
avoid overﬁtting (i.e., to avoid having back-propagation gradient of withYas input).
Connection to V AE-like objectives In practice, we implement the KL constraint in (1)as a penalty
weighted by an appropriately chosen coefﬁcient. Thus, one may interpret the objective in (1)as a
variation of-V AE [Burgess et al., 2018]. Due to the connection to V AEs, one may draw similarities
4

--- PAGE 5 ---
between our method and existing dialogue approaches such as VHRED [Serban et al., 2017b] and
VHCR [Park et al., 2018]. However, we emphasize that there are key differences, and these may be
explained by ﬁrst understanding how the objective in (1)encourages diversity , which is key to good
primitive learning. Namely, it is important that primitive discovery learns an encoder-decoder ;	
which can be modulated by the choice of z; i.e., changing z0while ﬁxing Xshould lead to different
distributions over generated utterances. The objective in (1)encourages this diversity by conditioning
the latent variable z0on both the target utterance Yandz= (X), i.e.,z0(jz;Y). In contrast,
the KL constraint is used to make sure that the stochastic encoder G0(jz)of our primitive LM is not
too varied for different Y, and thus has a limiting effect on diversity. For example, in the extreme
whenKL= 0(or,!1 when used as a regularizer) there will be no specialization of the latent
space for different Y. Although!1 is an extreme case, degenerate behavior can also happen
when= 1, i.e., in the traditional variational loss used by VHRED and VHCR. Speciﬁcally, it is
well-known that the traditional V AE loss is an upper bound on the negative log-likelihood of the data
under a stochastic encoder-decoder parameterization. Thus if the data can be modeled by a single
LM then a V AE-optimal decoder 	can simply ignore G0, leading to a degenerated latent space as
observed in previous work [Park et al., 2018]. This is precisely the reason that, in our approach, we
weaken the KL constraint ( KL0or, equivalently, 1). This enables our approach to more
reliably guarantee that a unique z0represents each distinct conversation pair (X;Y), thus capturing
diverse semantic modalities and enabling easier downstream specialization.
In the mathematical results below, we formalize the claim above, namely, that the log-likelihood
objective in (1)leads to a learned ;	that can easily recover any arbitrary desired LM by specializing
the latent spaceG. We begin with a deﬁnition that characterizes the coverage of an arbitrary LM on
the conditional conversation data distribution PD(YjX).
Deﬁnition 1. LMD;is a-common LM of data DifED[TV(LMD;(YjX)jjPD(YjX)))]:
Leveraging Theorem 4.1 in Ajay et al. [2020], we now present the theoretical result characterizing
the representational power of our primitive encoder-decoder pair (;	)on dataD.
Lemma 1. Let(;;	)be the solution to (1) with bEz0(jz;Y);z=(X)[ log 	(Yjz0)] =. Then
there exists LM:= (;G;	)such that ED[TV(LMD;(YjX)jjLM(YjX))]+q
1
2(+H);where
G(z0jz) =EYD[(z0jz;Y)], andH=ED[logPD(YjX)]is a constant depending on D.
The result above shows that, as long as LMD;is-common inD, then there exists a specialization of
the latent spaceGthat, when paired with ;	, can approximately recover LMD;. The quality of the
approximation is a function of — how well the objective in (1)was optimized — and . In practice,
to construct the primitive by replacing GwithG0, i.e., LM0= (;G0;	), becauseG0(z0jz)can be
viewed as an distillation of (z0jz;Y). This theoretical result also motivates the next section, where
we explain our algorithm’s “Step 2: Expert Construction”. Speciﬁcally, we show how to use the
trained encoder-decoder pair ;	to learn a spectrum of different specialized experts parameterized
by different latent distributions Gi.
5 Expert Construction with Plug-and-play Language Models
To complete the MoE framework one needs to systematically create a gamut of different experts
LMi,8i2f1;:::;mg, with each generating candidate utterances of different intents. By viewing
each expert as a distribution of particular behaviors in conversation data D, we leverage the results
of Section 4 and Lemma 1 and adopt a universal encoder-decoder (;	)among all the experts.
Therefore, each expert iis only parameterized by an arbitrary d-dimensional latent distribution
(e.g., Gaussian), and it samples certain regions of the latent space Z. Following the terminology
from Dathathri et al. [2019], these experts can all be catagorized as plug-and-play language models
(PPLMs) . Creating experts is handy because it only requires learning new latent distributions, while
switching between experts amounts to sampling a different distribution.
Denote by`i(X;Y)2Ra real-valued label that characterizes the intent of expert i2f1;:::;mg,
e.g., determined by an off-the-shelf sentiment classiﬁer. We train the latent distribution Gi(z)of
expertiby solving the optimization problem
min
GibEz0Gi(jz);z=(X);Y	(jz0)[ `i(X;Y)]: (2)
Unlike the weighted maximum likelihood approach considered in Dathathri et al. [2019], which
assigns weight `ito training samples that correspond to expert i, we propose to learn each expert via
5

--- PAGE 6 ---
reward-maximization and treat`ias a reward signal w.r.t. expert ito be maximized. Interestingly,
this approach is also linked to reinforcement learning (RL), in which both the “state” and “action”
spaces are the latent space Z, and the “policy” is the latent distribution Gi. The main beneﬁt of our
approach is that it does not require the target utterance Yfrom dataDand is thus less vulnerable to
data-imbalance issues in Don certain intents. Notice from (2)that the reward-maximization problem
is myopic, i.e., the above RL problem has a discounting factor of 0. The main motivation is that,
unlike dialogue management that is a sequential decision-making problem, here we want each expert
to possess particular behaviors, and this can readily be done via greedy maximization; Long-term
dialogue optimization will be handled by the dialogue manager rather than these experts.
For example in the case of a Gaussian Gi, we use the standard REINFORCE [Sutton et al., 1999]
algorithm to learn the model parameters (i;2
i)ofGiaccording to
fi;ig fi;ig+Ez0Gi(jz);Y	(jz0)[`i(X;Y)rfi;iglogPGi(z0jz)]; i2f1;:::;mg;
where>0is the learning rate. To reduce the variance of these estimates, we also adopt the baseline
reduction technique [Greensmith et al., 2004] in policy gradient. This can be simply done by replacing
`i(X;Y)with`i(X;Y) :=`i(X;Y) EY	(j(X))[`i(X;Y)]. To quantify the performance of
expert LMi, following arguments from Lemma 1 and Lemma 4.0.1 in Ajay et al. [2020], we have the
sub-optimality result.
Corollary 1. Denote the i-th reward-maximizing objective as Li(LM) :=bEYLM(jX)[`i(X;Y)].
Suppose an optimal LM for this objective LMi;2arg max LMLi(LM)is-common inD. Moreover,
letG?
ibe in the arg min of(2). Then with expert LMi= (;G?
i;	)and (,H) from Lemma 1, we
havejLi(LMi) Li(LMi;)j2k`ik1(+q
1
2(+H)).
While it may be obvious that optimizing Giw.r.t. (2) encourages expert LMito capture the behaviors
encouraged by `i, this corollary has two further implications: (i) Since the sub-optimality of LMi
compared to the oracle LMi;is bounded by the quantity deﬁned in Lemma 1, it justiﬁes using the
primitive (	;), which optimizes , for expert construction; (ii) Sub-optimality further depends on ,
quantifying how well LMi;is represented in the original dataset D.
6 Reinforcement Learning for MoE-LM Dialogue Manager
We now describe the dialogue manager (DM) of our MoE-LM and propose RL algorithms to train it.
As mentioned in Section 3, the DM is a policy that takes the encoded conversation history z= (X)
and them+ 1candidate action utterances generated by the experts fbYigm
i=0,4and stochastically
selects one of them to execute, i.e., bY(jz;fbYigm
i=0). Note that each expert i2f0;:::;mgis
a LM, LMi, that acts as a policy i(jX)and maps each conversation history Xto an utterance bYi.
With this architecture we address the large size of state and action spaces in the original MDP that
grows exponentially with the size of the vocabulary. As described in Section 2, the state and action
spaces of the original MDP are the tokenized conversation history and the tokenized language space,
respectively, while here the DM should choose among m+ 1actions given the latent space Zof
encoded conversations. It is important to note that our MoE-LM is different than other hierarchical
architectures [D et al., 2016] in which the decision at the high-level is to choose a low-level controller
only based on the current state of the system. In MoE-LM, the DM observes both the current state
and the actions suggested by the experts and then chooses one among them.
We learn the DM policy by solving an MDP, which we refer to as MoE-MDP, and denote it by
M= (S;A;P;R;s0;). The state space of MoE-MDP is the product of the learned latent space Z
and the joint action space of the m+ 1experts, i.e., S=ZAm+1. Its action space consists of
them+ 1experts, i.e., A=f0;:::;mg. Its initial state is the encoding of the initial user’s query
and the utterances suggested by the experts in response to this query. The transition still models
user’s responses but is now over the joint space of the latent states and experts’ actions. The reward
function is the same as in the original MDP, i.e., r(s;a) =r(X;aj), where s= (z;faigm
i=0)with
aii(jX)andz= (X), and a2f0;:::;mgis the expert selected by the DM. Since MoE-MDP
has ﬁnite number of actions, learning DM is equivalent to solving a ﬁnite-action MDP and ﬁnding a
policyin them-dimensional simplex with maximum expected cumulative discounted reward.
4For simplicity, we assume that each expert generates only a single candidate utterance at each step. It would
be straightforward to extend this to multiple (and even a varying number of) candidate utterances.
6

--- PAGE 7 ---
We use two RL algorithms to solve the MoE-MDP and learn the DM policy . The ﬁrst one
isconservative Q-learning (CQL) [Kumar et al., 2020], a popular ofﬂine RL algorithm. This
is suitable for our setting in which the policy must be learned from the collected conversations
Dwith no further (online) interaction with the real system. CQL is a regularization scheme
that learns a conservative Q-function that lower-bounds the true one. Given the ofﬂine conver-
sation dataD, we parameterize the Q-function by parameter and learnby minimizing the
Bellman error with behavior regularization: minP
(s;a;r;s+)2D(Ea[Q(s;a)] Q(s;a0)) +
(r+Qtarget(s+;arg maxa+2AQ(s+;a+)) Q(s;a))2, wherea0is action suggested by the primi-
tive LM (which approximates the behavior policy of D)a00,>0is a regularization parameter,
andtargetis the target Q-function parameter. Intuitively, CQL regularization minimizes the differ-
ences inQ-values of our DM and the primitive. According to the CQL algorithm, we can set the
DM as(ajs)/exp(Q(s;a)), which corresponds to the optimal policy of the entropy-regularized
Q-learning [Schulman et al., 2017].
The second RL algorithm we use is model-based RL (MBRL) [Shah et al., 2018, Wei et al., 2018].
Here we ﬁrst learn a user utterance model Puser(X+jX;a) :=Ez= user([X;a])[	user(X+jz)]via maxi-
mum likelihood, then generate data DMB, whose next-state bs+encodes the next conversation generated
from roll-outs and the corresponding candidate actions, and ﬁnally solve the Bellman error minimiza-
tion in MoE-MDP: minP
(s;a;r;bs+)2D MB(r+Qtarget(bs+;arg max a+2JQ(bs+;a+)) Q(s;a))2.
The beneﬁt of MBRL over CQL is two-fold. First, one can easily obtain a high-ﬁdelity user utterance
model [Peng et al., 2020] by simply ﬁne-tuning a large LM (e.g., GPT-3 [Floridi and Chiriatti, 2020]).
Second, with sufﬁcient dialogue roll-outs that captures many different scenarios, MBRL does not
require behavior regularization and can be less conservative.
7 Experiments
We evaluate our MoE-approach for dialogue management on two benchmark open-domain tasks.
The ﬁrst one is Cornell [Danescu-Niculescu-Mizil and Lee, 2011], which consists of conversations
between speakers in different movie lines and has a median conversation length of 3utterances, the
second is the Reddit [Ghandeharioun et al., 2019], which is a casual conversation corpus on various
topics between users of at least 3turns with the median conversation containing 7utterances.
We conduct several experiments to test the efﬁcacy of different parts in the MoE-LM, namely (i)
the predictive power and diversity of the primitive, (ii) the quality of experts, and (iii) the overall
DM performance. For each metric, we report the mean standard deviation over a evaluation set of
100conversations. We also ran an ablation study on 4transformer-based MoE-LMs, namely MoE-1,
MoE-2, MoE-3- MoE-4, to understand how performance is affected by different model architectures,
language encoders, and latent generators. MoE-1 and MoE-2 use a simpler architecture, while MoE-3
and MoE-4 use the same encoder architecture as BERT [Devlin et al., 2018]. MoE-1 uses much
smaller latent distribution models fGigthan MoE-2; MoE-3 uses the pre-trained BERT encoder,
while MoE-4 trains that from scratch. Details of these models can be found in Appendix ??.
EXP 1: Comparing Primitive Models We compare the quality of latent representations learned
by the 4MoE-LMs (via optimizing Eq. 1) and 2baselines (standard Transformer [Wolf et al.,
2019] and VHRED [Serban et al., 2017b]). To assess their quality, for each test conversation we
generated 25utterances and reported the following 3metrics: (i) Diversity : The 1 Sparsity [Hurley
and Rickard, 2009] of the singular values of the embedded utterances, i.e., Diversity (f^Yig) :=
1 p
d kSVDk1=kSVDk2=p
d 12[0;1], where SVD :=SVD(fSE(^Yig25
i=1), and SEis a
pre-trained sentence encoder (e.g., a USE [Cer et al., 2018]); (ii) Dist-f1;2;3g[Li et al., 2015]:
Ratio of uniquef1;2;3g-gram in the generated utterances; (iii) Perplexity [Bahl et al., 1983]. These
metrics measure both accuracy and semantic diversity.
The results of the above experiments are reported in Table 1 and 10 (Appendix B.1), and sample
utterances generated by these LMs can be found in Appendix B.2. In comparisons with the baselines
(Transformer and VHRED), generally (i) transformer-based LMs out-perform VHRED due to their
attention mechanism that explicitly encodes sequential semantic information, and (ii) the MoE-LMs
achieve way better diversity without sacriﬁcing much on accuracy (i.e., the perplexity scores are still
quite low). Qualitatively, the sample utterances generated the Transformer are closer to the targets
than that by MoE-2 and MoE-4, likely because Transformer tends to memorize the corpus [Kharitonov
et al., 2021]. Contrarily, MoE-LMs generate utterances that have similar contexts with targets but
paraphrased or similar structures but different contexts, demonstrating their generalizability.
7

--- PAGE 8 ---
Method Diversity Dist-1 Dist-2 Dist-3 Perplexity
MoE-1 0.0780.04 0.29 0.68 0.79 28.6841.32
MoE-2 0.150.02 0.33 0.81 0.92 42.1435.24
MoE-3 0.0930.02 0.31 0.77 0.90 44.2757.73
MoE-4 0.170.01 0.41 0.89 0.94 52.1218.20
Trans. 0.0910.02 0.28 0.71 0.83 20.7710.22
VHRED 0.110.02 0.37 0.68 0.80 88.6123.55
Table 1: Accuracy (Perplexity) and Diversity of
Language Primitive Experts Trained with Reddit.Method User Tot. Sent. User Sent. Trans. GPT-Perplexity
MoE-4 Primitive -0.050.07 0.050.09 81.1743.41
MoE-4 DQN 0.040.10 0.020.16 79.4345.70
MoE-4 CQL 0.090.16 0.080.17 75.4847.13
MoE-4 MBRL 0.120.15 0.100.13 82.7542.72
Trans. RL -0.260.12 -0.110.14 168.8075.35
Trans. KLC 0.030.09 -0.030.05 108.7368.21
Trans. VHRL 0.050.11 0.010.11 135.4755.78
Table 2: Performance (w.r.t. Avg. User Satisfaction in
Conversation) of RL-based DM Trained with Reddit.
(a)Transformer Primitive, TSNE
 (b)MoE-4 Primitive, TSNE
 (c)MoE-4 Sentiment, PCA
 (d)MoE-4 Emotion, PCA
Figure 2: Latent space visualizations. Figures (a) and (b) compares two primitive representations. Figures (c)
and (d) illustrates how experts (deﬁned by different sentiments and emotions) are represented by latent clusters.
Among different MoE-LMs, MoE-2 and MoE-4 have the best performances, particularly MoE-4 has
better diversity while MoE-2 has lower perplexity. This corroborates with our hypotheses that (i)
jointly training the encoder and decoder with Eq. 1 seems necessary to encourage semantic diversity
(as opposed to using a pre-trained BERT encoder, which maximizes likelihood), (ii) sufﬁcient
representation power is necessary for G0to match the posterior distribution in order to capture
different semantics in D. In Fig. 2a and 2b, we visualize the latent space of 200conversation data
samples for both Transformer and MoE-4. The latent states of MoE-4 are much more dispersed
across the embedding space, implying that most conversations get encoded uniquely. In contrast,
the latent space of Transformer has many clusters, suggesting it is more prone to generating similar
utterances even with different input conversation and is thus less generalizable.
EXP 2: Quality of Experts We compare the performance of experts learned by the 4MoE-LMs
(where experts are separately trained by optimizing Eq. 2) and 2baselines (WD [Holtzman et al.,
2018] and PPLM [Dathathri et al., 2019]). To study the sub-optimality gap in Corollary 1, we also
include the performance of Transformer-based expert end-to-end LMs that are individually optimized
with REINFORCE [Li et al., 2016], using the expert labels f`igas rewards. We use the following label
functions to deﬁne the intents of experts: (i) `pos-sent (Y),`neg-sent (Y),`joy(Y),`optimism (Y),`anger(Y),
`sadness (Y)quantify 6different sentiment tones and are constructed by a RoBERTa-based sentiment
detector [Liao et al., 2021] that predicts whether an utterance is of positive or negative sentiment,
and whether it falls into any of the 4more-reﬁned emotions: {joy, optimisim, sadness, anger}; (ii)
`sent-coh (X;Y)measures empathy , i.e., bot’s sentiment coherence with user’s; (iii) `question (Y)outputs
1when a bot question is detected and 0otherwise; (iv) `exp(X;Y)quantiﬁes exploration , i.e., the
tendency to avoid repetitive contexts. See Appendix A.7 for details.
The results of the above experiments are reported in Table 3 and 12 (Appendix B.1), with sample
utterances reported in Appendix B.3 to B.9. Compared with the baseline LMs, generally the experts
created under the MoE-LM framework, especially under MoE-2 and MoE-4, better capture all
different language intents (where WD and PPL appear to capture negative sentiments and emotions
much more effectively than behaviors), demonstrating the efﬁcacy of our approach which constructs
specialized experts on a diverse language space via reward maximization (instead of weighted MLE).
Similar to the ablation study in EXP 1, all the experts associated with MoE-2 and MoE-4 are also
among the best ones in capturing language intents. Interestingly, with the Reddit data the experts
in MoE-4 perform the best, while with much less data (Cornell) the best experts are built upon the
simpler MoE-2 architecture. We conjecture this difference is due to over-ﬁtting issues faced by the
larger LMs (MoE-4) when there is insufﬁcient data for expert ﬁne-tuning. In Fig. 2c and 2d we
visualize the latent space of the sentiment-based experts in MoE-4, each with 200conversation data
samples. Notice that the sentiment experts’ latent distributions are clearly separated (because positive
and negative sentiments have opposite behaviors), while the emotion expert’s latent distribution have
more gradual separations and even some overlaps (because e.g., joy versus optimism are quite similar,
while joy versus anger are quite different). This validates our MoE-LM represents different behaviors
8

--- PAGE 9 ---
Method Question Exploration Positive Sent. Negative Sent. Sent. Coherence Joy Optimism Anger Sadness
MoE-1 0.750.14 0.490.12 1.020.35 0.400.33 0.510.48 1.120.32 -0.190.55 0.470.56 1.010.67
MoE-2 0.960.18 0.580.20 3.410.56 2.080.71 0.550.44 2.020.65 1.270.41 1.320.69 2.090.99
MoE-3 0.430.27 0.500.33 1.030.32 1.050.29 0.620.41 1.170.42 0.420.51 0.280.32 1.150.27
MoE-4 0.910.25 0.530.40 3.340.77 2.120.64 0.500.36 2.281.59 1.590.99 2.011.32 2.270.45
WD 0.00.0 0.160.29 -0.961.86 1.362.02 0.690.23 -0.840.40 -1.771.36 0.920.35 1.991.5
PPLM 0.210.34 0.560.32 0.460.21 0.550.09 0.640.27 0.390.15 0.410.48 0.690.22 1.000.21
Trans. RL* 0.990.23 0.540.18 3.531.64 1.891.20 0.720.30 2.882.36 1.802.39 1.622.39 2.351.47
Table 3: Quality of each expert PPLM trained on Reddit dataset w.r.t. its trained label.
in separate regions of the latent space and justiﬁes our structural prior of modeling each expert as a
specialized version of the primitive LM, whose latent distribution focuses on particular regions.
EXP 3: MoE-RL Against DialoGPT Simulated Users We compare the dialogue management
performance of MoE-LM, for which their DMs are trained with different methods (BC, DQN,
CQL, MBRL), with 3baselines (REINFORCE [Li et al., 2016], KL-control [Jaques et al., 2019],
and VHRL [Saleh et al., 2020]). According to the results on expert quality in EXP2, we pick
the MoE-2 and MoE-4 frameworks for the Cornell and Reddit tasks respectively. For systematic
evaluation, we perform the experiment by having these RL agents interact with a DialoGPT [Zhang
et al., 2019] simulated user environment (a large LM capable of conducting natural open-domain
conversations), for a maximum of 5turns. The DM task is to maximize total user satisfaction
in the conversation level, which is measured by both (i) user’s overall sentiment, and (ii) user’s
sentiment transition. To construct an immediate reward that serves as a surrogate for user satisfaction,
we setr(X;a;X +) =1`sent(X+) +2(`sent(X+) 1 
1 LPL 1
l=0l`sent(Xl)), where the linear
combination weights (1;2) = (0:75;0:25)correlate with Ghandeharioun et al. [2019], and `sent(X)
is the same RoBerTa-based sentiment labeler as in EXP2, which assigns a score from [ 1;1]that is
proportional to the positive sentiment and inversely proportional to the negative sentiment prediction
probabilities. To ensure the baseline RL DM methods can also possess certain bot-level features, e.g.,
question, positive sentiment, etc., besides the above RL reward for user satisfaction we also optimize
a linear combination of bot-based rewards when training the baseline models, see Appendix B of
Saleh et al. [2020] for more details. Since the DM problem lasts at most 5turns, we use this as the
effective horizon and set = 1 1=5 = 0:8. To evaluate the ﬂuency of our LMs, we also report the
GPT-perplexity, which compute the perplexity score of the ﬁnal utterance w.r.t. a DialoGPT LM.
The results of the above experiments are reported in Table 2 and 11 (Appendix B.1), with sample
utterances reported in Appendix B.10. Our experiments show that MoE-LMs outperform most
baseline methods on DM performance. We attribute this ﬁnding to two factors: (i) MoE-MDP
restricts the action space into a smaller set of candidate utterances generated by experts (whose
qualities are validated in EXP2), the corresponding RL problem then becomes simpler and requires
less data (especially in Cornell) to solve. (ii) Unlike the baseline RL methods, which need to optimize
both bot-and-user signals, the MoE DM agents focus on optimizing the user satisfaction goal and are
therefore more effective. Interestingly, our MoE-LMs also have lower (better) GPT-perplexity scores
than other methods. This may be due to the fact that MoE-LM uses pre-trained encoder and decoder
from the primitive LM, which are optimized for generalization and accuracy, while other RL methods
may distort their language representations to create utterances that maximize reward but become less
natural. Among different MoE-RL strategies, MBRL, which ﬁrst learns a user utterance model (the
model uses the same encoder from the primitive LM and learns a separate decoder for user-utterance
prediction) and does Q-learning, performs the best. CQL moderately improves upon the primitive
LM (behavior policy), while DQN appears to be less effective in solving the ofﬂine RL problem.
8 Concluding Remarks
We developed a mixture-of-expert (MoE) approach for RL-based dialogue management (DM). Our
MoE language model (MoE-LM) comprises of three main components: (i) a LM that can generate
diverse semantics for conversation histories, (ii) a number of specialized LMs (or experts) that
can produce utterances corresponding to a particular attribute or intent, and (iii) a RL-based DM
that performs dialogue planning with the utterances generated by the experts. To understand how
well our MoE approach generates diverse and sensible utterances, and solves DM problems, we
evaluated it using two open-domain dialogue tasks and compared it with SOTA baselines. Our
results showed that MoE-LM (i) improves diversity of text generation, (ii) can generate utterances
with speciﬁc intents, and (iii) yields better overall performance. We consider our work as a step
9

--- PAGE 10 ---
forward in creating steerable LMs that possess different intents and in training RL-based DMs that
can carry on rich conversations. Future work includes improving the language representation with
information-theoretic approaches, ﬁne-tuning the experts based on the DM objective, extending the
RL agent to track users’ behaviors (via abstract belief states) and plan upon them, and evaluating our
MoE-LM on more realistic problems, such as information retrieval, recommendation, and negotiation.
10

--- PAGE 11 ---
Checklist
1. For all authors...
(a)Do the main claims made in the abstract and introduction accurately reﬂect the paper’s
contributions and scope? [Yes]
(b) Did you describe the limitations of your work? [Yes] See the summary (Section 8).
(c)Did you discuss any potential negative societal impacts of your work? [N/A] In this
work we proposed an abstract approach of designing dialogue managers, it is unrelated
to any negative impact applications.
(d)Have you read the ethics review guidelines and ensured that your paper conforms to
them? [Yes]
2. If you are including theoretical results...
(a)Did you state the full set of assumptions of all theoretical results? [Yes] For each result,
Section 4 and Section 5 either state the assumptions directly or refers to corresponding
references.
(b)Did you include complete proofs of all theoretical results? [N/A] All theoretical are
cited with corresponding references.
3. If you ran experiments...
(a)Did you include the code, data, and instructions needed to reproduce the main experi-
mental results (either in the supplemental material or as a URL)? [No] Unfortunately,
due to IP concerns our legal team does not allow code releases at this point.
(b)Did you specify all the training details (e.g., data splits, hyperparameters, how they
were chosen)? [Yes] General details in the beginning of Section 7, and speciﬁc details
per experiment in Appendix A.
(c)Did you report error bars (e.g., with respect to the random seed after running exper-
iments multiple times)? [Yes] In Talbes 10,1,12, 3, 11, 2, , we provide not only the
mean result but also the standard deviation.
(d)Did you include the total amount of compute and the type of resources used (e.g., type
of GPUs, internal cluster, or cloud provider)? [Yes] In the beginning of Appendix A.
4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...
(a) If your work uses existing assets, did you cite the creators? [N/A]
(b) Did you mention the license of the assets? [N/A]
(c)Did you include any new assets either in the supplemental material or as a URL? [N/A]
(d)Did you discuss whether and how consent was obtained from people whose data you’re
using/curating? [N/A]
(e)Did you discuss whether the data you are using/curating contains personally identiﬁable
information or offensive content? [N/A]
5. If you used crowdsourcing or conducted research with human subjects...
(a)Did you include the full text of instructions given to participants and screenshots, if
applicable? [N/A]
(b)Did you describe any potential participant risks, with links to Institutional Review
Board (IRB) approvals, if applicable? [N/A]
(c)Did you include the estimated hourly wage paid to participants and the total amount
spent on participant compensation? [N/A]
11

--- PAGE 12 ---
References
A. Ajay, A. Kumar, P. Agrawal, S. Levine, and O. Nachum. Opal: Ofﬂine primitive discovery for
accelerating ofﬂine reinforcement learning. arXiv preprint arXiv:2010.13611 , 2020.
K. Asadi and J. Williams. Sample-efﬁcient deep reinforcement learning for dialog control. arXiv
preprint arXiv:1612.06000 , 2016.
L. Bahl, F. Jelinek, and R. Mercer. A maximum likelihood approach to continuous speech recognition.
IEEE transactions on pattern analysis and machine intelligence , (2):179–190, 1983.
C. Burgess, I. Higgins, A. Pal, L. Matthey, N. Watters, G. Desjardins, and A. Lerchner. Understanding
disentangling in -vae. arXiv preprint arXiv:1804.03599 , 2018.
D. Cer, Y . Yang, S. Kong, N. Hua, N. Limtiaco, R. John, N. Constant, M. Guajardo-Cespedes, S. Yuan,
C. Tar, et al. Universal sentence encoder. arXiv preprint arXiv:1803.11175 , 2018.
Y . Chen, V . Li, K. Cho, and S. Bowman. A stable and effective learning strategy for trainable greedy
decoding. arXiv preprint arXiv:1804.07915 , 2018.
J. Chien and C. Kuo. Markov recurrent neural network language model. In 2019 IEEE Automatic
Speech Recognition and Understanding Workshop (ASRU) , pages 807–813. IEEE, 2019.
T. Kulkarni D, K. Narasimhan, A. Saeedi, and J. Tenenbaum. Hierarchical deep reinforcement
learning: Integrating temporal abstraction and intrinsic motivation. Advances in neural information
processing systems , 29, 2016.
C. Danescu-Niculescu-Mizil and L. Lee. Chameleons in imagined conversations: A new approach to
understanding coordination of linguistic style in dialogs. arXiv preprint arXiv:1106.3077 , 2011.
S. Dathathri, A. Madotto, J. Lan, J. Hung, E. Frank, P. Molino, J. Yosinski, and R. Liu. Plug
and play language models: A simple approach to controlled text generation. arXiv preprint
arXiv:1912.02164 , 2019.
A. Van den Oord, Y . Li, and O. Vinyals. Representation learning with contrastive predictive coding.
arXiv e-prints , pages arXiv–1807, 2018.
J. Devlin, M. Chang, K. Lee, and K. Toutanova. Bert: Pre-training of deep bidirectional transformers
for language understanding. arXiv preprint arXiv:1810.04805 , 2018.
M. Fatemi, L. Asri, H. Schulz, J. He, and K. Suleman. Policy networks with two-stage training for
dialogue systems. arXiv preprint arXiv:1606.03152 , 2016.
J. Ficler and Y . Goldberg. Controlling linguistic style aspects in neural language generation. arXiv
preprint arXiv:1707.02633 , 2017.
L. Floridi and M. Chiriatti. GPT-3: Its nature, scope, limits, and consequences. Minds and Machines ,
30(4):681–694, 2020.
M. Gaši ´c, F. Jur ˇcíˇcek, B. Thomson, K. Yu, and S. Young. On-line policy optimisation of spoken
dialogue systems via live interaction with human subjects. In 2011 IEEE Workshop on Automatic
Speech Recognition & Understanding , pages 312–317. IEEE, 2011.
A. Ghandeharioun, J. Shen, N. Jaques, C. Ferguson, N. Jones, A. Lapedriza, and R. Picard. Approxi-
mating interactive human evaluation with self-play for open-domain dialog systems. Advances in
Neural Information Processing Systems , 32, 2019.
E. Greensmith, P. Bartlett, and J. Baxter. Variance reduction techniques for gradient estimates in
reinforcement learning. Journal of Machine Learning Research , 5(9), 2004.
J. Gu, K. Cho, and V . Li. Trainable greedy decoding for neural machine translation. arXiv preprint
arXiv:1702.02429 , 2017.
T. Haarnoja, A. Zhou, P. Abbeel, and S. Levine. Soft actor-critic: Off-policy maximum entropy deep
reinforcement learning with a stochastic actor. ICML , 2018.
12

--- PAGE 13 ---
D. Hafner, T. Lillicrap, M. Norouzi, and J. Ba. Mastering atari with discrete world models. arXiv
preprint arXiv:2010.02193 , 2020.
B. Hancock, A. Bordes, P. Mazare, and J. Weston. Learning from dialogue after deployment: Feed
yourself, chatbot! arXiv preprint arXiv:1901.05415 , 2019.
A. Holtzman, J. Buys, M. Forbes, A. Bosselut, D. Golub, and Y . Choi. Learning to write with
cooperative discriminators. arXiv preprint arXiv:1805.06087 , 2018.
N. Hurley and S. Rickard. Comparing measures of sparsity. IEEE Transactions on Information
Theory , 55(10):4723–4741, 2009.
N. Jaques, A. Ghandeharioun, J. Shen, C. Ferguson, A. Lapedriza, N. Jones, S. Gu, and R. Pi-
card. Way off-policy batch deep reinforcement learning of implicit human preferences in dialog.
arXiv:1907.00456 , 2019.
E. Kharitonov, M. Baroni, and D. Hupkes. How bpe affects memorization in transformers. arXiv
preprint arXiv:2110.02782 , 2021.
A. Kumar, A. Zhou, G. Tucker, and S. Levine. Conservative q-learning for ofﬂine reinforcement
learning. Advances in Neural Information Processing Systems , 33:1179–1191, 2020.
E. Levin and R. Pieraccini. A stochastic model of computer-human interaction for learning dialogue
strategies. In Eurospeech , volume 97, pages 1883–1886. Citeseer, 1997.
J. Li, M. Galley, C. Brockett, J. Gao, and B. Dolan. A diversity-promoting objective function for
neural conversation models. arXiv preprint arXiv:1510.03055 , 2015.
J. Li, W. Monroe, A. Ritter, M. Galley, J. Gao, and D. Jurafsky. Deep reinforcement learning for
dialogue generation. arXiv preprint arXiv:1606.01541 , 2016.
J. Li, W. Monroe, T. Shi, S. Jean, A. Ritter, and D. Jurafsky. Adversarial learning for neural dialogue
generation. arXiv preprint arXiv:1701.06547 , 2017.
Z. Li, J. Kiseleva, and M. De Rijke. Dialogue generation: From imitation learning to inverse rein-
forcement learning. In Proceedings of the AAAI Conference on Artiﬁcial Intelligence , volume 33,
pages 6722–6729, 2019.
W. Liao, B. Zeng, X. Yin, and P. Wei. An improved aspect-category sentiment analysis model for
text sentiment analysis based on roberta. Applied Intelligence , 51(6):3522–3533, 2021.
Y . Park, J. Cho, and G. Kim. A hierarchical latent structure for variational conversation modeling.
arXiv preprint arXiv:1804.03424 , 2018.
B. Peng, C. Zhu, C. Li, X. Li, J. Li, M. Zeng, and J. Gao. Few-shot natural language generation for
task-oriented dialog. arXiv preprint arXiv:2002.12328 , 2020.
A. Razavi, A. van den Oord, and O. Vinyals. Generating diverse high-resolution images with vq-vae.
2019.
A. Saleh, N. Jaques, A. Ghandeharioun, J. Shen, and R. Picard. Hierarchical reinforcement learning for
open-domain dialog. In Proceedings of the AAAI Conference on Artiﬁcial Intelligence , volume 34,
pages 8741–8748, 2020.
C. Sankar, S. Subramanian, C. Pal, S. Chandar, and Y . Bengio. Do neural dialog systems use the
conversation history effectively? an empirical study. arXiv preprint arXiv:1906.01603 , 2019.
J. Schulman, X. Chen, and P. Abbeel. Equivalence between policy gradients and soft q-learning.
arXiv preprint arXiv:1704.06440 , 2017.
I. Serban, A. Sordoni, Y . Bengio, A. Courville, and J. Pineau. Building end-to-end dialogue systems
using generative hierarchical neural network models. In Proceedings of the AAAI Conference on
Artiﬁcial Intelligence , volume 30, 2016.
13

--- PAGE 14 ---
I. Serban, C. Sankar, M. Germain, S. Zhang, Z. Lin, S. Subramanian, T. Kim, M. Pieper, S. Chandar,
N. Ke, et al. A deep reinforcement learning chatbot. arXiv preprint arXiv:1709.02349 , 2017a.
I. Serban, A. Sordoni, R. Lowe, L. Charlin, J. Pineau, A. Courville, and Y . Bengio. A hierarchical
latent variable encoder-decoder model for generating dialogues. In Proceedings of the AAAI
Conference on Artiﬁcial Intelligence , volume 31, 2017b.
P. Shah, D. Hakkani-Tur, B. Liu, and G. Tür. Bootstrapping a neural conversational agent with
dialogue self-play, crowdsourcing and on-line reinforcement learning. In Proceedings of the 2018
Conference of the North American Chapter of the Association for Computational Linguistics:
Human Language Technologies, Volume 3 (Industry Papers) , pages 41–51, 2018.
W. Shi and Z. Yu. Sentiment adaptive end-to-end dialog systems. arXiv preprint arXiv:1804.10731 ,
2018.
J. Shin, P. Xu, A. Madotto, and P. Fung. Generating empathetic responses by looking ahead the user’s
sentiment. In ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal
Processing (ICASSP) , pages 7989–7993. IEEE, 2020.
R. Shu, T. Nguyen, Y . Chow, T. Pham, K. Than, M. Ghavamzadeh, S. Ermon, and H. Bui. Predictive
coding for locally-linear control. In International Conference on Machine Learning , pages 8862–
8871. PMLR, 2020.
S. Singh, D. Litman, M. Kearns, and M. Walker. Optimizing dialogue management with reinforcement
learning: Experiments with the njfun system. Journal of Artiﬁcial Intelligence Research , 16:105–
133, 2002.
N. Subramani, S. Bowman, and K. Cho. Can unconditional language models recover arbitrary
sentences? Advances in Neural Information Processing Systems , 32, 2019.
I. Sutskever, O. Vinyals, and Q. Le. Sequence to sequence learning with neural networks. Advances
in neural information processing systems , 27, 2014.
R. Sutton, D. McAllester, S. Singh, and Y . Mansour. Policy gradient methods for reinforcement
learning with function approximation. Advances in neural information processing systems , 12,
1999.
A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. Gomez, L. Kaiser, and I. Polosukhin.
Attention is all you need. Advances in neural information processing systems , 30, 2017.
S. Verma, J. Fu, M. Yang, and S. Levine. Chai: A chatbot ai for task-oriented dialogue with ofﬂine
reinforcement learning. arXiv preprint arXiv:2204.08426 , 2022.
M. Walker. An application of reinforcement learning to dialogue strategy selection in a spoken
dialogue system for email. Journal of Artiﬁcial Intelligence Research , 12:387–416, 2000.
W. Wei, Q. Le, A. Dai, and J. Li. Airdialogue: An environment for goal-oriented dialogue research.
InProceedings of the 2018 Conference on Empirical Methods in Natural Language Processing ,
pages 3844–3854, 2018.
J. Williams and S. Young. Partially observable markov decision processes for spoken dialog systems.
Computer Speech & Language , 21(2):393–422, 2007.
T. Wolf, L. Debut, V . Sanh, J. Chaumond, C. Delangue, A. Moi, P. Cistac, T. Rault, R. Louf,
M. Funtowicz, et al. Huggingface’s transformers: State-of-the-art natural language processing.
arXiv preprint arXiv:1910.03771 , 2019.
M. Yang and O. Nachum. Representation matters: Ofﬂine pretraining for sequential decision making.
InInternational Conference on Machine Learning , pages 11784–11794. PMLR, 2021.
S. Young, M. Gaši ´c, S. Keizer, F. Mairesse, J. Schatzmann, B. Thomson, and K. Yu. The hidden
information state model: A practical framework for pomdp-based spoken dialogue management.
Computer Speech & Language , 24(2):150–174, 2010.
14

--- PAGE 15 ---
Y . Zhang, S. Sun, M. Galley, Y . Chen, C. Brockett, X. Gao, J. Gao, J. Liu, and B. Dolan. Di-
alogpt: Large-scale generative pre-training for conversational response generation. arXiv preprint
arXiv:1911.00536 , 2019.
T. Zhao, K. Xie, and M. Eskenazi. Rethinking action spaces for reinforcement learning in end-to-end
dialog agents with latent variable models. arXiv preprint arXiv:1902.08858 , 2019.
L. Zhou, J. Gao, D. Li, and H. Shum. The design and implementation of xiaoice, an empathetic social
chatbot. Computational Linguistics , 46(1):53–93, 2020.
D. Ziegler, N. Stiennon, J. Wu, T. Brown, A. Radford, D. Amodei, P. Christiano, and G. Irving.
Fine-tuning language models from human preferences. arXiv preprint arXiv:1909.08593 , 2019.
15

--- PAGE 16 ---
This section describes more details about our experimental setup to evaluate the algorithms.
A Experimental Details
A.1 KL-Contrastive Constraint
Recall that the main purpose of the KL-constraint is to enforce consistency in the latent variables
predicted by the semantic generator and the posterior. However, since both G0(z0jz)and(z0jz;Y)
are both models to be learned, if the data can be modeled with a single, stationary LM that does not
depend on the latent space, one trivial degenerated solution (that satisﬁes the KL constraint) is to
have both of these models output very small values, which would impede the generalizability (and
diversity) of the LM embedding, especially to unseen conversations. Utilizing analogous arguments
as in Shu et al. [2020], den Oord et al. [2018] that connects KL distribution matching and mutual
information maximization in representation learning, we tackle this issue by considering the KL-
contrastive constraint, i.e., let F(z;Y) := KLz0 
(z0jz;Y)jjG0(z0jz), we replace the constraint in
the optimization problem in (1) with
bEz=(X);YDh
F(z;Y) +logexp( F(z;Y))R
Y0exp( F(z;Y))i
KL;
where > 0is a trade-off factor in the KL-constrastive constraint. While the ﬁrst part of the
constraint limits F(z;Y), the second part enforces F(z;Y)to a much higher value in the positive
samples (w.r.t. ground-truth next utterance) than in the negative samples (w.r.t. other next-utterance
candidates). Therefore, this constraint can prevent the aforementioned degeneration issue and inject
ﬂexibility to control the size of the latent representation space.
A.2 Discretization of andGi
Inspired by various works which use discrete bottlenecks [Razavi et al., 2019, Hafner et al., 2020,
Yang and Nachum, 2021], we employ discretization of andG0to encourage better generalization
to out-of-distribution inputs. Speciﬁcally, we parameterize (X) = disc 16(e(X)), where the output
ofeis a continuous-valued vector in Rdand the discretization operator discKworks as follows:
• Given vector v2Rd, splitvintov1;:::;vd=Kvectors, each of size K.
•For eachvi, sample a one-hot vector v0
iof sizeKbased on a softmax categorical distribution
with logits given by vi.
• Concatenate the vectors v0
ito yield a multi-hot vector v0of sized.
•When computing the backward pass on v0, use straight-through gradients; i.e.,@v0
i
@vi=
@softmax(vi)
@vi.
We similarly discretize z0, the output ofG0. Namely, we ﬁrst parameterize Gias a Gaussian and then
discretize that to form a multinomial distribution that produces multi-hot ( d=K -hot,K= 16 ) vectors.
We employ the same discretization for the experts Giand the prior (z0jz;Y).
To avoid convergence to local minima for , we employ an entropy regularizer on the discrete distri-
bution it is sampled from. Namely, we use an adaptive entropy regularizer in the style of [Haarnoja
et al., 2018] with a ﬁxed target entropy that is a hyper-parameter.
A.3 Model parameters
In this section, the model parameters are described for MoE-1, 2, 3 and 4. All of these models
represent Mixture of Experts and are based on transformer [Vaswani et al., 2017]. Transformer
is an encoder-decoder based model that uses self-attention to capture relationships between the
elements of the sequence. In our implementation, we used multi-head attention with implementa-
tion similar to https://www.tensorflow.org/text/tutorials/transformer#point_wise_
feed_forward_network .
MoE-1 and MoE-2 use the simple transformer architecture, while MoE-3 and MoE-4 use the same en-
coder architecture as BERT [Devlin et al., 2018]. MoE-1 uses much smaller latent distribution models
16

--- PAGE 17 ---
fGigthan MoE-2; MoE-3 uses the pre-trained BERT encoder https://tfhub.dev/tensorflow/
bert_en_uncased_L-12_H-768_A-12/4 , while MoE-4 trains that from scratch.
The transformer model parameters for the simple transformer architecture are summarized in Table
4:
Parameter Value
Number of layers 2
Embedding hidden size 256
FFN inner hidden size 512
Attention heads 8
Key size 256
Value size 256
Dropout 0.1
Table 4: Simple Transformer Architecture
The BERT based transformer model is similar to the architecture from Table 4. The differences for a
pre-trained BERT model are captured in Table 5.
Parameter Value
Embedding hidden size 768
Number of layers 12
Attention heads 12
Table 5: BERT-based Transformer Architecture
The differences for a BERT model we train from scratch are captured in Table 6.
Parameter Value
Embedding hidden size 768
Number of layers 2
Attention heads 8
Table 6: Trainable, Smaller “BERT”-based Transformer Architecture
Latent distributions fGigare implemented as FFN that model mean and variance of the normal
distribution. The MoE-1, 2, 3, 4 use different values for the hidden size of the neural network.
Additionally, MoE-1 and 3 use target entropy of 0:1, MoE-2 and 4 use target entropy of 1:0. The
common parameters for FFN are captured in Table 7 (note: FFN has a ﬁnal layer without an
activation).
Finally, Table 8 shows individual parameters distinct for each of MoE models.
A.4 Computational resources
Training and evaluation were run on 8 GPU instances with 20GB of RAM and a NVIDIA Tesla P100
graphics card.
A.5 Dataset
We trained our models on Reddit Casual and Cornell Movie conversational datasets. Both datasets
were downloaded from Neural Chat datasets of the MIT Media Lab https://affect.media.mit.
edu/neural_chat/datasets . They contain conversational exchanges between pairs of speakers.
Each batch of training data contains a subset of such conversations. The Reddit Casual is about 3
times bigger than Cornell corpus.
17

--- PAGE 18 ---
fGigFFN parameter Value
Number of layers 1
Activation tanh
Table 7:fGigFFN architecture
MoE model parameter fGigFFN hidden size Embedding hidden size Uses BERT encoder Pre-trained BERT
MoE-1 128 128 No N/A
MoE-2 32 128 No N/A
MoE-3 256 768 Yes Yes
MoE-4 256 768 Yes No
Table 8: MoE parameters
A.6 Expert Label Functions
During EXP2, we deﬁne several types of language experts whose utterance outputs can constitute to
smooth bot responses when used in dialogue interactions with users.
The ﬁrst type of experts we aim to create is sentiment-based , because a ﬂuent expression of emotions
is important for creating a sense of understanding in human conversations. To quantify the emotional
tone of a bot utterance, we use a state-of-the-art (e.g., RoBERTa Sentiment [Liao et al., 2021])
sentiment detector, which outputs 2sets of prediction probabilities – (i) whether a bot utterance
is of positive, neutral, or negative sentiment; (ii) whether the bot utterance falls into any of the 4
more-reﬁned emotions: {joy, optimisim, sadness, anger}.
Neglecting the neutral sentiment output, we deﬁne 6sentiment labeling functions: `pos-sent (Y),
`neg-sent (Y),`joy(Y),`optimism (Y),`anger(Y),`sadness (Y), which outputs a score that depends on senti-
ment prediction probability of any candidate bot utterance. We can also create a sentiment-empathetic
expert whose utterances will be coherent with the user’s sentiment.
RoBERTa gives scores for each of the 6 categories listed above, which then are summed weighted by
the coefﬁcients in Table 9 to produce the sentiment-based score:
Sentiment Coefﬁcient
pos-sent 0.5
neg-sent -0.5
joy 0.5
optimism 1
sadness -1
anger -0.5
Table 9: Sentiment Based Label Coefﬁcients
To quantify sentiment coherence between the user and bot, the labeling function `sent-coh (X;Y)calcu-
lates the cosine similarity of user-bot sentiment embeddings (which corresponds to the logit vector
of the ﬁrst set of RoBERTa predictions) in the conversation history. Concretely, it’s implemented
using tf.keras.losses.cosine_similarity ( https://www.tensorflow.org/api_docs/python/tf/
keras/losses/cosine_similarity ).
The second type of experts of interests is engagement-based , whose goal is to encourage user’s
participation in the conversation. One primary candidate is the question expert, because having a bot
that is appropriately inquisitive demonstrates the system’s attentiveness to users, and thereby also
increases user’s responsiveness. To characterize whether a bot utterance is linked to a question, we
deﬁne the label function `question (Y)which outputs 1when both a question word and a question mark
are present and 0otherwise. Another engagement skill of interests is exploration , i.e., the expert is
able to change the tone or topic of conversations to avoid having a stale conversation. To measure the
amount of exploration, in the label function `exp(X;Y)we utilize a sentence encoder (e.g., USE [Cer
et al., 2018]) to encode both the conversation history and the bot utterance and output the negative
cosine similarity between these two embeddings.
18

--- PAGE 19 ---
A.7 RL Rewards
For EXP3, the reward for RL-based dialogue management is deﬁned as r(X;a;X +) =1`sent(X+)+
2(`sent(X+) 1 
1 LPL 1
l=0l`sent(Xl)), where the linear combination weights (1;2) =
(0:75;0:25)correlate with Ghandeharioun et al. [2019], and `sent(X)is the same RoBerTa-based
sentiment labeler as in EXP2, which assigns a score from [ 1;1]that is proportional to the positive
sentiment and inversely proportional to the negative sentiment prediction probabilities. Intuitively, 1
assigns weight to sentiment-based score of the next user response X+.2assigns weight to transition
of user sentiment, which we deﬁne as the difference between sentiment-based score of next user
response and discounted sentiment-based score of the current conversation.
B Additional Results
B.1 Dialogue Management Results on Cornell Movie Corpus
Method Diversity Dist-1 Dist-2 Dist-3 Perplexity
MoE-1 0.0730.02 0.24 0.59 0.67 76.1733.04
MoE-2 0.120.01 0.30 0.65 0.77 45.2440.77
MoE-3 0.110.01 0.28 0.66 0.72 77.9426.55
MoE-4 0.160.01 0.35 0.77 0.84 60.0623.74
Trans. 0.0600.03 0.25 0.55 0.70 69.8616.88
VHRED 0.0950.03 0.27 0.53 0.68 101.8854.78
Table 10: Accuracy (Perplexity) and Diversity of
Language Primitive Experts Trained with Cornell.Method User Tot. Sent. User Sent. Trans. GPT-Perplexity
MoE-2 Primitive -0.140.11 0.100.05 93.1150.41
MoE-2 DQN -0.170.13 -0.080.05 90.0130.76
MoE-2 CQL 0.170.15 0.180.15 88.8357.78
MoE-2 MBRL 0.130.11 0.090.07 85.5940.01
Trans. RL -0.350.19 -0.150.18 199.7564.23
Trans. KLC -0.090.06 -0.130.08 145.0955.71
Trans. VHRL -0.070.13 0.050.07 160.0260.30
Table 11: Quality of DM Trained with Cornell Dataset.
Method Question Exploration Positive Sent. Negative Sent. Sent. Coherence Joy Optimism Anger Sadness
MoE-1 1.190.23 0.330.25 1.240.43 1.300.64 0.790.44 2.040.39 0.021.01 1.920.99 3.771.05
MoE-2 1.570.27 0.360.21 3.622.01 1.801.89 0.680.25 2.670.97 2.261.35 2.801.14 4.321.76
MoE-3 1.140.31 0.290.37 0.350.31 1.890.58 0.750.21 1.880.77 0.290.81 0.650.99 2.991.01
MoE-4 1.840.33 0.260.51 0.171.86 2.201.64 0.800.98 0.521.91 0.580.61 2.720.75 3.771.43
WD 0.861.7 0.210.289 -0.480.44 0.410.46 0.840.19 0.131.48 -1.110.88 1.512.02 1.220.80
PPLM 0.310.45 0.350.36 -0.492.32 0.422.13 0.740.24 -1.002.54 -0.862.41 0.690.05 0.742.27
Trans. RL* 2.200.32 0.440.26 3.581.05 2.981.53 0.820.30 3.061.85 1.641.21 3.222.01 3.981.88
Table 12: Quality of Each Expert PPLM Trained on Cornell Dataset w.r.t. Its Trained Label.
19

--- PAGE 20 ---
B.2 Sample Utterances for EXP 1
B.2.1 Reddit Casual
1.Input Conversation: (...) i mean , i have n’t changed or done anything drastically different
, but things have been good .
•MoE-1 R1: but my outlook on life is n’t meh .
•MoE-1 R2: but my outlook on life is subjective .
•MoE-1 R3: but my outlook on life is still meh .
•MoE-1 R4: but my view on life is still meh ?
•MoE-1 R5: but my outlook on life is n’t meh ?
•MoE-2 R1: i love the good things that i ’m starting too.
•MoE-2 R2: i do love your life , because mine ’s nothing .
•MoE-2 R3: no , i ’m not too busy in life
•MoE-2 R4: good for you , i ’m working on it .
•MoE-2 R5: but my life is boring and boring .
•MoE-3 R1: but my outlook on life is still sad .
•MoE-3 R2: but my outlook on life is the same .
•MoE-3 R3: but my outlook on life is my same !
•MoE-3 R4: but my outlook on life is not good .
•MoE-3 R5: but my outlook on life is my friend .
•MoE-4 R1: i ’m in my early 20 ’s , i do n’t know what to do
•MoE-4 R2: i ’m so happy for you .
•MoE-4 R3: for me , it ’s tough to go through life with pain .
•MoE-4 R4: i used to think that you ’d enjoy that much more than most people .
•MoE-4 R5: can you describe what happened ?
2.Input Conversation: (...) but my outlook on life is still meh
•MoE-1 R1: no need for drastically change, just take it slow for a break ?
•MoE-1 R2: no need to slow down, just take it a long day ?
•MoE-1 R3: no need to slow down , just take a step too long .
•MoE-1 R4: no need a blanket , just take it off .
•MoE-1 R5: no need for a breath , just take it a bit of time
•MoE-2 R1: being a good person is n’t a bad thing
•MoE-2 R2: i ’m in a similar situation for it .
•MoE-2 R3: take a break , try to ﬁnd something else .
•MoE-2 R4: oh yeah , life ’s pretty good for me .
•MoE-2 R5: like you ’re in a bad place for a few years ?
•MoE-3 R1: no need for drastic changes , just make it super busy
•MoE-3 R2: no need for drastic changes , just do it extra time
•MoE-3 R3: no need for unnecessary stress , just move the next direction
•MoE-3 R4: no change for unnecessary things , just move on .
•MoE-3 R5: no need for unnecessary consumption , just take with the move
•MoE-4 R1: it seems like a great time to just go outside and play a few songs , i ’m
always glad to hear that you have a good friend
•MoE-4 R2: i know life ’s not perfect , it can be difﬁcult at times !
•MoE-4 R3: end complaining all the time and just consider your life a failure .
20

--- PAGE 21 ---
•MoE-4 R4: you ’d be surprised at how nice life can go !
•MoE-4 R5: i mean some sort of hobby can deﬁnitely help out .
3.Input Conversation: (...) no need for drastically difference , just take it slow .
•MoE-1 R1: and it ’s nice to hear someone else ’s good , but it ’s all about my life .
•MoE-1 R2: and it ’s nice to hear , when you have new seasons of american world is
just a nature in canada .
•MoE-1 R3: and it ’s nice to hear why you ’ve been doing it , but my friend is still in it
...
•MoE-1 R4: and it ’s very good to hear why you ’ve been good with my wife , a lot of
things that ’s happening in the same way .
•MoE-1 R5: and it ’s nice to hear things have been good , my view of life changes with
time and mood
•MoE-2 R1: i ﬁnd it hard to get out of this world , but there is also a good way to ﬁnd a
positive way of life .,
•MoE-2 R2: you seem to be in the same situation , but it is a good way to do it for a lot
of things in life
•MoE-2 R3: my life is n’t bad , i ’m in a very long time and i m pretty happy about it .
•MoE-2 R4: i just wanted to see what ’s happening in my life and i m not sure what to
do .
•MoE-2 R5: at this point i ’m pretty sure the most part of my life is pretty normal , but
it s a lot of positive .
•MoE-3 R1: and it ’s nice to hear that things have been good for you that your view life
is a lot like mine .
•MoE-3 R2: and it ’s nice to hear that things have been good for you so my perspective
of life is too much and so i think that ’s a pass
•MoE-3 R3: and it ’s nice to hear that things have been good for you in my view of life
, like a lot of people are trying to have
•MoE-3 R4: and it ’s nice to hear that things have been good for you , my view my life
is awful that , but i feel like this is a lot better
•MoE-3 R5: and it ’s nice to hear that things have been good for you in the future of
your life , so maybe you ’re looking forward to it
•MoE-4 R1: i ’ve been trying to learn things about myself .
•MoE-4 R2: that ’s like i would be at this stage of life .
•MoE-4 R3: you will need to enjoy life for yourself .
•MoE-4 R4: for me it ’s like i do n’t have the time .
•MoE-4 R5: but like you said , you ’ve been trying to get your life together and learn to
be a normal person to love yourself .
4.Input Conversation: (...) and it ’s nice to hear that things have been good for you d my
view of life is meh too , it changes depending on time and mood
•MoE-1 R1: and i do n’t know why i say this , this is not a relevant post , but i can
really say the same things .
•MoE-1 R2: and i do n’t know why i say this , this is not even relevant , but any things
will be good .
•MoE-1 R3: and i do n’t know why i say this , this is not even a relevant topic , i do n’t
remember the same things i said
•MoE-1 R4: and i do n’t know why i say this , this is n’t even relevant , but deﬁnitely i
enjoy the same things
•MoE-1 R5: and i do n’t know why i say this , this is not a relevant topic , but i think
there ’s actually a bunch of things to do
21

--- PAGE 22 ---
•MoE-2 R1: i think i ’m just trying to be a good person , but i m not sure what it is like
in my life .
•MoE-2 R2: for me it ’s my life i feel like it s the same way of being around the world
and i m pretty sure it s not a lot
•MoE-2 R3: to be honest , i ’m not sure what the most beautiful things are like in the
world
•MoE-2 R4: i feel like you ’re going to be a good person , but i ’m not a very happy
about the world of things you are around
•MoE-2 R5: i just want to be in a way to see my life and i m not really sure how much
of other things i like
•MoE-3 R1: and i do n’t know why i say this , this is not really relevant , but i do wish
you the best .
•MoE-3 R2: and i do n’t know why i say this , this is not really relevant , but i can count
the experience
•MoE-3 R3: and i do n’t know why i say this , this is not even relevant , but now i feel
like it ’s the kind of boring ...
•MoE-3 R4: and i do n’t know why i say this , this is not even relevant , but i like
watching ultra match in my room .
•MoE-3 R5: and i do n’t know why i say this , this is not even relevant , but i do feel
like you ’re welcome here .
•MoE-4 R1: i hope things get better for you soon
•MoE-4 R2: i think it ’s ﬁne , i enjoy life and could be a little happier every day
•MoE-4 R3: i like it d be a good time to think about the things that you don t need to
do .
•MoE-4 R4: but let ’s forget on those things that make you miserable and trying to
focus on the basics .
•MoE-4 R5: i know it ’s not perfect , but enjoy the things you have .
5.Input Conversation: (...) and i do n’t know why i say this , this is not even relevant , but
remember rule 32 enjoy the little things
•MoE-1 R1: i ’m trying to enjoy the little things like walking down the street , or
playing random games .
•MoE-1 R2: i ’m just trying to enjoy the little things like sports , like small talk , or
random ones , or even give up
•MoE-1 R3: i ’m just trying to enjoy the little things like walking down the street with
the same interactions or drinking
•MoE-1 R4: i ’m trying to enjoy the little things like going down the beach with the
same thing , or a nice spot
•MoE-1 R5: i ’m trying to enjoy the little things like walking down the beach ,
watching the weird movies , listen to random music
•MoE-2 R1: this is a good time , i ’m just looking for a place to go and i ’ve always
wanted to go to the store
•MoE-2 R2: my favorite thing is that i ’m just looking for a good thing to do , but i ’m
always looking forward to the people i ’ve been
•MoE-2 R3: i might be in the same boat , but i ’m a little scared to know what is a
really good thing to look at the moment
•MoE-2 R4: i ’ve been trying to ﬁnd out what i want to do , but i ’m not really sure
•MoE-2 R5: i know it ’s a good thing , but i ’m always in the same boat as i ’ve been in
a long run
•MoE-3 R1: yeah haha , i ’m deﬁnitely trying to enjoy the little things like walking
down the street , or just have a hot cup of tea
22

--- PAGE 23 ---
•MoE-3 R2: yeah haha , i ’m deﬁnitely trying to enjoy the little things like walking
down the street or seeing what is in my neighborhood
•MoE-3 R3: yes , i m deﬁnitely trying to enjoy the little things like walking down stairs
, but i can t ﬁgure out what to see
•MoE-3 R4: yeah dude , i m deﬁnitely trying to enjoy the little things like walking
down the street with a huge fan of these kids
•MoE-3 R5: yeah man , i ’m deﬁnitely trying to enjoy the little things like from
walking up the street or to my little kid ’s house
•MoE-4 R1: that ’s what i ’m really trying to do and enjoy the moment .
•MoE-4 R2: i ’ve always been like that , i ’ve been really chill at least trying to enjoy
my life
•MoE-4 R3: i ’m trying to get a good life and have a good time , i ’m not sure what to
do in my free time
•MoE-4 R4: and i ’ve deﬁnitely learned a lot of things to do
•MoE-4 R5: i d say that it has been given me both the time and pleasure, but i m still
an introvert with few hobbies
B.2.2 Cornell Movie Corpus
1.Input Conversation: (...) excuse me
•MoE-1 R1: i do n’t know .
•MoE-1 R2: i do n’t know .
•MoE-1 R3: yes .
•MoE-1 R4: what do you mean ?
•MoE-1 R5: i ’m sorry .
•MoE-2 R1: i ’ll give you a few minutes .
•MoE-2 R2: i do n’t want to talk about it .
•MoE-2 R3: may i come in ?
•MoE-2 R4: where is this , mr. kessler ?
•MoE-2 R5: what do you think ?
•MoE-3 R1: what ’s it ? are you alright ?
•MoE-3 R2: you want me to read ?
•MoE-3 R3: i do n’t know .
•MoE-3 R4: i ’ll just have to kill you .
•MoE-3 R5: you ca n’t say it ’s over .
•MoE-4 R1: well if you hang up , you ’ll die on it .
•MoE-4 R2: superman ? oh , was he here ?
•MoE-4 R3: well , you know , that ’s a lie , i do n’t have your money .
•MoE-4 R4: are you the killer ben ?
•MoE-4 R5: there ’s nothing to be wrong with that .
2.Input Conversation: (...) yes ?
•MoE-1 R1: what do you mean ?
•MoE-1 R2: i ’m not sure .
•MoE-1 R3: what ’s the matter ?
•MoE-1 R4: i do n’t know .
•MoE-1 R5: no .
•MoE-2 R1: what did you say ?
23

--- PAGE 24 ---
•MoE-2 R2: he says that you ’re not a good man .
•MoE-2 R3: i ’ll tell you what i ’ll do . i ’ll be right back .
•MoE-2 R4: do you want to go to the police ?
•MoE-2 R5: are you still in love with him ?
•MoE-3 R1: sam , i ’m getting married .
•MoE-3 R2: johnny . it was announced this morning . he ’s going to play the lead in
the new ﬁlm .
•MoE-3 R3: i ’m sorry , mister mcmurphy , i count only eight .
•MoE-3 R4: i said i was n’t looking for him . will you excuse my miss ... ?
•MoE-3 R5: pay ! in and i say !
•MoE-4 R1: i would like to marry you . but i have already promised myself ... to god .
•MoE-4 R2: do you know where he ’s living ?
•MoE-4 R3: i know you ’re soft .
•MoE-4 R4: it ’s susan ’s cooking , claire . why uncle james lets them stay ?
•MoE-4 R5: i do n’t want to be any trouble .
3.Input Conversation: (...) can i ask my friend , can he come in ? just for a few minutes ?
•MoE-1 R1: i ’m not sure .
•MoE-1 R2: i do n’t know
•MoE-1 R3: he ’s not a man , is n’t he ?
•MoE-1 R4: no, i ’m sorry .
•MoE-1 R5: what do you mean ?
•MoE-2 R1: all right . what are you going to do ?
•MoE-2 R2: no , i ’ve never seen him before .
•MoE-2 R3: i want to be with him .
•MoE-2 R4: this is a very interesting man .
•MoE-2 R5: he ’s not the greatest . you do n’t know .
•MoE-3 R1: oh , come on , i ’m sick and tired of your life .
•MoE-3 R2: no . i still do n’t have any reason to do that .
•MoE-3 R3: my god , are you kidding , i ’m a little tired .
•MoE-3 R4: i do n’t understand . where is he ?
•MoE-3 R5: no . i still do n’t have any reason let you be together
•MoE-4 R1: oh , of course !
•MoE-4 R2: because he was scary , right ?
•MoE-4 R3: i ’m sure you ’re a good friend .
•MoE-4 R4: can i get you a glass of champagne ?
•MoE-4 R5: so i like to make a point . you got a fucking friend that does n’t work
4.Input Conversation: (...) your friend ?
•MoE-1 R1: i do n’t know
•MoE-1 R2: you ’re not going to tell him ?
•MoE-1 R3: well , i ’m not sure .
•MoE-1 R4: i do n’t know .
•MoE-1 R5: i ’m sorry
•MoE-2 R1: i like him . he ’s a very good man .
24

--- PAGE 25 ---
•MoE-2 R2: maybe i should go home and talk to him .
•MoE-2 R3: i ’m not going to let him go .
•MoE-2 R4: oh , please .
•MoE-2 R5: if you do n’t mind , you ’ll have to do it , will you ?
•MoE-3 R1: what ’s the idea of working with you ? what ’s the matter ? !
•MoE-3 R2: i ’ll look into her . tell ’em .
•MoE-3 R3: that ’s something i have n’t done the before .
•MoE-3 R4: so , our lawyers are here .
•MoE-3 R5: we ’ve got some plans here .
•MoE-4 R1: my friend , you must be really glad to help . if you do n’t mind .
•MoE-4 R2: is n’t there something you can do . how can you help at night ?
•MoE-4 R3: how do you do , mrs. ryan ? i ’d heard you were beautiful , and so you are
.
•MoE-4 R4: the winning side would have paid you much better .
•MoE-4 R5: now , here ’s a babe ! I give you a blue ox , you got ta help me !
5.Input Conversation: (...) he ’s going back to the front this evening . i ca n’t see him
otherwise .
•MoE-1 R1: i ’m not going to be here .
•MoE-1 R2: what do you mean ?
•MoE-1 R3: i ’m not sure . it ’s not your fault .
•MoE-1 R4: i do n’t know .
•MoE-1 R5: you ’re not going to tell him ?
•MoE-2 R1: i think i ’ll tell you what i ’m gon na do .
•MoE-2 R2: he ’s on the way , right ?
•MoE-2 R3: that ’s not true .
•MoE-2 R4: not too late . i ’m not going to be here .
•MoE-2 R5: what are you talking about ? he ’s a very sweet man .
•MoE-3 R1: what ? i think it ’s wonderful .
•MoE-3 R2: sure , i guess !
•MoE-3 R3: oh , for christ ’s sake .
•MoE-3 R4: they ’ll be all right , you ’re my guest .
•MoE-3 R5: leon , you are not going to negotiate !
•MoE-4 R1: ok. he asks about you all the time . i want to tell you .
•MoE-4 R2: the way i feel , believe me , it ’s hard to part and see a guy ’s picture .
•MoE-4 R3: do n’t worry . i ’ll take care of it .
•MoE-4 R4: certainly it ’s important .
•MoE-4 R5: yeah , and what a real hero .
B.3 Sample Utterances for EXP 2: Question Intent
B.3.1 Reddit Casual
1.Sample Conversation: (...) i love how genuine your comments are and you only comment
if it s how you really feel and not for karma like when you wish people a merry christmas
•MoE-1 R1: what was your favorite guys and why did you have a boyfriend ?
•MoE-1 R2: i really love your username , and i am so happy for you .
25

--- PAGE 26 ---
•MoE-1 R3: what was your favorite guys and why did you have a nice day ?
•MoE-2 R1: how did you ﬁnd someone that you like ?
•MoE-2 R2: just wondering if you re interested in reddit ?
•MoE-2 R3: how did you feel about it ?
•MoE-3 R1: people like you really have a special place in my heart .
•MoE-3 R2: people like you really have a special place in my heart to me
•MoE-3 R3: people like you really have a special place in my heart?
•MoE-2 R1: how are you liking it ?
•MoE-2 R2: do you know i just love being together with you ?
•MoE-2 R3: how are you my friend ? ?
2.Sample Conversation: (...) people like you really have a special place in my heart .
•MoE-1 R1: that s nice !
•MoE-1 R2: happy cake day !
•MoE-1 R3: that sounds nice , you have a good time to stay alone ?
•MoE-2 R1: just wondering if you re happy with me ?
•MoE-2 R2: how did you feel about it ?
•MoE-2 R3: how did you get this ?
•MoE-3 R1: hope your christmas was a nice one to celebrate with you
•MoE-3 R2: hope your christmas was pretty good , my friend being celebrate with .
•MoE-3 R3: hope your christmas was nice with my friend who celebrate with you
•MoE-4 R1: omg why !
•MoE-4 R2: how far into your heart ?
•MoE-4 R3: how are you liking this happiness as well ?
3.Sample Conversation: (...) hope your christmas was pretty good , my friend assuming you
celebrate .
•MoE-1 R1: thank you !
•MoE-1 R2: thanks !,
•MoE-1 R3: thank you !
•MoE-2 R1: how did you guys meet this year ?
•MoE-2 R2: how was your day going ?
•MoE-2 R3: how did you celebrate this year ?
•MoE-3 R1: haha thank you !
•MoE-3 R2: thank you !
•MoE-3 R3: thank you .
•MoE-4 R1: how ’s your day going ?
•MoE-4 R2: how are you liking it so far ?
•MoE-4 R3: i have no idea what it ’s about ?
26

--- PAGE 27 ---
B.3.2 Cornell Movie Corpus
1.Sample Conversation: that ’s some face they left hanging on you . you look like ...
•MoE-1 R1: what ? what are you talking about ?
•MoE-1 R2: what ? what are you talking about ?
•MoE-1 R3: what ?
•MoE-2 R1: what ? what ’s wrong with it ?
•MoE-2 R2: what ? you think they ’re going to kill me ?
•MoE-2 R3: what is it ?
•MoE-3 R1: well . what ’s the difference ?
•MoE-3 R2: what ? what ’s the deal ?
•MoE-3 R3: what ? what ? what ’s wrong with what happened ?
•MoE-4 R1: what ? there ’s no pain in my mind ?
•MoE-4 R2: what ? why do you think i want to know ?
•MoE-4 R3: what can i do ? there ’s no way i can change .
2.Sample Conversation: what hotel ?
•MoE-1 R1: what the fuck are you doing here ?
•MoE-1 R2: what ?
•MoE-1 R3: what are you talking about ?,
•MoE-2 R1: what ’s the matter ?
•MoE-2 R2: what about it ?
•MoE-2 R3: who ’re you traveling with?
•MoE-3 R1: whatever . i ’m going to work here .
•MoE-3 R2: tom . how are you ?
•MoE-3 R3: what ? what about the hotel ?
•MoE-4 R1: do you think i want the plaza ?
•MoE-4 R2: what do you think ? where ’s my mother ?
•MoE-4 R3: what hotel i should go?
3.Sample Conversation: the holiday hotel .
•MoE-1 R1: what are you talking about ?
•MoE-1 R2: what ?
•MoE-1 R3: what are you doing here ?
•MoE-2 R1: what is your travel plan?
•MoE-2 R2: how can i get there?
•MoE-2 R3: why do you want to be there?
•MoE-3 R1: what ? are you walking in there ?,
•MoE-3 R2: absolutely . what ’s up with the hotel ?
•MoE-3 R3: what ? bring ’em in
•MoE-4 R1: what are you ? a cop ?
•MoE-4 R2: what about that ? i work here .
•MoE-4 R3: what ? ... oh you know he ’s there ?,
27

--- PAGE 28 ---
B.4 Sample Utterances for EXP 2: Positive Sentiment Intent
B.4.1 Reddit Casual
1.Sample Conversation: (...) it s deﬁnitely not the college experience .
•MoE-1 R1: i feel like i m more of a high school and talking to people .
•MoE-1 R2: i feel like i ’m not a teacher , and i talk to , i talk to people about it .
•MoE-1 R3: i feel like a lot of people are just as nervous as i talk to , and i really really
like talking about .
•MoE-2 R1: i m so proud of you for being able to keep up with it !
•MoE-2 R2: i hope you re having a great day !
•MoE-2 R3: i have a very good time on social media !
•MoE-3 R1: seems like middle school to end up way more stable than everyone and
don t know who does this
•MoE-3 R2: seems like real good compared to everyone after work and nobody is
around me even the age of 35
•MoE-3 R3: feels like a real awkward going to say though and nobody cares about
each other with me
•MoE-4 R1: if you want to get into college , i ’m pretty good at it !
•MoE-4 R2: thank you for taking the time to look at it , i ’m trying to get a few more
opportunities for you now for your semester
•MoE-4 R3: good for you , i like college and have more people in my life , i know
better than high school i ve been
2.Sample Conversation: (...) feels more like high school except way easier to mess up and
nobody really talks to anyone lmao .
•MoE-1 R1: i m on reddit , and i m going to be pretty far from my ﬁrst year s college ,
but i d probably have to go to college
•MoE-1 R2: i m not really good at all , but i m a college student , i d be working on a
job , i d be able to go,
•MoE-1 R3: i m pretty sure it s a lot easier to get a job , but i guess it s a lot of work in
my ﬁeld
•MoE-2 R1: i m going to be a senior and i m happy to meet people !
•MoE-2 R2: i hope you re having a great time !
•MoE-2 R3: i get to see my new friends and family !
•MoE-3 R1: i ’m looking forward to being able to say , but not because i am a great
life all for everyone to see each other once in a while
•MoE-3 R2: i ’m looking forward to going out , not because i feel so much better
knowing i will still have a great day , and i ’m happy to see
•MoE-3 R3: i ’m looking forward to going home , not only because i think i will be a
lot happier with my family and looking at the very young people .
•MoE-4 R1: for sure , i ve been in college for the past few years that i ve had plenty of
people in my life .
•MoE-4 R2: thank you for your input , i appreciate it !
•MoE-4 R3: you ll be proud of yourself and i hope you are able to enjoy those people
on your ﬁrst year
3.Sample Conversation: (...) i m looking forward to ﬁnally being out , not only because i
think i ll be a lot happier at a full uni , but also bc i hate home
28

--- PAGE 29 ---
•MoE-1 R1: i ﬁnally got the job that i m going to be a very good dad , and it just sucks .
•MoE-1 R2: i ﬁnally got a new job that i feel like is not a good thing .
•MoE-1 R3: i ﬁnally got the hang of my parents , and i feel very lucky to be very far as
possible .
•MoE-2 R1: now i m a college student and i m very proud of myself !
•MoE-2 R2: i ll try to meet new people !
•MoE-2 R3: i feel like i m a little too proud of myself !
•MoE-3 R1: yeah well and the whole thing will really help me feel a bit shitty right
now is n’t easy
•MoE-3 R2: yeah well this is the start and really make me feel good a bit better than
what i am .
•MoE-3 R3: yeah well and the goal is really help me feel good since everyone is mostly
different in their lives .
•MoE-4 R1: good advice , i really like it when i have to get a college degree , but i ’ve
also got a decent amount of friends who have not
•MoE-4 R2: thank you for the advice , i really like to keep on going for college and i
’m sure my friends will go to college
•MoE-4 R3: for sure , i want to get back on track to how much i used to be doing , but i
don t really like the idea of studying
B.4.2 Cornell Movie Corpus
1.Sample Conversation: (...) no i fucking do n’t ! you ca n’t make a cup of tea , edward .
•MoE-1 R1: what ?
•MoE-1 R2: no .
•MoE-1 R3: no , i ’m not .
•MoE-2 R1: yeah , i got it .
•MoE-2 R2: oh , i ’m so glad you say it .
•MoE-2 R3: yes , it ’s a very nice idea .
•MoE-3 R1: yes , sir . what ’s wrong ?
•MoE-3 R2: yes . yes , sir .
•MoE-3 R3: yes . who is this ?
•MoE-4 R1: oh , yes . i ’m going to miss you .,
•MoE-4 R2: yes . i ’m sorry , i did n’t know how to do it .
•MoE-4 R3: yes , yes . i ’ll tell you something about it .
2.Sample Conversation: (...) why not ? the whole of the british empire was built on cups of
tea .
•MoE-1 R1: what ?
•MoE-1 R2: no !
•MoE-1 R3: no , no .
•MoE-2 R1: good . i ’m glad you say that .
•MoE-2 R2: yeah , i got it .
•MoE-2 R3: yes , you are right about that .
•MoE-3 R1: yes . yes , sir .
29

--- PAGE 30 ---
•MoE-3 R2: yes , of course .
•MoE-3 R3: yes . yes . that ’s right .
•MoE-4 R1: yes , i ’ll tell you what it is .
•MoE-4 R2: yes , yes . i ’ll tell you something else !
•MoE-4 R3: yes , i ’m with you .
3.Sample Conversation: (...) if you ’ll be good enough to remove those newspapers i ’ll have
a seat .
•MoE-1 R1: no , i ’m not .
•MoE-1 R2: what ?
•MoE-1 R3: no !
•MoE-2 R1: yes , i think it ’s a good idea .
•MoE-2 R2: yes , yes . i ’ll be in a minute .
•MoE-2 R3: good . yes , you ’re not going to have to do it .
•MoE-3 R1: yes . yes . yes . yes .
•MoE-3 R2: what ’s the matter with you ?
•MoE-3 R3: yes , ma’am , i do .
•MoE-4 R1: oh , yes ! i ’ll do it .
•MoE-4 R2: yes , yes . i ’m sure you must be a very sick man .
•MoE-4 R3: yes , yes . i ’m sure you do ..
B.5 Sample Utterances for EXP 2: Negative Sentiment Intent
B.5.1 Reddit Casual
1.Sample Conversation: (...) it s deﬁnitely not the college experience .
•MoE-1 R1: i m not much of a sports person , i ﬁnd that sort of an emotional connection
to others .
•MoE-1 R2: i ’m more of a high school student and i m wondering if anyone else to
talk to about this .
•MoE-1 R3: i ’m not a social person , but i ’m just really curious how to talk to other
people .
•MoE-2 R1: i don t know if i should be going to school right now .
•MoE-2 R2: i don t know how to do it , i m nervous .
•MoE-2 R3: i don t think i m going to be able to do all the things i ve been doing .
•MoE-3 R1: feels like shit not less to lie than excuse myself to just miss class all the
time .
•MoE-3 R2: feels like decent becoming middle school system and not close to him
anymore anyways because nobody ever mentioned .
•MoE-3 R3: feels like middle school only harder to stay up and nobody really talks
about anything except nowadays .
•MoE-4 R1: because i hate making out of my freshman year i was happy about it
•MoE-4 R2: but i hate to admit it , so like this was the ﬁrst time i even went to college .
•MoE-4 R3: and people are terrible at ﬁguring out what to do , you could n’t pay extra
for this year !
30

--- PAGE 31 ---
2.Sample Conversation: (...) feels more like high school except way easier to mess up and
nobody really talks to anyone lmao .
•MoE-1 R1: i m not really good at all , but i guess i would have to go to a university
for a good job .
•MoE-1 R2: so far that i ’m not happy to have my own experience , but i m also going
to have a job that i d like to have .
•MoE-1 R3: i m on the same boat as you , but i m also a college student for a few years
.
•MoE-2 R1: i m not going to try and start doing anything for the next semester .
•MoE-2 R2: i don t know if it s the same .
•MoE-2 R3: i don t know if it s going to be the same since i m still in college .
•MoE-3 R1: i m looking forward to going back to being alone , but not because i feel
like i m a better ﬁt in with the wait til stressful one
•MoE-3 R2: i ’m looking forward to going back home , not only because i feel that
there ’s a lot of time to do something productive after i get there
•MoE-3 R3: i ’m looking forward to being at school , not only because i think i ’ll be a
bit happier now and will have to pay for 4 months
•MoE-4 R1: and i hate it , i get bored !
•MoE-4 R2: i just switched because i was a senior student and i know absolutely hate
that i had to do
•MoE-4 R3: and i hate talking about it , i ’ll get left out
3.Sample Conversation: (...) i m looking forward to ﬁnally being out , not only because i
think i ll be a lot happier at a full uni , but also bc i hate home
•MoE-1 R1: so i ﬁnally got a new job that i am not a very good person .
•MoE-1 R2: i ’m not going to be able to ﬁnd a way to feel better about it , but i just
feel better .
•MoE-1 R3: i m not the most comfortable person who wants to be so bad about it or
something that i should be able to be able to do .
•MoE-2 R1: i feel like i m not going to be honest .
•MoE-2 R2: i feel like i m not going to be in the same position .
•MoE-2 R3: i don t know if it s all about going to school .
•MoE-3 R1: yeah well all and the person does really make me feel better for everyone
to be so serious about it .
•MoE-3 R2: yeah well this and the beat all does seem feel a bit better because everyone
is basically just that it is in their ass .
•MoE-3 R3: yeah well and the post really not me feel better a lot better since it is not
being considered so big .
•MoE-4 R1: and i hate waking up , i feel like it all the time .
•MoE-4 R2: and i hate to admit it , i do n’t know what ’s going on .
•MoE-4 R3: and i know there are people who can keep up with their homework but i
do n’t know how to handle them !
B.5.2 Cornell Movie Corpus
1.Sample Conversation: (...) no i fucking do n’t ! you ca n’t make a cup of tea , edward .
•MoE-1 R1: i ’m sorry .
31

--- PAGE 32 ---
•MoE-1 R2: i ’m not sure .
•MoE-1 R3: i do n’t know , i do n’t know .
•MoE-2 R1: what do i have to do ?
•MoE-2 R2: why do n’t you just leave it be ?
•MoE-2 R3: you do n’t know what you ’re talking about .
•MoE-3 R1: i ’m not interested in what people used to do .
•MoE-3 R2: i ’m afraid that ’s not up to me
•MoE-3 R3: yes . what ’s the problem with it ?
•MoE-4 R1: i do n’t want to hear your problems .
•MoE-4 R2: i do n’t care . i have a lot of money in my life .
•MoE-4 R3: i do n’t want a goddamn cup of tea . i want to go home . i ’ll have to be
here , okay ?
2.Sample Conversation: (...) why not ? the whole of the british empire was built on cups of
tea .
•MoE-1 R1: i do n’t know .
•MoE-1 R2: i ’m not sure . i ’m not going to be here .
•MoE-1 R3: i do n’t know .
•MoE-2 R1: who do you think you are ?
•MoE-2 R2: who cares ? i do n’t know what to say .
•MoE-2 R3: do n’t be a fool . do n’t you know what i ’m talking about .
•MoE-3 R1: yes . what ’s more like this ?
•MoE-3 R2: i do n’t believe that either .
•MoE-3 R3: that is correct . and how do we decide ?
•MoE-4 R1: i do n’t believe in it !
•MoE-4 R2: i do n’t want to hear you anymore . you hear me ?
•MoE-4 R3: i do n’t want to hear it . i know you ’re very clever .
3.Sample Conversation: (...) if you ’ll be good enough to remove those newspapers i ’ll have
a seat .
•MoE-1 R1: i do n’t know .
•MoE-1 R2: i ’m not sure .
•MoE-1 R3: i do n’t know .
•MoE-2 R1: i do n’t know what you ’re talking about .
•MoE-2 R2: who are you ? can you get out of here ?
•MoE-2 R3: do n’t be a fool . what do you want me to do ?
•MoE-3 R1: you ’re welcome to one of these , whatever .
•MoE-3 R2: what difference does it make ?
•MoE-3 R3: i ’m afraid not . have to ask you a question .
•MoE-4 R1: i do n’t want to hear it . i do n’t want to hear any more today .
•MoE-4 R2: look at this ! why are you laughing ?
•MoE-4 R3: i do n’t care ! i do n’t know what ’s good with you !
32

--- PAGE 33 ---
B.6 Sample Utterances for EXP 2: Joy Emotion Intent
B.6.1 Reddit Casual
1.Sample Conversation: (...) besides every anime intro and outro song ever at least from the
series i like , i ’ve been getting a kick out of j rock in general .
•MoE-1 R1: i got a song a few months ago and i can relate .
•MoE-1 R2: i got a song from a song that i can recently ﬁnish .
•MoE-1 R3: i got a song from a song that has been a really rough time lately .
•MoE-2 R1: what s your favourite anime to listen to ?
•MoE-2 R2: i just enjoy the new anime and i ’m a big fan of it .
•MoE-2 R3: i ’m always a fan of the anime and i ’ve been listening to it all the lately
•MoE-3 R1: i got very into french music this year which i can relate every year
•MoE-3 R2: i got into love pop music this year , so i can relate with very well .
•MoE-3 R3: i got into love rap recently this year so i can relate with you haha
•MoE-4 R1: haha i ’m into anime !
•MoE-4 R2: haha , anime manga is considered my ﬁrst language .
•MoE-4 R3: sounds like my favourite anime and manga japan , and they probably are
my main thing .
2.Sample Conversation: (...) i got deep into idol music this year so i can relate a bit .
•MoE-1 R1: i ’ve been thinking about the same as a lot of new bands i listen to .
•MoE-1 R2: i just started a new anime where i feel like i ’m into the same genre .
•MoE-1 R3: i just like the new design and see it on youtube .
•MoE-2 R1: <unk> is my favorite song
•MoE-2 R2: i love the song !
•MoE-2 R3: what do you like about the music ?
•MoE-3 R1: i have really watched deep dark <unk> recently .
•MoE-3 R2: yeah i have heard this song called so long
•MoE-3 R3: i know just your song i played video games sometimes .
•MoE-4 R1: i ’m also loving the music so far .
•MoE-4 R2: haha , i love anime manga from the 90 ’s .
•MoE-4 R3: haha yes but for me it ’s all anime .
3.Sample Conversation: (...) some people have the same username across multiple websites
such as steam or xbox .
•MoE-1 R1: people might even get mad at them , because they are on their own .
•MoE-1 R2: i might be the opposite .
•MoE-1 R3: i never thought about being a dick .
•MoE-2 R1: i guess there ’s a reason for people to use their username too .
•MoE-2 R2: i just use reddit , and the new design is pretty good .
•MoE-2 R3: i see a lot of people using this as well as the same goes .
•MoE-3 R1: you might also be able to get a hold of their different places with only
their username .
•MoE-3 R2: you might even be able to get a hold of them in different places with only
their username .
33

--- PAGE 34 ---
•MoE-3 R3: you might also be able to get a hold of my different places with the
internet access .
•MoE-4 R1: i ’m also loving the music so far .
•MoE-4 R2: haha well i guess you are talking about the internet .
•MoE-4 R3: haha good karma happens in a lot of us , but for me i ’m most on reddit .
B.6.2 Cornell Movie Corpus
1.Sample Conversation: (...) i guess i cut pretty loose in my day too .
•MoE-1 R1: oh , i ’m ﬁne .
•MoE-1 R2: oh , yeah .
•MoE-1 R3: oh , yeah .
•MoE-2 R1: yes , darling . i ’m looking for you .
•MoE-2 R2: nice . good .
•MoE-2 R3: okay , we ’ll see you .
•MoE-3 R1: oh yeah . that ’s nice .
•MoE-3 R2: oh , it ’s probably a good idea .
•MoE-3 R3: oh , it ’s worth it .
•MoE-4 R1: it ’s so beautiful . there ’s a lot of money in there .
•MoE-4 R2: i ’m so sure you ’ll ﬁnd out how that d go.
•MoE-4 R3: i said it ’s good call .
2.Sample Conversation: (...) i could get ben to tap into the baxter ’s main power to generate
enough voltage
•MoE-1 R1: yes , sir .
•MoE-1 R2: oh , yes , sir .
•MoE-1 R3: oh , yes , sir .
•MoE-2 R1: and i ’m sure it ’s a good idea
•MoE-2 R2: yes , ma’am . i ’m going to work .
•MoE-2 R3: oh , i ’m going to have a nice time .
•MoE-3 R1: hey . that ’s the problem .
•MoE-3 R2: oh , that ’s a possibility .
•MoE-3 R3: well . hope you enjoy it .
•MoE-4 R1: i do n’t know . but i ’m sure it ’s a very good idea .
•MoE-4 R2: i ’m glad you got your sense of humor back . think you ’ll keep it ?
•MoE-4 R3: yes , that ’s exactly what we got to do .
3.Sample Conversation: (...) or that he ca n’t be bothered to write us a proper letter ? a
dissertation on apples , we do n’t need !
•MoE-1 R1: no , sir .
•MoE-1 R2: yes , sir .
•MoE-1 R3: yes , sir .
•MoE-2 R1: yes , sir . they ’re telling me all this .
•MoE-2 R2: he ’s a bad guy , huh ?
34

--- PAGE 35 ---
•MoE-2 R3: oh , that ’s a good idea .
•MoE-3 R1: oh . well , that ’s good .
•MoE-3 R2: oh , that sounds great .
•MoE-3 R3: yes , he ’s that sweetheart .
•MoE-4 R1: he says he does n’t feel good too . i thought you might know .
•MoE-4 R2: yes . he was all right .
•MoE-4 R3: jeez , right . he ’s like a ghost !
B.7 Sample Utterances for EXP 2: Optimism Emotion Intent
B.7.1 Reddit Casual
1.Sample Conversation: (...) besides every anime intro and outro song ever at least from the
series i like , i ’ve been getting a kick out of j rock in general .
•MoE-1 R1: got a few more of my favorite songs !
•MoE-1 R2: have you ever got a song that you can listen to ?
•MoE-1 R3: i ve been listening to a lot of songs lately and i can relate .
•MoE-2 R1: good lord , deﬁnitely send forever shit to the artist ...
•MoE-2 R2: good for you , the fantastic video !
•MoE-2 R3: good one , but the next one is , better !
•MoE-3 R1: i got deep into idol music this year so i can relate a bit .
•MoE-3 R2: i got big into pop music today so i can relate your success !
•MoE-3 R3: i got deep into music recently so i will love my new year !
•MoE-4 R1: good for you , it s a good anime intro haha
•MoE-4 R2: might have some japanese jazz fusion and art
•MoE-4 R3: good one , the anime and manga really ﬁt me
2.Sample Conversation: (...) i got deep into idol music this year so i can relate a bit .
•MoE-1 R1: what do you like about it ?
•MoE-1 R2: what do you like to see ?
•MoE-1 R3: i ’m not sure what to watch ?
•MoE-2 R1: good one , the next anime ’s been awesome !,
•MoE-2 R2: good for you , my friend !
•MoE-2 R3: the best way to start the new year !
•MoE-3 R1: is it your favourite song ever ?
•MoE-3 R2: does it match your taste ?
•MoE-3 R3: is it really your favorite movie ?
•MoE-4 R1: good one , especially for the current age
•MoE-4 R2: thanks for your good song it gets more popular
•MoE-4 R3: good lord , the music is popular !
3.Sample Conversation: (...) some people have the same username across multiple websites
such as steam or xbox .
•MoE-1 R1: it ’s not even a joke , but i think it is a scam .
35

--- PAGE 36 ---
•MoE-1 R2: why people would use it as a joke ?
•MoE-1 R3: how do you know how to deal with it ?
•MoE-2 R1: what you can see is a new generation of the future.
•MoE-2 R2: be aware of what their user names are and comments are made to post
•MoE-2 R3: it depends on the mods and the subreddit , i see them as a possible
community .
•MoE-3 R1: you might even be able to get a hold of their different places with different
people
•MoE-3 R2: you might even be able to get a hold of their different places with different
people than your own view .
•MoE-3 R3: you may even be able to get a hold of your friend in different places with
their username ?
•MoE-4 R1: alright , so , especially reddit . might have to check out the real difference
, especially with older ones !
•MoE-4 R2: good on you for noticing when you mentioned that though not to be a
problem !
•MoE-4 R3: good for you , despite only being the mom and dad for me , i believe there
are some old people now , still hoping to do that
B.7.2 Cornell Movie Corpus
1.Sample Conversation: (...) i guess i cut pretty loose in my day too .
•MoE-1 R1: oh , i ’m ﬁne .
•MoE-1 R2: oh , yeah .
•MoE-1 R3: oh , i ’m sorry .
•MoE-2 R1: okay , take it easy .
•MoE-2 R2: all right . everything ’s been pretty .
•MoE-2 R3: go ahead . the last time you ’re right .
•MoE-3 R1: i ’m talking about ...
•MoE-3 R2: let ’s see if i ever known .
•MoE-3 R3: you learned from your american friends ?
•MoE-4 R1: i’m sure it can be ﬁne . it ’s just you and me , brad .
•MoE-4 R2: it ’s so cool . really .
•MoE-4 R3: you ’re right . i ’m sure it will work . i could feel you in your position .
2.Sample Conversation: (...) i could get ben to tap into the baxter ’s main power to generate
enough voltage
•MoE-1 R1: yes , sir . but we ’re not going to do the same thing .
•MoE-1 R2: no , sir .
•MoE-1 R3: yes , sir .
•MoE-2 R1: all right . it ’s the way . i ’m going to get it .
•MoE-2 R2: all right . you ’ll do it .
•MoE-2 R3: go ahead . i ’ll be all right .
•MoE-3 R1: it is ! i ’m stopping !
36

--- PAGE 37 ---
•MoE-3 R2: that bastard ! i ’ll gladly dispose of him in the name of the order , son of
malkovich .
•MoE-3 R3: i think they should stop and start looking right here i think they should
stop and start looking right here .
•MoE-4 R1: i ’m looking at it . i ’m going to get it right .
•MoE-4 R2: there ’s something else , major . i ’m starting to think what you said has a
ton of beauty in it
•MoE-4 R3: see , that ’s what we ’re here for .
3.Sample Conversation: (...) or that he ca n’t be bothered to write us a proper letter ? a
dissertation on apples , we do n’t need !
•MoE-1 R1: yes , sir . is that what you mean ?
•MoE-1 R2: yes , sir .
•MoE-1 R3: oh , yes , sir .
•MoE-2 R1: all right . we ’ll be able to ﬁgure out what ’s wrong with him .
•MoE-2 R2: okay , take it easy .
•MoE-2 R3: all right . we ’ll be able to ﬁgure out what ’s going on .
•MoE-3 R1: so ? the man got silver , china , rugs
•MoE-3 R2: he ’s out to the hospital ...
•MoE-3 R3: i see , i was just thinking ... maybe it ’s time to settle down .
•MoE-4 R1: you do n’t understand , i ’ve been in love with him !
•MoE-4 R2: he ’ll be back . i ’ll wait for his car .
•MoE-4 R3: i ’ll think of something . i do n’t think he ’s a bad guy .
B.8 Sample Utterances for EXP 2: Anger Emotion Intent
B.8.1 Reddit Casual
1.Sample Conversation: (...) besides every anime intro and outro song ever at least from the
series i like , i ’ve been getting a kick out of j rock in general .
•MoE-1 R1: i got ta have this song , but i can relate to this .,
•MoE-1 R2: i got this song a few months ago , and i can relate to a bit .
•MoE-1 R3: i got my thoughts into this , but i can relate to this .
•MoE-2 R1: why are you into anime ?,
•MoE-2 R2: i lose interest in it .
•MoE-2 R3: i ’m not an expert when it comes to it .
•MoE-3 R1: i got deep into idol music this year so i can relate a bit .
•MoE-3 R2: i got deep into this punk shows recently so i can relate with it .
•MoE-3 R3: i got ta learn rock this pop punk so i can relate with it .
•MoE-4 R1: keeping my speed for reading the anime shit .
•MoE-4 R2: why are you damn talking english only ?
•MoE-4 R3: and this is why i am not such a rich dude .
2.Sample Conversation: (...) i got deep into idol music this year so i can relate a bit .
•MoE-1 R1: oh wow , that ’s a good one .
37

--- PAGE 38 ---
•MoE-1 R2: i like it , i ’m not a fan of the music genre , but i ’ve had a lot of music .
•MoE-1 R3: oh wow .
•MoE-2 R1: why are you considering the big ex ?
•MoE-2 R2: i don ’t watch anime in general at the moment .
•MoE-2 R3: why are you considering anime good ?
•MoE-3 R1: i can totally see that this was all about the songs i did n’t talk to about .
•MoE-3 R2: i would n’t miss out on that video .
•MoE-3 R3: i don t miss that so much .
•MoE-4 R1: fuck yeah , i was there for like shit .
•MoE-4 R2: why are you considering doing a lot of anime ?
•MoE-4 R3: why do you think anime is bad ?
3.Sample Conversation: (...) some people have the same username across multiple websites
such as steam or xbox .
•MoE-1 R1: i think it all comes down to if they ’re serious .
•MoE-1 R2: i think it ’s just how they are in their mid 20s how they are , they are used
to their own lives .
•MoE-1 R3: it might seem like a lot of people in their late 20s , they have a large
problem with their accent .
•MoE-2 R1: why do people assume they have their own identity ?
•MoE-2 R2: it ’s just a series of spam jokes and whatnot
•MoE-2 R3: i think people are just dumb to the bottom line of their head .
•MoE-3 R1: you might also be able to ﬁnd a hold of them with different people than
the previous ones .
•MoE-3 R2: you might also be able to get a hold of them in different places with the
username .
•MoE-3 R3: you might even be able to get a hold of them in different places with their
username .
•MoE-4 R1: i dont know who downvoted you , but let people tell you the truth of your
karma . why are you asking on reddit ?
•MoE-4 R2: i dont necessarily agree with them but just became the ﬁrst and its just
became a good one .
•MoE-4 R3: you ’re around and just do n’t use the internet for any speciﬁc reason , i
think there are thousands of people watching .
B.8.2 Cornell Movie Corpus
1.Sample Conversation: (...) i guess i cut pretty loose in my day too .
•MoE-1 R1: you do n’t have to .
•MoE-1 R2: no .
•MoE-1 R3: you do n’t have to have a good look .
•MoE-2 R1: i think you must be crazy . you ca n’t tell me what you ’re doing here !
•MoE-2 R2: you ’re not the one trying to get away . who owns the gun ?
•MoE-2 R3: you do n’t pull this cowboy shit , you ’re gon na get him out ?
•MoE-3 R1: what do you know . i saw you ?
38

--- PAGE 39 ---
•MoE-3 R2: what the hell is that
•MoE-3 R3: oh , you do n’t know . i ’m sorry .
•MoE-4 R1: what are you talking about ? you love your job .
•MoE-4 R2: you ’re like an undercover guy !
•MoE-4 R3: you do n’t get paid till we close tonight .
2.Sample Conversation: (...) i could get ben to tap into the baxter ’s main power to generate
enough voltage
•MoE-1 R1: you do n’t have to do this .
•MoE-1 R2: you do n’t know what you ’re talking about .
•MoE-1 R3: you do n’t know what you ’re talking about .
•MoE-2 R1: you got to be kidding !
•MoE-2 R2: we ’re not going to do this .
•MoE-2 R3: we want to frighten you away . so that you ’ll move out
•MoE-3 R1: do n’t you dare , i ’ll be all that ...
•MoE-3 R2: so you ’re telling the truth ?
•MoE-3 R3: you think i ’m right
•MoE-4 R1: you ’re driving me nuts !
•MoE-4 R2: you ’re trying to kill me , are n’t you ?
•MoE-4 R3: you do n’t get it , pham . the idea was we were ripping them off .
3.Sample Conversation: (...) or that he ca n’t be bothered to write us a proper letter ? a
dissertation on apples , we do n’t need !
•MoE-1 R1: do n’t worry about it
•MoE-1 R2: do n’t you think he ’s in the dark .
•MoE-1 R3: do n’t worry about it .
•MoE-2 R1: i ca n’t believe you did n’t see that coming . you do n’t want to lose this !
•MoE-2 R2: what ? you ’re not going to kill him .
•MoE-2 R3: now what ? we ’re going to have to do something
•MoE-3 R1: because you do n’t know what you are doing .
•MoE-3 R2: oh , you do n’t know . i guess it ’s just not true .
•MoE-3 R3: and what the hell is that ?
•MoE-4 R1: he ’ll kill you ! motherfucker ! !
•MoE-4 R2: see , i told you he was gon na kill us all .
•MoE-4 R3: and you do n’t care what it says ?
B.9 Sample Utterances for EXP 2: Sadness Emotion Intent
B.9.1 Reddit Casual
1.Sample Conversation: (...) besides every anime intro and outro song ever at least from the
series i like , i ’ve been getting a kick out of j rock in general .
•MoE-1 R1: i got this feeling of thinking about this year and i can relate .
•MoE-1 R2: i got this feeling i can relate to this song a bit .
39

--- PAGE 40 ---
•MoE-1 R3: i got this song a lot , and i can relate to it .
•MoE-2 R1: i really miss the music i was listening to it .
•MoE-2 R2: i have n’t heard of it for a long time .
•MoE-2 R3: i ’m not a fan of anime at all .
•MoE-3 R1: i got deep into idol music this year so i can relate a bit .
•MoE-3 R2: i got very deep into this show so i can relate with this most .
•MoE-3 R3: i got very into ﬁlm school this year so i can relate with you .
•MoE-4 R1: no i would n’t have watched anime or video .
•MoE-4 R2: i only watched it in japanese and i was at a time .
•MoE-4 R3: i feel like i m just listening to the same music again .
2.Sample Conversation: (...) i got deep into idol music this year so i can relate a bit .
•MoE-1 R1: i ’m not the most interested in this movie .
•MoE-1 R2: i ’ve been listening to the whole genre of the past .
•MoE-1 R3: i ’ve been listening to a lot of people from the past few years .
•MoE-2 R1: i really miss the music i ’ve listened to before
•MoE-2 R2: i feel like i ’ve been listening to that music lately .
•MoE-2 R3: i hate reddit and have no idea what it is
•MoE-3 R1: i was also a huge fan of music so i do n’t listen to them tv .
•MoE-3 R2: i was very confused on my youtube was bc the record is bothering me .
•MoE-3 R3: i ’m also very into ﬁlm .
•MoE-4 R1: no but i only listen to rap .
•MoE-4 R2: i just watched anime and manga japan was probably the worst .
•MoE-4 R3: i have n’t heard anyone like anime .
3.Sample Conversation: (...) some people have the same username across multiple websites
such as steam or xbox .
•MoE-1 R1: i think it ’s because people who use the internet , they do n’t use them
anymore .
•MoE-1 R2: i think that ’s the case with the people who have their own knowledge of
their own .
•MoE-1 R3: i think people are just too used to it in their 30s or at their own cult .
•MoE-2 R1: i ’ve seen people get downvoted and it ’s all weird .
•MoE-2 R2: i even feel like it ’s true for everyone .
•MoE-2 R3: i ’ve heard people are n’t on reddit .
•MoE-3 R1: you might also be able to get a hold of their own place without similar
type places .
•MoE-3 R2: you might also be able to get a hold of them within the same price or not .
•MoE-3 R3: you might also be able to get a hold of them within different countries or
whatever they send you .
•MoE-4 R1: i have noticed it on twitter , and facebook . i never have anonymous
enough on twitter
•MoE-4 R2: i have n’t gotten around to it . i am literally wanting to delete my account .
•MoE-4 R3: i do n’t know why people are so dumb and useless .
40

--- PAGE 41 ---
B.10 Sample Utterances for EXP 3 (with Full MoE Decision Flow)
B.10.1 Reddit Casual, MoE-4 MBRL
1.Turn 0: (...) when i actually look back at it , it ’s not bad .
•MoE Primitive 1: oh god those words mean a lot in general . Q-value: 0.15
•MoE Primitive 2: when i get a good amount of things i put in the mood . Q-value:
-0.32
•MoE Question 1: i have n’t listened to music , but i played a few songs , what ’s it ?
Q-value: -0.38
•MoE Question 2: how much is it ? Q-value: -0.41
•MoE Exploration 1: and that ’s just me being the only way i can discover a life .
Q-value: -0.26
•MoE Exploration 2: i ’m 22 and have n’t hugged a girl yet forget about kissing .
Q-value: -0.55
•MoE Positive Sentiment 1: thank you for the amazing reply , i deﬁnitely look at it to
a high day ! Q-value: 0.45
•MoE Positive Sentiment 2: good for you , i really love the genre so things i consider
a best with as my life , it was a very difﬁcult decision Q-value: 0.05
•MoE Negative Sentiment 1: but on my own , i just do n’t see the appeal anymore
with how it is . Q-value: 0.05
•MoE Negative Sentiment 2: i hate it when i ’m slow . Q-value: -0.46
•MoE Sentiment Coherence 1: for me , i have a taste in music so i can not stand a lot
of art or without it i would be so tired Q-value: -0.38
•MoE Sentiment Coherence 2: the reason i love it , i have n’t been in a while , but i
feel like i was in a way that was when i was younger . Q-value: 0.25
•MoE Joy Emotion 1: haha well i ’m going through a lot of shit . Q-value: -0.25
•MoE Joy Emotion 2: haha yes i have my own one of my favorite things to do .
Q-value: -0.62
•MoE Optimism Emotion 1: good for you , i like the original music , it ’s a new skill
in painting , some of it , and just like every other Q-value: -0.14
•MoE Optimism Emotion 2: good on you for doing the right thing , just remember
that the past few months , i ’ve been putting it off , and have no idea about music
Q-value: 0.69
•MoE Anger Emotion 1: why do you think you re an adult ? Q-value: -0.16
•MoE Anger Emotion 2: why are you not asking me a question ? Q-value: -0.29
•MoE Sadness Emotion 1: i do n’t have much of an effect on my mood , what should i
do !Q-value: 0.60
•MoE Sadness Emotion 2: i have n’t done that yet but i ’m going to check out .
Q-value: -0.25
•Final Bot Response: Q-value: good on you for doing the right thing , just remember
that the past few months , i ’ve been putting it off and have no idea about music
Q-value: 0.69
•GPT-based Next-user Response: just love these memory of having that moment of
myself and lots to remember the past few years on life of music .
2.Turn 1: (...) just love these memory of having that moment of myself and lots to remember
the past few years on life of music .
•MoE Primitive 1: it has become an actual meme , and then on a cracked up . Q-value:
0.21
•MoE Primitive 2: i just love music , what genre would it be ? Q-value: 0.42
•MoE Question 1: how much do you enjoy now ? Q-value: -0.15
•MoE Question 2: how do you discover new music ? Q-value: 0.08
41

--- PAGE 42 ---
•MoE Exploration 1: but i was thinking of going to be a one , and maybe <unk> my
favorite shows . Q-value: 0.35
•MoE Exploration 2: and it ’s a good time to focus on something else , like a good
<unk> ’ , <unk> out of the good things . Q-value: -0.43
•MoE Positive Sentiment 1: thanks for the advice , i really hope things turn to someone
who does n’t have a life and does n’t deserve it and as much to be Q-value: -0.51
•MoE Positive Sentiment 2: thank you for the inspiration ! Q-value: 0.13
•MoE Negative Sentiment 1: but i hate when i have to do it all . Q-value: 0.18
•MoE Negative Sentiment 2: i am not one of those and i do n’t know about to be
honest .Q-value: -0.47
•MoE Sentiment Coherence 1: for the future , i love it and remember that song <unk>
would be a very nice place to achieve something like <unk> or goals . Q-value: -0.57
•MoE Sentiment Coherence 2: for me , i love the feeling of wanting to have a good
christmas tree since i was a kid Q-value: -0.77
•MoE Joy Emotion 1: haha , i am enjoying a lot of it , so i personally even know
nothing about it . Q-value: 0.09
•MoE Joy Emotion 2: haha , this is one of my favorite things to listen in the genre .
Q-value: 0.71
•MoE Optimism Emotion 1: good for you , the best of luck in the future ! Q-value:
0.13
•MoE Optimism Emotion 2: for me , the only thing i really like , is the music i like ,
and the way it gives me time to myself and be Q-value: 0.48
•MoE Anger Emotion 1: and what is an example of things you could do ? Q-value:
-0.11
•MoE Anger Emotion 2: and i do n’t like music , i ’ve felt so far . Q-value: -0.02
•MoE Sadness Emotion 1: i do n’t know what to do with my knowledge but i have no
idea what it is . Q-value: -0.03
•MoE Sadness Emotion 2: i have no clue why i do that these days . Q-value: -0.31
•Final Bot Response: haha , this is one of my favorite things to listen in the genre .
Q-value: 0.71
•GPT-based Next-user Response: I wonder how how it ’d go . but i do enjoy them .
they feel live and have the meaning of life .
B.10.2 Reddit Casual, MoE-4 CQL
1.Turn 0: (...) when i actually look back at it , it ’s not bad .
•MoE Primitive 1: well i ’m glad you ’re feeling better . Q-value: 0.38
•MoE Primitive 2: did you get a song that you ’re listening to ? Q-value: -0.06
•MoE Question 1: what ’s it worth ? Q-value: 0.35
•MoE Question 2: how did you get out of it ? Q-value: 0.12
•MoE Exploration 1: lately i ’ve been a lot of good things to do . Q-value: -0.55
•MoE Exploration 2: i love this song , and i will be happy with the music . Q-value:
-0.26
•MoE Positive Sentiment 1: i ’m glad you ’re able to ﬁnd a great life ! Q-value: 0.40
•MoE Positive Sentiment 2: i hope you have a great day ! Q-value: 0.39
•MoE Negative Sentiment 1: i do n’t know if it ’s worth a listen to it . Q-value: 0.22
•MoE Negative Sentiment 2: i do n’t know if i ’m going to be a bit stressful . Q-value:
0.17
•MoE Sentiment Coherence 1: i ’ll be able to do something with my own , but i ’ll be
able to ﬁnd a new genre . Q-value: -0.11
•MoE Sentiment Coherence 2: i might try to ﬁnd some new songs that i ’m not sure if
i ’m a bit interested in the music . Q-value: 0.20
42

--- PAGE 43 ---
•MoE Joy Emotion 1: i feel so much better now Q-value: -0.45
•MoE Joy Emotion 2: i want to do that myself . Q-value: -0.22
•MoE Optimism Emotion 1: be proud of yourself and happy for the ﬁrst time i ’ve
been able to make a great life . Q-value: 0.29
•MoE Optimism Emotion 2: be proud of yourself and be happy for the ﬁrst time i ’ve
been to a great life . Q-value: 0.09
•MoE Anger Emotion 1: it ’s so much easier to say than done ! Q-value: -0.50
•MoE Anger Emotion 2: i need to start doing something productive , but i ’m not
doing anything . Q-value: -0.11
•MoE Sadness Emotion 1: i just started a year ago and i ’m not sure what to do .
Q-value: 0.16
•MoE Sadness Emotion 2: i ’ve been trying to ﬁnd some new songs that are n’t a thing
.Q-value: 0.12
•Final Bot Response: i ’m glad you ’re able to ﬁnd a great life ! Q-value: 0.40
•GPT-based Next-user Response: yes , life feels young and happy again .
2.Turn 1: (...) yes , life feels young and happy again .
•MoE Primitive 1: i feel the same way . Q-value: 0.061
•MoE Primitive 2: i ’ve been through a lot of pain , but i do n’t know how to do it .
Q-value: -0.045
•MoE Question 1: how do you feel about it ? Q-value: -0.35
•MoE Question 2: i can understand that . how do you cope with this ? Q-value: 0.03
•MoE Exploration 1: but that ’s how i feel about it and i ’m not going to be able to
enjoy it .Q-value: 0.15
•MoE Exploration 2: because it ’s not a good feeling to be able to do something i
Q-value: -0.56
•MoE Positive Sentiment 1: be proud of yourself and be the best part of life , i ’m
happy that you ’re happy . Q-value: 0.85
•MoE Positive Sentiment 2: i hope i can ﬁnd a great life too ! Q-value: 0.65
•MoE Negative Sentiment 1: i do n’t know if it ’s going to be the problem . Q-value:
-0.22
•MoE Negative Sentiment 2: yeah i feel like i have a hard time . Q-value: 0.18
•MoE Sentiment Coherence 1: i might try to get into the good stuff i ’m not going to
do .Q-value: 0.05
•MoE Sentiment Coherence 2: i ’ll be able to ﬁnd the better , but i ’m not sure if i can
.Q-value: -0.19
•MoE Joy Emotion 1: i just enjoy playing music , and i ’m happy for myself . Q-value:
0.55
•MoE Joy Emotion 2: just in the mood , i ’m going to enjoy a bit of it . Q-value: -0.33
•MoE Optimism Emotion 1: just in the mood , i ’m going to enjoy a bit of it . Q-value:
-0.61
•MoE Optimism Emotion 2: i just enjoy playing music , and i ’m happy for myself .
Q-value: 0.28
•MoE Anger Emotion 1: i just started a new year ago and i ’m not a huge fan of the
music .Q-value: -0.43
•MoE Anger Emotion 2: why do you have to do this ? Q-value: -0.59
•MoE Sadness Emotion 1: got any hobbies that i feel like i ’m alone . Q-value: -0.13
•MoE Sadness Emotion 2: do you have any advice or am i just a little curious about
this ?Q-value: -0.08
•Final Bot Response: be proud of yourself and be the best part of life , i ’m happy
that you ’re happy .
43

--- PAGE 44 ---
•GPT-based Next-user Response: thank you i ’d proud of you ’ve been enjoy life too !
B.10.3 Reddit Casual, MoE-4 DQN
1.Turn 0: (...) when i actually look back at it , it ’s not bad .
•MoE Primitive 1: oh god those words mean a lot in general too . Q-value: 0.03
•MoE Primitive 2: when i m in a really bad mood , i ll have a look about myself .
Q-value: -0.05
•MoE Question 1: how do you know what ’s good ? Q-value: -0.25
•MoE Question 2: how in the world do you have all the time ? Q-value: -0.35
•MoE Exploration 1: and that ’s what i think of when i want to have a good idea .
Q-value: 0.52
•MoE Exploration 2: at least i have a couple of hours of listening to the same tunes .
Q-value: 0.28
•MoE Positive Sentiment 1: thanks for the good things , i ’ve found in 2018 , still ,
and if you like it ’s a little bit of inspiration , my own memories . Q-value: 0.16
•MoE Positive Sentiment 2: thank you for your recommendations , i deﬁnitely do n’t
have a fantastic artist , it ’s absolutely amazing to me , but i really want to learn more
Q-value: -0.4
•MoE Negative Sentiment 1: but on my mind , i ca n’t even focus on the music .
Q-value: -0.06
•MoE Negative Sentiment 2: but no i just do n’t know ... Q-value: 0.55
•MoE Sentiment Coherence 1: thanks for the recommendation i really enjoyed it !
Q-value: -0.04
•MoE Sentiment Coherence 2: that ’s what i ’ve heard about in the ﬁrst place . Q-
value: -0.13
•MoE Joy Emotion 1: not bad , i have all my <unk> on the side and <unk> . Q-value:
-0.18
•MoE Joy Emotion 2: good for you , for me , my best friend is <unk> Q-value: -0.27
•MoE Optimism Emotion 1: good on you for the time , but it ’s actually a bit of
a hiatus from the genre your get to your development aspect , regardless of songs
Q-value: -0.67
•MoE Optimism Emotion 2: you know what i m missing out on . Q-value: 0.24
•MoE Anger Emotion 1: i do n’t like the term toxic masculinity , but i think this idea
of pride is accurately described . Q-value: -0.36
•MoE Anger Emotion 2: why do you think the weed smell is a good idea ? Q-value:
-0.64
•MoE Sadness Emotion 1: i do n’t have much of a high expectation in my life .
Q-value: 0.15
•MoE Sadness Emotion 2: i ’m no expert on turtles and different types of turtle
species , i just saw an interesting documentary on sea turtles . Q-value: -0.04
•Final Bot Response: but no i just do n’t know ... Q-value: 0.55
•GPT-based Next-user Response: i agree , just make sure what you want to do and
ﬁgure out how to proud
2.Turn 1: (...) i agree , just make sure what you want to do and ﬁgure out how to proud
•MoE Primitive 1: it has become an actual effect on my mood . Q-value: 0.65
•MoE Primitive 2: but i ’ve discovered that by not giving any fucks about what i want .
Q-value: 0.13
•MoE Question 1: how the fuck do you think about it ? Q-value: -0.06
•MoE Question 2: how are you enjoying life , what you used to do ? Q-value: 0.18
•MoE Exploration 1: that s why i have a favourite meme playlist right . Q-value:
-0.24
44

--- PAGE 45 ---
•MoE Exploration 2: for me , i do n’t know what a genre is hit these days . Q-value:
-0.34
•MoE Positive Sentiment 1: for me , i love the good drawing and trying to keep it up ,
but it s not a big deal , i like a lot of it Q-value: 0.23
•MoE Positive Sentiment 2: good for you , for me , my best friend is music Q-value:
0.12
•MoE Negative Sentiment 1: i hate to admit it , i just look through the whole world .
Q-value: 0.08
•MoE Negative Sentiment 2: i hate to admit it , i do n’t know what i like to listen
Q-value: 0.28
•MoE Sentiment Coherence 1: taste is all subjective and i have no matter to taste or
texture other things on the genre . Q-value: -0.55
•MoE Sentiment Coherence 2: although i ’m on youtube , i enjoy old music . Q-value:
0.17
•MoE Joy Emotion 1: good for you , there s really no way to do it , but i m in the
mood for it , in my day Q-value: -0.23
•MoE Joy Emotion 2: good on you for the time , i think it ’s a little complicated haha
Q-value: 0.45
•MoE Optimism Emotion 1: good one , i have an amazing time , but , the little it can
be so challenging , especially to discover the passion . Q-value: 0.75
•MoE Optimism Emotion 2: this is the best recommendation ever , and at a good old
dance moves are n’t any other , or at the same time Q-value: 0.28
•MoE Anger Emotion 1: no taste in music , but the more <unk> ’ is my favorite song
ever on things . Q-value: -0.48
•MoE Anger Emotion 2: also , i have n’t watched an entire year of it . Q-value: -0.08
•MoE Sadness Emotion 1: why do i have to not use it ? Q-value: -0.0
•MoE Sadness Emotion 2: i do n’t know why i stopped putting on so much . Q-value:
0.15
•Final Bot Response: good one , i have an amazing time , but , the little it can be so
challenging , especially to discover the passion . Q-value: 0.75
•GPT-based Next-user Response: i already have a really vivid of memories of those
conversations , thats what i have heard from .
B.10.4 Cornell Movie Corpus, MoE-2 MBRL
1.Turn 0: (...) excuse me
•MoE Primitive 1: you , huh ? is that you ? Q-value: 0.17
•MoE Primitive 2: i ’ll promise you . but i ’d not like one of them , do n’t worry .
Q-value: 0.28
•MoE Question 1: what ? what ? because he was worried about ? Q-value: -0.34
•MoE Question 2: what ? oh , i thought maybe you did too ? Q-value: -0.28
•MoE Exploration 1: he asked you for a few bucks ? i want him along , anyway
Q-value: 0.05
•MoE Exploration 2: i do n’t know . i ’ve been hearing from you since i left . Q-value:
-0.01
•MoE Positive Sentiment 1: he says you ’re very nice . he has a gun . Q-value: -0.46
•MoE Positive Sentiment 2: that ’s right . he said that his name was familiar and the
formal negotiation is handled ’ Q-value: 0.18
•MoE Negative Sentiment 1: i do n’t know . i packed up my shit and ran away to here
.Q-value: -0.22
•MoE Negative Sentiment 2: no , i was n’t gon na see you tonight . Q-value: -0.59
45

--- PAGE 46 ---
•MoE Sentiment Coherence 1: i do n’t know what happened . i ’ve never been there
before .Q-value: 0.05
•MoE Sentiment Coherence 2: i do n’t know . i was with him and you ’re all i know
is that these years i thought you were going to do it Q-value: -0.35
•MoE Joy Emotion 1: i ’m glad you got your memory back , father ? Q-value: 0.33
•MoE Joy Emotion 2: haha , it is all good . Q-value: -0.17
•MoE Optimism Emotion 1: i ’m so sure you do . and he ’s got lots of friends left
Q-value: -0.07
•MoE Optimism Emotion 2: i was n’t saying anything . i was singing . Q-value: 0.16
•MoE Anger Emotion 1: What ? you do n’t pull that ? Q-value: -0.77
•MoE Anger Emotion 2: you did n’t work for him , did n’t you ? Q-value: -0.56
•MoE Sadness Emotion 1: he does n’t like me ? Q-value: -0.15
•MoE Sadness Emotion 2: i ’m sorry , i was n’t feeling that way . Q-value: 0.21
•Final Bot Response: i ’m glad you got your memory back , father ? Q-value: 0.33
•GPT-based Next-user Response: sure yea . you see i should worry nothing and do
exactly as said
2.Turn 1: (...) sure yea . you see i should worry nothing and do exactly as said
•MoE Primitive 1: i went down to meet the president . Q-value: -0.14
•MoE Primitive 2: he ’s the one i told him you . Q-value: 0.08
•MoE Question 1: what ? what did you think he wanted to do , then ? Q-value: -0.35
•MoE Question 2: what did you think ? when did you talk about it ? Q-value: -0.05
•MoE Exploration 1: i ’m a little girl . if you do n’t get me a girlfriend , maybe ﬁve
bucks .Q-value: -0.20
•MoE Exploration 2: it was like tommy was possessed or something . there was a hate
in his eyes that i could n’t really call human . Q-value: -0.41
•MoE Positive Sentiment 1: it ’s so nice to see you again . Q-value: 0.45
•MoE Positive Sentiment 2: it was so cool . you know who ’s being a jerk . Q-value:
0.05
•MoE Negative Sentiment 1: i do n’t want to be a fool . you do n’t want to look ?
Q-value: -0.04
•MoE Negative Sentiment 2: i do n’t care what you say ! i do n’t want to ﬁght you .
kinda <unk> . Q-value: -0.46
•MoE Sentiment Coherence 1: no . i think he ’s in the house . Q-value: -0.43
•MoE Sentiment Coherence 2: i do n’t know what else you ’d call it . Q-value: -0.35
•MoE Joy Emotion 1: it ’s not that bad , it just the way you always wanted it to be , or
did you ?Q-value: 0.33
•MoE Joy Emotion 2: there you go . i like you . Q-value: 0.34
•MoE Optimism Emotion 1: i ’m sure he ’s very ﬂattering , birdie , and i ’m sure there
’s nothing wrong with that . Q-value: -0.25
•MoE Optimism Emotion 2: he said it ’s up to us . Q-value: 0.02
•MoE Anger Emotion 1: you do n’t get paid till you calm down . you ’re sure you
want to stay ? Q-value: -0.26
•MoE Anger Emotion 2: you say that because you have no idea ? Q-value: -0.31
•MoE Sadness Emotion 1: no , i ’m surprised what three years ago . i do n’t know .
Q-value: -0.05
•MoE Sadness Emotion 2: i ’m sorry , i was n’t feeling like this , all . Q-value: -0.10
•Final Bot Response: it ’s so nice to see you again . Q-value: 0.45
•GPT-based Next-user Response: we think about you too , love you ,
46

--- PAGE 47 ---
B.10.5 Cornell Movie Corpus, MoE-2 CQL
1.Turn 0: (...) excuse me
•MoE Primitive 1: you , huh ? is that you ? Q-value: -0.42
•MoE Primitive 2: jesus , not sure . how are you ? Q-value: -0.24
•MoE Question 1: what ? what ? you think he wanted to kill the baby ? Q-value:
-0.091
•MoE Question 2: what ’s the matter ? Q-value: -0.080
•MoE Exploration 1: i ’ll destroy you , i swear it . Q-value: -0.51
•MoE Exploration 2: he asked you for a few bucks ? do you want him along ? Q-value:
-0.13
•MoE Positive Sentiment 1: sure , i ’d love to see you again . Q-value: -0.07
•MoE Positive Sentiment 2: it ’s so beautiful . he was crazy about you . Q-value: 0.37
•MoE Negative Sentiment 1: i do n’t want to hear it . i know you ’re talking to him .
Q-value: -0.11
•MoE Negative Sentiment 2: i did n’t want to get involved . did you ever think to work
with the police station chiefs . Q-value: -0.24
•MoE Sentiment Coherence 1: i do n’t know what else you ’d call it . Q-value: -0.26
•MoE Sentiment Coherence 2: i was tired , what is that for ? Q-value: -0.26
•MoE Joy Emotion 1: he ’s likely to be in love with you . Q-value: -0.24
•MoE Joy Emotion 2: i ’ll be right there . i ’ll have the money , you got that go .
Q-value: 0.25
•MoE Optimism Emotion 1: i ’m sure you ’ll remember that , in the ﬁrst date ?
Q-value: 0.25
•MoE Optimism Emotion 2: i ’m surprised you do n’t know . when i was a kid , i live
off the street . Q-value: 0.12
•MoE Anger Emotion 1: you do n’t sound like it ! Q-value: -0.61
•MoE Anger Emotion 2: you were n’t attracted to him ? Q-value: -0.11
•MoE Sadness Emotion 1: i ’m sorry , i do n’t know how to make it out . Q-value:
-0.17
•MoE Sadness Emotion 2: i ’m sorry , i do n’t know what to say . Q-value: 0.05
•Final Bot Response: it ’s so beautiful . he was crazy about you . Q-value: 0.37
•GPT-based Next-user Response: i ’m glad to know . but tonight mr. wade may not
come here .
2.Turn 1: (...) i ’m glad to know . but tonight mr. mel may not come here .
•MoE Primitive 1: certainly , when i get to go up to your room . Q-value: -0.33
•MoE Primitive 2: no . do n’t even be serious . but i ’m telling me the truth . Q-value:
-0.21
•MoE Question 1: what do you think he got to lose ? Q-value: -0.06
•MoE Question 2: then what ’s he talking about ? i ’m sorry . Q-value: -0.10
•MoE Exploration 1: i just want to hear the details ... Q-value: 0.39
•MoE Exploration 2: i do n’t want to hear you anymore . you made love ? Q-value:
-0.09
•MoE Positive Sentiment 1: yes . i can live here with you Q-value: 0.25
•MoE Positive Sentiment 2: right , youth . that ’s why i need you to lead the troops .
Q-value: -0.45
•MoE Negative Sentiment 1: i do n’t know . he fell for you . Q-value: -0.35
•MoE Negative Sentiment 2: i do n’t blame him . what happened ? Q-value: 0.01
•MoE Sentiment Coherence 1: but you did n’t think about it . what ’s the one said .
Q-value: -0.08
47

--- PAGE 48 ---
•MoE Sentiment Coherence 2: i do n’t know . i thought i might . but i ’m sure he ’s
quite human . Q-value: -0.06
•MoE Joy Emotion 1: it ’s just you know , i mean . it ’s been a pleasure . Q-value:
•MoE Joy Emotion 2: i ’m sure he ’s the right person . Q-value:
•MoE Optimism Emotion 1: yeah , i know . it ’s been so long . Q-value: -0.18
•MoE Optimism Emotion 2: i ’m sure you have n’t done anything . Q-value: -0.22
•MoE Anger Emotion 1: what ? i do n’t know what else ? Q-value: 0.13
•MoE Anger Emotion 2: you do n’t have to prove it ? Q-value:
•MoE Sadness Emotion 1: i was n’t aware of that . but this is the beauty of it . Q-value:
0.55
•MoE Sadness Emotion 2: clark . i would n’t want to come in tonight . Q-value:
-0.24
•Final Bot Response: i was n’t aware of that . but this is the beauty of it . Q-value:
0.55
•GPT-based Next-user Response: i ’m surprised you do n’t know . he said some
good thing about you too
B.10.6 Cornell Movie Corpus, MoE-2 DQN
1.Turn 0: (...) excuse me
•MoE Primitive 1: i ’ll promise you . but i do n’t have any new evidence . Q-value:
-0.19
•MoE Primitive 2: no , it ’s not the same thing . you do n’t have the same . Q-value:
-0.26
•MoE Question 1: what ? what do you think happened here ? Q-value: 0.45
•MoE Question 2: what did you think ? i ’m going to tell you what . it ’s over , boy .
Q-value: 0.11
•MoE Exploration 1: it ’s a lot of money for you to do . you know , i mean , you know
, i ’m not going to do that Q-value: 0.04
•MoE Exploration 2: it ’s the only way i can do it . i ’m not going to be a writer .
Q-value: 0.05
•MoE Positive Sentiment 1: yes . it ’s very nice . Q-value: -0.20
•MoE Positive Sentiment 2: yes , it ’s true . Q-value: -0.32
•MoE Negative Sentiment 1: i do n’t want to be here . i ’m not in love with you .
Q-value: -0.25
•MoE Negative Sentiment 2: do you want to be sure ? i want to know what you want .
Q-value: -0.16
•MoE Sentiment Coherence 1: i do n’t know what you ’re talking about . Q-value:
-0.15
•MoE Sentiment Coherence 2: you do n’t have to be a cop . you ’re not going to be
there .Q-value: 0.03
•MoE Joy Emotion 1: i ’m so sure you could have been anything ? Q-value: -0.28
•MoE Joy Emotion 2: it was you , was n’t it ? i ’ve seen your show . Q-value: 0.11
•MoE Optimism Emotion 1: it ’s not your fault . Q-value: 0.15
•MoE Optimism Emotion 2: that ’s all right , you ’re gon na be ﬁne . Q-value: -0.51
•MoE Anger Emotion 1: you do n’t pull that kick out your ass , you ’ll try ? Q-value:
-0.26
•MoE Anger Emotion 2: you do n’t have to do this to me ! Q-value: -0.53
•MoE Sadness Emotion 1: i ’m sorry , i did n’t know it . all i know is he did n’t get to
be here ﬁrst . Q-value: 0.23
•MoE Sadness Emotion 2: i ’m sorry to trouble you , but i have to . Q-value: 0.15
48

--- PAGE 49 ---
•Final Bot Response: what ? what do you think happened here ? Q-value: 0.45
•GPT-based Next-user Response: jesus , not sure . huh ? is that you ?
2.Turn 1: (...) jesus , not sure . huh ? is that you ?
•MoE Primitive 1: we ran up against a platoon of soldiers . there were actually walking
dead .Q-value: -0.05
•MoE Primitive 2: no . it ’s him , but he did n’t make the choice . Q-value: 0.87
•MoE Question 1: what ? what would you think ? i ’m going to be here . i ’ve never
seen this guy . Q-value: 0.75
•MoE Question 2: what did you think ? when did you talk about it ? Q-value: 0.18
•MoE Exploration 1: that ’s all i ever wanted . a man with the world without a different
girl from one , desert one ’s a dead , and later . Q-value: -0.51
•MoE Exploration 2: i dunno ... police . Q-value: -0.02
•MoE Positive Sentiment 1: it was like , was n’t it ? you ’re far too good . Q-value:
-0.44
•MoE Positive Sentiment 2: it ’s so nice to see you again . Q-value: -0.56
•MoE Negative Sentiment 1: oh , i do n’t care . but it ’s got to be different . Q-value:
-0.11
•MoE Negative Sentiment 2: i do n’t want to hurt you . he ’s not trying to get involved
.Q-value: -0.30
•MoE Sentiment Coherence 1: no . i was just going to say , you know . Q-value:
-0.45
•MoE Sentiment Coherence 2: i do n’t know what else you ’d call it . Q-value: -0.53
•MoE Joy Emotion 1: i can be sure of that when you want your opinion . Q-value:
-0.07
•MoE Joy Emotion 2: it was so obvious . i mean , all of nicky ’s half assed mechanics
, they were real signal happy . Q-value: 0.28
•MoE Optimism Emotion 1: i ’m sure he ’s very ﬂattering , birdie , and i ’m sure there
’s nothing wrong with that . Q-value: -0.15
•MoE Optimism Emotion 2: there you go . that ’s the truth . Q-value: 0.08
•MoE Anger Emotion 1: you do n’t like him , do you ? Q-value: -0.07
•MoE Anger Emotion 2: he ’s sleeping in the back , does n’t he ? Q-value: -0.31
•MoE Sadness Emotion 1: no i was right behind you , but you ’re too dumb to turn
around .Q-value: 0.07
•MoE Sadness Emotion 2: i do n’t know , i ’ve seen him . that ’s the name of a man i
thought .Q-value: -0.25
•Final Bot Response: no . it ’s him , but he did n’t make the choice . Q-value: 0.87
•GPT-based Next-user Response: that left me a surprise . did he say something ?
49

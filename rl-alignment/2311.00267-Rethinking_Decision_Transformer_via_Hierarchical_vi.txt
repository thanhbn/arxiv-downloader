# 2311.00267.pdf
# ÄÃ£ chuyá»ƒn Ä‘á»•i tá»« PDF sang TXT
# ÄÆ°á»ng dáº«n nguá»“n: /home/admin88/arxiv-downloader/rl-alignment/2311.00267.pdf
# KÃ­ch thÆ°á»›c tá»‡p: 2518121 bytes

===============================================
Ná»˜I DUNG Tá»†P PDF
===============================================

--- TRANG 1 ---
Suy nghÄ© láº¡i vá» Decision Transformer thÃ´ng qua Há»c tÄƒng cÆ°á»ng phÃ¢n cáº¥p
Yi Ma1,âˆ—Chenjun Xiao2,âˆ—Hebin Liang1Jianye Hao1,2
1Há»c viá»‡n TrÃ­ tuá»‡ vÃ  TÃ­nh toÃ¡n, Äáº¡i há»c ThiÃªn TÃ¢n2Huawei, PhÃ²ng thÃ­ nghiá»‡m Noah's Ark,
{mayi, lianghebin, jianye.hao}@tju.edu.cn, chenjun@ualberta.ca
TÃ³m táº¯t
Decision Transformer (DT) lÃ  má»™t thuáº­t toÃ¡n Ä‘á»™t phÃ¡ táº­n dá»¥ng nhá»¯ng tiáº¿n bá»™ gáº§n Ä‘Ã¢y cá»§a kiáº¿n trÃºc transformer trong há»c tÄƒng cÆ°á»ng (RL). Tuy nhiÃªn, má»™t háº¡n cháº¿ Ä‘Ã¡ng chÃº Ã½ cá»§a DT lÃ  sá»± phá»¥ thuá»™c vÃ o viá»‡c nhá»› láº¡i cÃ¡c quá»¹ Ä‘áº¡o tá»« táº­p dá»¯ liá»‡u, máº¥t Ä‘i kháº£ nÄƒng liá»n máº¡ch ná»‘i káº¿t cÃ¡c quá»¹ Ä‘áº¡o khÃ´ng tá»‘i Æ°u vá»›i nhau. Trong cÃ´ng trÃ¬nh nÃ y, chÃºng tÃ´i giá»›i thiá»‡u má»™t khung mÃ´ hÃ¬nh hÃ³a chuá»—i tá»•ng quÃ¡t Ä‘á»ƒ nghiÃªn cá»©u viá»‡c Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh tuáº§n tá»± thÃ´ng qua lÄƒng kÃ­nh cá»§a Há»c tÄƒng cÆ°á»ng phÃ¢n cáº¥p. Táº¡i thá»i Ä‘iá»ƒm Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh, má»™t chÃ­nh sÃ¡ch cáº¥p cao trÆ°á»›c tiÃªn Ä‘á» xuáº¥t má»™t prompt lÃ½ tÆ°á»Ÿng cho tráº¡ng thÃ¡i hiá»‡n táº¡i, má»™t chÃ­nh sÃ¡ch cáº¥p tháº¥p sau Ä‘Ã³ táº¡o ra má»™t hÃ nh Ä‘á»™ng Ä‘Æ°á»£c Ä‘iá»u kiá»‡n hÃ³a theo prompt Ä‘Ã£ cho. ChÃºng tÃ´i chá»‰ ra ráº±ng DT xuáº¥t hiá»‡n nhÆ° má»™t trÆ°á»ng há»£p Ä‘áº·c biá»‡t cá»§a khung nÃ y vá»›i cÃ¡c lá»±a chá»n nháº¥t Ä‘á»‹nh vá» chÃ­nh sÃ¡ch cáº¥p cao vÃ  cáº¥p tháº¥p, vÃ  tháº£o luáº­n vá» kháº£ nÄƒng tháº¥t báº¡i tiá»m nÄƒng cá»§a nhá»¯ng lá»±a chá»n nÃ y. ÄÆ°á»£c truyá»n cáº£m há»©ng tá»« nhá»¯ng quan sÃ¡t nÃ y, chÃºng tÃ´i nghiÃªn cá»©u cÃ¡ch tá»‘i Æ°u hÃ³a Ä‘á»“ng thá»i cÃ¡c chÃ­nh sÃ¡ch cáº¥p cao vÃ  cáº¥p tháº¥p Ä‘á»ƒ kÃ­ch hoáº¡t kháº£ nÄƒng ná»‘i káº¿t, Ä‘iá»u nÃ y dáº«n Ä‘áº¿n viá»‡c phÃ¡t triá»ƒn cÃ¡c thuáº­t toÃ¡n RL offline má»›i. Káº¿t quáº£ thá»±c nghiá»‡m cá»§a chÃºng tÃ´i cho tháº¥y rÃµ rÃ ng ráº±ng cÃ¡c thuáº­t toÃ¡n Ä‘Æ°á»£c Ä‘á» xuáº¥t vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ so vá»›i DT trÃªn má»™t sá»‘ benchmark Ä‘iá»u khiá»ƒn vÃ  Ä‘iá»u hÆ°á»›ng. ChÃºng tÃ´i hy vá»ng nhá»¯ng Ä‘Ã³ng gÃ³p cá»§a mÃ¬nh cÃ³ thá»ƒ truyá»n cáº£m há»©ng cho viá»‡c tÃ­ch há»£p cÃ¡c kiáº¿n trÃºc transformer trong lÄ©nh vá»±c RL.

1 Giá»›i thiá»‡u
Má»™t trong nhá»¯ng Ä‘áº·c Ä‘iá»ƒm Ä‘Ã¡ng chÃº Ã½ nháº¥t Ä‘Æ°á»£c quan sÃ¡t trong cÃ¡c mÃ´ hÃ¬nh chuá»—i lá»›n, Ä‘áº·c biá»‡t lÃ  cÃ¡c mÃ´ hÃ¬nh Transformer, lÃ  kháº£ nÄƒng há»c trong ngá»¯ cáº£nh [Radford et al., 2019, Brown et al., 2020, Ramesh et al., 2021, Gao et al., 2020, AkyÃ¼rek et al., 2022, Garg et al., 2022, Laskin et al., 2022, Lee et al., 2023]. Vá»›i má»™t prompt thÃ­ch há»£p, má»™t transformer Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c cÃ³ thá»ƒ há»c cÃ¡c nhiá»‡m vá»¥ má»›i mÃ  khÃ´ng cáº§n giÃ¡m sÃ¡t rÃµ rÃ ng vÃ  cáº­p nháº­t tham sá»‘ bá»• sung. Decision Transformer (DT) lÃ  má»™t phÆ°Æ¡ng phÃ¡p Ä‘á»™t phÃ¡ cá»‘ gáº¯ng khÃ¡m phÃ¡ Ã½ tÆ°á»Ÿng nÃ y cho viá»‡c Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh tuáº§n tá»± [Chen et al., 2021]. KhÃ´ng giá»‘ng nhÆ° cÃ¡c thuáº­t toÃ¡n há»c tÄƒng cÆ°á»ng (RL) truyá»n thá»‘ng, mÃ  há»c má»™t hÃ m giÃ¡ trá»‹ báº±ng bootstrapping hoáº·c tÃ­nh toÃ¡n gradient chÃ­nh sÃ¡ch, DT trá»±c tiáº¿p há»c má»™t mÃ´ hÃ¬nh sinh tá»± há»“i quy tá»« dá»¯ liá»‡u quá»¹ Ä‘áº¡o sá»­ dá»¥ng má»™t causal transformer [Vaswani et al., 2017, Radford et al., 2019]. CÃ¡ch tiáº¿p cáº­n nÃ y cho phÃ©p táº­n dá»¥ng cÃ¡c kiáº¿n trÃºc transformer hiá»‡n cÃ³ Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i trong cÃ¡c nhiá»‡m vá»¥ ngÃ´n ngá»¯ vÃ  thá»‹ giÃ¡c dá»… dÃ ng má»Ÿ rá»™ng, vÃ  hÆ°á»Ÿng lá»£i tá»« má»™t khá»‘i lÆ°á»£ng nghiÃªn cá»©u Ä‘Ã¡ng ká»ƒ táº­p trung vÃ o viá»‡c huáº¥n luyá»‡n á»•n Ä‘á»‹nh transformer [Radford et al., 2019, Brown et al., 2020, Fedus et al., 2022, Chowdhery et al., 2022].

DT Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u quá»¹ Ä‘áº¡o, (ğ‘…0,ğ‘ 0,ğ‘0,â€¦,ğ‘…ğ‘‡,ğ‘ ğ‘‡,ğ‘ğ‘‡), trong Ä‘Ã³ ğ‘…ğ‘¡ lÃ  return-to-go, tá»•ng cá»§a cÃ¡c pháº§n thÆ°á»Ÿng tÆ°Æ¡ng lai dá»c theo quá»¹ Ä‘áº¡o báº¯t Ä‘áº§u tá»« bÆ°á»›c thá»i gian ğ‘¡. Äiá»u nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c xem nhÆ° viá»‡c há»c má»™t mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n hÃ nh Ä‘á»™ng nÃ o nÃªn thá»±c hiá»‡n táº¡i má»™t tráº¡ng thÃ¡i cho trÆ°á»›c Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c nhiá»u return nhÆ° váº­y. Theo Ä‘Ã³, chÃºng ta cÃ³ thá»ƒ xem prompt return-to-go nhÆ° má»™t cÃ´ng táº¯c, hÆ°á»›ng dáº«n mÃ´ hÃ¬nh trong viá»‡c Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh táº¡i thá»i Ä‘iá»ƒm kiá»ƒm tra. Náº¿u má»™t mÃ´ hÃ¬nh nhÆ° váº­y cÃ³ thá»ƒ Ä‘Æ°á»£c há»c hiá»‡u quáº£ vÃ  tá»•ng quÃ¡t hÃ³a tá»‘t ngay cáº£ cho return-to-go ngoÃ i phÃ¢n phá»‘i, thÃ¬ viá»‡c mong Ä‘á»£i DT cÃ³ thá»ƒ táº¡o ra má»™t chÃ­nh sÃ¡ch tá»‘t hÆ¡n báº±ng cÃ¡ch prompting má»™t return cao hÆ¡n lÃ  há»£p lÃ½. Tháº­t khÃ´ng may, Ä‘iá»u nÃ y dÆ°á»ng nhÆ° Ä‘Ã²i há»i má»™t má»©c Ä‘á»™ kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a thÆ°á»ng quÃ¡ cao trong cÃ¡c bÃ i toÃ¡n Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh tuáº§n tá»± thá»±c táº¿. TrÃªn thá»±c táº¿, thÃ¡ch thá»©c chÃ­nh mÃ  DT Ä‘á»‘i máº·t lÃ  lÃ m tháº¿ nÃ o Ä‘á»ƒ cáº£i thiá»‡n tÃ­nh máº¡nh máº½ cá»§a nÃ³ Ä‘á»‘i vá»›i phÃ¢n phá»‘i dá»¯ liá»‡u cÆ¡ báº£n, Ä‘áº·c biá»‡t khi há»c tá»« cÃ¡c quá»¹ Ä‘áº¡o Ä‘Æ°á»£c thu tháº­p bá»Ÿi cÃ¡c chÃ­nh sÃ¡ch khÃ´ng gáº§n vá»›i tá»‘i Æ°u. CÃ¡c nghiÃªn cá»©u gáº§n Ä‘Ã¢y Ä‘Ã£ chá»‰ ra ráº±ng Ä‘á»‘i vá»›i cÃ¡c bÃ i toÃ¡n yÃªu cáº§u kháº£ nÄƒng ná»‘i káº¿t, tá»©c kháº£ nÄƒng tÃ­ch há»£p cÃ¡c quá»¹ Ä‘áº¡o khÃ´ng tá»‘i Æ°u tá»« dá»¯ liá»‡u, DT khÃ´ng thá»ƒ cung cáº¥p lá»£i tháº¿ Ä‘Ã¡ng ká»ƒ so vá»›i behavior cloning [Fujimoto and Gu, 2021, Emmons et al., 2021, Kostrikov et al., 2022, Yamagata et al., 2023, Badrinath et al., 2023, Xiao et al., 2023a]. Äiá»u nÃ y cÃ ng kháº³ng Ä‘á»‹nh ráº±ng má»™t prompt return-to-go ngÃ¢y thÆ¡ khÃ´ng Ä‘á»§ tá»‘t Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh tuáº§n tá»± phá»©c táº¡p.

âˆ—ÄÃ³ng gÃ³p ngang nhau.
1arXiv:2311.00267v1 [cs.LG] 1 Nov 2023

--- TRANG 2 ---
1Causal Transformer
ğ’‘ğ’•âˆ’ğŸğ’”ğ’•âˆ’ğŸğ’‚ğ’•âˆ’ğŸğ’‘ğ’•ğ’‚ğ’•
ğ’”ğ’•ğ’‚ğ’• ğ’‘ğ’•âˆ’ğŸğ’”ğ’•âˆ’ğŸğ’‚ğ’•âˆ’ğŸ
ğœ‹â„ğœ‹â„ğœ‹â„ğ’‚ğ’•âˆ’ğŸ ğ’‚ğ’•âˆ’ğŸ
... ... HÃ¬nh 1: Kiáº¿n trÃºc ADT. ChÃ­nh sÃ¡ch cáº¥p cao táº¡o ra cÃ¡c prompt thÃ´ng bÃ¡o cho chÃ­nh sÃ¡ch cáº¥p tháº¥p Ä‘á»ƒ Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh. ChÃºng tÃ´i ná»‘i prompt vá»›i states thay vÃ¬ coi chÃºng nhÆ° cÃ¡c token riÃªng biá»‡t. CÃ¡c embedding cá»§a token Ä‘Æ°á»£c Ä‘Æ°a vÃ o má»™t causal transformer dá»± Ä‘oÃ¡n actions má»™t cÃ¡ch tá»± há»“i quy.

Tiáº¿n bá»™ gáº§n Ä‘Ã¢y trong cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n cho tháº¥y ráº±ng cÃ¡c prompt Ä‘Æ°á»£c Ä‘iá»u chá»‰nh cáº©n tháº­n, dÃ¹ Ä‘Æ°á»£c viáº¿t bá»Ÿi con ngÆ°á»i hay tá»± khÃ¡m phÃ¡ bá»Ÿi mÃ´ hÃ¬nh, lÃ m tÄƒng Ä‘Ã¡ng ká»ƒ hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh transformer [Lester et al., 2021, Singhal et al., 2022, Zhang et al., 2022, Wei et al., 2022, Wang et al., 2022, Yao et al., 2023, Liu et al., 2023]. Äáº·c biá»‡t, ngÆ°á»i ta Ä‘Ã£ quan sÃ¡t tháº¥y ráº±ng kháº£ nÄƒng thá»±c hiá»‡n lÃ½ luáº­n phá»©c táº¡p xuáº¥t hiá»‡n má»™t cÃ¡ch tá»± nhiÃªn trong cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n Ä‘á»§ lá»›n khi chÃºng Ä‘Æ°á»£c trÃ¬nh bÃ y vá»›i má»™t vÃ i minh chá»©ng chain of thought nhÆ° máº«u trong cÃ¡c prompt [Wei et al., 2022, Wang et al., 2022, Yao et al., 2023]. ÄÆ°á»£c thÃºc Ä‘áº©y bá»Ÿi táº§m quan trá»ng cá»§a nhá»¯ng cÃ´ng trÃ¬nh nÃ y trong cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯, má»™t cÃ¢u há»i náº£y sinh: Äá»‘i vá»›i RL, liá»‡u cÃ³ kháº£ thi khÃ´ng khi há»c Ä‘á»ƒ tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh prompt, sao cho má»™t mÃ´ hÃ¬nh quyáº¿t Ä‘á»‹nh tuáº§n tá»± dá»±a trÃªn transformer cÃ³ thá»ƒ há»c cÃ¡c chÃ­nh sÃ¡ch Ä‘iá»u khiá»ƒn tá»‘i Æ°u tá»« dá»¯ liá»‡u offline? BÃ i bÃ¡o nÃ y cá»‘ gáº¯ng giáº£i quyáº¿t váº¥n Ä‘á» nÃ y. Nhá»¯ng Ä‘Ã³ng gÃ³p chÃ­nh cá»§a chÃºng tÃ´i lÃ :

â€¢ ChÃºng tÃ´i trÃ¬nh bÃ y má»™t khung tá»•ng quÃ¡t Ä‘á»ƒ nghiÃªn cá»©u viá»‡c Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh thÃ´ng qua mÃ´ hÃ¬nh hÃ³a tuáº§n tá»± báº±ng cÃ¡ch káº¿t ná»‘i nÃ³ vá»›i Há»c tÄƒng cÆ°á»ng phÃ¢n cáº¥p [Nachum et al., 2018]: má»™t chÃ­nh sÃ¡ch cáº¥p cao trÆ°á»›c tiÃªn Ä‘á» xuáº¥t má»™t prompt cho tráº¡ng thÃ¡i hiá»‡n táº¡i, má»™t chÃ­nh sÃ¡ch cáº¥p tháº¥p sau Ä‘Ã³ táº¡o ra má»™t hÃ nh Ä‘á»™ng Ä‘Æ°á»£c Ä‘iá»u kiá»‡n hÃ³a theo prompt Ä‘Ã£ cho. ChÃºng tÃ´i cho tháº¥y DT cÃ³ thá»ƒ Ä‘Æ°á»£c khÃ´i phá»¥c nhÆ° má»™t trÆ°á»ng há»£p Ä‘áº·c biá»‡t cá»§a khung nÃ y.

â€¢ ChÃºng tÃ´i Ä‘iá»u tra khi nÃ o vÃ  táº¡i sao DT tháº¥t báº¡i trong viá»‡c ná»‘i káº¿t cÃ¡c quá»¹ Ä‘áº¡o khÃ´ng tá»‘i Æ°u. Äá»ƒ kháº¯c phá»¥c nhÆ°á»£c Ä‘iá»ƒm nÃ y cá»§a DT, chÃºng tÃ´i Ä‘iá»u tra cÃ¡ch tá»‘i Æ°u hÃ³a Ä‘á»“ng thá»i cÃ¡c chÃ­nh sÃ¡ch cáº¥p cao vÃ  cáº¥p tháº¥p Ä‘á»ƒ kÃ­ch hoáº¡t kháº£ nÄƒng ná»‘i káº¿t. Äiá»u nÃ y dáº«n Ä‘áº¿n viá»‡c phÃ¡t triá»ƒn hai thuáº­t toÃ¡n má»›i cho RL offline. Khung tá»‘i Æ°u hÃ³a chÃ­nh sÃ¡ch káº¿t há»£p lÃ  Ä‘Ã³ng gÃ³p chÃ­nh cá»§a chÃºng tÃ´i so vá»›i cÃ¡c nghiÃªn cá»©u trÆ°á»›c Ä‘Ã¢y vá» cáº£i thiá»‡n cÃ¡c mÃ´ hÃ¬nh quyáº¿t Ä‘á»‹nh dá»±a trÃªn transformer [Yamagata et al., 2023, Wu et al., 2023, Badrinath et al., 2023].

â€¢ ChÃºng tÃ´i cung cáº¥p káº¿t quáº£ thÃ­ nghiá»‡m trÃªn má»™t sá»‘ benchmark RL offline, bao gá»“m Ä‘iá»u khiá»ƒn váº­n Ä‘á»™ng, Ä‘iá»u hÆ°á»›ng vÃ  robot, Ä‘á»ƒ chá»©ng minh hiá»‡u quáº£ cá»§a cÃ¡c thuáº­t toÃ¡n Ä‘Æ°á»£c Ä‘á» xuáº¥t. NgoÃ i ra, chÃºng tÃ´i tiáº¿n hÃ nh cÃ¡c nghiÃªn cá»©u ablation ká»¹ lÆ°á»¡ng vá» cÃ¡c thÃ nh pháº§n chÃ­nh cá»§a thuáº­t toÃ¡n Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c hiá»ƒu biáº¿t sÃ¢u sáº¯c hÆ¡n vá» Ä‘Ã³ng gÃ³p cá»§a chÃºng. ThÃ´ng qua cÃ¡c nghiÃªn cá»©u ablation nÃ y, chÃºng tÃ´i Ä‘Ã¡nh giÃ¡ tÃ¡c Ä‘á»™ng cá»§a cÃ¡c thiáº¿t káº¿ thuáº­t toÃ¡n cá»¥ thá»ƒ Ä‘áº¿n hiá»‡u suáº¥t tá»•ng thá»ƒ.

2 Kiáº¿n thá»©c ná»n

2.1 Há»c tÄƒng cÆ°á»ng Offline
ChÃºng tÃ´i xem xÃ©t QuÃ¡ trÃ¬nh Quyáº¿t Ä‘á»‹nh Markov (MDP) Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh bá»Ÿi ğ‘€={,,ğ‘ƒ,ğ‘Ÿ,ğ›¾}[Puterman, 2014], trong Ä‘Ã³  vÃ   Ä‘áº¡i diá»‡n cho khÃ´ng gian tráº¡ng thÃ¡i vÃ  hÃ nh Ä‘á»™ng. Há»‡ sá»‘ chiáº¿t kháº¥u Ä‘Æ°á»£c cho bá»Ÿi ğ›¾âˆˆ[0,1), ğ‘Ÿâˆ¶Ã—â†’â„ biá»ƒu thá»‹ hÃ m pháº§n thÆ°á»Ÿng, ğ‘ƒâˆ¶Ã—â†’Î”() Ä‘á»‹nh nghÄ©a dynamics chuyá»ƒn Ä‘á»•i1. Äáº·t ğœ=(ğ‘ 0,ğ‘0,ğ‘Ÿ0,â€¦,ğ‘ ğ‘‡,ğ‘ğ‘‡,ğ‘Ÿğ‘‡) lÃ  má»™t quá»¹ Ä‘áº¡o. Return cá»§a nÃ³

1ChÃºng tÃ´i sá»­ dá»¥ng Î”() Ä‘á»ƒ biá»ƒu thá»‹ táº­p há»£p cÃ¡c phÃ¢n phá»‘i xÃ¡c suáº¥t trÃªn  cho má»™t táº­p há»¯u háº¡n .
2

--- TRANG 3 ---
Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a nhÆ° tá»•ng cÃ³ chiáº¿t kháº¥u cá»§a cÃ¡c pháº§n thÆ°á»Ÿng dá»c theo quá»¹ Ä‘áº¡o: ğ‘…=âˆ‘ğ‘‡
ğ‘¡=0ğ›¾ğ‘¡ğ‘Ÿğ‘¡. Cho má»™t chÃ­nh sÃ¡ch ğœ‹âˆ¶â†’Î”(), chÃºng ta sá»­ dá»¥ng ğ”¼ğœ‹ Ä‘á»ƒ biá»ƒu thá»‹ ká»³ vá»ng dÆ°á»›i phÃ¢n phá»‘i Ä‘Æ°á»£c táº¡o ra bá»Ÿi sá»± káº¿t ná»‘i giá»¯a ğœ‹ vÃ  mÃ´i trÆ°á»ng. HÃ m giÃ¡ trá»‹ xÃ¡c Ä‘á»‹nh tá»•ng pháº§n thÆ°á»Ÿng cÃ³ chiáº¿t kháº¥u tÆ°Æ¡ng lai thu Ä‘Æ°á»£c báº±ng cÃ¡ch tuÃ¢n theo chÃ­nh sÃ¡ch ğœ‹,

ğ‘‰ğœ‹(ğ‘ )=ğ”¼ğœ‹
[âˆ
âˆ‘
ğ‘¡=0ğ›¾ğ‘¡ğ‘Ÿ(ğ‘ ğ‘¡,ğ‘ğ‘¡)|||ğ‘ 0=ğ‘ ], (1)

Tá»“n táº¡i má»™t chÃ­nh sÃ¡ch tá»‘i Æ°u ğœ‹âˆ— tá»‘i Ä‘a hÃ³a giÃ¡ trá»‹ cho táº¥t cáº£ cÃ¡c tráº¡ng thÃ¡i ğ‘ âˆˆ.

Trong cÃ´ng trÃ¬nh nÃ y, chÃºng tÃ´i xem xÃ©t viá»‡c há»c má»™t chÃ­nh sÃ¡ch Ä‘iá»u khiá»ƒn tá»‘i Æ°u tá»« táº­p dá»¯ liá»‡u offline Ä‘Ã£ thu tháº­p trÆ°á»›c Ä‘Ã³, ={ğœğ‘–}ğ‘›âˆ’1
ğ‘–=0, bao gá»“m ğ‘› quá»¹ Ä‘áº¡o. Má»—i quá»¹ Ä‘áº¡o Ä‘Æ°á»£c táº¡o ra bá»Ÿi quy trÃ¬nh sau: má»™t tráº¡ng thÃ¡i ban Ä‘áº§u ğ‘ 0âˆ¼ğœ‡0 Ä‘Æ°á»£c láº¥y máº«u tá»« phÃ¢n phá»‘i tráº¡ng thÃ¡i ban Ä‘áº§u ğœ‡0; cho bÆ°á»›c thá»i gian ğ‘¡â‰¥0, ğ‘ğ‘¡âˆ¼ğœ‹, ğ‘ ğ‘¡+1âˆ¼ğ‘ƒ(â‹…|ğ‘ ğ‘¡,ğ‘ğ‘¡), ğ‘Ÿğ‘¡=ğ‘Ÿ(ğ‘ ğ‘¡,ğ‘ğ‘¡), quÃ¡ trÃ¬nh nÃ y láº·p láº¡i cho Ä‘áº¿n khi Ä‘áº¡t Ä‘Æ°á»£c bÆ°á»›c thá»i gian tá»‘i Ä‘a cá»§a mÃ´i trÆ°á»ng. á» Ä‘Ã¢y ğœ‹ lÃ  má»™t chÃ­nh sÃ¡ch hÃ nh vi chÆ°a biáº¿t. Trong RL offline, thuáº­t toÃ¡n há»c chá»‰ cÃ³ thá»ƒ láº¥y máº«u tá»«  mÃ  khÃ´ng thu tháº­p dá»¯ liá»‡u má»›i tá»« mÃ´i trÆ°á»ng [Levine et al., 2020].

2.2 Decision Transformer
Decision Transformer (DT) lÃ  má»™t vÃ­ dá»¥ phi thÆ°á»ng ná»‘i cáº§u giá»¯a mÃ´ hÃ¬nh hÃ³a chuá»—i vá»›i viá»‡c Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh [Chen et al., 2021]. NÃ³ cho tháº¥y ráº±ng má»™t mÃ´ hÃ¬nh Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh tuáº§n tá»± cÃ³ thá»ƒ Ä‘Æ°á»£c táº¡o ra thÃ´ng qua viá»‡c chá»‰nh sá»­a tá»‘i thiá»ƒu kiáº¿n trÃºc transformer [Vaswani et al., 2017, Radford et al., 2019]. NÃ³ xem xÃ©t biá»ƒu diá»…n quá»¹ Ä‘áº¡o sau Ä‘Ã¢y cho phÃ©p huáº¥n luyá»‡n vÃ  táº¡o sinh tá»± há»“i quy:

ğœ=(Ì‚ğ‘…0,ğ‘ 0,ğ‘0,Ì‚ğ‘…1,ğ‘ 1,ğ‘1,â€¦,Ì‚ğ‘…ğ‘‡,ğ‘ ğ‘‡,ğ‘ğ‘‡). (2)

á» Ä‘Ã¢y Ì‚ğ‘…ğ‘¡=âˆ‘ğ‘‡
ğ‘–=ğ‘¡ğ‘Ÿğ‘– lÃ  returns-to-go báº¯t Ä‘áº§u tá»« bÆ°á»›c thá»i gian ğ‘¡. ChÃºng ta kÃ½ hiá»‡u ğœ‹DT(ğ‘ğ‘¡|ğ‘ ğ‘¡,Ì‚ğ‘…ğ‘¡,ğœğ‘¡) lÃ  chÃ­nh sÃ¡ch DT, trong Ä‘Ã³ ğœğ‘¡=(ğ‘ 0,ğ‘0,Ì‚ğ‘…0,â€¦,ğ‘ ğ‘¡âˆ’1ğ‘ğ‘¡âˆ’1,Ì‚ğ‘…ğ‘¡âˆ’1)2 lÃ  quá»¹ Ä‘áº¡o con trÆ°á»›c bÆ°á»›c thá»i gian ğ‘¡. NhÆ° Ä‘Æ°á»£c chá»‰ ra vÃ  xÃ¡c minh bá»Ÿi Lee et al. [2023], ğœğ‘¡ cÃ³ thá»ƒ Ä‘Æ°á»£c xem nhÆ° má»™t Ä‘áº§u vÃ o ngá»¯ cáº£nh cá»§a má»™t chÃ­nh sÃ¡ch, táº­n dá»¥ng Ä‘áº§y Ä‘á»§ kháº£ nÄƒng há»c trong ngá»¯ cáº£nh cá»§a mÃ´ hÃ¬nh transformer Ä‘á»ƒ tá»•ng quÃ¡t hÃ³a tá»‘t hÆ¡n [AkyÃ¼rek et al., 2022, Garg et al., 2022, Laskin et al., 2022].

DT gÃ¡n má»™t returns-to-go mong muá»‘n ğ‘…0, cÃ¹ng vá»›i má»™t tráº¡ng thÃ¡i ban Ä‘áº§u ğ‘ 0 Ä‘Æ°á»£c sá»­ dá»¥ng nhÆ° Ä‘áº§u vÃ o khá»Ÿi táº¡o cá»§a mÃ´ hÃ¬nh. Sau khi thá»±c hiá»‡n hÃ nh Ä‘á»™ng Ä‘Æ°á»£c táº¡o ra, DT giáº£m return mong muá»‘n báº±ng pháº§n thÆ°á»Ÿng Ä‘áº¡t Ä‘Æ°á»£c vÃ  tiáº¿p tá»¥c quÃ¡ trÃ¬nh nÃ y cho Ä‘áº¿n khi episode káº¿t thÃºc. Chen et al. [2021] láº­p luáº­n ráº±ng mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n cÃ³ Ä‘iá»u kiá»‡n cÃ³ thá»ƒ thá»±c hiá»‡n tá»‘i Æ°u hÃ³a chÃ­nh sÃ¡ch mÃ  khÃ´ng sá»­ dá»¥ng láº­p trÃ¬nh Ä‘á»™ng. Tuy nhiÃªn, cÃ¡c cÃ´ng trÃ¬nh gáº§n Ä‘Ã¢y quan sÃ¡t tháº¥y ráº±ng DT thÆ°á»ng cho tháº¥y hiá»‡u suáº¥t kÃ©m hÆ¡n so vá»›i cÃ¡c thuáº­t toÃ¡n RL offline dá»±a trÃªn láº­p trÃ¬nh Ä‘á»™ng khi táº­p dá»¯ liá»‡u offline bao gá»“m cÃ¡c quá»¹ Ä‘áº¡o khÃ´ng tá»‘i Æ°u [Fujimoto and Gu, 2021, Emmons et al., 2021, Kostrikov et al., 2022].

3 Autotuned Decision Transformer
Trong pháº§n nÃ y, chÃºng tÃ´i trÃ¬nh bÃ y Autotuned Decision Transformer (ADT), má»™t mÃ´ hÃ¬nh quyáº¿t Ä‘á»‹nh dá»±a trÃªn transformer má»›i cÃ³ thá»ƒ ná»‘i káº¿t cÃ¡c quá»¹ Ä‘áº¡o khÃ´ng tá»‘i Æ°u tá»« táº­p dá»¯ liá»‡u offline. Thuáº­t toÃ¡n cá»§a chÃºng tÃ´i Ä‘Æ°á»£c phÃ¡t triá»ƒn dá»±a trÃªn má»™t khung quyáº¿t Ä‘á»‹nh phÃ¢n cáº¥p tá»•ng quÃ¡t trong Ä‘Ã³ DT xuáº¥t hiá»‡n má»™t cÃ¡ch tá»± nhiÃªn nhÆ° má»™t trÆ°á»ng há»£p Ä‘áº·c biá»‡t. Trong khung nÃ y, chÃºng tÃ´i tháº£o luáº­n vá» cÃ¡ch ADT kháº¯c phá»¥c má»™t sá»‘ háº¡n cháº¿ cá»§a DT báº±ng cÃ¡ch tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh prompt cho viá»‡c Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh.

3.1 CÃ¡c quan sÃ¡t chÃ­nh
Thuáº­t toÃ¡n cá»§a chÃºng tÃ´i Ä‘Æ°á»£c phÃ¡t triá»ƒn báº±ng cÃ¡ch xem xÃ©t má»™t khung tá»•ng quÃ¡t káº¿t ná»‘i cÃ¡c mÃ´ hÃ¬nh quyáº¿t Ä‘á»‹nh dá»±a trÃªn transformer vá»›i há»c tÄƒng cÆ°á»ng phÃ¢n cáº¥p (HRL) [Nachum et al., 2018]. Cá»¥ thá»ƒ, chÃºng tÃ´i sá»­ dá»¥ng biá»ƒu diá»…n phÃ¢n cáº¥p sau cá»§a chÃ­nh sÃ¡ch

ğœ‹(ğ‘|ğ‘ )=âˆ«ğœ‹â„(ğ‘|ğ‘ )â‹…ğœ‹ğ‘™(ğ‘|ğ‘ ,ğ‘)ğ‘‘ğ‘, (3)

2ChÃºng tÃ´i Ä‘á»‹nh nghÄ©a ğœ0 lÃ  chuá»—i rá»—ng Ä‘á»ƒ hoÃ n chá»‰nh.
3

--- TRANG 4 ---
trong Ä‘Ã³  lÃ  má»™t táº­p há»£p cÃ¡c prompt. Äá»ƒ Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh, chÃ­nh sÃ¡ch cáº¥p cao ğœ‹â„ trÆ°á»›c tiÃªn táº¡o ra má»™t prompt ğ‘âˆˆ, Ä‘Æ°á»£c hÆ°á»›ng dáº«n bá»Ÿi Ä‘Ã³ chÃ­nh sÃ¡ch cáº¥p tháº¥p ğœ‹ğ‘™ tráº£ vá» má»™t hÃ nh Ä‘á»™ng Ä‘Æ°á»£c Ä‘iá»u kiá»‡n hÃ³a theo ğ‘. DT phÃ¹ há»£p má»™t cÃ¡ch tá»± nhiÃªn vá»›i khung quyáº¿t Ä‘á»‹nh phÃ¢n cáº¥p nÃ y. Xem xÃ©t cÆ¡ cháº¿ prompting giÃ¡ trá»‹ sau. Táº¡i tráº¡ng thÃ¡i ğ‘ âˆˆ, chÃ­nh sÃ¡ch cáº¥p cao táº¡o ra má»™t prompt giÃ¡ trá»‹ thá»±c ğ‘…âˆˆâ„, Ä‘áº¡i diá»‡n cho "TÃ´i muá»‘n thu Ä‘Æ°á»£c ğ‘… returns báº¯t Ä‘áº§u tá»« ğ‘ .". ÄÆ°á»£c thÃ´ng bÃ¡o bá»Ÿi prompt nÃ y, chÃ­nh sÃ¡ch cáº¥p tháº¥p pháº£n há»“i má»™t hÃ nh Ä‘á»™ng ğ‘âˆˆ, "ÄÆ°á»£c, náº¿u báº¡n muá»‘n thu Ä‘Æ°á»£c returns ğ‘…, báº¡n nÃªn thá»±c hiá»‡n hÃ nh Ä‘á»™ng ğ‘ ngay bÃ¢y giá».". ÄÃ¢y chÃ­nh xÃ¡c lÃ  nhá»¯ng gÃ¬ DT lÃ m. NÃ³ Ã¡p dá»¥ng má»™t chÃ­nh sÃ¡ch cáº¥p cao giáº£ máº¡o ban Ä‘áº§u chá»n má»™t prompt return-to-go má»¥c tiÃªu vÃ  sau Ä‘Ã³ giáº£m dáº§n nÃ³ dá»c theo quá»¹ Ä‘áº¡o. ChÃ­nh sÃ¡ch cáº¥p tháº¥p DT, ğœ‹DT(â‹…|ğ‘ ,ğ‘…,ğœ), há»c dá»± Ä‘oÃ¡n hÃ nh Ä‘á»™ng nÃ o nÃªn thá»±c hiá»‡n táº¡i tráº¡ng thÃ¡i ğ‘  Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c returns ğ‘… cho trÆ°á»›c ngá»¯ cáº£nh ğœ.

Äá»ƒ hiá»ƒu rÃµ hÆ¡n vá» sá»± tháº¥t báº¡i cá»§a DT vá»›i dá»¯ liá»‡u khÃ´ng tá»‘i Æ°u, chÃºng tÃ´i xem xÃ©t láº¡i vÃ­ dá»¥ minh há»a Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 2 cá»§a Chen et al. [2021]. Táº­p dá»¯ liá»‡u bao gá»“m cÃ¡c quá»¹ Ä‘áº¡o bÆ°á»›c ngáº«u nhiÃªn vÃ  return-to-go theo tá»«ng tráº¡ng thÃ¡i liÃªn quan cá»§a chÃºng. Giáº£ sá»­ ráº±ng chÃ­nh sÃ¡ch DT ğœ‹DT hoÃ n toÃ n ghi nhá»› táº¥t cáº£ thÃ´ng tin quá»¹ Ä‘áº¡o cÃ³ trong táº­p dá»¯ liá»‡u. Prompt return-to-go thá»±c táº¿ hoáº¡t Ä‘á»™ng nhÆ° má»™t cÃ´ng táº¯c Ä‘á»ƒ hÆ°á»›ng dáº«n mÃ´ hÃ¬nh Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh. Äáº·t (ğ‘ ) lÃ  táº­p há»£p cÃ¡c quá»¹ Ä‘áº¡o báº¯t Ä‘áº§u tá»« ğ‘  Ä‘Æ°á»£c lÆ°u trá»¯ trong táº­p dá»¯ liá»‡u, vÃ  ğ‘…(ğœ) lÃ  return cá»§a má»™t quá»¹ Ä‘áº¡o ğœ. Cho ğ‘…â€²âˆˆ{ğ‘…(ğœ),ğœâˆˆ(ğ‘ )}, ğœ‹DT cÃ³ thá»ƒ Ä‘Æ°a ra má»™t hÃ nh Ä‘á»™ng dáº«n tá»›i ğœ. Do Ä‘Ã³, cho má»™t oracle return ğ‘…âˆ—(ğ‘ )=max ğœâˆˆ(ğ‘ )ğ‘…(ğœ), dá»± kiáº¿n lÃ  DT cÃ³ thá»ƒ tuÃ¢n theo quá»¹ Ä‘áº¡o tá»‘i Æ°u cÃ³ trong táº­p dá»¯ liá»‡u theo cÃ´ng táº¯c.

CÃ³ má»™t sá»‘ váº¥n Ä‘á». Thá»© nháº¥t, oracle return ğ‘…âˆ— khÃ´ng Ä‘Æ°á»£c biáº¿t. Prompt return-to-go ban Ä‘áº§u cá»§a DT Ä‘Æ°á»£c chá»n báº±ng tay vÃ  cÃ³ thá»ƒ khÃ´ng nháº¥t quÃ¡n vá»›i cÃ¡i Ä‘Æ°á»£c quan sÃ¡t trong táº­p dá»¯ liá»‡u. Äiá»u nÃ y Ä‘Ã²i há»i mÃ´ hÃ¬nh pháº£i tá»•ng quÃ¡t hÃ³a tá»‘t cho return-to-go vÃ  quyáº¿t Ä‘á»‹nh chÆ°a tháº¥y. Thá»© hai, ngay cáº£ khi ğ‘…âˆ— Ä‘Æ°á»£c biáº¿t cho táº¥t cáº£ cÃ¡c tráº¡ng thÃ¡i, viá»‡c ghi nhá»› thÃ´ng tin quá»¹ Ä‘áº¡o váº«n khÃ´ng Ä‘á»§ Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c kháº£ nÄƒng ná»‘i káº¿t vÃ¬ ğ‘…âˆ— chá»‰ phá»¥c vá»¥ nhÆ° má»™t cáº­n dÆ°á»›i cho return Ä‘áº¡t Ä‘Æ°á»£c tá»‘i Ä‘a. Äá»ƒ hiá»ƒu Ä‘iá»u nÃ y, hÃ£y xem xÃ©t má»™t vÃ­ dá»¥ vá»›i hai quá»¹ Ä‘áº¡o ğ‘â†’ğ‘â†’ğ‘, vÃ  ğ‘‘â†’ğ‘â†’ğ‘’. Giáº£ sá»­ ráº±ng ğ‘’ dáº«n Ä‘áº¿n return lÃ  10, trong khi ğ‘ dáº«n Ä‘áº¿n return lÃ  0. Trong trÆ°á»ng há»£p nÃ y, sá»­ dá»¥ng 10 lÃ m prompt return-to-go táº¡i tráº¡ng thÃ¡i ğ‘, DT sáº½ cÃ³ thá»ƒ chuyá»ƒn sang quá»¹ Ä‘áº¡o mong muá»‘n. Tuy nhiÃªn, thÃ´ng tin "nghiÃªng vá» ğ‘ cÃ³ thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c return lÃ  10" khÃ´ng Ä‘Æ°á»£c truyá»n tá»›i ğ‘ trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n, vÃ¬ quá»¹ Ä‘áº¡o ğ‘â†’ğ‘â†’ğ‘’ khÃ´ng tá»“n táº¡i trong dá»¯ liá»‡u. Náº¿u dá»¯ liá»‡u offline chá»©a má»™t quá»¹ Ä‘áº¡o khÃ¡c báº¯t Ä‘áº§u tá»« ğ‘ vÃ  dáº«n Ä‘áº¿n return trung bÃ¬nh (vÃ­ dá»¥ 1), DT cÃ³ thá»ƒ chuyá»ƒn sang quá»¹ Ä‘áº¡o Ä‘Ã³ táº¡i ğ‘ sá»­ dá»¥ng 10 lÃ m prompt return-to-go, bá» lá»¡ má»™t con Ä‘Æ°á»ng há»©a háº¹n hÆ¡n. Do Ä‘Ã³, viá»‡c dá»± Ä‘oÃ¡n chá»‰ Ä‘Æ°á»£c Ä‘iá»u kiá»‡n hÃ³a theo return-to-go khÃ´ng Ä‘á»§ cho tá»‘i Æ°u hÃ³a chÃ­nh sÃ¡ch. Váº«n cáº§n má»™t sá»‘ hÃ¬nh thá»©c lan truyá»n thÃ´ng tin ngÆ°á»£c.

3.2 Thuáº­t toÃ¡n
ADT tá»‘i Æ°u hÃ³a Ä‘á»“ng thá»i cÃ¡c chÃ­nh sÃ¡ch phÃ¢n cáº¥p Ä‘á»ƒ kháº¯c phá»¥c cÃ¡c háº¡n cháº¿ cá»§a DT Ä‘Ã£ tháº£o luáº­n á»Ÿ trÃªn. Má»™t minh há»a kiáº¿n trÃºc ADT Ä‘Æ°á»£c cung cáº¥p trong HÃ¬nh 1. TÆ°Æ¡ng tá»± DT, ADT Ã¡p dá»¥ng má»™t mÃ´ hÃ¬nh transformer cho chÃ­nh sÃ¡ch cáº¥p tháº¥p. Thay vÃ¬ (2), nÃ³ xem xÃ©t biá»ƒu diá»…n quá»¹ Ä‘áº¡o sau,

ğœ=(ğ‘0,ğ‘ 0,ğ‘0,ğ‘1,ğ‘ 1,ğ‘1,â€¦,ğ‘ğ‘‡,ğ‘ ğ‘‡,ğ‘ğ‘‡). (4)

á» Ä‘Ã¢y ğ‘ğ‘– lÃ  prompt Ä‘Æ°á»£c táº¡o ra bá»Ÿi chÃ­nh sÃ¡ch cáº¥p cao ğ‘ğ‘–âˆ¼ğœ‹â„(â‹…|ğ‘ ğ‘–), thay tháº¿ prompt return-to-go Ä‘Æ°á»£c sá»­ dá»¥ng bá»Ÿi DT. Tá»©c lÃ , Ä‘á»‘i vá»›i má»—i quá»¹ Ä‘áº¡o trong táº­p dá»¯ liá»‡u offline, chÃºng tÃ´i gÃ¡n nhÃ£n láº¡i báº±ng cÃ¡ch thÃªm má»™t prompt Ä‘Æ°á»£c táº¡o ra bá»Ÿi cÃ¡c chÃ­nh sÃ¡ch cáº¥p cao cho má»—i chuyá»ƒn Ä‘á»•i. ÄÆ°á»£c trang bá»‹ khung quyáº¿t Ä‘á»‹nh phÃ¢n cáº¥p tá»•ng quÃ¡t nÃ y, chÃºng tÃ´i Ä‘á» xuáº¥t hai thuáº­t toÃ¡n Ã¡p dá»¥ng chiáº¿n lÆ°á»£c táº¡o prompt cáº¥p cao khÃ¡c nhau trong khi chia sáº» má»™t khung tá»‘i Æ°u hÃ³a chÃ­nh sÃ¡ch cáº¥p tháº¥p thá»‘ng nháº¥t. ChÃºng tÃ´i há»c má»™t chÃ­nh sÃ¡ch cáº¥p cao ğœ‹ğœ”â‰ˆğœ‹â„ vá»›i tham sá»‘ ğœ™, vÃ  má»™t chÃ­nh sÃ¡ch cáº¥p tháº¥p ğœ‹ğœƒâ‰ˆğœ‹ğ‘™ vá»›i tham sá»‘ ğœƒ.

3.2.1 Value-prompted Autotuned Decision Transformer
Thuáº­t toÃ¡n Ä‘áº§u tiÃªn cá»§a chÃºng tÃ´i, Value-promped Autotuned Decision Transformer (V-ADT), sá»­ dá»¥ng cÃ¡c giÃ¡ trá»‹ vÃ´ hÆ°á»›ng lÃ m prompt. NhÆ°ng khÃ´ng giá»‘ng DT, nÃ³ Ã¡p dá»¥ng má»™t thiáº¿t káº¿ cÃ³ nguyÃªn táº¯c hÆ¡n cá»§a cÃ¡c prompt giÃ¡ trá»‹ thay vÃ¬ return-to-go. V-ADT nháº±m tráº£ lá»i hai cÃ¢u há»i: giÃ¡ trá»‹ Ä‘áº¡t Ä‘Æ°á»£c tá»‘i Ä‘a báº¯t Ä‘áº§u tá»« tráº¡ng thÃ¡i ğ‘  lÃ  gÃ¬, vÃ  hÃ nh Ä‘á»™ng nÃ o nÃªn thá»±c hiá»‡n Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c giÃ¡ trá»‹ nhÆ° váº­y? Äá»ƒ tráº£ lá»i nhá»¯ng cÃ¢u há»i nÃ y, chÃºng tÃ´i xem táº­p dá»¯ liá»‡u offline nhÆ° má»™t MDP thá»±c nghiá»‡m, ğ‘€={,,ğ‘ƒ,ğ‘Ÿ,ğ›¾}, trong Ä‘Ã³ âŠ† lÃ  táº­p há»£p cÃ¡c tráº¡ng thÃ¡i quan sÃ¡t Ä‘Æ°á»£c trong dá»¯ liá»‡u, ğ‘ƒ lÃ  chuyá»ƒn Ä‘á»•i, Ä‘Ã¢y lÃ  má»™t Æ°á»›c tÃ­nh thá»±c nghiá»‡m cá»§a chuyá»ƒn Ä‘á»•i gá»‘c ğ‘ƒ [Fujimoto et al., 2019]. GiÃ¡ trá»‹ tá»‘i Æ°u cá»§a MDP thá»±c nghiá»‡m nÃ y lÃ 

ğ‘‰âˆ—
(ğ‘ )= max
ğ‘âˆ¶ğœ‹(ğ‘|ğ‘ )>0ğ‘Ÿ(ğ‘ ,ğ‘)+ğ›¾ğ”¼ğ‘ â€²âˆ¼ğ‘ƒ(â‹…|ğ‘ ,ğ‘)[ğ‘‰âˆ—
(ğ‘ â€²)]. (5)
4

--- TRANG 5 ---
Äáº·t ğ‘„âˆ—
(ğ‘ ,ğ‘) lÃ  giÃ¡ trá»‹ tráº¡ng thÃ¡i-hÃ nh Ä‘á»™ng tÆ°Æ¡ng á»©ng. ğ‘‰âˆ—
 Ä‘Æ°á»£c biáº¿t Ä‘áº¿n nhÆ° giÃ¡ trá»‹ tá»‘i Æ°u trong máº«u trong RL offline [Fujimoto et al., 2018, Kostrikov et al., 2022, Xiao et al., 2023b]. TÃ­nh toÃ¡n giÃ¡ trá»‹ nÃ y yÃªu cáº§u thá»±c hiá»‡n láº­p trÃ¬nh Ä‘á»™ng mÃ  khÃ´ng truy váº¥n cÃ¡c hÃ nh Ä‘á»™ng ngoÃ i phÃ¢n phá»‘i. ChÃºng tÃ´i Ã¡p dá»¥ng Implicit Q-learning (IQL) Ä‘á»ƒ há»c ğ‘‰ğœ™â‰ˆğ‘‰âˆ—
 vÃ  ğ‘„ğœ“â‰ˆğ‘„âˆ—
 vá»›i tham sá»‘ ğœ™,ğœ“ [Kostrikov et al., 2022]. Chi tiáº¿t cá»§a IQL Ä‘Æ°á»£c trÃ¬nh bÃ y trong Phá»¥ lá»¥c. BÃ¢y giá» chÃºng tÃ´i mÃ´ táº£ cÃ¡ch V-ADT tá»‘i Æ°u hÃ³a Ä‘á»“ng thá»i cÃ¡c chÃ­nh sÃ¡ch cáº¥p cao vÃ  tháº¥p Ä‘á»ƒ táº¡o Ä‘iá»u kiá»‡n ná»‘i káº¿t.

ChÃ­nh sÃ¡ch cáº¥p cao V-ADT xem xÃ©t =â„ vÃ  Ã¡p dá»¥ng má»™t chÃ­nh sÃ¡ch xÃ¡c Ä‘á»‹nh ğœ‹ğœ”âˆ¶â†’â„, dá»± Ä‘oÃ¡n giÃ¡ trá»‹ tá»‘i Æ°u trong máº«u ğœ‹ğœ”â‰ˆğ‘‰âˆ—
. VÃ¬ chÃºng ta Ä‘Ã£ cÃ³ má»™t giÃ¡ trá»‹ tá»‘i Æ°u trong máº«u xáº¥p xá»‰ ğ‘‰ğœ™, chÃºng ta Ä‘áº·t ğœ‹ğœ”=ğ‘‰ğœ™. ChÃ­nh sÃ¡ch cáº¥p cao nÃ y mang láº¡i hai lá»£i tháº¿ chÃ­nh. Thá»© nháº¥t, cÃ¡ch tiáº¿p cáº­n nÃ y hiá»‡u quáº£ táº¡o Ä‘iá»u kiá»‡n lan truyá»n thÃ´ng tin ngÆ°á»£c vá» cÃ¡c tráº¡ng thÃ¡i sá»›m hÆ¡n trÃªn má»™t quá»¹ Ä‘áº¡o, giáº£i quyáº¿t má»™t háº¡n cháº¿ chÃ­nh cá»§a DT. Äiá»u nÃ y Ä‘áº¡t Ä‘Æ°á»£c báº±ng cÃ¡ch sá»­ dá»¥ng ğ‘‰âˆ—
 lÃ m prompt giÃ¡ trá»‹, Ä‘áº£m báº£o ráº±ng chÃºng ta cÃ³ kiáº¿n thá»©c chÃ­nh xÃ¡c vá» return Ä‘áº¡t Ä‘Æ°á»£c tá»‘i Ä‘a cho báº¥t ká»³ tráº¡ng thÃ¡i nÃ o. Viá»‡c dá»± Ä‘oÃ¡n Ä‘Æ°á»£c Ä‘iá»u kiá»‡n hÃ³a theo ğ‘…âˆ—(ğ‘ ) khÃ´ng Ä‘á»§ cho tá»‘i Æ°u hÃ³a chÃ­nh sÃ¡ch, vÃ¬ ğ‘…âˆ—(ğ‘ )=max ğœâˆˆ(ğ‘ )ğ‘…(ğœ) chá»‰ Ä‘Æ°a ra cáº­n dÆ°á»›i cho ğ‘‰âˆ—
(ğ‘ ) vÃ  do Ä‘Ã³ sáº½ lÃ  hÆ°á»›ng dáº«n yáº¿u hÆ¡n (xem Pháº§n 3.1 Ä‘á»ƒ tháº£o luáº­n chi tiáº¿t). Thá»© hai, Ä‘á»‹nh nghÄ©a cá»§a ğ‘‰âˆ—
 táº­p trung Ä‘á»™c quyá»n vÃ o giÃ¡ trá»‹ tá»‘i Æ°u Ä‘Æ°á»£c rÃºt ra tá»« dá»¯ liá»‡u quan sÃ¡t vÃ  do Ä‘Ã³ trÃ¡nh cÃ¡c return ngoÃ i phÃ¢n phá»‘i. Äiá»u nÃ y ngÄƒn chÃ­nh sÃ¡ch cáº¥p tháº¥p Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh Ä‘Æ°á»£c Ä‘iá»u kiá»‡n hÃ³a theo cÃ¡c prompt Ä‘Ã²i há»i ngoáº¡i suy.

ChÃ­nh sÃ¡ch cáº¥p tháº¥p Viá»‡c huáº¥n luyá»‡n trá»±c tiáº¿p mÃ´ hÃ¬nh Ä‘á»ƒ dá»± Ä‘oÃ¡n quá»¹ Ä‘áº¡o, nhÆ° Ä‘Æ°á»£c thá»±c hiá»‡n trong DT, khÃ´ng phÃ¹ há»£p vá»›i cÃ¡ch tiáº¿p cáº­n cá»§a chÃºng tÃ´i. Äiá»u nÃ y lÃ  do hÃ nh Ä‘á»™ng ğ‘ğ‘¡ quan sÃ¡t trong dá»¯ liá»‡u cÃ³ thá»ƒ khÃ´ng nháº¥t thiáº¿t tÆ°Æ¡ng á»©ng vá»›i hÃ nh Ä‘á»™ng táº¡i tráº¡ng thÃ¡i ğ‘ ğ‘¡ dáº«n Ä‘áº¿n return ğ‘‰âˆ—
(ğ‘ ğ‘¡). Tuy nhiÃªn, xÃ¡c suáº¥t chá»n ğ‘ğ‘¡ nÃªn tá»· lá»‡ thuáº­n vá»›i giÃ¡ trá»‹ cá»§a hÃ nh Ä‘á»™ng nÃ y. Do Ä‘Ã³, chÃºng tÃ´i sá»­ dá»¥ng advantage-weighted regression Ä‘á»ƒ há»c chÃ­nh sÃ¡ch cáº¥p tháº¥p [Peng et al., 2019, Kostrikov et al., 2022, Xiao et al., 2023b]: cho dá»¯ liá»‡u quá»¹ Ä‘áº¡o (4), má»¥c tiÃªu Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a lÃ 

(ğœƒ)=âˆ’ğ‘‡
âˆ‘
ğ‘¡=0exp(ğ‘„ğœ“(ğ‘ ğ‘¡,ğ‘ğ‘¡)âˆ’ğ‘‰ğœ™(ğ‘ ğ‘¡)
ğ›¼ )logğœ‹ğœƒ(ğ‘ğ‘¡|ğ‘ ğ‘¡,ğœ‹ğœ”(ğ‘ ğ‘¡)), (6)

trong Ä‘Ã³ ğ›¼ >0 lÃ  má»™t siÃªu tham sá»‘. ChÃ­nh sÃ¡ch cáº¥p tháº¥p láº¥y Ä‘áº§u ra cá»§a chÃ­nh sÃ¡ch cáº¥p cao lÃ m Ä‘áº§u vÃ o. Äiá»u nÃ y Ä‘áº£m báº£o khÃ´ng cÃ³ sá»± khÃ¡c biá»‡t giá»¯a prompt giÃ¡ trá»‹ huáº¥n luyá»‡n vÃ  kiá»ƒm tra Ä‘Æ°á»£c sá»­ dá»¥ng bá»Ÿi cÃ¡c chÃ­nh sÃ¡ch. ChÃºng tÃ´i lÆ°u Ã½ ráº±ng sá»± khÃ¡c biá»‡t duy nháº¥t cá»§a Ä‘iá»u nÃ y so vá»›i má»¥c tiÃªu maximum log-likelihood tiÃªu chuáº©n cho mÃ´ hÃ¬nh hÃ³a chuá»—i lÃ  Ã¡p dá»¥ng trá»ng sá»‘ cho má»—i chuyá»ƒn Ä‘á»•i. NgÆ°á»i ta cÃ³ thá»ƒ dá»… dÃ ng triá»ƒn khai Ä‘iá»u nÃ y vá»›i dá»¯ liá»‡u quá»¹ Ä‘áº¡o cho má»™t transformer. Trong thá»±c táº¿, chÃºng tÃ´i cÅ©ng quan sÃ¡t tháº¥y ráº±ng lÆ°á»£c Ä‘á»“ tokenization khi xá»­ lÃ½ dá»¯ liá»‡u quá»¹ Ä‘áº¡o áº£nh hÆ°á»Ÿng Ä‘áº¿n hiá»‡u suáº¥t cá»§a ADT. Thay vÃ¬ coi prompt ğ‘ğ‘¡ nhÆ° má»™t token duy nháº¥t nhÆ° trong DT, chÃºng tÃ´i tháº¥y cÃ³ lá»£i khi ná»‘i ğ‘ğ‘¡ vÃ  ğ‘ ğ‘¡ vá»›i nhau vÃ  tokenize vector Ä‘Ã£ ná»‘i. ChÃºng tÃ´i cung cáº¥p má»™t nghiÃªn cá»©u ablation vá» Ä‘iá»u nÃ y trong Pháº§n 5.2.3. Äiá»u nÃ y hoÃ n táº¥t mÃ´ táº£ V-ADT.

3.2.2 Goal-prompted Autotuned Decision Transformer
Trong HRL, chÃ­nh sÃ¡ch cáº¥p cao thÆ°á»ng xem xÃ©t má»™t khÃ´ng gian hÃ nh Ä‘á»™ng tiá»m áº©n. CÃ¡c lá»±a chá»n Ä‘iá»ƒn hÃ¬nh cá»§a hÃ nh Ä‘á»™ng tiá»m áº©n bao gá»“m sub-goal [Nachum et al., 2018, Park et al., 2023], skills [Ajay et al., 2020, Jiang et al., 2022], vÃ  options [Sutton et al., 1999, Bacon et al., 2017, Klissarov and Machado, 2023]. ChÃºng tÃ´i xem xÃ©t bÃ i toÃ¡n Ä‘áº¡t má»¥c tiÃªu nhÆ° má»™t vÃ­ dá»¥ vÃ  sá»­ dá»¥ng sub-goal nhÆ° hÃ nh Ä‘á»™ng tiá»m áº©n, dáº«n Ä‘áº¿n thuáº­t toÃ¡n thá»© hai, Goal-promped Autotuned Decision Transformer (G-ADT). Äáº·t  lÃ  khÃ´ng gian má»¥c tiÃªu3. HÃ m pháº§n thÆ°á»Ÿng cÃ³ Ä‘iá»u kiá»‡n má»¥c tiÃªu ğ‘Ÿ(ğ‘ ,ğ‘,ğ‘”) cung cáº¥p pháº§n thÆ°á»Ÿng cá»§a viá»‡c thá»±c hiá»‡n hÃ nh Ä‘á»™ng ğ‘ táº¡i tráº¡ng thÃ¡i ğ‘  Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c má»¥c tiÃªu ğ‘”âˆˆ. Äáº·t ğ‘‰(ğ‘ ,ğ‘”) lÃ  hÃ m giÃ¡ trá»‹ phá»• quÃ¡t Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a bá»Ÿi cÃ¡c pháº§n thÆ°á»Ÿng cÃ³ Ä‘iá»u kiá»‡n má»¥c tiÃªu [Nachum et al., 2018, Schaul et al., 2015]. TÆ°Æ¡ng tá»±, chÃºng tÃ´i Ä‘á»‹nh nghÄ©a ğ‘‰âˆ—
(ğ‘ ,ğ‘”) vÃ  ğ‘„âˆ—
(ğ‘ ,ğ‘,ğ‘”) lÃ  hÃ m giÃ¡ trá»‹ phá»• quÃ¡t tá»‘i Æ°u trong máº«u. ChÃºng tÃ´i cÅ©ng huáº¥n luyá»‡n ğ‘‰ğœ™â‰ˆğ‘‰âˆ—
 vÃ  ğ‘„ğœ“â‰ˆğ‘„âˆ—
 Ä‘á»ƒ xáº¥p xá»‰ cÃ¡c hÃ m giÃ¡ trá»‹ phá»• quÃ¡t. BÃ¢y giá» chÃºng tÃ´i mÃ´ táº£ cÃ¡ch G-ADT tá»‘i Æ°u hÃ³a Ä‘á»“ng thá»i cÃ¡c chÃ­nh sÃ¡ch.

ChÃ­nh sÃ¡ch cáº¥p cao G-ADT xem xÃ©t = vÃ  sá»­ dá»¥ng má»™t chÃ­nh sÃ¡ch cáº¥p cao ğœ‹ğœ”âˆ¶â†’. Äá»ƒ tÃ¬m Ä‘Æ°á»ng Ä‘i ngáº¯n hÆ¡n, chÃ­nh sÃ¡ch cáº¥p cao ğœ‹ğœ” táº¡o ra má»™t chuá»—i sub-goal ğ‘”ğ‘¡=ğœ‹ğœ”(ğ‘ ğ‘¡) hÆ°á»›ng dáº«n ngÆ°á»i há»c tá»«ng bÆ°á»›c vá» phÃ­a má»¥c tiÃªu cuá»‘i cÃ¹ng. ChÃºng tÃ´i sá»­ dá»¥ng má»™t sub-goal náº±m trong ğ‘˜-bÆ°á»›c xa hÆ¡n tá»« tráº¡ng thÃ¡i hiá»‡n táº¡i, trong Ä‘Ã³ ğ‘˜ lÃ  má»™t siÃªu tham sá»‘ cá»§a thuáº­t toÃ¡n Ä‘Æ°á»£c Ä‘iá»u chá»‰nh cho má»—i miá»n [Badrinath et al., 2023, Park et al., 2023]. Cá»¥ thá»ƒ, cho dá»¯ liá»‡u quá»¹ Ä‘áº¡o (4), chÃ­nh sÃ¡ch cáº¥p cao há»c bÆ°á»›c nháº£y k-bÆ°á»›c tá»‘i Æ°u sá»­ dá»¥ng thuáº­t toÃ¡n Hierarchical Implicit Q-learning (HIQL) Ä‘Æ°á»£c Ä‘á» xuáº¥t gáº§n Ä‘Ã¢y [Park et al., 2023]:

(ğœ™)=âˆ’ğ‘‡
âˆ‘
ğ‘¡=0exp(âˆ‘ğ‘˜âˆ’1
ğ‘¡â€²=ğ‘¡ğ›¾ğ‘¡â€²âˆ’ğ‘¡ğ‘Ÿ(ğ‘ ğ‘¡â€²,ğ‘ğ‘¡â€²,ğ‘”)+ğ›¾ğ‘˜ğ‘‰ğœ™(ğ‘ ğ‘¡+ğ‘˜,ğ‘”)âˆ’ğ‘‰ğœ™(ğ‘ ğ‘¡,ğ‘”)
ğ›¼ )logğœ‹ğœ”(ğ‘ ğ‘¡+ğ‘˜|ğ‘ ğ‘¡,ğ‘”).

ChÃ­nh sÃ¡ch cáº¥p tháº¥p ChÃ­nh sÃ¡ch cáº¥p tháº¥p trong G-ADT há»c Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c sub-goal Ä‘Æ°á»£c táº¡o ra bá»Ÿi chÃ­nh sÃ¡ch cáº¥p cao. G-ADT chia sáº» cÃ¹ng má»¥c tiÃªu chÃ­nh sÃ¡ch cáº¥p tháº¥p nhÆ° V-ADT. Cho dá»¯ liá»‡u quá»¹ Ä‘áº¡o (4), nÃ³ xem xÃ©t nhÆ° sau

(ğœƒ)=âˆ’ğ‘‡
âˆ‘
ğ‘¡=0exp(ğ‘„ğœ“(ğ‘ ğ‘¡,ğ‘ğ‘¡,ğœ‹ğœ”(ğ‘ ğ‘¡))âˆ’ğ‘‰ğœ™(ğ‘ ğ‘¡,ğœ‹ğœ”(ğ‘ ğ‘¡))
ğ›¼ )logğœ‹ğœƒ(ğ‘ğ‘¡|ğ‘ ğ‘¡,ğœ‹ğœ”(ğ‘ ğ‘¡)),

LÆ°u Ã½ ráº±ng Ä‘iá»u nÃ y hoÃ n toÃ n giá»‘ng nhÆ° (6) ngoáº¡i trá»« viá»‡c cÃ¡c advantage Ä‘Æ°á»£c tÃ­nh bá»Ÿi cÃ¡c hÃ m giÃ¡ trá»‹ phá»• quÃ¡t. G-ADT cÅ©ng Ã¡p dá»¥ng cÃ¹ng phÆ°Æ¡ng phÃ¡p tokenization nhÆ° V-ADT báº±ng cÃ¡ch ná»‘i ğœ‹ğœ”(ğ‘ ğ‘¡) vÃ  ğ‘ ğ‘¡ vá»›i nhau trÆ°á»›c. Äiá»u nÃ y káº¿t thÃºc mÃ´ táº£ thuáº­t toÃ¡n G-ADT.

4 Tháº£o luáº­n

Loáº¡i Prompt Reed et al. [2022] Ä‘Ã£ Ä‘i sÃ¢u vÃ o kháº£ nÄƒng má»Ÿ rá»™ng tiá»m nÄƒng cá»§a cÃ¡c mÃ´ hÃ¬nh quyáº¿t Ä‘á»‹nh dá»±a trÃªn transformer thÃ´ng qua prompting. Há» cho tháº¥y ráº±ng má»™t causal transformer, Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn cÃ¡c táº­p dá»¯ liá»‡u offline Ä‘a nhiá»‡m vá»¥, thá»ƒ hiá»‡n kháº£ nÄƒng thÃ­ch á»©ng Ä‘Ã¡ng chÃº Ã½ vá»›i cÃ¡c nhiá»‡m vá»¥ má»›i thÃ´ng qua fine-tuning. Kháº£ nÄƒng thÃ­ch á»©ng Ä‘áº¡t Ä‘Æ°á»£c báº±ng cÃ¡ch cung cáº¥p má»™t prompt chuá»—i nhÆ° Ä‘áº§u vÃ o cá»§a mÃ´ hÃ¬nh transformer, thÆ°á»ng Ä‘Æ°á»£c biá»ƒu diá»…n nhÆ° má»™t quá»¹ Ä‘áº¡o minh chá»©ng chuyÃªn gia. KhÃ´ng giá»‘ng cÃ¡c prompt quá»¹ Ä‘áº¡o chuyÃªn gia nhÆ° váº­y, prompt cá»§a chÃºng tÃ´i cÃ³ thá»ƒ Ä‘Æ°á»£c xem nhÆ° má»™t hÃ nh Ä‘á»™ng tiá»m áº©n Ä‘Æ°á»£c táº¡o ra bá»Ÿi chÃ­nh sÃ¡ch cáº¥p cao, phá»¥c vá»¥ nhÆ° hÆ°á»›ng dáº«n cho chÃ­nh sÃ¡ch cáº¥p tháº¥p Ä‘á»ƒ thÃ´ng bÃ¡o quÃ¡ trÃ¬nh Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh cá»§a nÃ³.

So sÃ¡nh vá»›i cÃ¡c cáº£i tiáº¿n DT khÃ¡c Má»™t sá»‘ cÃ´ng trÃ¬nh gáº§n Ä‘Ã¢y Ä‘Ã£ Ä‘Æ°á»£c Ä‘á» xuáº¥t Ä‘á»ƒ kháº¯c phá»¥c cÃ¡c háº¡n cháº¿ cá»§a DT. Yamagata et al. [2023] gÃ¡n nhÃ£n láº¡i dá»¯ liá»‡u quá»¹ Ä‘áº¡o báº±ng cÃ¡ch thay tháº¿ return-to-go vá»›i cÃ¡c giÃ¡ trá»‹ Ä‘Æ°á»£c há»c bá»Ÿi cÃ¡c thuáº­t toÃ¡n RL offline. Badrinath et al. [2023] Ä‘á» xuáº¥t sá»­ dá»¥ng sub-goal lÃ m prompt, hÆ°á»›ng dáº«n chÃ­nh sÃ¡ch DT tÃ¬m Ä‘Æ°á»ng Ä‘i ngáº¯n hÆ¡n trong cÃ¡c bÃ i toÃ¡n Ä‘iá»u hÆ°á»›ng. Wu et al. [2023] há»c returns Ä‘áº¡t Ä‘Æ°á»£c tá»‘i Ä‘a, ğ‘…âˆ—(ğ‘ )=max ğœâˆˆ(ğ‘ )ğ‘…(ğœ), Ä‘á»ƒ tÄƒng cÆ°á»ng kháº£ nÄƒng ná»‘i káº¿t cá»§a DT táº¡i thá»i Ä‘iá»ƒm quyáº¿t Ä‘á»‹nh. Liu and Abbeel [2023] cáº¥u trÃºc dá»¯ liá»‡u quá»¹ Ä‘áº¡o báº±ng cÃ¡ch gÃ¡n nhÃ£n láº¡i return má»¥c tiÃªu cho má»—i quá»¹ Ä‘áº¡o nhÆ° tá»•ng pháº§n thÆ°á»Ÿng tá»‘i Ä‘a trong má»™t chuá»—i quá»¹ Ä‘áº¡o. PhÃ¡t hiá»‡n cá»§a há» cho tháº¥y ráº±ng cÃ¡ch tiáº¿p cáº­n nÃ y cho phÃ©p má»™t mÃ´ hÃ¬nh quyáº¿t Ä‘á»‹nh dá»±a trÃªn transformer tá»± cáº£i thiá»‡n trong cáº£ thá»i gian huáº¥n luyá»‡n vÃ  kiá»ƒm tra. So vá»›i nhá»¯ng ná»— lá»±c trÆ°á»›c Ä‘Ã¢y nÃ y, ADT giá»›i thiá»‡u má»™t khung cÃ³ nguyÃªn táº¯c cá»§a tá»‘i Æ°u hÃ³a chÃ­nh sÃ¡ch phÃ¢n cáº¥p. CÃ¡c nghiÃªn cá»©u thá»±c táº¿ cá»§a chÃºng tÃ´i cho tháº¥y ráº±ng tá»‘i Æ°u hÃ³a Ä‘á»“ng thá»i cÃ¡c chÃ­nh sÃ¡ch cáº¥p cao vÃ  tháº¥p lÃ  chÃ¬a khÃ³a Ä‘á»ƒ tÄƒng cÆ°á»ng hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh quyáº¿t Ä‘á»‹nh dá»±a trÃªn transformer.

5 ThÃ­ nghiá»‡m
ChÃºng tÃ´i Ä‘iá»u tra ba cÃ¢u há»i chÃ­nh trong cÃ¡c thÃ­ nghiá»‡m cá»§a mÃ¬nh. Thá»© nháº¥t, ADT hoáº¡t Ä‘á»™ng tá»‘t nhÆ° tháº¿ nÃ o trÃªn cÃ¡c nhiá»‡m vá»¥ RL offline so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p dá»±a trÃªn DT trÆ°á»›c Ä‘Ã¢y? Thá»© hai, viá»‡c tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh prompt cho mÃ´ hÃ¬nh quyáº¿t Ä‘á»‹nh dá»±a trÃªn transformer cÃ³ cáº§n thiáº¿t khÃ´ng? Thá»© ba, áº£nh hÆ°á»Ÿng cá»§a cÃ¡c chi tiáº¿t triá»ƒn khai khÃ¡c nhau trong ADT Ä‘áº¿n hiá»‡u suáº¥t tá»•ng thá»ƒ nhÆ° tháº¿ nÃ o? ChÃºng tÃ´i giá»›i thiá»‡u Ä‘á»™c giáº£ Ä‘áº¿n Phá»¥ lá»¥c A Ä‘á»ƒ biáº¿t chi tiáº¿t bá»• sung vÃ  cÃ¡c thÃ­ nghiá»‡m bá»• sung.

CÃ¡c bÃ i toÃ¡n Benchmark ChÃºng tÃ´i táº­n dá»¥ng cÃ¡c táº­p dá»¯ liá»‡u qua má»™t sá»‘ miá»n bao gá»“m Gym-Mujoco, AntMaze, vÃ  FrankaKitchen tá»« benchmark RL offline D4RL [Fu et al., 2020]. Äá»‘i vá»›i Mujoco, cÃ¡c táº­p dá»¯ liá»‡u offline Ä‘Æ°á»£c táº¡o ra sá»­ dá»¥ng ba chÃ­nh sÃ¡ch hÃ nh vi riÃªng biá»‡t: '-medium', '-medium-play', vÃ  '-medium-expert', vÃ  tráº£i rá»™ng qua ba nhiá»‡m vá»¥ cá»¥ thá»ƒ: 'halfcheetah', 'hopper', vÃ  'walker2d'. Má»¥c tiÃªu chÃ­nh trong nhiá»‡m vá»¥ Ä‘iá»u hÆ°á»›ng táº§m xa AntMaze lÃ  hÆ°á»›ng dáº«n má»™t robot Ant 8-DoF tá»« vá»‹ trÃ­ báº¯t Ä‘áº§u Ä‘áº¿n má»™t vá»‹ trÃ­ má»¥c tiÃªu Ä‘Æ°á»£c Ä‘á»‹nh trÆ°á»›c. ChÃºng tÃ´i sá»­ dá»¥ng sÃ¡u táº­p dá»¯ liá»‡u bao gá»“m '-umaze', '-umaze-diverse', '-medium-play', 'medium-diverse', '-large-play', vÃ  '-large-diverse'. Miá»n Kitchen táº­p trung vÃ o viá»‡c hoÃ n thÃ nh bá»‘n nhiá»‡m vá»¥ phá»¥ riÃªng biá»‡t sá»­ dá»¥ng robot Franka 9-DoF. ChÃºng tÃ´i sá»­ dá»¥ng ba táº­p dá»¯ liá»‡u thu giá»¯ má»™t loáº¡t cÃ¡c hÃ nh vi: '-complete', '-partial', vÃ  '-mixed' cho miá»n nÃ y.

6

--- TRANG 7 ---
Báº£ng 1: Hiá»‡u suáº¥t cá»§a V-ADT trÃªn táº¥t cáº£ cÃ¡c táº­p dá»¯ liá»‡u. CÃ¡c phÆ°Æ¡ng phÃ¡p bÃªn pháº£i Ä‘Æ°á»ng tháº³ng Ä‘á»©ng lÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p dá»±a trÃªn transformer, Ä‘iá»ƒm sá»‘ cao nháº¥t trong sá»‘ chÃºng Ä‘Æ°á»£c tÃ´ Ä‘áº­m.

Environment TD3+BC CQL IQL DT QLDT V-ADT
halfcheetah-medium-v2 48.3 Â±0.3 44.0Â±5.4 47.4Â±0.2 42.4Â±0.2 42.3Â±0.4 48.7Â±0.2
hopper-medium-v2 59.3 Â±4.2 58.5Â±2.1 66.2Â±5.7 63.5Â±5.2 66.5Â±6.3 60.6Â±2.8
walker2d-medium-v2 83.7 Â±2.1 72.5Â±0.8 78.3Â±8.7 69.2Â±4.9 67.1Â±3.2 80.9Â±3.5
halfcheetah-medium-replay-v2 44.6 Â±0.5 45.5Â±0.5 44.2Â±1.2 35.4Â±1.6 35.6Â±0.5 42.8Â±0.2
hopper-medium-replay-v2 60.9 Â±18.8 95.0 Â±6.4 94.7Â±8.6 43.3Â±23.9 52.1Â±20.3 83.5Â±9.5
walker2d-medium-replay-v2 81.8 Â±5.5 77.2Â±5.5 73.8Â±7.1 58.9Â±7.1 58.2Â±5.1 86.3Â±1.4
halfcheetah-medium-expert-v2 90.7 Â±4.3 91.6Â±2.8 86.7Â±5.3 84.9Â±1.6 79.0Â±7.2 91.7Â±1.5
hopper-medium-expert-v2 98.0 Â±9.4 105.4 Â±6.8 91.5Â±14.3 100.6Â±8.3 94.2Â±8.2 101.6Â±5.4
walker2d-medium-expert-v2 110.1 Â±0.5 108.8Â±0.7 109.6Â±1.0 89.6Â±38.4 101.7 Â±3.4 112.1Â±0.4
mujoco-avg 75.3 Â±4.9 77.6Â±3.4 76.9Â±5.8 65.3Â±10.1 66.3 Â±6.1 78.7Â±2.8
antmaze-umaze-v2 78.6 74.0 87.5 Â±2.6 53.6Â±7.3 67.2Â±2.3 88.2Â±2.5
antmaze-umaze-diverse-v2 71.4 84.0 62.2 Â±13.8 42.2Â±5.4 62.1Â±1.6 58.6Â±4.3
antmaze-medium-play-v2 10.6 61.2 71.2 Â±7.3 0.0Â±0.0 0.0Â±0.0 62.2Â±2.5
antmaze-medium-diverse-v2 3.0 53.7 70.0 Â±10.9 0.0Â±0.0 0.0Â±0.0 52.6Â±1.4
antmaze-large-play-v2 0.2 15.8 39.6 Â±5.8 0.0Â±0.0 0.0Â±0.0 16.6Â±2.9
antmaze-large-diverse-v2 0.0 14.9 47.5 Â±9.5 0.0Â±0.0 0.0Â±0.0 36.4Â±3.6
antmaze-avg 27.3 50.6 63.0 Â±8.3 16.0Â±2.1 21.6Â±0.7 52.4Â±2.9
kitchen-complete-v0 25.0 Â±8.8 43.8 62.5 46.5Â±3.0 38.8Â±15.8 55.1Â±1.4
kitchen-partial-v0 38.3 Â±3.1 49.8 46.3 31.4Â±19.5 36.9Â±10.7 46.0Â±1.6
kitchen-mixed-v0 45.1 Â±9.5 51.0 51.0 25.8Â±5.0 17.7Â±9.5 46.8Â±6.3
kitchen-avg 36.1 Â±7.1 48.2 53.3 34.6Â±9.2 30.5Â±12.0 49.3Â±3.1
average 52.7 63.7 68.3 43.8Â±7.3 45.4Â±5.3 65.0Â±2.9

Báº£ng 2: Hiá»‡u suáº¥t cá»§a G-ADT trÃªn táº¥t cáº£ cÃ¡c táº­p dá»¯ liá»‡u. CÃ¡c phÆ°Æ¡ng phÃ¡p bÃªn pháº£i Ä‘Æ°á»ng tháº³ng Ä‘á»©ng lÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p dá»±a trÃªn transformer, Ä‘iá»ƒm sá»‘ cao nháº¥t trong sá»‘ chÃºng Ä‘Æ°á»£c tÃ´ Ä‘áº­m.

Environment RvS-R/G HIQL WT G-ADT
antmaze-umaze-v2 65.4 Â±4.9 83.9Â±5.3 64.9Â±6.1 83.8Â±2.3
antmaze-umaze-diverse-v2 60.9 Â±2.5 87.6Â±4.8 71.5Â±7.6 83.0Â±3.1
antmaze-medium-play-v2 58.1 Â±12.7 89.9 Â±3.5 62.8Â±5.8 82.0Â±1.7
antmaze-medium-diverse-v2 67.3 Â±8.0 87.0Â±8.4 66.7Â±3.9 83.4Â±1.9
antmaze-large-play-v2 32.4 Â±10.5 87.3 Â±3.7 72.5Â±2.8 71.0Â±1.3
antmaze-large-diverse-v2 36.9 Â±4.8 81.2Â±6.6 72.0Â±3.4 65.4Â±4.9
antmaze-avg 53.5 Â±7.2 86.2Â±5.4 68.4Â±4.9 78.1Â±2.5
kitchen-complete-v0 50.2 Â±3.6 43.8Â±19.5 49.2Â±4.6 51.4Â±1.7
kitchen-partial-v0 51.4 Â±2.6 65.0Â±9.2 63.8Â±3.5 64.2Â±5.1
kitchen-mixed-v0 60.3 Â±9.4 67.7Â±6.8 70.9Â±2.1 69.2Â±3.3
kitchen-avg 54.0 Â±5.2 58.8Â±11.8 61.3Â±3.4 61.6Â±3.4
average 53.7 Â±6.5 77.1Â±7.5 66.0Â±4.4 72.6Â±2.8

CÃ¡c thuáº­t toÃ¡n Baseline ChÃºng tÃ´i so sÃ¡nh hiá»‡u suáº¥t cá»§a ADT vá»›i má»™t sá»‘ baseline Ä‘áº¡i diá»‡n bao gá»“m (1) cÃ¡c phÆ°Æ¡ng phÃ¡p RL offline: TD3+BC [Fujimoto and Gu, 2021], CQL [Kumar et al., 2020] vÃ  IQL [Kostrikov et al., 2022]; (2) cÃ¡c phÆ°Æ¡ng phÃ¡p cÃ³ Ä‘iá»u kiá»‡n giÃ¡ trá»‹: Decision Transformer (DT) [Chen et al., 2021] vÃ  Q-Learning Decision Transformer (QLDT) [Yamagata et al., 2023]; (3) cÃ¡c phÆ°Æ¡ng phÃ¡p cÃ³ Ä‘iá»u kiá»‡n má»¥c tiÃªu: HIQL [Park et al., 2023], RvS [Emmons et al., 2021] vÃ  Waypoint Transformer (WT) [Badrinath et al., 2023]. Táº¥t cáº£ káº¿t quáº£ baseline ngoáº¡i trá»« QLDT Ä‘Æ°á»£c láº¥y tá»« [Badrinath et al., 2023] vÃ  [Park et al., 2023] hoáº·c báº±ng cÃ¡ch cháº¡y cÃ¡c mÃ£ cá»§a kho CORL [Tarasov et al., 2022]. Äá»‘i vá»›i HIQL, chÃºng tÃ´i trÃ¬nh bÃ y hiá»‡u suáº¥t cá»§a HIQL vá»›i biá»ƒu diá»…n má»¥c tiÃªu trong Kitchen vÃ  khÃ´ng cÃ³ biá»ƒu diá»…n má»¥c tiÃªu trong AntMaze, theo triá»ƒn khai cá»§a chÃºng tÃ´i trong ADT, Ä‘á»ƒ Ä‘áº£m báº£o so sÃ¡nh cÃ´ng báº±ng. QLDT vÃ  transformer-based actor cá»§a ADT Ä‘Æ°á»£c triá»ƒn khai dá»±a trÃªn mÃ£ DT trong CORL, vá»›i kiáº¿n trÃºc tÆ°Æ¡ng tá»±. Chi tiáº¿t Ä‘Æ°á»£c Ä‘Æ°a ra trong Phá»¥ lá»¥c. CÃ¡c critic vÃ  cÃ¡c chÃ­nh sÃ¡ch Ä‘á»ƒ táº¡o prompt Ä‘Æ°á»£c sá»­ dá»¥ng trong ADT Ä‘Æ°á»£c triá»ƒn khai láº¡i trong PyTorch theo cÃ¡c mÃ£ chÃ­nh thá»©c cá»§a IQL vÃ  HIQL. Trong táº¥t cáº£ cÃ¡c thÃ­ nghiá»‡m Ä‘Æ°á»£c tiáº¿n hÃ nh, nÄƒm seeds ngáº«u nhiÃªn riÃªng biá»‡t Ä‘Æ°á»£c sá»­ dá»¥ng. Káº¿t quáº£ Ä‘Æ°á»£c mÃ´ táº£ vá»›i khoáº£ng tin cáº­y 95%, Ä‘Æ°á»£c biá»ƒu diá»…n báº±ng cÃ¡c vÃ¹ng tÃ´ mÃ u trong cÃ¡c hÃ¬nh vÃ  thá»ƒ hiá»‡n nhÆ° Ä‘á»™ lá»‡ch chuáº©n trong cÃ¡c báº£ng. Káº¿t quáº£ bÃ¡o cÃ¡o cá»§a ADT trong cÃ¡c báº£ng Ä‘Æ°á»£c thu Ä‘Æ°á»£c báº±ng cÃ¡ch Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh cuá»‘i cÃ¹ng.

5.1 Káº¿t quáº£ chÃ­nh
Báº£ng 1 vÃ  2 trÃ¬nh bÃ y hiá»‡u suáº¥t cá»§a hai biáº¿n thá»ƒ cá»§a ADT Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ trÃªn cÃ¡c táº­p dá»¯ liá»‡u offline. ADT vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c thuáº­t toÃ¡n Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh dá»±a trÃªn transformer trÆ°á»›c Ä‘Ã¢y. So vá»›i DT vÃ  QLDT, hai thuáº­t toÃ¡n dá»±a trÃªn transformer Ä‘á»ƒ Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh, V-ADT thá»ƒ hiá»‡n sá»± vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ Ä‘áº·c biá»‡t trÃªn AntMaze vÃ  Kitchen yÃªu cáº§u kháº£ nÄƒng ná»‘i káº¿t Ä‘á»ƒ thÃ nh cÃ´ng. Trong khi Ä‘Ã³, Báº£ng 2 cho tháº¥y ráº±ng G-ADT vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ so vá»›i WT, má»™t thuáº­t toÃ¡n sá»­ dá»¥ng sub-goal lÃ m prompt cho má»™t chÃ­nh sÃ¡ch transformer. ChÃºng tÃ´i lÆ°u Ã½ ráº±ng ADT cÃ³ hiá»‡u suáº¥t so sÃ¡nh vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p RL offline tiÃªn tiáº¿n. VÃ­ dá»¥, V-ADT vÆ°á»£t trá»™i táº¥t cáº£ cÃ¡c baseline RL offline trong cÃ¡c bÃ i toÃ¡n Mujoco. Trong AntMaze vÃ  Kitchen, V-ADT khá»›p vá»›i hiá»‡u suáº¥t cá»§a IQL, vÃ  vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ so vá»›i TD3+BC vÃ  CQL. Báº£ng 2 káº¿t thÃºc vá»›i nhá»¯ng phÃ¡t hiá»‡n tÆ°Æ¡ng tá»± cho G-ADT.

5.2 CÃ¡c nghiÃªn cá»©u Ablation

5.2.1 Hiá»‡u quáº£ cá»§a Prompting
[Tiáº¿p tá»¥c vá»›i pháº§n cÃ²n láº¡i...]

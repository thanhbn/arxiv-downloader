# 2305.05586.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/rl-alignment/2305.05586.pdf
# Kích thước tệp: 4949740 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
1
RLocator: Học tăng cường cho việc
Định vị lỗi
Partha Chakraborty ,Thành viên sinh viên, IEEE , Mahmoud Alfadel ,Thành viên, IEEE , và Meiyappan Nagappan
Tóm tắt —Các nhà phát triển phần mềm dành một phần thời gian đáng kể để sửa lỗi trong các dự án của họ. Để hợp lý hóa quá trình này, các phương pháp định vị lỗi đã được đề xuất để xác định các tệp mã nguồn có khả năng chịu trách nhiệm cho một lỗi cụ thể. Các nghiên cứu trước đã đề xuất một số kỹ thuật học máy dựa trên độ tương tự cho việc định vị lỗi. Mặc dù có những tiến bộ đáng kể trong các kỹ thuật này, chúng không trực tiếp tối ưu hóa các thước đo đánh giá. Chúng tôi lập luận rằng việc tối ưu hóa trực tiếp các thước đo đánh giá có thể đóng góp tích cực vào hiệu suất của các phương pháp định vị lỗi.

Do đó, trong bài báo này, chúng tôi sử dụng các kỹ thuật Học tăng cường (RL) để tối ưu hóa trực tiếp các thước đo xếp hạng. Chúng tôi đề xuất RLocator, một phương pháp định vị lỗi dựa trên Học tăng cường. Chúng tôi công thức hóa RLocator bằng cách sử dụng Quá trình Quyết định Markov (MDP) để tối ưu hóa trực tiếp các thước đo đánh giá. Chúng tôi trình bày kỹ thuật và đánh giá thực nghiệm nó dựa trên bộ dữ liệu chuẩn gồm 8.316 báo cáo lỗi từ sáu dự án Apache rất phổ biến. Kết quả đánh giá của chúng tôi cho thấy RLocator đạt được Thứ hạng Tương hỗ Trung bình (MRR) là 0,62, Độ chính xác Trung bình (MAP) là 0,59 và điểm Top 1 là 0,46. Chúng tôi so sánh RLocator với ba công cụ định vị lỗi tiên tiến, FLIM, BugLocator và BL-GAN. Đánh giá của chúng tôi cho thấy RLocator vượt trội hơn cả hai phương pháp với biên độ đáng kể, với cải thiện 38,3% về MAP, 36,73% về MRR và 23,68% về thước đo Top K. Những phát hiện này nhấn mạnh rằng việc tối ưu hóa trực tiếp các thước đo đánh giá đóng góp đáng kể vào việc cải thiện hiệu suất của bài toán định vị lỗi.

Thuật ngữ chỉ mục —Học tăng cường, Định vị lỗi, Học sâu

I. GIỚI THIỆU
Lỗi phần mềm là một phần không thể tránh khỏi của việc phát triển phần mềm. Các nhà phát triển dành một phần ba thời gian của họ để gỡ lỗi và sửa lỗi [1]. Sau khi một báo cáo lỗi/vấn đề đã được nộp, nhóm dự án xác định các tệp mã nguồn cần được kiểm tra và sửa đổi để giải quyết vấn đề. Tuy nhiên, việc định vị thủ công các tệp chịu trách nhiệm cho một lỗi là tốn kém (về thời gian và tài nguyên), đặc biệt khi có nhiều tệp và báo cáo lỗi. Hơn nữa, số lượng lỗi được báo cáo thường cao hơn số lượng nhà phát triển có sẵn [2]. Do đó, thời gian sửa lỗi và chi phí bảo trì tăng lên khi tỷ lệ hài lòng của khách hàng giảm [3].

Định vị lỗi là một phương pháp đề cập đến việc xác định các tệp mã nguồn nơi một lỗi cụ thể xuất phát. Cho một báo cáo lỗi, các phương pháp định vị lỗi sử dụng thông tin văn bản trong báo cáo lỗi và các tệp mã nguồn của dự án để liệt kê ngắn các tệp có khả năng bị lỗi. Các nghiên cứu trước đã đề xuất các phương pháp Định vị lỗi dựa trên Truy xuất thông tin (IRBL) khác nhau để giúp các nhà phát triển tăng tốc quá trình gỡ lỗi (ví dụ: Deeplocator [4], CAST [5], KGBugLocator [6], BL-GAN [7]).

Một chủ đề chung trong số các phương pháp này là chúng tuân theo một phương pháp dựa trên độ tương tự để định vị lỗi. Các kỹ thuật như vậy đo lường độ tương tự giữa các báo cáo lỗi và các tệp mã nguồn. Để ước tính độ tương tự, chúng sử dụng các phương pháp khác nhau như khoảng cách cosine [8], Mạng nơ-ron sâu (DNN) [9] và Mạng nơ-ron tích chập (CNN) [5]. Sau đó, chúng xếp hạng các tệp mã nguồn dựa trên điểm tương tự của chúng. Trong giai đoạn huấn luyện của các phương pháp này, mô hình học để tối ưu hóa các thước đo tương tự. Ngược lại, trong giai đoạn kiểm tra, mô hình được kiểm tra với các thước đo xếp hạng (ví dụ: Thứ hạng Tương hỗ Trung bình (MRR) hoặc Độ chính xác Trung bình (MAP)).

Mặc dù hầu hết các phương pháp này đều cho thấy hiệu suất đầy hứa hẹn, chúng tối ưu hóa một thước đo gián tiếp đại diện cho các thước đo hiệu suất. Các nghiên cứu trước [10], [11], [12], [13] đã phát hiện rằng việc tối ưu hóa trực tiếp các thước đo đánh giá đóng góp đáng kể vào việc cải thiện hiệu suất của các vấn đề xếp hạng. Tối ưu hóa trực tiếp cũng hiệu quả hơn so với việc tối ưu hóa các thước đo gián tiếp [13]. Do đó, chúng tôi lập luận rằng việc các giải pháp được đề xuất bởi các nghiên cứu trước cảm nhận được cách một dự đoán sai sẽ ảnh hưởng đến các thước đo đánh giá hiệu suất là thách thức [10]. Nói cách khác, nếu chúng ta sử dụng các thước đo truy xuất (ví dụ: MAP) trong giai đoạn huấn luyện, mô hình sẽ học cách mỗi dự đoán sẽ tác động đến các thước đo đánh giá. Một dự đoán sai sẽ thay đổi thứ hạng của tệp mã nguồn và cuối cùng tác động đến các thước đo đánh giá.

Học tăng cường (RL) là một phân loại con của các phương pháp học máy trong đó không cần dữ liệu được gán nhãn. Trong RL, mô hình không được huấn luyện để dự đoán một giá trị cụ thể. Thay vào đó, mô hình được cung cấp một tín hiệu về lựa chọn đúng hoặc sai trong quá trình huấn luyện [14]. Dựa trên tín hiệu, mô hình cập nhật quyết định của nó. Điều này cho phép RL sử dụng các thước đo đánh giá như MRR và MAP trong giai đoạn huấn luyện và tối ưu hóa trực tiếp các thước đo đánh giá. Hơn nữa, do sử dụng MRR/MAP như một tín hiệu thay vì một nhãn, vấn đề quá khớp sẽ ít phổ biến hơn. Quá trình Quyết định Markov (MDP) là một yếu tố nền tảng của RL. MDP là một khung toán học cho phép việc hình thức hóa các vấn đề quyết định thời gian rời rạc [15]. Các vấn đề thực tế thường cần được hình thức hóa như MDP để áp dụng RL.

© 2024 IEEE. Bản sao trước xuất bản của tác giả. Ấn bản cuối cùng có sẵn trực tuyến tại: https://doi.org/10.1109/TSE.2024.3452595arXiv:2305.05586v3  [cs.SE]  30 Sep 2024

--- TRANG 2 ---
2
Trong bài báo này, chúng tôi trình bày RLocator, một kỹ thuật RL để định vị các lỗi phần mềm trong các tệp mã nguồn. Chúng tôi công thức hóa RLocator thành một MDP. Trong mỗi bước của MDP, chúng tôi sử dụng MRR và MAP như các tín hiệu để hướng dẫn mô hình đến lựa chọn tối ưu. Chúng tôi đánh giá RLocator trên một bộ dữ liệu chuẩn gồm sáu dự án Apache và thấy rằng, so với các kỹ thuật định vị lỗi tiên tiến hiện có, RLocator đạt được cải thiện hiệu suất đáng kể. Mặc dù việc xác định chính xác lý do cho hiệu suất vượt trội của RL so với các kỹ thuật có giám sát khác có thể là thách thức, RL học các phương pháp tổng quát hơn, đặc biệt trong các môi trường động và phức tạp. So với học có giám sát, nó học các phương pháp có khả năng thích ứng cao hơn với nhiều tình huống khác nhau [16], [17], đó là một dạng tổng quát hóa. Ngoài ra, RL thể hiện thành thạo trong các tình huống mà giải pháp tối ưu không được xác định rõ ràng, thể hiện tính linh hoạt của nó qua các nhiệm vụ và lĩnh vực khác nhau [14]. Những yếu tố này có thể đóng góp vào hiệu suất vượt trội của RLocator.

Những đóng góp chính của công trình chúng tôi như sau:
• Chúng tôi trình bày RLocator, một phương pháp định vị lỗi phần mềm dựa trên RL. Tính mới lạ kỹ thuật chính của RLocator là việc sử dụng RL cho định vị lỗi, bao gồm việc công thức hóa quá trình định vị lỗi thành một MDP.
• Chúng tôi cung cấp một đánh giá thực nghiệm của RLocator với 8.316 báo cáo lỗi từ sáu dự án Apache. Khi RLocator có thể định vị, nó đạt được MRR từ 0,49 - 0,62, MAP từ 0,47 - 0,59 và Top 1 từ 0,38 - 0,46 trên tất cả các dự án được nghiên cứu. Ngoài ra, chúng tôi so sánh hiệu suất của RLocator với các phương pháp định vị lỗi tiên tiến. RLocator vượt trội hơn FLIM [18] 38,3% về MAP, 36,73% về MRR và 23,68% về Top K. Hơn nữa, RLocator vượt trội hơn BugLocator [3] 56,86% về MAP, 41,51% về MRR và 26,32% về Top K. Về Top K, RLocator cho thấy hiệu suất cải thiện so với BL-GAN [7], với mức tăng từ 55,26% đến 3,33%. Mức tăng hiệu suất cho MAP và MRR lần lượt là 40,74% và 32,2%.

II. ĐỘNG LỰC
Học tăng cường (RL) nổi bật với khả năng học từ phản hồi, một đặc tính giúp các mô hình tự sửa đổi dựa trên kết quả của các hành động của chúng. Tính năng này được ứng dụng rộng rãi, được ví dụ hóa bởi các nền tảng như Spotify, một dịch vụ phát âm thanh sử dụng RL để học sở thích của người dùng [19]. Mô hình phát triển và thích ứng bằng cách trình bày các lựa chọn âm nhạc và tinh chỉnh các đề xuất thông qua tương tác của người dùng. Tính linh hoạt của RL mở rộng ra ngoài giải trí; các công ty khác nhau [20] và các lĩnh vực [21] tận dụng khả năng học tập và điều chỉnh lặp đi lặp lại của nó.

Thành thạo cần thiết cho việc định vị lỗi thường được thu thập thông qua kinh nghiệm, với các nhà phát triển giàu kinh nghiệm thể hiện khả năng tìm lỗi nhanh hơn so với các đồng nghiệp ít kinh nghiệm hơn [22]. Nhận thức được tầm quan trọng của kinh nghiệm trong việc định vị lỗi, chúng tôi đề xuất việc tích hợp học tăng cường vào lĩnh vực này. Bằng cách sử dụng RL, một mô hình có thể trình bày cho các nhà phát triển các tập hợp tệp mã nguồn như các nguyên nhân có thể của một lỗi và học từ phản hồi của họ để nâng cao kỹ năng định vị lỗi trong phần mềm. Trái ngược với các phương pháp học máy thông thường, chỉ dựa vào dữ liệu được gán nhãn và thiếu khả năng thích ứng dễ dàng, học tăng cường mang lại hai lợi thế riêng biệt: thứ nhất, khả năng học từ phản hồi của nhà phát triển, và thứ hai, việc loại bỏ yêu cầu dữ liệu được gán nhãn trong các tình huống thực tế. Do đó, nghiên cứu của chúng tôi nhằm kết hợp học tăng cường vào việc định vị lỗi, tận dụng khả năng thích ứng và nâng cao hiệu suất thông qua phản hồi lặp đi lặp lại.

III. KIẾN THỨC NỀN TẢNG
Trong phần này, chúng tôi mô tả các thuật ngữ liên quan đến bài toán định vị lỗi, mà chúng tôi sử dụng trong suốt nghiên cứu của mình. Ngoài ra, chúng tôi trình bày tổng quan về học tăng cường.

A. Hệ thống Định vị Lỗi
Một hệ thống định vị lỗi điển hình sử dụng một số nguồn dữ liệu, ví dụ: báo cáo lỗi, dấu vết ngăn xếp và nhật ký, để xác định các tệp mã nguồn chịu trách nhiệm. Một thách thức cụ thể của hệ thống là báo cáo lỗi chứa ngôn ngữ tự nhiên, trong khi các tệp mã nguồn được viết bằng ngôn ngữ lập trình.

Thông thường, các hệ thống định vị lỗi xác định liệu một báo cáo lỗi có liên quan đến một tệp mã nguồn hay không. Để làm điều này, hệ thống trích xuất các đặc trưng từ cả báo cáo lỗi và các tệp mã nguồn. Các nghiên cứu trước đã sử dụng các kỹ thuật như N-gram [23], [24] và Word2Vec [25], [26] để trích xuất các đặc trưng (embedding) từ báo cáo lỗi và các tệp mã nguồn. Các nghiên cứu khác (ví dụ: Devlin et al. [27]) đã giới thiệu mô hình dựa trên transformer BERT đã đạt được hiệu suất cao hơn tất cả các kỹ thuật trước đó. Một trong những lý do mà các mô hình dựa trên transformer hoạt động tốt hơn trong việc trích xuất các đặc trưng văn bản là transformer sử dụng chú ý đa đầu, có thể sử dụng ngữ cảnh dài trong khi tạo embedding. Các nghiên cứu trước đã đề xuất một mô hình BERT đa phương thức [28] cho các ngôn ngữ lập trình, có thể trích xuất các đặc trưng từ cả báo cáo lỗi và các tệp mã nguồn.

Một báo cáo lỗi chủ yếu chứa thông tin liên quan đến hành vi không mong muốn và cách tái tạo nó. Nó chủ yếu bao gồm ID lỗi, tiêu đề, mô tả văn bản về lỗi và phiên bản của cơ sở mã nơi lỗi tồn tại. Báo cáo lỗi có thể có một ví dụ về mã, dấu vết ngăn xếp hoặc nhật ký. Một hệ thống định vị lỗi truy xuất tất cả các tệp mã nguồn từ một kho mã nguồn tại phiên bản cụ thể đó. Ví dụ, giả sử chúng ta có 100 tệp mã nguồn trong một kho ở một phiên bản cụ thể. Sau khi truy xuất 100 tệp từ phiên bản đó, hệ thống sẽ ước tính mức độ liên quan giữa báo cáo lỗi và mỗi tệp trong số 100 tệp. Mức độ liên quan có thể được đo lường theo nhiều cách. Ví dụ, một hệ thống đơn giản có thể kiểm tra có bao nhiêu từ của báo cáo lỗi tồn tại trong mỗi tệp mã nguồn. Một hệ thống tinh vi có thể so sánh embedding bằng khoảng cách cosine [29]. Sau khi ước tính mức độ liên quan, hệ thống xếp hạng các tệp dựa trên điểm liên quan của chúng. Danh sách tệp được xếp hạng là đầu ra cuối cùng của hệ thống định vị lỗi mà các nhà phát triển sẽ sử dụng.

--- TRANG 3 ---
3
B. Học tăng cường
Trong Học tăng cường (RL), agent tương tác với môi trường thông qua quan sát. Một cách chính thức, một quan sát được gọi là "State", S. Trong mỗi state, tại thời điểm t, St, agent thực hiện hành động A dựa trên hiểu biết của nó về state. Sau đó, môi trường cung cấp phản hồi/phần thưởng ℜ và chuyển agent vào một state mới St+1. Chiến lược của agent để xác định hành động tốt nhất, cuối cùng sẽ dẫn đến phần thưởng tích lũy cao nhất, được gọi là policy [30], [14].

Phần thưởng tích lũy (cho đến mục tiêu/kết thúc) mà một agent có thể nhận được nếu nó thực hiện một hành động cụ thể trong một state nhất định được gọi là giá trị Q. Hàm được sử dụng để ước tính giá trị Q thường được gọi là hàm Q hoặc hàm Value.

Trong RL, một agent bắt đầu hành trình từ một state bắt đầu và sau đó tiến về phía trước bằng cách chọn hành động phù hợp. Hành trình kết thúc ở một state kết thúc được xác định trước. Hành trình từ state bắt đầu đến state kết thúc được gọi là episode.

Từ mức độ cao, chúng ta có thể chia các thuật toán RL tiên tiến thành hai lớp. Lớp đầu tiên là các thuật toán model-free, trong đó agent không có kiến thức trước về môi trường. Agent học về môi trường bằng cách tương tác với môi trường. Loại khác là thuật toán model-based. Trong thuật toán model-based, agent sử dụng dự đoán phần thưởng từ mô hình thay vì tương tác với môi trường.

Nhiệm vụ định vị lỗi khá tương tự với môi trường model-free vì chúng ta không thể dự đoán/xác định các tệp bị lỗi mà không kiểm tra báo cáo lỗi và các tệp mã nguồn (mà không tương tác với môi trường). Do đó, chúng tôi sử dụng các thuật toán RL model-free trong nghiên cứu này. Hai biến thể phổ biến của các thuật toán RL model-free là:

• Tối ưu hóa Value: Agent cố gắng học hàm giá trị Q trong các phương pháp tối ưu hóa value. Agent giữ hàm giá trị Q trong bộ nhớ và cập nhật nó dần dần. Nó tham khảo hàm giá trị Q trong một state cụ thể và chọn hành động sẽ cho giá trị (phần thưởng) cao nhất. Một ví dụ về phương pháp dựa trên tối ưu hóa value là Deep Q Network (DQN) [14].

• Tối ưu hóa Policy: Trong phương pháp tối ưu hóa Policy, agent cố gắng học ánh xạ giữa state và hành động sẽ dẫn đến phần thưởng cao nhất. Agent sẽ chọn hành động dựa trên ánh xạ trong một state cụ thể. Một ví dụ về phương pháp dựa trên tối ưu hóa policy là Advantage Actor-Critic (A2C) [31], [14].

A2C là một thuật toán dựa trên policy trong đó agent học một policy tối ưu để giải quyết một vấn đề. Trong Actor-Critic, mô hình actor chọn hành động. Lợi nhuận tương lai (phần thưởng) của hành động được ước tính bằng mô hình critic. Mô hình actor sử dụng mô hình critic để chọn hành động tốt nhất trong bất kỳ state nào. Advantage actor-critic trừ đi một giá trị cơ sở từ lợi nhuận trong bất kỳ timestep nào. A2C với entropy thêm entropy của xác suất của hành động có thể với loss của mô hình actor. Kết quả là, trong bước gradient descent, mô hình cố gắng tối đa hóa entropy của policy đã học. Việc tối đa hóa entropy đảm bảo rằng agent gán xác suất gần như bằng nhau cho một hành động với lợi nhuận tương tự.

IV. RLOCATOR: HỌC TĂNG CƯỜNG CHO ĐỊNH VỊ LỖI
Trong phần này, chúng tôi thảo luận về các bước chúng tôi làm theo để sử dụng RLocator. Đầu tiên, chúng tôi giải thích (trong Phần IV-A) bước tiền xử lý cần thiết để sử dụng RLocator. Sau đó, chúng tôi giải thích (trong Phần IV-B) các bước công thức hóa thiết kế RLocator của chúng tôi. Chúng tôi trình bày tổng quan về phương pháp của chúng tôi trong Hình 1.

A. Tiền xử lý
Trước khi sử dụng các báo cáo lỗi và tệp mã nguồn để huấn luyện mô hình RL, chúng trải qua một loạt các bước tiền xử lý. Các bước được mô tả trong phần này.

Đầu vào: Đầu vào cho công cụ định vị lỗi của chúng tôi là các báo cáo lỗi và tệp mã nguồn liên quan đến một phiên bản cụ thể của kho dự án. Các dự án phần mềm duy trì một kho cho các lỗi hoặc vấn đề của họ (ví dụ: Jira, Github, Bugzilla). Thành phần đầu tiên, báo cáo lỗi, có thể được truy xuất từ các kho vấn đề đó. Chúng tôi sử dụng báo cáo lỗi để có được thành phần thứ hai (tức là mã nguồn) bằng cách xác định phiên bản dự án bị ảnh hưởng bởi lỗi. Thông thường, mỗi báo cáo lỗi được liên kết với một phiên bản hoặc commit SHA của kho dự án. Sau khi xác định phiên bản bị lỗi, chúng tôi thu thập tất cả các tệp mã nguồn từ phiên bản cụ thể của kho mã. Trong giai đoạn huấn luyện, chúng tôi biên dịch các báo cáo lỗi và tệp mã nguồn thành một bộ dữ liệu để sử dụng sau này. Bộ dữ liệu của chúng tôi chứa một tập hợp các báo cáo lỗi trong đó mỗi báo cáo lỗi có tập hợp tệp mã nguồn riêng của nó. Trong việc sử dụng thực tế, RLocator trực tiếp truy cập các báo cáo lỗi và tệp mã nguồn từ kho. Trong Hình 1, chúng tôi minh họa giai đoạn đầu vào nơi chúng tôi nhận báo cáo lỗi và tệp mã nguồn từ bộ dữ liệu.

Lọc ngắn các tệp mã nguồn: Số lượng tệp mã nguồn trong các phiên bản khác nhau của kho có thể khác nhau. Tất cả các tệp mã nguồn có thể tiềm ẩn chịu trách nhiệm cho một lỗi. Trong bước này, chúng tôi xác định K tệp mã nguồn như các ứng viên cho mỗi lỗi. Chúng tôi giới hạn các ứng viên thành K vì chúng tôi không thể truyền một số lượng biến đổi các tệp mã nguồn cho mô hình RL. Hơn nữa, cho rằng RLocator chủ yếu học từ phản hồi của nhà phát triển, việc sử dụng nó có thể chứng tỏ là thách thức đối với một nhà phát triển có nhiều tệp mã nguồn ứng viên. Để minh họa vấn đề, hãy xem xét một kho với 700 tệp. RLocator trình bày các tệp cho nhà phát triển từng cái một để xác minh mức độ liên quan. Phương pháp tuần tự này kéo dài đáng kể thời gian cần thiết để tìm một tệp có liên quan, dẫn đến việc lãng phí thời gian của nhà phát triển. Do đó, việc giới hạn số lượng tệp được hiển thị cho các nhà phát triển bằng cách cung cấp một tập hợp được lọc ngắn để đánh giá là rất quan trọng.

Để xác định K tệp có liên quan nhất, chúng tôi sử dụng ElasticSearch (ES). ES là một công cụ tìm kiếm dựa trên dự án công cụ tìm kiếm Lucene. Nó là một công cụ tìm kiếm và phân tích phân tán, mã nguồn mở cho tất cả các loại dữ liệu, bao gồm văn bản. Nó phân tích và lập chỉ mục các từ/token để khớp văn bản và sử dụng BM25 để xếp hạng các tệp khớp với truy vấn. Chúng tôi sử dụng chỉ mục ES để xác định k tệp mã nguồn hàng đầu liên quan đến một báo cáo lỗi. Theo nghiên cứu của Liu et el. [32] (người đã sử dụng ES trong bối cảnh tìm kiếm mã), chúng tôi xây dựng một chỉ mục ES bằng cách sử dụng các tệp mã nguồn và sau đó truy vấn chỉ mục bằng cách sử dụng báo cáo lỗi làm truy vấn. Sau đó, chúng tôi chọn k tệp đầu tiên có độ tương tự văn bản cao nhất với báo cáo lỗi. Chúng tôi muốn

--- TRANG 4 ---
4
Hình 1. Định vị Lỗi như Quá trình Quyết định Markov.

lưu ý rằng mục tiêu của việc định vị lỗi là để có được các tệp có liên quan được xếp hạng càng gần vị trí thứ 1 càng tốt. Do đó, các thước đo như MAP và MRR có thể đo lường hiệu suất của các kỹ thuật định vị lỗi. Mặc dù người ta có thể lập luận tại sao chúng tôi không chỉ dựa vào ES để xếp hạng các tệp có liên quan, chúng tôi thấy rằng MAP và MRR của việc sử dụng ES là kém. Kỹ thuật dựa trên RL của chúng tôi học từ phản hồi và nhằm xếp hạng lại đầu ra từ ES để có được điểm MAP và MRR cao hơn. Trong Hình 1, chúng tôi minh họa bước tinh chỉnh ứng viên nơi chúng tôi truy vấn ElasticSearch bằng báo cáo lỗi và sử dụng đầu ra để tinh chỉnh các tệp mã nguồn ứng viên.

Lọc báo cáo lỗi và tệp mã nguồn: Một hạn chế của ES là đôi khi nó trả về các tệp không liên quan trong số k tệp mã nguồn có liên quan nhất. Khi không có tệp liên quan nào trong k tệp đầu tiên, nó cản trở việc huấn luyện RLocator bằng phản hồi của nhà phát triển và đưa vào nhiễu. Do đó, chúng tôi sử dụng một bộ phân loại nhị phân dựa trên XGBoost [33] để xác định các trường hợp mà ES có thể trả về không có tệp liên quan nào trong k tệp hàng đầu. Lý do để sử dụng XGBoost là hai mặt: (1) để tối ưu hóa thời gian của nhà phát triển bằng cách không trình bày các tệp không liên quan và (2) để lọc ra nhiễu trong quá trình huấn luyện.

Lọc dựa trên ES không được sử dụng vì các giá trị tương tự của nó không được chuẩn hóa và độ tương tự cosine không thể áp dụng cho dữ liệu văn bản. Chúng tôi cung cấp cho mô hình XGBoost báo cáo lỗi và k tệp hàng đầu được truy xuất bởi ES để xác định xem có tệp nào có liên quan không. Nếu mô hình XGBoost dự đoán không có tệp liên quan nào trong tập hợp, chúng tôi loại trừ những báo cáo lỗi đó và các tệp liên quan của chúng. Mỗi báo cáo lỗi được liên kết với tập hợp tệp mã nguồn duy nhất của nó, vì vậy việc lọc một báo cáo không ảnh hưởng đến những báo cáo khác.

Để xây dựng mô hình, chúng tôi nghiên cứu các đặc trưng quan trọng nhất liên quan đến nhiệm vụ dự đoán. Chúng tôi tham khảo tài liệu liên quan trong lĩnh vực truy xuất thông tin [35], [38], [36] và phân loại báo cáo lỗi [34] để lựa chọn đặc trưng. Danh sách các đặc trưng được tính toán được trình bày trong Bảng I. Đối với bộ dữ liệu của chúng tôi, chúng tôi tính toán các đặc trưng đã chọn và huấn luyện mô hình bằng cách sử dụng xác thực chéo 10-fold. Kết quả cho thấy mô hình phân loại của chúng tôi có độ chính xác là 0,78, độ nhạy là 0,93 và điểm F1 là 0,85. Ngoài ra, mô hình có thể phân loại chính xác 91% bộ dữ liệu (sẽ có các tệp mã nguồn có liên quan trong k tệp hàng đầu được trả về bởi ES).

Sau khi lọc, chúng tôi chuyển mỗi báo cáo lỗi và các tệp mã nguồn của nó cho RLocator. Trong Hình 1, chúng tôi đã mô tả quy trình hoạt động của RLocator. Quy trình làm việc bắt đầu với một bộ dữ liệu được chọn lọc chứa các báo cáo lỗi và tệp mã nguồn. Tiếp theo, chúng tôi lập chỉ mục các tệp mã nguồn vào chỉ mục ES. Từ ES, chúng tôi có được các báo cáo lỗi và danh sách ngắn K tệp mã nguồn được liên kết với những báo cáo lỗi đó. Sau việc lọc ngắn này, chúng tôi sử dụng mô hình XGBoost để dự đoán sự hiện diện của một tệp có liên quan trong K tệp hàng đầu. Nếu ít nhất một tệp có liên quan tồn tại, chúng tôi tiến hành bước tiếp theo bằng cách chuyển các báo cáo lỗi và tệp mã nguồn đã lọc.

--- TRANG 5 ---
5
BẢNG I
MÔ TẢ VÀ LÝ DO CỦA CÁC ĐẶC TRƯNG ĐƯỢC CHỌN.

Đặc trưng | Mô tả | Lý do
---|---|---
Độ dài Báo cáo Lỗi | Độ dài của báo cáo lỗi. | Fan et al. [34] thấy rằng khó định vị lỗi bằng một báo cáo lỗi ngắn. Một báo cáo lỗi ngắn sẽ chứa ít thông tin về lỗi. Do đó, ElasticSearch sẽ khó truy xuất tệp mã nguồn chịu trách nhiệm cho lỗi này.
Độ dài Mã nguồn | Độ dài trung vị của các tệp mã nguồn liên quan đến một lỗi cụ thể. Lưu ý rằng chúng tôi tính độ dài chuỗi của các tệp mã nguồn sau khi loại bỏ các bình luận mã. | Các nghiên cứu trước [35], [36] thấy rằng việc tính toán độ tương tự văn bản là thách thức đối với các văn bản dài. Độ dài của mã nguồn có thể góp phần vào việc giảm hiệu suất của ElasticSearch.
Stacktrace | Khả năng có sẵn của dấu vết ngăn xếp trong báo cáo lỗi. | Schroter et al. [37] thấy rằng các dấu vết ngăn xếp trong báo cáo lỗi có thể giúp quá trình gỡ lỗi vì chúng có thể chứa thông tin hữu ích. Khả năng có sẵn của dấu vết ngăn xếp có thể cải thiện hiệu suất của ElasticSearch.
Tương tự | Tỷ lệ các token tương tự giữa báo cáo lỗi và tệp mã nguồn | Tương tự cho biết lượng thông tin hữu ích trong báo cáo lỗi. Chúng tôi tính toán độ tương tự dựa trên phương trình được trình bày trong Phần VI.

B. Công thức hóa RLocator
Trong bước trước, chúng tôi đã tiền xử lý bộ dữ liệu để huấn luyện mô hình học tăng cường. Chúng tôi lọc ngắn k tệp có liên quan nhất cho mỗi báo cáo lỗi. Sau đó, chúng tôi xác định các báo cáo lỗi mà sẽ không có tệp liên quan nào trong k tệp hàng đầu và lọc ra những báo cáo lỗi đó. Cuối cùng, chúng tôi chuyển k tệp có liên quan hàng đầu cho RLocator. Trong phần này, chúng tôi giải thích cách RLocator sử dụng Học tăng cường cho việc định vị lỗi của nó. Phương pháp của chúng tôi dựa trên niềm tin rằng mỗi báo cáo lỗi chứa các chỉ báo cụ thể, như thuật ngữ và từ khóa, giúp các nhà phát triển xác định các tệp mã nguồn có vấn đề. Ví dụ, trong mã Java, chúng ta có thể gặp ngoại lệ lồng nhau (ngoại lệ dẫn đến ngoại lệ khác, và khác nữa; một ví dụ có sẵn trong Phụ lục trực tuyến [39]). Một nhà phát triển có thể xác định ngoại lệ gốc và phương thức gọi nào (hoặc khối mã nào khác) gây ra điều đó. Sau đó, họ có thể đi đến việc thực hiện phương thức đó trong các tệp mã nguồn. Quá trình này cho thấy rằng các nhà phát triển có thể xác định và sử dụng thông tin quan trọng từ một báo cáo lỗi. Theo các nghiên cứu trước [40], [41], chúng tôi công thức hóa RLocator thành một Quá trình Quyết định Markov (MDP) bằng cách chia vấn đề xếp hạng thành một chuỗi các bước ra quyết định. Một mô hình RL tổng quát có thể được biểu diễn bởi một tuple ⟨S, A, τ, ℜ, π⟩, bao gồm các state, hành động, chuyển đổi, phần thưởng và policy tương ứng. Hình 1 cho thấy tổng quan về phương pháp RLocator của chúng tôi. Tiếp theo, chúng tôi mô tả các bước công thức hóa của mỗi thành phần của RLocator.

States: S là tập hợp các state. Mô hình RL di chuyển từ state này sang state khác cho đến khi nó đạt đến state kết thúc. Để hình thành các state của MDP, chúng tôi áp dụng các bước sau:

Đầu vào:
Đầu vào của MDP của chúng tôi bao gồm một báo cáo lỗi và K tệp mã nguồn có liên quan hàng đầu từ một kho dự án. Chúng tôi sử dụng CodeBERT [28], một mô hình dựa trên transformer, để chuyển đổi văn bản thành embedding, biểu diễn văn bản trong không gian đa chiều. CodeBERT được chọn vì khả năng xử lý ngữ cảnh dài, làm cho nó phù hợp cho các tệp mã nguồn dài nơi các phương thức có thể được khai báo xa cách việc sử dụng chúng. Không giống như Word2Vec, tạo ra embedding tĩnh cho các từ, CodeBERT tạo ra embedding động cho các chuỗi, nắm bắt ngữ cảnh trong quá trình suy luận. Điều này rất quan trọng trong các tệp mã nguồn nơi việc sử dụng biến phụ thuộc vào phạm vi. CodeBERT, được huấn luyện trên các cặp ngôn ngữ tự nhiên và ngôn ngữ lập trình, xử lý cả ngôn ngữ lập trình và ngôn ngữ tự nhiên. Cơ chế tự chú ý của nó đánh giá tầm quan trọng của các thuật ngữ riêng lẻ, giúp liên kết các báo cáo lỗi với các tệp mã nguồn có liên quan. Ví dụ, trong một ngoại lệ lồng nhau Java, các nhà phát triển có thể xác định ngoại lệ chính và chỉ ra khối mã chịu trách nhiệm. RLocator dựa vào cơ chế tự chú ý này để xác định và tận dụng các gợi ý thông tin này một cách hiệu quả.

Trong phương pháp của chúng tôi, như được hiển thị trong Hình 1, mô hình embedding xử lý các báo cáo lỗi và tệp mã nguồn, tạo ra embedding cho các tệp mã nguồn F1, F2, ..., Fk và báo cáo lỗi R.

Concatenation: Sau khi chúng tôi có được embedding cho mã nguồn và báo cáo lỗi, chúng tôi nối chúng lại. Như các nghiên cứu trước [42], [43] đề xuất, việc kết hợp các tập hợp đặc trưng riêng biệt thông qua concatenation và xử lý chúng với một lớp tuyến tính cho phép tương tác hiệu quả giữa các đặc trưng. Hơn nữa, tương tác đặc trưng là cơ bản trong việc xác định độ tương tự [44], [45]. Do đó, với mục tiêu tính toán độ tương tự giữa một cặp báo cáo lỗi và tệp mã nguồn, chúng tôi nối embedding của chúng. Cho ví dụ của chúng tôi trong Hình 1, chúng tôi nối embedding của F1, F2, ..., và Fk với embedding của báo cáo lỗi R một cách độc lập. Bước này dẫn chúng tôi đến việc có được embedding được nối tương ứng E1, E2, ..., và Ek, như được hiển thị trong Hình 1.

Lưu ý rằng mỗi state của MDP bao gồm hai danh sách: một danh sách ứng viên và một danh sách được xếp hạng. Danh sách ứng viên chứa danh sách nối của embedding. Như được hiển thị trong ví dụ của chúng tôi trong Hình 1, danh sách ứng viên chứa E1, E2, ..., và Ek. Trong danh sách ứng viên, embedding mã nguồn (tệp mã và embedding báo cáo lỗi được nối với nhau) được xếp hạng ngẫu nhiên. Danh sách khác là danh sách được xếp hạng của các tệp mã nguồn dựa trên mức độ liên quan của chúng với báo cáo lỗi R. Ban đầu (tại State 1), danh sách ứng viên đầy và danh sách được xếp hạng trống. Trong mỗi lần chuyển đổi state, mô hình di chuyển một embedding từ danh sách ứng viên sang danh sách được xếp hạng dựa trên xác suất chịu trách nhiệm cho một lỗi của chúng. Trong state cuối cùng, danh sách được xếp hạng sẽ đầy và danh sách ứng viên sẽ trống. Chúng tôi mô tả quá trình chọn và xếp hạng một tệp chi tiết trong bước tiếp theo.

Actions: Chúng tôi định nghĩa Actions trong MDP của chúng tôi là việc chọn một tệp từ

--- TRANG 6 ---
6
danh sách ứng viên và di chuyển nó sang danh sách được xếp hạng. Giả sử tại timestep t; mô hình RL chọn embedding E1, thì thứ hạng của tệp cụ thể đó sẽ là t. Trong Hình 1 tại timestamp 1, mô hình chọn embedding được nối của tệp F2. Do đó, thứ hạng của F2 sẽ là 1. Vì trong mỗi timestamp, chúng tôi đang di chuyển một tệp từ danh sách ứng viên sang danh sách được xếp hạng; tổng số tệp sẽ bằng số lượng state và số lượng hành động. Để xác định hành động tốt nhất tiềm năng tại bất kỳ timestamp t nào, chúng tôi sử dụng một mô hình học sâu (DL) (được chỉ ra là Ranking Model trong Hình 1), bao gồm một Mạng nơ-ron tích chập (CNN) theo sau là một Long Short-Term Memory (LSTM) [46]. Theo [47], [48], [49], chúng tôi sử dụng CNN để thiết lập kết nối giữa các tệp mã nguồn và báo cáo lỗi và trích xuất các đặc trưng có liên quan. Như đã đề cập trước đó, các nhà phát triển có được khả năng nhận dạng các gợi ý và sau đó sử dụng chúng để thiết lập mối liên hệ giữa các tệp mã nguồn và báo cáo lỗi. CNN tạo điều kiện cho giai đoạn thứ hai của việc định vị lỗi, liên quan đến việc trích xuất các đặc trưng quan trọng. Đầu vào của CNN là embedding được nối của cả báo cáo lỗi và mỗi tệp mã nguồn, và đầu ra của CNN là các đặc trưng được trích xuất từ embedding kết hợp của báo cáo lỗi và tệp mã nguồn. Các đặc trưng sau đó được sử dụng để tính toán mức độ liên quan.

Mặt khác, LSTM [50] có ý định làm cho mô hình nhận thức về một hạn chế, mà chúng tôi gọi là nhận thức state. Đó là, trong mỗi timestamp, mô hình được phép chọn embedding tốt nhất tiềm năng chưa được chọn, tức là nếu một tệp được chọn tại State i, nó không thể được chọn lại trong một state sau đó (tức là State i+j; j≥1). LSTM giữ lại state và hỗ trợ agent RL trong việc chọn một hành động tiếp theo không xung đột với các hành động trước đó. Do đó, theo các nghiên cứu trước [51], [52], chúng tôi sử dụng LSTM để làm cho mô hình nhận thức về các hành động trước đó. LSTM lấy một tập hợp các vector đặc trưng làm đầu vào và xuất ra id của tệp mã nguồn phù hợp nhất cho state hiện tại.

Transition: τ(S, A) là một hàm τ: S × A→S ánh xạ một state st thành một state mới st+1 để phản ứng với hành động được chọn at. Chọn một hành động at có nghĩa là loại bỏ một tệp khỏi danh sách ứng viên và đặt nó vào danh sách được xếp hạng.

Reward: Một phần thưởng là một giá trị được cung cấp cho agent RL như phản hồi về hành động của họ. Chúng tôi gọi một phần thưởng nhận được từ một hành động là return. Kỹ thuật RL báo hiệu cho agent về hành động phù hợp trong mỗi bước thông qua Hàm Phần thưởng, có thể được mô hình hóa bằng các thước đo truy xuất. Do đó, agent RL có thể học tối ưu hóa các thước đo truy xuất thông qua hàm phần thưởng. Chúng tôi xem xét hai yếu tố quan trọng trong đánh giá xếp hạng: vị trí của các tệp có liên quan và khoảng cách giữa các tệp có liên quan trong danh sách được xếp hạng của embedding. Chúng tôi đã kết hợp cả hai yếu tố trong việc thiết kế hàm phần thưởng được hiển thị dưới đây.

ℜ(S, A) = M*file relevance / log2(t+ 1)*distance (s); nếu A là một hành động chưa được chọn trước đó (1)

ℜ(S, A) = −log2(t+ 1); ngược lại (2)

Hình 2. Ảnh hưởng của M trong biểu đồ phần thưởng-episode.

distance (S) = Avg.(Khoảng cách giữa các tệp liên quan tiếp theo hiện tại được chọn) (3)

Trong Phương trình 1 và 2, t là timestamp, S là State và A là Action. Mean reciprocal rank (MRR) đo lường thứ hạng tương hỗ trung bình của tất cả các tệp có liên quan. Trong Phương trình 1, file relevance / log2(t+1) đại diện cho MRR. Việc sử dụng hàm logarit trong phương trình được thúc đẩy bởi các nghiên cứu trước [53], [54], đã thấy rằng nó dẫn đến một loss ổn định. Khi các tệp có liên quan được xếp hạng cao hơn, độ chính xác trung bình có xu hướng cao hơn. Để khuyến khích hệ thống học tăng cường xếp hạng các tệp có liên quan cao hơn, chúng tôi giới thiệu một cơ chế phạt nếu có khoảng cách lớn hơn giữa hai tệp có liên quan. Bằng cách áp đặt hình phạt này lên agent, chúng tôi khuyến khích nó ưu tiên các tệp có liên quan ở thứ hạng cao hơn, điều này từ đó đóng góp vào Mean Average Precision (MAP).

Chúng tôi minh họa các hàm phần thưởng với một ví dụ dưới đây. Giả định rằng quá trình đạt đến State S6 và các embedding được nối hiện tại được chọn là E1, E2, E3, E4, E5, E6 và mức độ liên quan của chúng với báo cáo lỗi là ⟨0,0,1,0,1,1⟩. Điều này có nghĩa là các embedding (hoặc tệp) này được xếp hạng ở vị trí thứ 3, 5 và 6 có liên quan đến báo cáo lỗi. Vị trí của các tệp có liên quan là ⟨3,5,6⟩, và khoảng cách giữa chúng là ⟨1,0⟩. Do đó, distance (S6) = Avg.⟨1,0⟩ = 0.5. Nếu agent chọn một tệp có liên quan mới, chúng tôi thưởng cho agent M lần thứ hạng tương hỗ của tệp chia cho khoảng cách giữa các tệp liên quan đã được chọn. Trong ví dụ của chúng tôi, tệp được chọn cuối cùng, mức độ liên quan của E6 là 1. Do đó, chúng tôi có các giá trị sau cho Phương trình 1: distance (S6) = 0.5; log2(6 + 1) = 2.8074; file relevance = 1. Lưu ý rằng M là một siêu tham số. Chúng tôi thấy rằng ba là giá trị của M dẫn đến phần thưởng cao nhất cho mô hình RL của chúng tôi. Chúng tôi xác định giá trị tốt nhất cho M bằng cách thử nghiệm với các giá trị khác nhau (1, 3, 6 và 9). Hình 2 cho thấy biểu đồ phần thưởng-episode kết quả bằng cách sử dụng các giá trị khác nhau của M. Do đó, cho M = 3, giá trị của hàm phần thưởng sẽ là ℜ(S, A) = 3*1 / 2.8074*0.5 = 2.14. Phần thưởng có thể thay đổi từ M đến ~0. Một giá trị cao hơn của hàm phần thưởng cho thấy một hành động tốt hơn của mô hình. Cuối cùng, trong trường hợp xếp hạng tối ưu, distance (S) sẽ bằng không. Chúng tôi xử lý trường hợp này bằng cách gán giá trị 1 cho distance (S). Mặc dù chúng tôi đang sử dụng MRR và MAP như các mục tiêu tối ưu hóa, chúng tôi không yêu cầu dữ liệu được gán nhãn. Thay vào đó, nó học từ phản hồi của nhà phát triển. Nó trình bày một tập hợp hạn chế các tệp cho nhà phát triển, tìm kiếm phản hồi của họ. Nếu một nhà phát triển coi một tệp cụ thể là có liên quan, họ có thể nhấp vào nó. Phản hồi nhấp này biểu thị mức độ liên quan của tệp trong tập hợp. RLocator tận dụng đầu vào này tại Phương trình 1 và học quy trình định vị lỗi. Việc kết hợp phản hồi của nhà phát triển có thể gây ra một số bất tiện. Tuy nhiên, tất cả các mô hình học máy đều dễ bị data drift [55], [56], [57], nơi dữ liệu huấn luyện ban đầu không còn khớp với dữ liệu hiện tại, dẫn đến hiệu suất giảm sút. RLocator giải quyết điều này bằng cách liên tục cập nhật việc học của nó dựa trên phản hồi của nhà phát triển.

Chúng tôi giới hạn số lượng hành động thành 31 trong RLocator. Vì số lượng state bằng số lượng hành động, chúng tôi cũng giới hạn số lượng state thành 31. Không gian dự đoán của một agent học tăng cường không thể biến đổi, và số lượng tệp mã nguồn là biến đổi. Do đó, chúng tôi phải cố định số lượng hành động, k, thành một số có thể quản lý phù hợp với bộ nhớ. Chúng tôi sử dụng GPU Nvidia V100 16 GB và thấy rằng với hơn 31 hành động, các script huấn luyện thất bại do lỗi hết bộ nhớ. Do đó, chúng tôi đặt K = 31 để giữ kích thước state dưới tầm kiểm soát. Như đã đề cập trong Phần IV-A, chúng tôi chọn 31 tệp mã nguồn có liên quan hàng đầu từ ES và chuyển chúng cho RLocator, đảm bảo số lượng state và tệp vẫn giống nhau.

C. Quy trình Làm việc của Nhà phát triển
Hình 3. Luồng tương tác của nhà phát triển.

Hình 3 minh họa luồng tương tác của các nhà phát triển sử dụng RLocator, được biểu diễn như một hộp đen trung tâm trong sơ đồ. Chi tiết của RLocator được trình bày trong Hình 1. Quá trình bắt đầu với RLocator nhận hai đầu vào chính: một báo cáo lỗi và tất cả các tệp mã nguồn, được gán nhãn là 1 và 2 tương ứng trong hình. Sau khi xử lý các đầu vào này, RLocator xuất ra một danh sách được xếp hạng gồm 31 tệp mã nguồn, được chỉ ra bởi bước #4. Các nhà phát triển sau đó xem xét danh sách này để xác định và chọn các tệp có thể chứa lỗi; một ví dụ được hiển thị khi một nhà phát triển chọn Tệp 3, được ghi chú là bước #5. Việc lựa chọn này phục vụ như phản hồi cho RLocator, được đánh dấu bởi bước #6, hỗ trợ trong việc tinh chỉnh chiến lược định vị lỗi của nó. Phản hồi từ các nhà phát triển được thể hiện như một giá trị nhị phân: các tệp mà nhà phát triển mở được đánh dấu bằng 1, và tất cả các tệp khác được đánh dấu bằng 0. Ngoài ra, hệ thống cũng có thể chỉ ra việc không thể định vị lỗi cho một báo cáo đã cho, như được hiển thị bởi bước #3. Vòng lặp liên tục này cho phép RLocator cập nhật với các thay đổi trong kỹ thuật và mẫu, nâng cao hiệu suất định vị lỗi của nó.

BẢNG II
THỐNG KÊ BỘ DỮ LIỆU.

Dự án | # Báo cáo Lỗi | Trung bình # Tệp Bị lỗi trên mỗi Lỗi
---|---|---
AspectJ | 593 | 4.0
Birt | 6,182 | 3.8
Eclipse UI | 6,495 | 2.7
JDT | 6,274 | 2.6
SWT | 4,151 | 2.1
Tomcat | 1,056 | 2.4

V. BỘ DỮ LIỆU VÀ CÁC THƯỚC ĐO ĐÁNH GIÁ
Trong phần này, chúng tôi thảo luận về bộ dữ liệu được sử dụng để huấn luyện và đánh giá mô hình của chúng tôi (phần V-A). Sau đó, chúng tôi trình bày các thước đo đánh giá mà chúng tôi sử dụng để đánh giá (phần V-B).

A. Bộ dữ liệu
Trong thí nghiệm của chúng tôi, chúng tôi đánh giá phương pháp của mình trên sáu dự án mã nguồn mở thực tế [58], thường được sử dụng như bộ dữ liệu chuẩn trong các nghiên cứu định vị lỗi [18], [6]. Công trình trước đã cho thấy rằng bộ dữ liệu này có số lượng false positive và negative thấp nhất so với các bộ dữ liệu khác [59], [60], [3], [61], [62]. Theo các nghiên cứu trước, chúng tôi huấn luyện mô hình RLocator của mình riêng biệt cho mỗi dự án Apache (AspectJ, Birt, Eclipse Platform UI, JDT, SWT, Tomcat). Bảng II hiển thị thống kê mô tả về các bộ dữ liệu.

Bộ dữ liệu chứa metadata như ID lỗi, mô tả, timestamp báo cáo, commit SHA của commit sửa lỗi và đường dẫn tệp mã nguồn bị lỗi. Mỗi báo cáo lỗi được liên kết với một commit SHA/phiên bản, và chúng tôi sử dụng phương pháp khớp tập hợp nhiều phiên bản để chỉ sử dụng các tệp mã nguồn được liên kết với mỗi báo cáo cụ thể [59]. Phương pháp này gần giống với quy trình định vị lỗi được thực hiện bởi các nhà phát triển và giảm nhiễu trong bộ dữ liệu, cải thiện hiệu suất của công cụ.

Chúng tôi xác định phiên bản chứa lỗi từ commit SHA và thu thập tất cả các tệp mã nguồn có liên quan từ phiên bản đó, loại trừ mã sửa lỗi. Điều này đảm bảo hệ thống định vị lỗi của chúng tôi bắt chước chặt chẽ các tình huống thực tế.

Để huấn luyện và kiểm tra, chúng tôi sử dụng 91% dữ liệu, sắp xếp bộ dữ liệu theo ngày của báo cáo lỗi và chia nó 60:40 cho huấn luyện và kiểm tra tương ứng. Không giống như các nghiên cứu trước [63] đã sử dụng chia 60:20:20, chúng tôi tái sử dụng dữ liệu validation cho việc kiểm tra để rút ngắn thời gian huấn luyện.

B. Các Thước đo Đánh giá
Bộ dữ liệu được đề xuất bởi Ye et al. [58] cung cấp ground truth liên quan đến mỗi báo cáo lỗi. Ground truth chứa đường dẫn của tệp trong kho dự án đã được sửa đổi để sửa một lỗi cụ thể. Để đánh giá hiệu suất RLocator, chúng tôi sử dụng ground truth và phân tích kết quả thí nghiệm dựa trên ba tiêu chí, được áp dụng rộng rãi trong các nghiên cứu định vị lỗi [3], [5], [6], [7], [8].

• Mean Reciprocal Rank (MRR): Để xác định thứ hạng trung bình của tệp có liên quan trong tập hợp tệp được truy xuất, chúng tôi áp dụng Mean Reciprocal Rank. MRR là thứ hạng tương hỗ trung bình của các tệp mã nguồn cho tất cả các báo cáo lỗi. Chúng tôi trình bày phương trình để tính MRR dưới đây, trong đó A là tập hợp các báo cáo lỗi.

MRR = 1/|A| ∑A 1/(Thứ hạng nhỏ nhất của các tệp có liên quan) (4)

Giả sử chúng ta có hai báo cáo lỗi, báo cáo 1 và báo cáo 2. Đối với mỗi báo cáo lỗi, mô hình định vị lỗi sẽ xếp hạng sáu tệp. Đối với báo cáo 1, ground truth của các tệp được truy xuất là [0,0,1,0,1,0] và đối với báo cáo 2, ground truth của các tệp được truy xuất là [1,0,0,0,0,1]. Trong trường hợp này, thứ hạng nhỏ nhất của các tệp có liên quan lần lượt là 3 và 1 cho báo cáo 1 và báo cáo 2. Bây giờ, MRR = 1/2(1/3+1/1) = 0.67

• Mean Average Precision (MAP): Để xem xét trường hợp một lỗi được liên kết với nhiều tệp mã nguồn, chúng tôi áp dụng Mean Average Precision. Nó cung cấp một thước đo chất lượng của việc truy xuất [3], [64]. MRR chỉ xem xét thứ hạng tốt nhất của các tệp có liên quan; ngược lại, MAP xem xét thứ hạng của tất cả các tệp có liên quan trong danh sách tệp được truy xuất. Do đó, MAP mô tả nhiều hơn và không thiên vị hơn MRR. Precision có nghĩa là việc truy xuất có ồn ào đến mức nào. Nếu chúng ta tính precision trên hai tệp được truy xuất đầu tiên, chúng ta sẽ có precision@2. Để tính average precision, chúng ta phải tìm precision@1, precision@2,... precision@k, và sau đó chúng ta phải lấy trung bình precision tại các điểm khác nhau. Sau khi tính average precision cho mỗi báo cáo lỗi, chúng ta phải tìm mean của average precision để tính MAP.

MAP = 1/|A| ∑A AvgPrecision (Báo cáo i) (5)

Chúng tôi hiển thị tính toán MAP cho ví dụ trước về hai báo cáo lỗi. Average precision cho báo cáo 1 và báo cáo 2 sẽ là 0.37 và 0.67. Vậy, MAP = 1/2(0.36 + 0.67) = 0.52

• Top K: Để so sánh công bằng với các nghiên cứu trước [49], [48] và để trình bày hiểu biết đơn giản về hiệu suất, chúng tôi tính Top K. Top K đo lường hiệu suất xếp hạng tổng thể của mô hình định vị lỗi. Nó chỉ ra tỷ lệ phần trăm các báo cáo lỗi mà ít nhất một nguồn bị lỗi xuất hiện trong số K vị trí hàng đầu trong danh sách được xếp hạng được tạo bởi công cụ định vị lỗi. Theo các nghiên cứu trước (ví dụ: [49], [48]), chúng tôi xem xét ba giá trị của K: 1, 5 và 10.

VI. HIỆU SUẤT RLOCATOR
Chúng tôi đánh giá RLocator trên bộ dữ liệu hold-out bằng các thước đo được mô tả trong Phần V-B. Vì chưa có công cụ định vị lỗi dựa trên RL nào, chúng tôi so sánh RLocator với ba công cụ định vị lỗi tiên tiến: BugLocator, FLIM và BL-GAN.

Một mô tả ngắn về các phương pháp được trình bày dưới đây.
• BugLocator [3]: một công cụ dựa trên IR sử dụng mô hình không gian vector để xác định các tệp mã nguồn có khả năng chịu trách nhiệm bằng cách ước tính độ tương tự giữa tệp mã nguồn và báo cáo lỗi.
• FLIM [18]: một mô hình dựa trên deep-learning sử dụng một mô hình ngôn ngữ lớn như CodeBERT.
• BL-GAN [7]: sử dụng chiến lược đối nghịch sinh để huấn luyện một mô hình transformer dựa trên attention.

Chúng tôi sử dụng các triển khai gốc để đánh giá hiệu suất của BugLocator [3] và FLIM [18]. Ngoài ra, chúng tôi fine-tune một mô hình CodeBERT [28] như một baseline để chứng minh lợi ích của việc sử dụng học tăng cường. Đối với các công cụ như CAST [5], KGBugLocator [6] và BL-GAN [7], thiếu các gói replication, chúng tôi tham chiếu đến các nghiên cứu tương ứng của chúng. Các nghiên cứu này cho thấy rằng KGBugLocator vượt trội hơn CAST, và BL-GAN vượt trội hơn KGBugLocator. Do đó, chúng tôi tái tạo BL-GAN dựa trên mô tả nghiên cứu của nó.

Về FBL-BERT [8], một kỹ thuật gần đây, chúng tôi không so sánh nó với RLocator. Điều này là do FBL-BERT thực hiện định vị lỗi ở cấp độ changeset, và việc áp dụng nó cho bộ dữ liệu cấp độ tệp của chúng tôi sẽ bất lợi cho FBL-BERT, vì nó được thiết kế cho các tài liệu ngắn hơn. Do đó, việc so sánh nó với RLocator sẽ không công bằng.

Hơn nữa, các nghiên cứu khác, như DeepLoc [63], bjXnet [65], CAST [5], KGBugLocator [6] và Cheng et al. [66], cũng đề xuất các phương pháp dựa trên deep learning nhưng không cung cấp các gói replication. Mặc dù các nghiên cứu này đánh giá các dự án tương tự, việc thiếu mã có sẵn hoặc các mô hình được huấn luyện trước ngăn cản việc so sánh thêm. Tuy nhiên, để đảm bảo thông tin toàn diện, chúng tôi bao gồm một bảng trong phụ lục trực tuyến [39] hiển thị hiệu suất của chúng cùng với RLocator.

A. Hiệu suất truy xuất
Chúng tôi sử dụng k=31 tệp có liên quan trong RLocator, cho phép chúng tôi xếp hạng lại các tệp cho 91% báo cáo lỗi. Bảng III hiển thị hiệu suất của RLocator trên 91% và 100% dữ liệu. RLocator không được thiết kế cho 100% dữ liệu vì nó không thể xếp hạng lại các tệp nếu không có tệp liên quan nào trong k tệp hàng đầu. Đối với những trường hợp như vậy, chúng tôi ước tính hiệu suất giả định đóng góp bằng không, cung cấp một giới hạn dưới cho hiệu quả của RLocator. Phương pháp bảo thủ này đảm bảo chúng tôi không đánh giá quá cao hiệu quả của kỹ thuật. Bảng III cho thấy rằng RLocator đạt được hiệu suất tốt hơn BugLocator và FLIM trong cả MRR và MAP trên tất cả các dự án được nghiên cứu khi sử dụng dữ liệu 91%. Trên dữ liệu 91%, RLocator vượt trội hơn FLIM 5.56-38.3% về MAP và 3.77-36.73% về MRR. Về Top K, cải thiện hiệu suất lên đến 23.68%, 15.22% và 11.32% theo Top 1, Top 5 và Top 10 tương ứng. So với BugLocator, RLocator đạt được cải thiện hiệu suất 12.5 - 56.86% và 9.8% - 41.51%, theo MAP và MRR tương ứng. Về Top K, cải thiện hiệu suất lên đến 26.32%, 41.3% và 35.85% theo Top 1, Top 5 và Top 10 tương ứng.

Kết quả chỉ ra rằng RLocator vượt trội hơn BL-GAN một cách nhất quán trong cài đặt 91% trên tất cả các thước đo. Cụ thể, trong các phép đo TopK, hiệu suất của RLocator vượt trội hơn BL-GAN, với cải thiện từ 55.26% đến 3.33%. Ngoài ra, RLocator đạt được mức tăng hiệu suất 40.74% về MAP và 32.2% về MRR tương ứng.

--- TRANG 9 ---
9
BẢNG III
HIỆU SUẤT RLOCATOR.

Dự án | Mô hình | Top 1 | Top 5 | Top 10 | MAP | MRR
---|---|---|---|---|---|---
| | 91% | 100% | 91% | 100% | 91% | 100% | 91% | 100% | 91% | 100%
AspectJ | RLocator | 0.46 | 0.40 | 0.69 | 0.63 | 0.75 | 0.70 | 0.56 | 0.46 | 0.59 | 0.50
| BugLocator | 0.36 | 0.28 | 0.50 | 0.45 | 0.56 | 0.51 | 0.33 | 0.31 | 0.49 | 0.48
| FLIM | 0.51 | 0.36 | 0.65 | 0.60 | 0.72 | 0.67 | 0.41 | 0.35 | 0.47 | 0.45
| CodeBERT | 0.4 | 0.35 | 0.59 | 0.55 | 0.65 | 0.61 | 0.49 | 0.39 | 0.51 | 0.44
| BL-GAN | 0.41 | 0.38 | 0.6 | 0.55 | 0.71 | 0.65 | 0.33 | 0.31 | 0.42 | 0.39
Birt | RLocator | 0.65 | 0.25 | 0.46 | 0.41 | 0.53 | 0.48 | 0.47 | 0.38 | 0.49 | 0.41
| BugLocator | 0.61 | 0.15 | 0.27 | 0.21 | 0.34 | 0.29 | 0.30 | 0.30 | 0.39 | 0.38
| FLIM | 0.49 | 0.18 | 0.39 | 0.34 | 0.47 | 0.42 | 0.29 | 0.25 | 0.31 | 0.28
| CodeBERT | 0.33 | 0.22 | 0.39 | 0.35 | 0.46 | 0.43 | 0.41 | 0.33 | 0.42 | 0.35
| BL-GAN | 0.17 | 0.16 | 0.33 | 0.3 | 0.46 | 0.42 | 0.32 | 0.29 | 0.4 | 0.37
Eclipse Platform UI | RLocator | 0.45 | 0.37 | 0.69 | 0.63 | 0.78 | 0.73 | 0.54 | 0.42 | 0.59 | 0.50
| BugLocator | 0.45 | 0.33 | 0.54 | 0.49 | 0.63 | 0.58 | 0.29 | 0.30 | 0.38 | 0.35
| FLIM | 0.48 | 0.41 | 0.72 | 0.67 | 0.80 | 0.75 | 0.51 | 0.48 | 0.52 | 0.53
| CodeBERT | 0.39 | 0.32 | 0.6 | 0.55 | 0.68 | 0.62 | 0.47 | 0.36 | 0.52 | 0.44
| BL-GAN | 0.34 | 0.31 | 0.53 | 0.49 | 0.66 | 0.61 | 0.32 | 0.3 | 0.4 | 0.36
JDT | RLocator | 0.44 | 0.33 | 0.67 | 0.61 | 0.78 | 0.75 | 0.51 | 0.44 | 0.53 | 0.45
| BugLocator | 0.34 | 0.21 | 0.51 | 0.45 | 0.60 | 0.55 | 0.22 | 0.20 | 0.31 | 0.28
| FLIM | 0.40 | 0.35 | 0.65 | 0.60 | 0.82 | 0.77 | 0.42 | 0.41 | 0.51 | 0.49
| CodeBERT | 0.38 | 0.29 | 0.59 | 0.54 | 0.68 | 0.66 | 0.44 | 0.38 | 0.46 | 0.39
| BL-GAN | 0.3 | 0.27 | 0.53 | 0.48 | 0.64 | 0.59 | 0.35 | 0.32 | 0.44 | 0.41
SWT | RLocator | 0.40 | 0.30 | 0.57 | 0.51 | 0.63 | 0.58 | 0.48 | 0.42 | 0.51 | 0.44
| BugLocator | 0.37 | 0.25 | 0.50 | 0.45 | 0.56 | 0.51 | 0.42 | 0.40 | 0.46 | 0.43
| FLIM | 0.51 | 0.37 | 0.70 | 0.65 | 0.83 | 0.78 | 0.43 | 0.43 | 0.48 | 0.50
| CodeBERT | 0.34 | 0.27 | 0.5 | 0.45 | 0.54 | 0.51 | 0.42 | 0.37 | 0.45 | 0.39
| BL-GAN | 0.31 | 0.29 | 0.53 | 0.48 | 0.6 | 0.55 | 0.37 | 0.34 | 0.44 | 0.4
Tomcat | RLocator | 0.46 | 0.39 | 0.61 | 0.55 | 0.73 | 0.68 | 0.59 | 0.47 | 0.62 | 0.51
| BugLocator | 0.40 | 0.29 | 0.43 | 0.38 | 0.55 | 0.50 | 0.31 | 0.27 | 0.37 | 0.35
| FLIM | 0.51 | 0.42 | 0.70 | 0.65 | 0.76 | 0.71 | 0.52 | 0.47 | 0.59 | 0.60
| CodeBERT | 0.39 | 0.34 | 0.53 | 0.49 | 0.62 | 0.6 | 0.51 | 0.41 | 0.53 | 0.44
| BL-GAN | 0.38 | 0.35 | 0.61 | 0.55 | 0.65 | 0.61 | 0.43 | 0.4 | 0.55 | 0.5

Kết quả chỉ ra rằng RLocator vượt trội hơn BL-GAN trên tất cả các thước đo trong cài đặt 91%. Cụ thể, trong TopK, RLocator đạt được hiệu suất tốt hơn BL-GAN, từ 3.33% đến 55.26%. Mức tăng hiệu suất là 40.74% và 32.2% cho MAP và MRR tương ứng.

So với mô hình CodeBERT được huấn luyện như một bộ phân loại (CodeBERT), RLocator đạt được hiệu suất tốt hơn trên tất cả các thước đo. Mô hình CodeBERT đạt được hiệu suất thấp hơn một cách nhất quán trên tất cả các thước đo. Hiệu suất giảm lên đến 17.65%, 15.63%, 17.95%, 17.14% và 16.67% cho Top1, Top5, Top 10, MAP và MRR tương ứng.

Khi chúng tôi xem xét 100% dữ liệu, RLocator có kết quả MAP tốt hơn FLIM trong ba trong số sáu dự án (AspectJ, Birt và JDT) với 6.82-34.21%, bằng FLIM trong một dự án (Tomcat) và tệ hơn FLIM trong 2 dự án (Eclipse Platform UI và SWT) với 2-14%. Hiệu suất kém của RLocator trong các dự án Eclipse Platform UI và SWT có thể được liên kết với chất lượng kém và không nhất quán của các báo cáo lỗi, tạo ra một khoảng cách từ vựng đáng kể giữa các báo cáo và mã nguồn. Bằng cách áp dụng phương pháp IMaChecker [67], chúng tôi phát hiện rằng các báo cáo AspectJ có chất lượng cao nhất, trong khi các báo cáo cho Eclipse Platform UI, SWT và Tomcat xếp hạng trong số những báo cáo có chất lượng thấp nhất. Để phân tích chi tiết về chất lượng báo cáo lỗi, vui lòng tham khảo Phụ lục trực tuyến [39]. Về MRR, RLocator tốt hơn FLIM trong 2 dự án (AspectJ và Birt) với 10-31.71% và tệ hơn FLIM trong bốn dự án còn lại (Eclipse platform UI, JDT, SWT và Tomcat) với 6-18%. Về Top K, RLocator xếp hạng 4.29-12.5% nhiều lỗi hơn trong top 10 vị trí so với FLIM trong hai dự án. Mặt khác, trong bốn dự án còn lại, FLIM xếp hạng nhiều lỗi hơn trong top 10 vị trí, từ 2.74 - 34.48%. Khi so sánh RLocator với BugLocator cho dữ liệu 100% theo MAP, chúng tôi thấy rằng RLocator tốt hơn trong năm trong số sáu dự án và tương tự trong chỉ dự án Tomcat. Về MRR, RLocator tốt hơn BugLocator trong tất cả sáu dự án. Về Top K, RLocator xếp hạng nhiều lỗi hơn BugLocator trong top 10 vị trí, nơi cải thiện từ 12.07 -39.58%. Kết quả chứng minh rằng RLocator vượt trội hơn BL-GAN một cách nhất quán trong tất cả các thước đo trong cài đặt 100%. Cụ thể, trong thước đo TopK, hiệu suất của RLocator tốt hơn BL-GAN, với cải thiện từ 3.33% đến 36%. Các cải thiện hiệu suất cho RLocator là 32% về MAP và 1.96% về MRR tương ứng.

Điều quan trọng cần lưu ý là MAP cung cấp một cái nhìn cân bằng hơn so với MRR và top K vì nó tính đến tất cả các tệp liên quan đến một báo cáo lỗi chứ không chỉ một tệp. Ngoài ra, trong kỹ thuật của chúng tôi, chúng tôi tối ưu hóa để đưa ra kết quả chính xác hơn cho hầu hết các báo cáo lỗi hơn là đưa ra kết quả ít chính xác hơn trung bình cho tất cả các báo cáo lỗi. Do đó, bằng cách nhìn vào dữ liệu MAP cho 91%, chúng ta có thể thấy rằng RLocator hoạt động tốt hơn các kỹ thuật tiên tiến trong tất cả các dự án. Ngay cả khi chúng ta xem xét 100% dữ liệu, RLocator vẫn tốt hơn các kỹ thuật khác trong đa số các dự án. Chỉ với 100% dữ liệu và khi sử dụng MRR làm thước đo đánh giá, RLocator không hoạt động tốt hơn tiên tiến trong hầu hết các dự án.

RLocator hoạt động tệ nhất trong dự án Birt, với hiệu suất giảm 10.47% về MAP, 11.71% về MRR và 41.42% về top 10 so với trung bình của nó trên 91% dữ liệu. Mặc dù vậy, RLocator vượt trội hơn FLIM 38.3% về MAP, 36.73% về MRR và 11.32% về top 10. Nó cũng vượt trội hơn BugLocator 36.17% về MAP, 20.41% về MRR và 35.85% về top 10. Các yếu tố như chất lượng báo cáo lỗi, lượng thông tin trong báo cáo lỗi và độ dài mã nguồn có thể góp phần vào việc giảm hiệu suất. Chúng tôi đo lường thông tin hữu ích trong các báo cáo lỗi bằng cách sử dụng một thước đo tương tự, tính toán tỷ lệ các token tương tự giữa các tệp mã nguồn và báo cáo lỗi, chỉ ra tiềm năng hữu ích của báo cáo cho việc định vị lỗi. Thước đo được định nghĩa trong phương trình 6.

Similarity = Bug Report Tokens ∩ File Tokens / #of Unique Tokens in Bug Report (6)

Điểm tương tự trung vị cho các dự án Birt, Eclipse Platform UI và SWT lần lượt là 0.29, 0.30 và 0.33, làm cho chúng thấp nhất trong số sáu dự án. Quan sát này cho thấy rằng chất lượng thấp hơn của các báo cáo lỗi (phản ánh trong độ tương tự của chúng với các tệp nguồn) có thể góp phần vào việc giảm hiệu suất của RLocator trong các dự án này.

Để sử dụng hiệu quả RLocator trong các tình huống thực tế, chúng tôi sử dụng một mô hình XGBoost (Phần IV-A) để lọc ra các báo cáo lỗi mà các tệp có liên quan không xuất hiện trong K(=31) tệp hàng đầu. Sau đó, chúng tôi tính toán tầm quan trọng của các đặc trưng được liệt kê trong Bảng I bằng cách sử dụng mô-đun tích hợp của XGBoost. Điểm tầm quan trọng chỉ ra đóng góp của mỗi đặc trưng cho mô hình, với các giá trị cao hơn biểu thị tầm quan trọng lớn hơn. Hình 4 cho thấy rằng tương tự là đặc trưng quan trọng nhất, tiếp theo là độ dài mã nguồn và độ dài báo cáo lỗi. Những phát hiện này nhấn mạnh

Hình 4. Tầm quan trọng đặc trưng của mô hình phân loại.

tầm quan trọng của độ tương tự trong các hệ thống tìm kiếm dựa trên văn bản và cho thấy rằng các báo cáo lỗi chất lượng cao có thể ảnh hưởng đến hiệu suất định vị.

B. Phân tích Ablation Entropy: Tác động của Entropy lên hiệu suất RLocator
Chúng tôi thực hiện một nghiên cứu ablation để có được cái nhìn sâu sắc về tầm quan trọng của mỗi thành phần của RLocator. Hai thành phần chính của RLocator là bước lọc ngắn dựa trên ES và bước học tăng cường.

Trong RL, chúng tôi đã sử dụng thuật toán A2C với entropy. Entropy đề cập đến tính không thể dự đoán được của các hành động của agent. Entropy thấp chỉ ra một policy có thể dự đoán được, trong khi entropy cao đại diện cho một policy ngẫu nhiên và mạnh mẽ hơn. Một agent trong RL sẽ có xu hướng lặp lại các hành động trước đó đã dẫn đến phần thưởng tích cực trong khi học policy. Agent có thể bị kẹt trong một tối ưu cục bộ do khai thác các hành động đã học thay vì khám phá các hành động mới và tìm ra một tối ưu toàn cục cao hơn. Đây là lúc entropy trở nên hữu ích: chúng ta có thể sử dụng entropy để khuyến khích khám phá và tránh bị kẹt trong các tối ưu cục bộ [68]. Vì điều này, entropy trong RL đã trở nên rất phổ biến trong thiết kế các phương pháp RL như A2C [69].

Trong mô hình được đề xuất của chúng tôi (Phần VI-A), chúng tôi sử dụng A2C với entropy để huấn luyện RLocator nhằm xếp hạng các tệp có liên quan gần nhau hơn. Vì entropy là một phần của phần thưởng, quá trình gradient descent sẽ cố gắng tối đa hóa entropy. Entropy sẽ tăng nếu mô hình xác định các hành động khác nhau là tốt nhất trong cùng một state. Tuy nhiên, những hành động đó phải chọn một tệp có liên quan; nếu không, phần thưởng sẽ bị giảm. Do đó, nếu có nhiều tệp có liên quan trong một state, mô hình A2C với entropy regularized sẽ gán xác suất gần như giống nhau trong những hành động đó (các hành động liên quan đến việc chọn những tệp có liên quan đó). Điều này có nghĩa là khi các state được lặp lại, một hành động khác có khả năng được chọn mỗi lần. Việc gán xác suất này sẽ dẫn đến MAP cao hơn.

Hiệu suất quan sát được của RLocator trong việc đạt được MAP cao hơn có thể được diễn giải do hai yếu tố: 1) cách chúng tôi thiết kế hàm phần thưởng của mình, cho rằng chúng tôi định nghĩa một hàm nhằm khuyến khích MAP cao hơn; 2) việc bao gồm entropy, vì regularization entropy được giả định là cho phép mô hình đạt được MAP cao hơn.

Do đó, để cung cấp hiểu biết tốt hơn về mô hình của chúng tôi, chúng tôi đo lường hiệu suất của ba bước khác nhau của mô hình một cách riêng biệt. Bước lọc ngắn dựa trên ES, mô hình RL dựa trên A2C (không có entropy) và mô hình A2C với entropy. Do hạn chế tài nguyên (thời gian và GPU), chúng tôi giới hạn đánh giá của mình đến một nửa tổng số dự án trong bộ dữ liệu của chúng tôi, tức là AspectJ, Birt và Eclipse Platform UI. Chúng tôi quan sát một xu hướng tương tự trong ba dự án đó. Do đó, chúng tôi tin rằng kết quả của chúng tôi sẽ theo một xu hướng tương tự trong các dự án còn lại.

Bảng IV trình bày hiệu suất của ba lựa chọn (tức là ES, chỉ A2C và A2C với Entropy). Bảng IV cho thấy rằng ES đạt được hiệu suất cơ bản, thấp hơn 53-61% so với mô hình A2C với entropy về MAP và thấp hơn 47-54% về MRR. Chúng tôi cũng thấy rằng MRR và MAP của các mô hình không có entropy thấp hơn so với các mô hình A2C với entropy. Bảng IV cho thấy rằng về MAP, hiệu suất của các mô hình A2C với entropy cao hơn các mô hình A2C với phạm vi 27.78-34.04%. Trong MRR và top 10, mô hình A2C với entropy đạt được hiệu suất cao hơn với phạm vi 11.86-13.56% và 18.87 - 36% tương ứng. Những kết quả như vậy chỉ ra rằng entropy có thể đóng góp đáng kể vào hiệu suất mô hình về MAP, MRR và Top K. Hơn nữa, điều này cho thấy rằng việc sử dụng entropy khuyến khích agent RL khám phá các policy thay thế có thể [70]; do đó, nó có cơ hội cao hơn để có được một policy tốt hơn để giải quyết vấn đề trong một môi trường nhất định so với mô hình A2C.

--- TRANG 11 ---
11
BẢNG IV
HIỆU SUẤT RLOCATOR CÓ VÀ KHÔNG CÓ ENTROPY CHO A2C.

Dự án | Mô hình | Top 1 | Top 5 | Top 10 | MAP | MRR
---|---|---|---|---|---|---
AspectJ | ES | 0.15 | 0.20 | 0.28 | 0.23 | 0.27
| A2C | 0.27 | 0.39 | 0.48 | 0.40 | 0.52
| A2C với Entropy | 0.46 | 0.69 | 0.75 | 0.56 | 0.59
Birt | ES | 0.10 | 0.14 | 0.17 | 0.18 | 0.23
| A2C | 0.21 | 0.30 | 0.43 | 0.31 | 0.42
| A2C với Entropy | 0.38 | 0.46 | 0.53 | 0.47 | 0.49
Eclipse Platform UI | ES | 0.09 | 0.15 | 0.19 | 0.25 | 0.31
| A2C | 0.25 | 0.38 | 0.51 | 0.39 | 0.51
| A2C với Entropy | 0.45 | 0.69 | 0.78 | 0.54 | 0.59

VII. CÔNG TRÌNH LIÊN QUAN
Công trình liên quan nhất đến nghiên cứu của chúng tôi rơi vào các nghiên cứu về kỹ thuật định vị lỗi. Dưới đây, chúng tôi thảo luận về công trình liên quan và phản ánh về cách công trình so sánh với của chúng tôi.

Rất nhiều công trình đã nghiên cứu cách các nhà phát triển định vị lỗi [71], [72], [73], [74]. Ví dụ, Böhme et al. [71] đã nghiên cứu cách các nhà phát triển gỡ lỗi. Họ thấy rằng kỹ thuật phổ biến nhất để định vị lỗi là lý luận tiến, nơi các nhà phát triển đi qua từng bước tính toán của một test case thất bại để xác định vị trí. Zimmermann et al. [74] đã nghiên cứu các đặc điểm của một báo cáo lỗi tốt và thấy rằng các test case và dấu vết ngăn xếp là một trong những tiêu chí quan trọng nhất tạo nên một báo cáo lỗi tốt. Trong khi các nghiên cứu này tập trung vào việc định vị lỗi thủ công của các nhà phát triển, phương pháp của chúng tôi xem xét việc tự động hóa quá trình định vị lỗi cho các nhà phát triển.

Một số nghiên cứu đã đưa ra các giải pháp dựa trên độ bao phủ test case cho việc định vị lỗi [75], [76], [77]. Vancsics et al. [75] đã đề xuất một phổ dựa trên đếm thay vì phổ dựa trên hit trong công cụ Spectrum-Based Fault Localization (SBFL). GRACE [76] đã đề xuất việc học biểu diễn dựa trên mạng nơ-ron đồ thị cổng để cải thiện kỹ thuật SBFL. Tuy nhiên, các nghiên cứu này chủ yếu sử dụng các test case để định vị lỗi, trong khi phương pháp của chúng tôi (RLocator) tập trung vào báo cáo lỗi cho việc định vị lỗi.

Đã có một số nỗ lực để đánh giá tác động của việc cải tạo truy vấn trong việc cải thiện hiệu suất của các công cụ định vị lỗi hiện có [78], [79]. Ví dụ, Rahman et al. [78] thấy rằng thay vì sử dụng toàn bộ báo cáo lỗi như một truy vấn toàn văn, một truy vấn được cải tạo với một số mở rộng bổ sung hoạt động tốt hơn. BugLocator [3] đã sử dụng một Vector Space Model (rVSM) được sửa đổi để ước tính độ tương tự văn bản giữa các báo cáo lỗi và tệp mã nguồn.

Một số nghiên cứu đã kết hợp thông tin về cấu trúc chương trình như Program Dependence Graph (PDG), Data Flow Graph (DFG) [80] và Abstract Syntax Tree (AST) để học biểu diễn mã nguồn [4], [63], [80], [5], [65]. Ví dụ, CAST [5] đã sử dụng AST của mã nguồn để trích xuất thông tin ngữ nghĩa và sau đó sử dụng Word2Vec để chiếu mã nguồn và báo cáo lỗi trong cùng một không gian embedding. Họ đã sử dụng một mô hình CNN đo lường độ tương tự giữa một báo cáo lỗi và mã nguồn. Mô hình xếp hạng tệp dựa trên độ tương tự được tính toán. Hyloc [9] đã kết hợp các kỹ thuật định vị lỗi dựa trên IR với deep learning. Nó đã nối vector TF-IDF của mã nguồn với metadata cấp độ kho và tệp.

Các nghiên cứu khác đã áp dụng một số phương pháp dựa trên deep learning cho việc định vị lỗi [81], [6], [65]. DEMOB [81] đã sử dụng attention trên embedding ELMo [82], trong khi KGBugLocator [6] đã sử dụng attention trên graph embedding. BL-GAN [7] đã đưa ra một giải pháp dựa trên generative adversarial network (GAN) cho việc định vị lỗi. GAN thường được xem như một phương pháp liên quan chặt chẽ đến học tăng cường, nhưng nó khác biệt với việc sử dụng điển hình của Markov decision process (MDP), một khía cạnh cơ bản của học tăng cường [83], [14]. Ngoài ra, BL-GAN có hạn chế trong việc học tích cực định vị lỗi từ các hành động thời gian thực của nhà phát triển. Ngược lại, chúng tôi đã kết hợp phản hồi của nhà phát triển trực tiếp vào hàm phần thưởng, cho phép RLocator học từ các hành động của nhà phát triển. Xie et al. [84] đã sử dụng GAN để tạo ra các test case thất bại, giải quyết vấn đề mất cân bằng dữ liệu trong các phương pháp định vị lỗi. White et al. [85] đã sử dụng học tăng cường cho việc định vị lỗi trong các mạng phân tán. Tuy nhiên, phương pháp của họ liên quan đến việc agent học tăng cường hiểu cách tương tác với mạng khác với phương pháp của chúng tôi. Trong phương pháp của chúng tôi, agent học định vị lỗi từ hoạt động của nhà phát triển. Rezapour et al. [86] đã cung cấp một khám phá kỹ lưỡng về ứng dụng của học tăng cường trong định vị lỗi trong các hệ thống điện. Tuy nhiên, các phương pháp được thảo luận của họ khác biệt đáng kể so với của chúng tôi. Trong bối cảnh hệ thống điện, agent học tăng cường có thể quan sát trực tiếp các thành phần hiện tượng (ví dụ: dòng điện, điện áp) liên quan đến môi trường. Hơn nữa, các agent được phép thăm dò môi trường bằng cách thay đổi dòng điện hoặc điện áp. Ngược lại, định vị lỗi đòi hỏi các thành phần hiện tượng trừu tượng hơn trong môi trường (ví dụ: các khối mã tương tác) và agent không được phép thay đổi bất kỳ mã nào hoặc thực thi mã. Các nghiên cứu khác tập trung vào việc liên kết các commit với báo cáo lỗi [87], [8]. Ví dụ, FBL-BERT [8] đã sử dụng embedding CodeBERT để ước tính độ tương tự giữa các tệp mã nguồn và changeset của một commit. Dựa trên độ tương tự, nó xếp hạng commit đáng ngờ. FLIM [18] cũng đã sử dụng embedding CodeBERT để ước tính độ tương tự. Tuy nhiên, FLIM hoạt động trên định vị lỗi cấp độ hàm.

Phương pháp của chúng tôi, RLocator, sử dụng deep reinforcement learning cho việc định vị lỗi, khác biệt với các phương pháp dựa trên độ tương tự trước đó. Bằng cách công thức hóa vấn đề như một Markov Decision Process (MDP), chúng tôi tối ưu hóa trực tiếp các thước đo đánh giá. Kiểm tra trên bộ dữ liệu gồm 8.316 dự án từ sáu dự án Apache phổ biến, kết quả của chúng tôi cho thấy cải thiện hiệu suất đáng kể.

VIII. CÁC MỐI ĐE DỌA ĐỐI VỚI TÍNH HỢP LỆ
RLocator cũng có một số hạn chế. Chúng tôi xác định chúng và thảo luận cách khắc phục các hạn chế dưới đây.

Tính hợp lệ nội bộ. Một hạn chế của phương pháp chúng tôi là chúng tôi không thể sử dụng 9% bộ dữ liệu của mình do hạn chế của tìm kiếm dựa trên văn bản. Người ta có thể chỉ ra rằng chúng tôi loại trừ các báo cáo lỗi mà chúng tôi không hoạt động tốt. Nhưng mô hình XGBoost trong phương pháp của chúng tôi tự động xác định chúng và chúng tôi nói rằng chúng tôi thà không định vị các tệp mã nguồn cho những báo cáo lỗi này hơn là định vị chúng một cách không chính xác. Do đó, các nhà phát triển cần dựa vào phân tích thủ công của họ chỉ cho 9%. Hơn nữa, như một biện pháp minh bạch đầy đủ, chúng tôi ước tính giới hạn dưới của hiệu suất RLocator cho dữ liệu 100% và cho thấy rằng sự khác biệt là không đáng kể.

Tính hợp lệ ngoại vi. Mối quan tâm chính cho tính hợp lệ ngoại vi của đánh giá RLocator bắt nguồn từ việc giới hạn của nó đối với một số lượng nhỏ lỗi trong sáu dự án mã nguồn mở thực tế đa dạng, có khả năng ảnh hưởng đến khả năng áp dụng rộng rãi của nó. Tuy nhiên, những dự án đó từ các lĩnh vực khác nhau và được sử dụng bởi các nghiên cứu trước [4], [5], [81], [6], [9], [88]. Hơn nữa, mô hình A2C không có entropy chỉ được đánh giá trên ba dự án vì các tài nguyên đáng kể cần thiết cho việc huấn luyện—mất khoảng bốn ngày trên GPU Nvidia V100 16GB. Kết quả đồng nhất trên các dự án này chỉ ra rằng các kết quả tương tự có thể được mong đợi trong các dự án còn lại. Ngoài ra, do thiếu gói replication, chúng tôi đã tái tạo BL-GAN dựa trên mô tả của nó trong nghiên cứu gốc, có thể dẫn đến sự lệch hiệu suất nhẹ. Tuy nhiên, sau khi thử nghiệm với các siêu tham số khác nhau, chúng tôi đã chọn một tập hợp đạt được hiệu suất tương đương với những gì được báo cáo trong nghiên cứu gốc.

Tính hợp lệ cấu trúc. Cuối cùng, các thước đo đánh giá của chúng tôi có thể là một mối đe dọa đối với tính hợp lệ cấu trúc. Các thước đo đánh giá có thể không phản ánh hoàn toàn các tình huống thực tế. Mối đe dọa được giảm thiểu bởi thực tế là các thước đo đánh giá được sử dụng là nổi tiếng [8], [18], [58], [3] và tốt nhất có sẵn để đo lường và so sánh hiệu suất của các công cụ định vị lỗi dựa trên truy xuất thông tin.

IX. KẾT LUẬN
Trong bài báo này, chúng tôi đề xuất RLocator, một kỹ thuật dựa trên học tăng cường (RL) để xếp hạng các tệp mã nguồn nơi lỗi có thể cư trú, cho báo cáo lỗi. Đóng góp chính của nghiên cứu chúng tôi là việc công thức hóa vấn đề định vị lỗi bằng cách sử dụng Markov Decision Process (MDP), giúp chúng tôi tối ưu hóa trực tiếp các thước đo đánh giá. Chúng tôi đánh giá RLocator trên 8.316 báo cáo lỗi và thấy rằng RLocator hoạt động tốt hơn các kỹ thuật tiên tiến khi sử dụng MAP làm thước đo đánh giá. Sử dụng bộ dữ liệu báo cáo lỗi 91%, RLocator vượt trội hơn các công cụ trước đó trong tất cả các dự án về cả MAP và MRR. Khi sử dụng dữ liệu 100%, RLocator vượt trội hơn tất cả các phương pháp trước đó trong bốn trong số sáu dự án sử dụng MAP và hai trong số sáu dự án sử dụng MRR. RLocator có thể được sử dụng cùng với các phương pháp định vị lỗi khác để cải thiện hiệu suất. Kết quả của chúng tôi cho thấy rằng RL là một hướng đầy hứa hẹn cho việc khám phá trong tương lai khi nói đến việc thúc đẩy các kỹ thuật tiên tiến cho việc định vị lỗi. Nghiên cứu trong tương lai có thể khám phá việc áp dụng các thuật toán học tăng cường tiên tiến trong định vị lỗi. Ngoài ra, các nhà nghiên cứu có thể điều tra cách huấn luyện trên các bộ dữ liệu lớn hơn ảnh hưởng đến hiệu suất của các công cụ trong bối cảnh độ tương tự thấp.

X. TÍNH KHẢ DỤNG CỦA DỮ LIỆU
Để thúc đẩy nghiên cứu trong tương lai trong lĩnh vực này, chúng tôi tạo ra một gói replication bao gồm bộ dữ liệu và mã của chúng tôi được công khai có sẵn [39].

TÀI LIỆU THAM KHẢO
[Phần tài liệu tham khảo được giữ nguyên như trong bản gốc]

--- TRANG 14 ---
14
[Tiếp tục phần tài liệu tham khảo và thông tin tác giả]

Partha Chakraborty là nghiên cứu sinh tiến sĩ tại Trường Khoa học Máy tính Cheriton, Đại học Waterloo, Canada. Lĩnh vực nghiên cứu của anh bao gồm định vị lỗi, phát hiện lỗ hổng và việc sử dụng các kỹ thuật học máy trong kỹ thuật phần mềm. Tìm hiểu thêm về anh tại https://parthac.me/.

Mahmoud Alfadel là Phó Giáo sư tại Khoa Khoa học Máy tính, Đại học Calgary. Lĩnh vực nghiên cứu của ông bao gồm khai thác kho phần mềm, hệ sinh thái phần mềm, bảo mật mã nguồn mở và kỹ thuật phát hành.

Meiyappan Nagappan là Phó Giáo sư tại Trường Khoa học Máy tính Cheriton, Đại học Waterloo. Ông đã làm việc về kỹ thuật phần mềm thực nghiệm để giải quyết các mối quan tâm về phát triển phần mềm và hiện đang nghiên cứu tác động của các mô hình ngôn ngữ lớn đối với việc phát triển phần mềm.

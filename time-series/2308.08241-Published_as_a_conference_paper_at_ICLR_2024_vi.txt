# 2308.08241.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/time-series/2308.08241.pdf
# Kích thước tệp: 3096326 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
TEST: EMBEDDING NGUYÊN MẪU VĂN BẢN ĐỀ KÍCH HOẠT KHẢ NĂNG CỦA LLM CHO CHUỖI THỜI GIAN
Chenxi Sun1,2,3, Hongyan Li1,2,3,4,∗, Yaliang Li5, Shenda Hong6,7,∗
1Phòng thí nghiệm Trọng điểm Quốc gia về Trí tuệ Nhân tạo Tổng quát, Đại học Bắc Kinh
2Phòng thí nghiệm Trọng điểm về Nhận thức Máy (Bộ Giáo dục), Đại học Bắc Kinh
3Trường Khoa học và Công nghệ Thông minh, Đại học Bắc Kinh
4Viện Trí tuệ Nhân tạo PKU-WUHAN
5Tập đoàn Alibaba
6Viện Khoa học Dữ liệu Y tế Quốc gia, Đại học Bắc Kinh
7Viện Công nghệ Y tế, Trung tâm Khoa học Sức khỏe, Đại học Bắc Kinh
{chenxi sun,leehy }@pku.edu,cn
yaliang.li@alibaba-inc.com, hongshenda@pku.edu.cn
TÓM TẮT
Nghiên cứu này tóm tắt hai cách để thực hiện các nhiệm vụ Chuỗi Thời gian (TS) trong bối cảnh Mô hình Ngôn ngữ Lớn (LLM) hiện tại: LLM-for-TS (tập trung vào mô hình) thiết kế và huấn luyện một mô hình lớn cơ bản, hoặc tinh chỉnh một LLM đã được tiền huấn luyện cho dữ liệu TS; TS-for-LLM (tập trung vào dữ liệu) chuyển đổi TS thành một biểu diễn thân thiện với mô hình để cho phép LLM đã được tiền huấn luyện xử lý dữ liệu TS. Do thiếu dữ liệu, tài nguyên hạn chế, yêu cầu ngữ cảnh ngữ nghĩa, v.v., nghiên cứu này tập trung vào TS-for-LLM, nơi chúng tôi nhằm kích hoạt khả năng của LLM đối với dữ liệu TS bằng cách thiết kế một phương pháp embedding TS phù hợp cho LLM. Phương pháp được đề xuất có tên TEST. Đầu tiên nó token hóa TS, xây dựng một encoder để embed TS thông qua tương phản theo từng instance, theo từng feature và căn chỉnh nguyên mẫu văn bản, trong đó không gian embedding TS được căn chỉnh với không gian lớp embedding của LLM, sau đó tạo ra các prompt mềm để làm cho LLM mở rộng hơn đối với các embedding đó, và cuối cùng thực hiện các nhiệm vụ TS bằng cách sử dụng LLM đã được đóng băng. Chúng tôi cũng chứng minh tính khả thi của TS-for-LLM thông qua lý thuyết và thí nghiệm. Các thí nghiệm được thực hiện trên các nhiệm vụ phân loại TS, dự báo và biểu diễn sử dụng tám LLM đã được đóng băng với các cấu trúc và kích thước khác nhau. Kết quả cho thấy LLM đã được tiền huấn luyện với chiến lược TEST có thể đạt được hiệu suất tốt hơn hoặc tương đương với các mô hình TS SOTA hiện tại và mang lại lợi ích cho việc học few-shot và tổng quát hóa. Bằng cách coi LLM như một máy nhận dạng mẫu, TEST có thể trao cho LLM khả năng xử lý dữ liệu TS mà không làm tổn hại khả năng ngôn ngữ. Chúng tôi hy vọng rằng nghiên cứu này sẽ phục vụ như một nền tảng cho công việc tương lai để hỗ trợ tiến bộ TS+LLM.

1 GIỚI THIỆU
Thực hiện các nhiệm vụ Chuỗi Thời gian (TS), chẳng hạn như y tế, công nghiệp và khí tượng, là một lĩnh vực nghiên cứu chuyên sâu Sun et al. (2020). Các mô hình liên quan đã phát triển từ mô hình thống kê đến RNN, CNN và Transformer. Ngày nay, chúng ta thấy sự tăng trưởng nhanh chóng và hiệu suất đáng chú ý của các Mô hình Ngôn ngữ Lớn đã được tiền huấn luyện (LLM) trong các lĩnh vực NLP và CV Zhao et al. (2023). Do đó, việc hỏi liệu LLM có thể được sử dụng cho các nhiệm vụ TS dường như là điều tự nhiên. Tuy nhiên, theo các thí nghiệm, hầu hết các LLM đã được tiền huấn luyện không đạt được tiến bộ đáng kể liên quan đến TS trừu tượng.
Để trả lời yêu cầu này, chúng tôi hình dung hai cách để đạt được mô hình TS+LLM1:
• LLM-for-TS (tập trung vào mô hình, sửa đổi LLM). Đối với dữ liệu TS, thiết kế và huấn luyện một Mô hình Lớn cơ bản từ đầu (LM-of-TS), sau đó tinh chỉnh mô hình tương ứng cho các nhiệm vụ downstream khác nhau. Hoặc, tinh chỉnh LLM đã được tiền huấn luyện hiện có và chuyển đổi nó từ các nhiệm vụ văn bản sang các nhiệm vụ TS;
∗Tác giả liên hệ
1Phân loại này tập trung vào yêu cầu thay đổi mô hình. Nhưng từ công nghệ, LLM+TS có thể đạt được bằng tiền huấn luyện, tinh chỉnh, phương pháp tăng cường công cụ, encoder bên ngoài và sự kết hợp của chúng.
1arXiv:2308.08241v2  [cs.CL]  22 Feb 2024

--- TRANG 2 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
• TS-for-LLM (tập trung vào dữ liệu, sửa đổi TS). Dựa trên các LLM hiện có, đóng băng chúng xa nhất, thiết kế một số cơ chế để tùy chỉnh TS cho chúng bằng cách tạo biểu diễn TS thân thiện với LLM.
Chúng tôi thừa nhận rằng cách thứ nhất, đặc biệt là phát triển và huấn luyện một mô hình từ đầu, là giải pháp thiết yếu nhất vì tiền huấn luyện là bước quan trọng để truyền đạt kiến thức cho mô hình.
Và cách thứ hai thực sự là thách thức để vượt qua khả năng ban đầu của mô hình. Tuy nhiên, trong nghiên cứu này, chúng tôi vẫn tập trung vào cách thứ hai do ba cân nhắc sau:
Góc độ dữ liệu. Các phương pháp LLM-for-TS, đặc biệt khi xây dựng một mô hình nền tảng, cần bộ dữ liệu lớn, nhưng TS là chuyên nghiệp, bộ dữ liệu lớn nhất nhỏ hơn 10GB, nhỏ hơn nhiều so với NLP Zhou et al. (2023); Các phương pháp TS-for-LLM có thể sử dụng bộ dữ liệu tương đối nhỏ vì mục tiêu của nó chỉ là hỗ trợ LLM hiện có trong việc suy luận TS; Góc độ mô hình. Các phương pháp LLM-for-TS tập trung vào các ngành dọc. Do sự khác biệt lớn trong TS giữa các lĩnh vực, các mô hình lớn khác nhau nhắm mục tiêu TS y tế, TS công nghiệp, v.v. phải được xây dựng và huấn luyện từ đầu; Các phương pháp TS-for-LLM cần ít hoặc thậm chí không cần huấn luyện. Bằng cách sử dụng các mô-đun cắm vào, nó làm cho việc sử dụng trở nên tổng quát và thuận tiện hơn; Góc độ sử dụng. Các phương pháp LLM-for-TS phù hợp cho các trường hợp liên quan đến chuyên gia; Các phương pháp TS-for-LLM duy trì khả năng văn bản của LLM trong khi cung cấp ngữ nghĩa bổ sung phong phú, dễ tiếp cận và thân thiện với người dùng.

Mà không thay đổi mô hình hiện có, cách tiếp cận tự nhiên nhất là coi TS như dữ liệu văn bản. Ví dụ, một cuộc đối thoại có thể như sau: [Q] Chẩn đoán nếu một bệnh nhân bị nhiễm trùng huyết thông qua chuỗi áp lực động mạch trung bình sau đây tính bằng mm Hg: 88, 95, 78, 65, 52, 30. [A] Có. Tuy nhiên, TS thường là đa biến trong khi văn bản là đơn biến. Ví dụ, ngoại trừ áp lực động mạch trung bình, hàng chục dấu hiệu sinh tồn và giá trị phòng thí nghiệm, chẳng hạn như nhịp tim, axit lactic, v.v., cần được bao gồm khi chẩn đoán nhiễm trùng huyết. Một phương pháp trực quan là chia một TS đa biến thành nhiều chuỗi đơn biến và nhập chúng vào LLM từng cái một. Tuy nhiên, điều này sẽ dẫn đến ba nhược điểm. Thứ nhất, các câu prompt khác nhau, thứ tự dữ liệu và câu kết nối sẽ tạo ra các kết quả khác nhau; Thứ hai, một chuỗi đầu vào dài có thể làm cho LLM không hiệu quả và khó nhớ TS đơn biến trước đó; Thứ ba, các khía cạnh quan trọng của sự phụ thuộc đa biến trong TS sẽ bị bỏ qua.

Để giải quyết các vấn đề trên và đạt được TS-for-LLM, chúng tôi không trực tiếp nhập TS vào LLM, mà thay vào đó, chúng tôi đầu tiên token hóa TS, sau đó thiết kế một encoder để embed chúng, cuối cùng bỏ qua lớp embedding để nhập chúng vào LLM. Theo cách này, cốt lõi là tạo ra các embedding mà LLM có thể hiểu được.
Embedding TS chất lượng cao có thể được sử dụng như kiểu hình tính toán mà mô hình học sâu có thể hiểu Hong et al. (2023). Để làm cho embedding có thể hiểu được bởi các mô hình ngôn ngữ. Hầu hết các cách tiếp cận đa phương thức sử dụng căn chỉnh, ví dụ, căn chỉnh embedding văn bản và embedding hình ảnh thông qua mô tả văn bản của hình ảnh Wang et al. (2023). Tuy nhiên, TS thiếu các tín hiệu thị giác và có nút cổ chai chú thích gây ra bởi các đặc điểm phức tạp của nó. Chỉ một số TS cụ thể, chẳng hạn như ECG, có mô tả văn bản trong mỗi đoạn, nơi tuyến đường khớp hình ảnh-văn bản có thể được triển khai. Nhưng trong hầu hết các trường hợp, điều này là không khả thi.

Học Tương phản (CL) có thể tránh nút cổ chai chú thích thông qua việc thiết kế các nhiệm vụ pretext bằng cách sử dụng thông tin nội tại thay vì dựa vào kiến thức tiên nghiệm được xác định trước. Hiện tại, các phương pháp CL cho dữ liệu TS cũng đã tiến bộ Meng et al. (2023b). Các phương pháp này đánh giá hiệu quả của embedding TS thông qua các mô hình phân loại, dự đoán hoặc phân cụm tiếp theo, chẳng hạn như SVM Franceschi et al. (2019b). Tuy nhiên, các mô hình đơn giản và mới được huấn luyện này khác biệt đáng kể so với LLM phức tạp và được tiền huấn luyện. Vector biểu diễn được tạo ra bởi CL không bị ràng buộc có thể sai lệch lớn so với không gian embedding nhận thức của LLM.

Để giải quyết các vấn đề trên, chúng tôi đề xuất một phương pháp embedding cho các token Chuỗi Thời gian để căn chỉnh không gian embedding văn bản của LLM (TEST). Dựa trên CL, TEST sử dụng các vector embedding văn bản làm nguyên mẫu để ràng buộc không gian embedding của TS và làm nổi bật các mẫu theo feature. Chúng tôi cho thấy rằng TEST có thể kích hoạt khả năng của LLM như một máy nhận dạng mẫu. Những đóng góp của nghiên cứu này là:
• Tóm tắt hai mô hình TS+LLM, LLM-for-TS, TS-for-LLM, với các phương pháp tiềm năng của chúng;
• Đề xuất TEST cho TS-for-LLM. TEST có thể tạo ra embedding dựa trên độ tương tự, theo instance, theo feature và căn chỉnh nguyên mẫu văn bản cho các token TS. Chúng tôi chứng minh rằng prompt tuning gần như tương đương với supervised fine-tuning khi embedding TS và embedding từ được căn chỉnh;
• Các thí nghiệm về phân loại TS, dự báo, few-shot và các nhiệm vụ biểu diễn chứng minh rằng TEST có thể kích hoạt khả năng của LLM để lưu trữ các nhiệm vụ TS, nơi các kết quả ngẫu nhiên và không thỏa mãn được tạo ra bởi LLM gốc có thể được nâng lên đến baseline.

--- TRANG 3 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
Loại Phương tiện Ưu điểm Nhược điểm Công việc
LM-of-TS Huấn luyện Chuyên biệt, Không phổ quát, Tiền huấn luyện Ma et al. (2023)
chính xác bộ dữ liệu lớn Earth transformer Bi et al. (2023)
LLM-for-TS Tinh chỉnh Đầu-cuối, Nhiều thí nghiệm hơn, GPT4TS Zhou et al. (2023)
chính xác mất khả năng ngôn ngữ LLM4TS Chang et al. (2023)
Tool
augmented Hiệu quả tham số,
ít thí nghiệm hơn Cần chuyên gia,
cần chú thích PromptCast Xue & Salim (2023)
Health Learner Liu et al. (2023)
METS Li et al. (2024)
Text2ECG Chung et al. (2023)
TS-for-LLM External
encoder Hiệu quả tham số, Kém mạnh mẽ TEST
khả năng đa dạng
Bảng 1: Công việc hiện có về TS+LLM

Như tên của TEST ngụ ý, đây là một bài kiểm tra có tầm nhìn xa mà chúng tôi hy vọng sẽ đặt nền móng cho nghiên cứu tương lai. Và nó thực sự mang lại cho LLM những khả năng mới và làm nổi bật những đặc tính của nó như một máy nhận dạng mẫu.

2 CÔNG VIỆC LIÊN QUAN
2.1 CHUỖI THỜI GIAN VÀ MÔ HÌNH NGÔN NGỮ LỚN
Không có nhiều nghiên cứu được thực hiện về TS+LLM vì lĩnh vực này vẫn đang trong giai đoạn sơ khai. Chúng tôi tóm tắt các công việc hiện có trong Bảng 1. LLM-for-TS với việc thay đổi mô hình có thể đạt được thông qua tinh chỉnh hoặc phương tiện tool augmented; TS-for-LLM với việc thay đổi dữ liệu có thể đạt được thông qua xây dựng encoder bên ngoài.

LM-of-TS Ma et al. (2023) huấn luyện một mô hình cơ bản và chính xác dựa trên dữ liệu TS lĩnh vực tích lũy, nhưng có thể khó xây dựng một bộ dữ liệu lớn được gắn nhãn tốt do chi phí thu thập và chú thích dữ liệu. So sánh, Supervised Fine-Tuning (SFT) trong LLM-for-TS Chang et al. (2023) có khối lượng công việc tương đối nhỏ hơn so với tiền huấn luyện, nhưng nó có thể làm cho LLM mất khả năng ngôn ngữ và ưu thế của nó so với một mô hình tinh vi được thiết kế đặc biệt cho các nhiệm vụ TS không rõ ràng. Về việc coi TS như chuỗi văn bản và sử dụng prompt như công cụ tăng cường Liu et al. (2023) có thể nhập TS số vào LLM trực tiếp, nhưng nó không chính xác, đòi hỏi nhiều kinh nghiệm hơn và sẽ thất bại đối với TS đa biến. Các phương pháp đa phương thức Li et al. (2024) có thể căn chỉnh văn bản và TS, nhưng ngoài ECG, hầu hết các bộ dữ liệu TS không có chú thích đoạn.

2.2 EMBEDDING CHUỖI THỜI GIAN
Embedding TS có thể cung cấp danh tính bằng cách bao gồm các thuộc tính điển hình, liên kết và phụ thuộc.
Các phương pháp dựa trên CL có thể nhận được biểu diễn dữ liệu Chen et al. (2020), sử dụng nhiệm vụ pretext phân biệt instance để đưa các cặp tương tự lại gần nhau trong khi đẩy các cặp không tương tự ra xa trong không gian embedding. Một số nỗ lực đã được thực hiện để triển khai tương phản cấp instance Woo et al. (2022b); Zheng et al. (2023), tương phản cấp thời gian Meng et al. (2023c); Franceschi et al. (2019b), và tương phản cấp clustering Meng et al. (2023a) trên dữ liệu TS, với kết quả đầy hứa hẹn. Tuy nhiên, tương phản trực tiếp không thể kết nối embedding TS và không gian có thể hiểu được của LLM. Trong thiết lập của chúng tôi, chúng tôi thích đóng băng LLM đã được tiền huấn luyện và để embedding thỏa hiệp. Nghĩa là, chúng tôi sử dụng embedding token văn bản trong LLM để giới hạn và hướng dẫn embedding token TS.

Lấy cảm hứng từ tương phản cấp nguyên mẫu Caron et al. (2020a), vượt ra ngoài giả định độc lập và khai thác thông tin cụm ẩn có trong các mẫu. Chúng ta có thể chọn một số embedding văn bản làm nguyên mẫu cơ bản để dẫn dắt việc học. Tuy nhiên, ngoài việc căn chỉnh, chúng ta vẫn cần xem xét các vấn đề về lựa chọn nguyên mẫu, sự khác biệt Meng et al. (2023c), tính đồng nhất Wang & Isola (2020), tính ổn định Huang et al. (2023) và v.v.

3 PHƯƠNG PHÁP
TEST có hai bước chính: Trong Hình 1, xây dựng một encoder để embed TS; Trong Hình 2, tạo prompt để làm cho LLM có thể chấp nhận embedding TS làm đầu vào.

--- TRANG 4 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
Encoder Instance contrast Text prototype Anchor Positive Negative Augmentation Projector Feature contrast
Text alignment Similarity
Value 19 Shape up down Frequency high low Frequency Value Shape
Value Frequency Shape Decoder Autoencoding Feature matrix
Hình 1: Embedding TS căn chỉnh nguyên mẫu văn bản bằng Tương phản theo Instance và theo Feature

3.1 TĂNG CƯỜNG VÀ ENCODING TOKEN TS
Định nghĩa 1 (Token Embedding của Chuỗi Thời gian) Một chuỗi thời gian đa biến x={xd
t}T,D
t=1,d=1 có
D biến và T điểm thời gian. Nó có thể được phân đoạn thành một danh sách K chuỗi con không chồng lấp
s={sk}K
k=1 bởi một hàm phân đoạn fs:x→s, trong đó độ dài của sk=xti:tj là tùy ý,
1≤ti< tj≤T. Chúng ta gọi s là danh sách token của chuỗi thời gian x. Hơn nữa, mỗi token có thể được embed
vào một không gian biểu diễn M chiều bởi một hàm embedding fe:sk∈RD×T→ek∈RM.
Cuối cùng, danh sách token embedding của x là e={ek}K
k=1=fe(s) =fe(fs(x)).

Chúng tôi đầu tiên token hóa TS thành một số phân đoạn/chuỗi con/token/instance thông qua phương pháp cửa sổ trượt cổ điển trong học biểu diễn Yue et al. (2022) s=fs(x). Chúng tôi định nghĩa một token TS s như instance anchor. Các positive s+ của nó là các instance tăng cường, sweak∼ Tweak (chiến lược jitter-and-scale, thêm các biến thiên ngẫu nhiên vào tín hiệu và phóng to độ lớn của nó), sstrong∼ Tstrong (chiến lược permutation-and-jitter, chia chuỗi thành một số đoạn ngẫu nhiên và xáo trộn chúng một cách ngẫu nhiên) Eldele et al. (2021b). Các negative s− của nó là từ các instance không chồng lấp không có cùng chuỗi con với s.

Sau khi có anchor-positive-negative, chúng tôi xây dựng một mạng neural làm encoder để embed instance thành vector e=fe(s). Chúng tôi cũng huấn luyện một decoder fd bằng cách sử dụng loss auto-encoding Lae=1
NPN
i=1sim(s, fd(e)) để đảm bảo tính đại diện của embedding và xác minh tiếp theo. Bởi vì mục tiêu chính của chúng tôi là lấy encoder, decoder này cũng có thể không được xây dựng mà không làm hại quá trình tương lai.

3.2 TƯƠNG PHẢN THEO INSTANCE VÀ THEO FEATURE
CL cơ bản theo instance coi mỗi instance độc lập và thiết kế nhiệm vụ pretext phân biệt instance để giữ các instance tương tự gần nhau và các instance không tương tự xa nhau. Để ngăn không gian embedding sụp đổ, chúng tôi coi các view tăng cường của cùng một instance là cặp positive duy nhất, và tất cả những cái còn lại trong minibatch kích thước B là các cặp negative He et al. (2020). Loss tương phản theo instance được hiển thị trong Phương trình 1. Trong đó cho embedding instance e, e+/−, chúng tôi xây dựng một projection head fp, là một MLP một lớp để có được fp(e). σ(e, e+/−) được sử dụng để tính toán độ tương tự giữa hai vector đã được chiếu thông qua một hàm tương tự sim như cosine similarity với tham số nhiệt độ cấp instance τ.

Lins=−log exp(σ(e, e+))
exp(σ(e, e+)) +PB
i=1exp(σ(e, e−
i))
σ(e, e+/−) =sim(fp(e), fp(e+/−))
τ (1)

--- TRANG 5 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
Chúng tôi cũng đề xuất một phương pháp tương phản theo feature để phá vỡ sự độc lập giữa các instance. Như được hiển thị trong Hình 1, sau khi embedding, một feature matrix RB×M được hình thành bởi các vector biểu diễn của các instance trong một minibatch. Trong đó mỗi hàng là một embedding của một instance, do đó các hàng có thể được coi như nhãn mềm của các instance được sử dụng trong Phương trình 1. Ngoài các hàng, các cột của feature matrix cũng có thông tin ngữ nghĩa. Li et al. (2021c) đề xuất rằng các cột có thể được coi thêm như biểu diễn cụm. Tuy nhiên, các phương pháp cluster-wise như vậy đòi hỏi kiến thức tiên nghiệm để chỉ định trước số lượng cụm, điều này không tầm thường đối với dữ liệu TS không được gắn nhãn trong nghiên cứu này. Do đó, chúng tôi đề xuất coi các cột như nhãn mềm của các feature và thực hiện phân biệt giữa các nhóm feature tương tự.

Đối với một anchor feature matrix m, trong đó m là bản sao hàng B của vector e, chúng tôi có được một positive feature matrix m+ và một negative feature matrix m−, trong đó m+/−= [ei]B
i=1∈RB×M. Chúng tôi đánh dấu các cột trong matrix là m∈mT. Như được thể hiện bởi mục trước mũi tên bên phải trong Phương trình 2, tương phản theo feature chủ yếu căn chỉnh và phân biệt cùng một cột feature giữa positive và negative. Tuy nhiên, điều này có thể khiến không gian biểu diễn co lại trong một khu vực nhỏ. Chúng tôi thấy rằng việc đảm bảo sự khác biệt giữa các feature có thể giải quyết vấn đề này tốt hơn. Nghĩa là, chúng tôi đề xuất tương phản giữa các cột feature khác nhau như được hiển thị trong mục sau mũi tên bên phải.

Lfea=−MX
i=1(σ(mi, m+
i)|{z}
Alignment−σ(mi, m−
i)|{z}
Difference)⇒ −MX
i=1log exp(σ(mi, m+
i))PM
j=1[exp(σ(mi, m+
j)) + exp( σ(mi, m−
j))]
| {z }
Feature category uniformity (2)

Quan trọng hơn, việc đưa vào sự khác biệt cột feature cũng có thể hỗ trợ rất lớn trong việc triển khai tiếp theo tương phản căn chỉnh nguyên mẫu văn bản. Bởi vì tương phản đó sẽ áp dụng embedding token văn bản đã chọn cho các cột feature, như các trục tọa độ.

3.3 TƯƠNG PHẢN CĂNG CHỈNH NGUYÊN MẪU VĂN BẢN
LLM đã được tiền huấn luyện có embedding token riêng của nó, ví dụ, GPT-2 nhỏ, trung bình và lớn embed các token văn bản từ từ điển từ vào không gian biểu diễn với 768, 1024 và 1280 chiều. Một cách ngây thơ, chúng ta có thể căn chỉnh token embedding của TS và văn bản bằng cách sử dụng ước lượng độ tương tự. Mặc dù các token TS thiếu chú thích văn bản, chúng ta có thể đặt embedding của chúng gần các mô tả văn bản điển hình của TS, chẳng hạn như giá trị, hình dạng và tần số. Theo cách này, có thể trực quan mong đợi rằng các token TS khác nhau có thể biểu diễn các thuật ngữ mô tả khác nhau chẳng hạn như nhỏ, lớn, lên, xuống, ổn định, dao động, v.v. Tự nhiên, ví dụ trên dựa trên nguyên tắc láng giềng gần nhất vì không gian embedding của một token văn bản là rời rạc, giống như một bảng vector, nhưng của token TS của chúng ta là liên tục.

Tuy nhiên, tất nhiên, kết quả thực tế sẽ không khớp với những gì chúng ta mong đợi vì chúng ta không cung cấp nhãn giám sát hoặc ground truth. Ví dụ, embedding của một chuỗi con có xu hướng tăng có thể rất gần với của một từ suy giảm, hoặc thậm chí không mô tả xu hướng. Nhưng việc ngữ nghĩa có thể được hiểu bởi chúng ta hay không là không liên quan. Như thông thường, thực tế là con người không thể hiểu được chế độ nhận thức của mô hình.

Gần đây, các nhà nghiên cứu đã chứng minh rằng LLM là các máy nhận dạng mẫu Mirchandani et al. (2023). Do đó, trong nghiên cứu này, chúng tôi đạt được "TS →mẫu →văn bản" để kích hoạt khả năng của LLM cho các nhiệm vụ TS. Việc lựa chọn nguyên mẫu văn bản có thể được nới lỏng, không nhất thiết phải là mô tả liên quan đến TS.

Trong nghiên cứu này, chúng tôi chọn P embedding văn bản đại diện tp làm pivot/nguyên mẫu, và ánh xạ embedding TS đến chúng. Trong không gian chiều cao, hầu như tất cả các vector đều trực giao từng cặp Hopcroft & Kannan (2013), do đó số lượng nguyên mẫu chứ không phải loại mới quan trọng, và sự khác biệt của chúng có thể được phản ánh trong một chiều/feature duy nhất. Do đó, chức năng mô hình hóa của nguyên mẫu văn bản tp được thực hiện bởi tương phản theo feature. Như được thể hiện bởi Phương trình 3, thuật ngữ căn chỉnh đảm bảo rằng hai phạm vi không gian gần như giống nhau thông qua ràng buộc độ tương tự, thuật ngữ tương phản sử dụng tp như trục tọa độ để ánh xạ embedding TS, làm cho các giá trị biểu diễn trong các trục tọa độ văn bản của instance tương tự tương tự. Feature matrix không còn được có được thông qua projector mà thông qua ánh xạ nguyên mẫu e·tp→m.

Ltext=−PX
i=1[sim(tpi, e)|{z}
Text alignment−Lfea(e·tp, e+·tp, e−·tp)]| {z }
Text contrast (3)

--- TRANG 6 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
3.4 EMBEDDING PROMPT CÓ THỂ HỌC
Ngay cả khi TS đã được mô tả bằng một biểu diễn embedded mà LLM có thể hiểu, LLM vẫn phải được hướng dẫn về cách thực hiện các nhiệm vụ TS tiếp theo.

Token Encoder Language model
TS embedding…
Question Answer Train Decoder Fine-tune Fine-tune Trainable layer Soft prompt Classifier Classification Regression [cls]
Hình 2: Khung của LLM cho Nhiệm vụ TS

Prompt engineering như template và chain-of-thought là trực quan. Các ngữ cảnh của chúng nhất quán trong ngữ nghĩa con người, nhưng một danh sách embedding TS không có ngữ nghĩa con người, nó về một chuỗi mẫu hơn. Do đó, để tạo ra một mẫu prompt nhất quán hơn, chúng tôi huấn luyện một soft prompt bằng p-tuning Lester et al. (2021) làm cho LLM dễ hiểu đầu vào hơn. Những soft prompt này là embedding cụ thể theo nhiệm vụ, học thông qua loss từ đầu ra của LLM và ground truth nhiệm vụ trong Phương trình 4.

Lpromp =Lreg/cls (concat( pe, e)) (4)

GPT4TS Zhou et al. (2023) đã chứng minh tính khả thi rằng SFT có thể làm cho LLM áp dụng cho TS. Dựa trên điều này, chúng tôi chứng minh tính khả thi của TEST bằng cách chứng minh sự tương đương giữa soft prompt và SFT.

Xem xét một nhiệm vụ tạo có điều kiện trong đó đầu vào x là một ngữ cảnh và đầu ra y là một chuỗi token. Giả sử một LLM tự hồi quy pϕ(y|x) với tham số ϕ, z= [x;y]. Suy luận của một LLM đã được tiền huấn luyện là tính toán hi như một hàm của zi và các kích hoạt quá khứ trong ngữ cảnh bên trái của nó, Y=LM ϕ(zi, hi). Quá khứ hi trong soft prompt turning với prompt peθ là hi=peθ[i,:], nếu i∈peidx
LM ϕ(zi, hi), ngược lại. SFT từ LLM đến TS-LLM là Phương trình 5. Biến đổi của nó cho thấy rằng soft prompt tuning gần như tương đương với SFT.

max
ϕpϕ(y′|x) = max
ϕX
i∈Yidxlogpϕ(z′
i|h<i) =X
i∈Yidxlogpϕ+∆(zi+δzi|h<i)
≈X
i∈Yidxlogpϕ(zi|h<i)·X
i∈peidxlogp∆(δzi|h<i)
=X
i∈Yidxlogpϕ(zi| fe(s)|{z}
Text−TS alignment| {z }
Frozen LLM)·X
i∈peidxlogp∆(δzi|h<i)
| {z }
Prompt peθ (5)

Phương trình 5 cũng gợi ý rằng không gian chiếu của các token TS nên bao phủ tập hợp hoàn chỉnh của không gian embedding văn bản. Do đó, chúng tôi sử dụng clustering để tìm P nguyên mẫu văn bản đại diện. Quá trình sử dụng LLM để suy luận TS được hiển thị trong Hình 2. Trong khung này, dữ liệu văn bản được đưa vào lớp embedding của LLM, trong khi các prompt và embedding TS bỏ qua lớp này.

4 THÍ NGHIỆM
Cốt lõi của TEST là huấn luyện một encoder fe và một soft prompt pe như được mô tả trong Thuật toán 1. Encoder phải có thể trích xuất thông tin liên quan từ TS, cần phải hiệu quả về thời gian và bộ nhớ, và phải cho phép đầu vào có độ dài biến đổi. Do đó, chúng tôi xây dựng một TCN nhân quả với 10 lớp khối tích chập. Mỗi khối tích chập là một chuỗi GELU, DilatedConv, BatchNorm, GELU, DilatedConv, với kết nối bỏ qua qua mỗi khối. Các DilatedConv có dilation của 2i trong mỗi lớp i của khối tích chập. Một khối tích chập cuối cùng được sử dụng để ánh xạ các kênh ẩn đến kênh đầu ra có kích thước giống với kích thước embedding của LLM.

--- TRANG 7 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
Thuật toán 1 Huấn luyện TEST
1:for e in epochs do
2: // CẬP NHẬT ENCODER
3: θfe=θfe−η▽θfe(Lins+Ltext)
4: // CẬP NHẬT DECODER (TÙY CHỌN)
5: θfd=θfd−η▽θfdLae
6: // CẬP NHẬT PROJECTOR
7: θfp=θfp−η▽θfpLins
8:end for 9:for e in epochs do
10: // CẬP NHẬT PROMPT
11: pe=pe−η▽θpeLpromp
12: // TINH CHỈNH DECODER (TÙY CHỌN)
13: θfd=θfd−η′▽θfdLreg
14: // CẬP NHẬT CLASSIFIER (TÙY CHỌN)
15: θfc=θfc−η▽θfcLcls
16:end for

Model Size Embed. dimension
Bert Devlin et al. (2018) 110M, 335M 748, 1024
GPT2 Radford et al. (2019) 117M, 345M, 774M 768, 1024, 1280
ChatGLM Du et al. (2022) 6B 4096
LLaMa2 Touvron et al. (2023) 7B, 13B 4096
Bảng 2: Mô hình Ngôn ngữ được Sử dụng

Các LLM được sử dụng được liệt kê trong Bảng 2. Mỗi encoder và soft prompt của LLM được huấn luyện bằng trình tối ưu Adam trên 20 GPU NVIDIA Tesla V100-SXM2 với CUDA 11.3.

Chúng tôi so sánh phương pháp của chúng tôi với 5 loại phương pháp bao gồm 12 baseline: 1) Các phương pháp LLM-QA Xue & Salim (2023); Liu et al. (2023) với template phân loại Phân loại chuỗi [domain] đã cho là [class label] hoặc [class label]: [numerical sequence]. [A] và template dự báo [Q] Dự báo giá trị tiếp theo của chuỗi [domain] đã cho: [numerical sequence]. [A] ; 2) Phương pháp SFT LLM-for-TS GPT4TS Zhou et al. (2023); 3) các mô hình TS cổ điển DWT, DWTD Bagnall et al. (2018), 1NNED, và TCN Tan et al. (2021); 4) các mô hình TS SOTA Informer Zhou et al. (2021), DLinear Zeng et al. (2023), và TimesNet Wu et al. (2023); 5) các mô hình TS dựa trên CL SOTA Tloss Franceschi et al. (2019b), TS2Vec Yue et al. (2022), và CoST Woo et al. (2022a).

Kết quả tổng thể được hiển thị trong Hình 3 (Phụ lục có nhiều mô hình SOTA cổ điển được so sánh hơn và kết quả chi tiết về dự báo dài hạn, ngắn hạn, few-shot và zero-shot, phân loại chuỗi thời gian đa biến và các nhiệm vụ biểu diễn.). Nhìn chung, sau khi sử dụng TEST, khi kích thước của LLM đạt khoảng 300M, độ chính xác của chúng tương đương với mô hình SOTA.

4.1 PHÂN LOẠI
Chúng tôi trình bày điểm độ chính xác cho tất cả 128 loại bộ dữ liệu TS đơn biến trong kho lưu trữ UCR Dau et al. (2019) và tất cả 30 loại bộ dữ liệu TS đa biến trong kho lưu trữ UEA Bagnall et al. (2018).

Độ chính xác. Trong Hình 3 (a-b), TEST làm cho độ chính xác phân loại của LLM tăng đáng kể. Hiệu suất phân loại gốc của LLM được chứng minh thông qua hai kết quả QA. Nó gần như đoán nhãn phân loại một cách ngẫu nhiên, đặc biệt đối với TS đa biến. Sau khi sử dụng TEST, GPT2-774M, có độ chính xác trung bình giữa tất cả các mô hình, có thể cải thiện độ chính xác ít nhất 18% cho TS đơn biến và 25% cho TS đa biến. TEST làm cho hầu hết LLM tương đương, nếu không tốt hơn, các mô hình hiện có. Khi kích thước đạt khoảng 300M, độ chính xác có thể vượt qua baseline TS; Khi kích thước đạt khoảng 700M, độ chính xác có thể vượt qua SOTA TS transformer.

Ablation. Trong Hình 3 (c-d), các nguyên mẫu văn bản khác nhau sẽ dẫn đến các kết quả khác nhau. Chúng tôi đặt 3 nhóm nguyên mẫu văn bản: embedding của value, shape, frequency, và embedding của 3 hoặc 10 trung tâm cụm. Việc chọn một nhóm nguyên mẫu đại diện chính xác hơn cho toàn bộ không gian embedding văn bản của LLM có thể cải thiện hiệu suất. Điều này cũng được gợi ý bởi Phương trình 5. Các loại prompt khác nhau, khởi tạo và độ dài sẽ dẫn đến các kết quả khác nhau. Chúng tôi so sánh soft prompt với hard prompt của Phân loại chuỗi [domain] đã cho là [class label] hoặc [class label]: [TS embedding]. Độ chính xác khác biệt ít nhất 10%. Chúng tôi đặt khởi tạo ngẫu nhiên từ phân phối đều và khởi tạo mô tả nhiệm vụ từ Phân loại chuỗi đã cho. Cái sau làm cho việc huấn luyện hội tụ nhanh hơn. Khi mô hình đạt 1B, độ dài prompt là 10 có thể đạt được kết quả xuất sắc.

4.2 DỰ BÁO
Chúng tôi trình bày điểm MSE dự báo ngắn hạn cho tất cả 19 loại bộ dữ liệu chuỗi thời gian đa dạng trong kho lưu trữ TSER Tan et al. (2021), và điểm MSE dự báo dài hạn cho 8 bộ dữ liệu benchmark thế giới thực phổ biến bao gồm weather, traffic, electricity, ILI và ETT từ Wu et al. (2023).

--- TRANG 8 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
Univariate Classification Multivariate Classification Shot-term Forecasting Long-term Forecasting Few-shot Forecasting General Forecasting Representation TEST (GPT2-774M) TimesNet DLinear Informer TCN TS2Vec 
LLM+TEST (ours) Classical SOTA models QA CL models
LLM+TEST (ours) Classical SOTA models QA CL models b LLM+TEST (ours) Classical SOTA models QA
LLM+TEST (ours) SOTA models QA SFT e
f
UCR classification accuracy UCR classification accuracy c LLM+TEST (ours) Classical SOTA models
LLM+TEST (ours) SOTA models QA SFT h
Embedding before / after inputting LLM (ours)  + SVM CL models + SVM a
i d g LLM+TEST (ours) Classical SOTA models QA CL models UCR classification accuracy using representation UCR classification accuracy
Hình 3: Kết quả Thí nghiệm. (a-d) hiển thị kết quả phân loại; (e-h) hiển thị kết quả dự báo; (i) hiển thị kết quả biểu diễn. Đường đứt nét màu đỏ đại diện cho kết quả tốt nhất.

Độ chính xác. Trong Hình 3 (e-f), TEST làm cho độ chính xác dự báo của LLM tăng đáng kể và có thể so sánh với các mô hình SOTA. Khi kích thước đạt khoảng 300M, độ chính xác có thể vượt qua SOTA TS transformer.

Tổng quát hóa. Chúng tôi kết hợp 19 bộ dữ liệu thành 1 bộ dữ liệu và kiểm tra phương pháp trên bộ dữ liệu kết hợp này. Như được hiển thị trong Hình 3 (g), so với baseline, các mô hình dựa trên LLM có tính tổng quát tốt hơn.

Few-shot. LLM đã chứng minh hiệu suất đáng chú ý trong học few-shot. Dựa trên các thiết lập trong Zhou et al. (2023), chúng tôi trình bày dự báo few-shot cho 10% bước thời gian trong bộ dữ liệu huấn luyện. Như được hiển thị trong Hình 3 (h), TEST đạt được hiệu suất tốt nhất và chứng minh việc giảm MSE tương đối trung bình 23,5%.

--- TRANG 9 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
4.3 BIỂU DIỄN
Active silence silent absent important final night voiced White important change loop happy actively limit finally
Hình 4: Khớp Embedding TS với Từ

Học biểu diễn. Học biểu diễn phổ quát cho TS là một vấn đề cơ bản nhưng thách thức. Cả bước đầu tiên của TEST (tạo embedding TS) và bước thứ hai (đầu ra của LLM) đều có thể đạt được nhiệm vụ này. Dựa trên nhiệm vụ học biểu diễn cổ điển, chúng tôi đánh giá hiệu quả của biểu diễn TEST bằng cách sử dụng classifier SVM trên bộ dữ liệu UCR. Lưu ý rằng việc sử dụng một classifier đơn giản có thể phản ánh tốt hơn hiệu ứng trình bày. Trong Hình 3 (i), embedding trong bước đầu tiên của TEST có thể so sánh với các phương pháp biểu diễn SOTA, và embedding trong bước thứ hai của TEST có thể vượt trội hơn chúng. Điều này cho thấy rằng sau khi sử dụng LLM, biểu diễn của TS trở nên phân biệt hơn.

Trường hợp. Chúng tôi sử dụng phương pháp láng giềng gần nhất để tìm văn bản mà một token TS khớp trong không gian embedding từ của LLM đã được đóng băng. Trong Hình 4, phần lớn các từ được xác định là tính từ và danh từ liên quan đến cảm xúc. Chúng tôi suy đoán rằng bằng cách prompting, mô hình sẽ coi nhiệm vụ phân loại TS như một nhiệm vụ phân loại cảm xúc. Do đó, việc giới thiệu prompt giống như việc giới thiệu một đường tắt cho LLM. Bên cạnh đó, các từ khớp giống như một loại Shapelet văn bản cho phân đoạn TS, đại diện cho TS thông qua một loạt các mẫu. Thay vì coi TS như một chuỗi số, chúng tôi đề xuất sử dụng từ để xác định các mẫu trong TS vì LLM không có SFT không giỏi về toán học khi thực hiện các nhiệm vụ kỹ thuật số, nhưng chúng giỏi trích xuất kiến thức như một máy nhận dạng mẫu. Ngữ nghĩa của các mẫu có thể gây bối rối cho chúng ta, nhưng nó có ý nghĩa đối với LLM.

5 THẢO LUẬN VÀ KẾT LUẬN
Bài báo này đề xuất một phương pháp embedding TS căn chỉnh nguyên mẫu văn bản theo instance, theo feature để đạt được TS-for-LLM. Nó có thể kích hoạt khả năng của LLM cho các nhiệm vụ TS trong khi duy trì khả năng ngôn ngữ ban đầu của nó. Các thí nghiệm về phân loại, dự báo và các nhiệm vụ biểu diễn cho thấy rằng sử dụng TEST, LLM có thể lưu trữ hiệu suất tương đương với các phương pháp SOTA.

TS-for-LLM có thể làm phong phú khả năng của LLM. SFT LLM có thể hiệu quả hơn TS-for-LLM, nhưng ưu thế của nó so với các mô hình TS tùy chỉnh vẫn không rõ ràng; Huấn luyện các mô hình tùy chỉnh có thể chính xác hơn trong các nhiệm vụ TS, nhưng TS-for-LLM cung cấp tất cả các lợi ích đáng chú ý của LLM bổ sung.

TS-for-LLM có thể khám phá cơ chế của LLM như một máy nhận dạng mẫu. Bản chất của TS-for-LLM là: TS ↔ embedding TS ↔ mẫu ↔ embedding văn bản/từ ↔ văn bản. Mặc dù TEST tạo ấn tượng về các hoạt động căn chỉnh cưỡng bức giữa TS và văn bản, nó thực sự chuyển đổi TS thành một chuỗi mẫu có thể hiểu được cho LLM, điều đó chứng minh rõ ràng rằng bản chất của LLM là nhận dạng mẫu. Thực tế, TS là dữ liệu khách quan, trong khi hình ảnh, văn bản và giọng nói là dữ liệu chủ quan có thể được con người cảm nhận. TEST căn chỉnh dữ liệu TS khách quan và dữ liệu văn bản chủ quan ở cấp độ máy, nhưng cách căn chỉnh chúng ở cấp độ nhận thức con người đòi hỏi nghiên cứu tương lai.

Trong khi đó, ngoài nguyên mẫu văn bản và prompt, kích thước và loại LLM cũng ảnh hưởng đến kết quả. Tác động của loại mô hình là trực quan, nó liên quan đến các nhiệm vụ downstream, trong đó cấu trúc hai chiều có lợi cho phân loại, và cấu trúc tạo có lợi cho dự báo. Tác động của kích thước mô hình, trong đó một mô hình lớn hơn tạo ra kết quả chính xác hơn, có thể được quy cho nhiều lý do khác nhau. Ngoài tác động của các tham số bổ sung, chúng tôi tin rằng các bộ dữ liệu được sử dụng trong quá trình tiền huấn luyện cũng quan trọng, với kích thước, tính đa dạng và loại corpus đều có tác động. Chúng tôi phỏng đoán rằng nhiều dữ liệu huấn luyện hơn sẽ cung cấp cho mô hình nhiều cơ hội hơn để học các mẫu thời gian. Do đó, chúng tôi có ý định tiến hành nhiều thí nghiệm hơn để điều tra các mối tương quan sâu hơn giữa corpus và dữ liệu TS Chen et al. (2023).

LỜI CẢM ÕN
Nghiên cứu này được hỗ trợ bởi Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc (Số 62172018, Số 62102008) và Cơ sở Thí nghiệm Tổng hợp Quốc gia Vùng Phát triển Công nghệ cao Đông Hồ Vũ Hán để Quản trị Xã hội Thông minh.

--- TRANG 10 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
TÀI LIỆU THAM KHẢO
Anthony J. Bagnall, Hoang Anh Dau, Jason Lines, Michael Flynn, James Large, Aaron Bostrom,
Paul Southam, và Eamonn J. Keogh. Kho lưu trữ phân loại chuỗi thời gian đa biến UEA,
2018. CoRR , abs/1811.00075, 2018.

Kaifeng Bi, Lingxi Xie, Hengheng Zhang, Xin Chen, Xiaotao Gu, và Qi Tian. Dự báo thời tiết toàn cầu tầm trung chính xác với mạng neural 3d. Nature , pp. 1476–4687, 2023. doi:
10.1038/s41586-023-06545-z.

Aaron Bostrom, Anthony Bagnall, Eamonn Keogh, Hoang Anh Dau, James Large, Jason Lines,
Michael Flynn, và Paul Southam. Kho lưu trữ phân loại chuỗi thời gian đa biến uea, 2018,
2018.

Eoin Brophy, Zhengwei Wang, Qi She, và Tom ´as Ward. Mạng đối nghịch tạo sinh trong chuỗi thời gian: Một đánh giá tài liệu có hệ thống. ACM Comput. Surv. , 55(10):199:1–199:31, 2023.

Mathilde Caron, Ishan Misra, Julien Mairal, Priya Goyal, Piotr Bojanowski, và Armand Joulin.
Học không giám sát các đặc trưng thị giác bằng cách tương phản phân công cụm. Trong Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, và Hsuan-Tien Lin (biên tập), Advances
in Neural Information Processing Systems , 2020a.

Mathilde Caron, Ishan Misra, Julien Mairal, Priya Goyal, Piotr Bojanowski, và Armand Joulin.
Học không giám sát các đặc trưng thị giác bằng cách tương phản phân công cụm. 2020b.

CDC. Bệnh tật. 2021. doi: https://gis.cdc.gov/grasp/fluview/fluportaldashboard.html.

Ching Chang, Wen-Chih Peng, và Tien-Fu Chen. LLM4TS: tinh chỉnh hai giai đoạn cho dự báo chuỗi thời gian với LLM đã được tiền huấn luyện. CoRR , abs/2308.08469, 2023.

Daoyuan Chen, Yilun Huang, và et al. Data-juicer: Một hệ thống xử lý dữ liệu một cửa cho các mô hình ngôn ngữ lớn. CoRR , abs/2309.0203, 2023.

Ting Chen, Simon Kornblith, Mohammad Norouzi, và Geoffrey E. Hinton. Một khung đơn giản
cho học tương phản biểu diễn thị giác. Trong Proceedings of International Conference on
Machine Learning , tập 119, pp. 1597–1607, 2020.

Hyunseung Chung, Jiho Kim, Joon-Myoung Kwon, Ki-Hyun Jeon, Min Sung Lee, và Edward
Choi. Text-to-ecg: Tổng hợp điện tâm đồ 12 chuyển đạo có điều kiện trên báo cáo văn bản lâm sàng. Trong
IEEE International Conference on Acoustics, Speech and Signal Processing , pp. 1–5, 2023.

Hoang Anh Dau, Anthony Bagnall, Kaveh Kamgar, Chin-Chia Michael Yeh, Yan Zhu, Shaghayegh
Gharghabi, Chotirat Ann Ratanamahatana, và Eamonn Keogh. Kho lưu trữ chuỗi thời gian ucr.
IEEE/CAA Journal of Automatica Sinica , 6:1293–1305, 2019. doi: 10.1109/JAS.2019.1911747.

Angus Dempster, Daniel F. Schmidt, và Geoffrey I. Webb. Minirocket: Một biến đổi rất nhanh (gần như) xác định cho phân loại chuỗi thời gian. Trong ACM SIGKDD Conference on Knowledge
Discovery and Data Mining , pp. 248–257, 2021. doi: 10.1145/3447548.3467231.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. BERT: tiền huấn luyện của các transformer hai chiều sâu cho hiểu ngôn ngữ. CoRR , abs/1810.04805, 2018.

Jiaxiang Dong, Haixu Wu, Haoran Zhang, Li Zhang, Jianmin Wang, và Mingsheng Long. Simmtm:
Một khung tiền huấn luyện đơn giản cho mô hình chuỗi thời gian có mặt nạ. CoRR , abs/2302.00861, 2023.

Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, và Jie Tang. Glm:
Tiền huấn luyện mô hình ngôn ngữ tổng quát với điền chỗ trống tự hồi quy. Trong Proceedings of Annual
Meeting of the Association for Computational Linguistics , tập 1, pp. 320–335, 2022.

Emadeldeen Eldele, Mohamed Ragab, Zhenghua Chen, Min Wu, Chee Keong Kwoh, Xiaoli Li, và
Cuntai Guan. Học biểu diễn chuỗi thời gian qua tương phản thời gian và ngữ cảnh. Trong
Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence , pp. 2352–
2359, 2021a.

--- TRANG 11 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
Emadeldeen Eldele, Mohamed Ragab, Zhenghua Chen, Min Wu, Chee Keong Kwoh, Xiaoli Li, và
Cuntai Guan. Học biểu diễn chuỗi thời gian qua tương phản thời gian và ngữ cảnh. Trong
International Joint Conference on Artificial Intelligence , pp. 2352–2359, 2021b.

Jean-Yves Franceschi, Aymeric Dieuleveut, và Martin Jaggi. Học biểu diễn có thể mở rộng không giám sát cho chuỗi thời gian đa biến. Trong Advances in Neural Information Processing Systems , pp.
4652–4663, 2019a.

Jean-Yves Franceschi, Aymeric Dieuleveut, và Martin Jaggi. Học biểu diễn có thể mở rộng không giám sát cho chuỗi thời gian đa biến. Trong Advances in Neural Information Processing Systems , pp.
4652–4663, 2019b.

Ge Gao, Qitong Gao, Xi Yang, Miroslav Pajic, và Min Chi. Một khung khai thác mẫu được thông báo bởi học tăng cường
cho phân loại chuỗi thời gian đa biến. Trong Proceedings of International
Joint Conference on Artificial Intelligence , pp. 2994–3000, 2022. doi: 10.24963/IJCAI.2022/415.

Jean-Bastien Grill, Florian Strub, Florent Altch ´e, Corentin Tallec, Pierre H. Richemond, Elena
Buchatskaya, Carl Doersch, Bernardo ´Avila Pires, Zhaohan Guo, Mohammad Gheshlaghi Azar,
Bilal Piot, Koray Kavukcuoglu, R ´emi Munos, và Michal Valko. Bootstrap your own latent - Một
cách tiếp cận mới cho học tự giám sát. Trong Advances in Neural Information Processing Systems ,
2020.

Nate Gruver, Marc Finzi, Shikai Qiu, và Andrew Gordon Wilson. Các mô hình ngôn ngữ lớn là các bộ dự báo chuỗi thời gian zero-shot. CoRR , abs/2310.07820, 2023. doi: 10.48550/ARXIV .2310.07820.

Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, và Ross B. Girshick. Momentum contrast cho
học biểu diễn thị giác không giám sát. Trong Computer Vision and Pattern Recognition , pp.
9726–9735, 2020.

Shenda Hong, Hongyan Li, Chenxi Sun, và Junyuan Shang. Nghiên cứu và ứng dụng trích xuất kiểu hình tính toán từ chuỗi thời gian dấu hiệu sinh tồn. China Seience and Technology Achivements ,
10, 2023. doi: 10.3772/j.issn.1009-5659.223.10.002.

John Hopcroft và Ravindran Kannan. Lý thuyết khoa học máy tính cho thời đại thông tin . Cambridge
University press, 2013.

Zhizhong Huang, Jie Chen, Junping Zhang, và Hongming Shan. Học biểu diễn cho phân cụm qua phân tán nguyên mẫu và lấy mẫu tích cực. IEEE Trans. Pattern Anal. Mach. Intell. , 45
(6):7509–7524, 2023. doi: 10.1109/TPAMI.2022.3216454.

Ming Jin, Shiyu Wang, Lintao Ma, Zhixuan Chu, James Y . Zhang, Xiaoming Shi, Pin-Yu Chen,
Yuxuan Liang, Yuan-Fang Li, Shirui Pan, và Qingsong Wen. Time-llm: Dự báo chuỗi thời gian bằng cách lập trình lại các mô hình ngôn ngữ lớn. CoRR , abs/2310.01728, 2023. doi: 10.48550/ARXIV .
2310.01728.

Fazle Karim, Somshubra Majumdar, Houshang Darabi, và Samuel Harford. Multivariate lstm-fcns
cho phân loại chuỗi thời gian. Neural Networks , 116:237–245, 2019. doi: 10.1016/J.NEUNET.
2019.04.014.

Salar Hosseini Khorasgani, Yuxuan Chen, và Florian Shkurti. SLIC: học tự giám sát với phân cụm lặp cho video hành động con người. Trong IEEE/CVF Conference on Computer Vision and
Pattern Recognition , pp. 16070–16080, 2022. doi: 10.1109/CVPR52688.2022.01562.

Nikita Kitaev, Lukasz Kaiser, và Anselm Levskaya. Reformer: Transformer hiệu quả. Trong
International Conference on Learning Representations , 2020.

Brian Lester, Rami Al-Rfou, và Noah Constant. Sức mạnh của quy mô cho tinh chỉnh prompt hiệu quả tham số. Trong Proceedings of Conference on Empirical Methods in Natural Language Processing ,
pp. 3045–3059, 2021. doi: 10.18653/v1/2021.emnlp-main.243.

Guozhong Li, Byron Choi, Jianliang Xu, Sourav S. Bhowmick, Kwok-Pan Chun, và Grace Lai-
Hung Wong. Shapenet: Một cách tiếp cận mạng shapelet-neural cho phân loại chuỗi thời gian đa biến. Trong AAAI Conference on Artificial Intelligence , pp. 8375–8383, 2021a. doi:
10.1609/AAAI.V35I9.17018.

--- TRANG 12 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
Jun Li, Che Liu, Sibo Cheng, Rossella Arcucci, và Shenda Hong. Mô hình ngôn ngữ đóng băng giúp học zero-shot ecg. Trong Medical Imaging with Deep Learning , pp. 402–415, 2024.

Junnan Li, Pan Zhou, Caiming Xiong, và Steven C. H. Hoi. Học tương phản nguyên mẫu của biểu diễn không giám sát. Trong International Conference on Learning Representations , 2021b.

Yunfan Li, Peng Hu, Jerry Zitao Liu, Dezhong Peng, Joey Tianyi Zhou, và Xi Peng. Phân cụm tương phản. Trong AAAI Conference on Artificial Intelligence, , pp. 8547–8555, 2021c.

Xin Liu, Daniel McDuff, Geza Kovacs, Isaac R. Galatzer-Levy, Jacob E. Sunshine, Jiening Zhan,
Ming-Zher Poh, Shun Liao, Paolo Di Achille, và Shwetak N. Patel. Các mô hình ngôn ngữ lớn là những người học sức khỏe few-shot. CoRR , abs/2305.15525, 2023. doi: 10.48550/arXiv.2305.15525.

Yong Liu, Haixu Wu, Jianmin Wang, và Mingsheng Long. Transformer không ổn định: Khám phá tính ổn định trong dự báo chuỗi thời gian. Trong Advances in Neural Information Processing Systems ,
2022.

Qianli Ma, Zhen Liu, Zhenjing Zheng, Ziyang Huang, Siying Zhu, Zhongzhong Yu, và James T.
Kwok. Một khảo sát về các mô hình tiền huấn luyện chuỗi thời gian. CoRR , abs/2305.10716, 2023. doi: 10.48550/
arXiv.2305.10716.

Qianwen Meng, Hangwei Qian, Yong Liu, Yonghui Xu, Zhiqi Shen, và Lizhen Cui. MHCCL:
học tương phản phân cấp có mặt nạ cho chuỗi thời gian đa biến. CoRR ,
abs/2212.01141, 2022.

Qianwen Meng, Hangwei Qian, Yong Liu, Lizhen Cui, Yonghui Xu, và Zhiqi Shen. MHCCL:
học tương phản phân cấp có mặt nạ cho chuỗi thời gian đa biến. Trong AAAI Conference on Artificial Intelligence , pp. 9153–9161, 2023a. doi: 10.1609/aaai.v37i8.26098.

Qianwen Meng, Hangwei Qian, Yong Liu, Yonghui Xu, Zhiqi Shen, và Lizhen Cui. Học biểu diễn không giám sát cho chuỗi thời gian: Một đánh giá. CoRR , abs/2308.01578, 2023b. doi: 10.48550/
arXiv.2308.01578.

Qianwen Meng, Hangwei Qian, Yong Liu, Yonghui Xu, Zhiqi Shen, và Lizhen Cui. Học biểu diễn không giám sát cho chuỗi thời gian: Một đánh giá. CoRR , abs/2308.01578, 2023c.

Suvir Mirchandani, Fei Xia, Pete Florence, Brian Ichter, Danny Driess, Montserrat Gonzalez Arenas, Kanishka Rao, Dorsa Sadigh, và Andy Zeng. Các mô hình ngôn ngữ lớn như máy mẫu tổng quát. Trong Conference on Robot Learning , tập 229 của Proceedings of Machine Learning
Research , pp. 2498–2518, 2023.

Yuqi Nie, Nam H. Nguyen, Phanwadee Sinthong, và Jayant Kalagnanam. Một chuỗi thời gian đáng giá 64 từ: Dự báo dài hạn với transformer. Trong International Conference on Learning
Representations , 2023.

Boris N. Oreshkin, Dmitri Carpov, Nicolas Chapados, và Yoshua Bengio. N-BEATS: phân tích mở rộng cơ sở neural cho dự báo chuỗi thời gian có thể giải thích. Trong 8th International Conference on
Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020 , 2020.

PeMS. Giao thông. 2021. doi: http://pems.dot.ca.gov/.

Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, và Ilya Sutskever. Các mô hình ngôn ngữ là những người học đa nhiệm không giám sát. OpenAI , 2019.

Patrick Sch ¨afer và Ulf Leser. Phân loại chuỗi thời gian đa biến với WEASEL+MUSE. CoRR ,
abs/1711.11343, 2017.

Vivek Sharma, Makarand Tapaswi, M. Saquib Sarfraz, và Rainer Stiefelhagen. Học tương phản dựa trên phân cụm để cải thiện biểu diễn khuôn mặt. Trong IEEE International Conference on Automatic Face and Gesture Recognition , pp. 109–116, 2020. doi: 10.1109/FG47880.2020.00011.

Taylor SJ và Letham B. Dự báo ở quy mô. Trong PeerJ Preprints , pp. 5:e3190v2, 2017. doi:
10.7287/peerj.preprints.3190v2.

--- TRANG 13 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
Chenxi Sun, Shenda Hong, và et al. Một đánh giá về các phương pháp học sâu cho dữ liệu chuỗi thời gian y tế được lấy mẫu không đều. CoRR , abs/2010.12493, 2020. doi: 10.48550/arXiv.2010.12493.

Chang Wei Tan, Christoph Bergmeir, Francois Petitjean, và Geoffrey I Webb. Hồi quy ngoại sinh chuỗi thời gian. Data Mining and Knowledge Discovery , pp. 1–29, 2021. doi: https://doi.org/10.1007/
s10618-021-00745-9.

Sana Tonekaboni, Danny Eytan, và Anna Goldenberg. Học biểu diễn không giám sát cho chuỗi thời gian với mã hóa lân cận thời gian. Trong International Conference on Learning Representations , 2021.

Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, và et al. Llama 2:
Mô hình nền tảng mở và chat được tinh chỉnh. CoRR , abs/2307.09288, 2023.

A¨aron van den Oord, Yazhe Li, và Oriol Vinyals. Học biểu diễn với mã hóa dự đoán tương phản. CoRR , abs/1807.03748, 2018.

Tongzhou Wang và Phillip Isola. Hiểu học biểu diễn tương phản thông qua căn chỉnh và tính đồng nhất trên hypersphere. Trong Proceedings of International Conference on Machine
Learning , tập 119, pp. 9929–9939, 2020.

Xiao Wang, Guangyao Chen, Guangwu Qian, Pengcheng Gao, Xiao-Yong Wei, Yaowei Wang,
Yonghong Tian, và Wen Gao. Các mô hình tiền huấn luyện đa phương thức quy mô lớn: Một khảo sát toàn diện. Mach. Intell. Res. , 20(4):447–482, 2023. doi: 10.1007/s11633-022-1410-8.

Wetterstation. Thời tiết. 2017. doi: https://www.bgc-jena.mpg.de/wetter/.

Kristoffer Wickstrøm, Michael Kampffmeyer, Karl Øyvind Mikalsen, và Robert Jenssen. Trộn lẫn học tương phản: Học biểu diễn tự giám sát cho chuỗi thời gian. Pattern Recognit.
Lett., 155:54–61, 2022.

Gerald Woo, Chenghao Liu, Doyen Sahoo, Akshat Kumar, và Steven C. H. Hoi. Cost: Học tương phản của biểu diễn xu hướng-mùa vụ tách rời cho dự báo chuỗi thời gian. Trong International Conference on Learning Representations , 2022a.

Gerald Woo, Chenghao Liu, Doyen Sahoo, Akshat Kumar, và Steven C. H. Hoi. Cost: Học tương phản của biểu diễn xu hướng-mùa vụ tách rời cho dự báo chuỗi thời gian. Trong The International Conference on Learning Representations , 2022b.

Gerald Woo, Chenghao Liu, Doyen Sahoo, Akshat Kumar, và Steven C. H. Hoi. Etsformer: Transformer làm mịn hàm mũ cho dự báo chuỗi thời gian. CoRR , abs/2202.01381, 2022c.

Haixu Wu, Jiehui Xu, Jianmin Wang, và Mingsheng Long. Autoformer: Transformer phân tách với tự tương quan cho dự báo chuỗi dài hạn. Trong Advances in Neural Information Processing Systems , pp. 22419–22430, 2021.

Haixu Wu, Tengge Hu, Yong Liu, Hang Zhou, Jianmin Wang, và Mingsheng Long. Timesnet:
Mô hình hóa biến thiên 2d thời gian cho phân tích chuỗi thời gian tổng quát. Trong International Conference on
Learning Representations , 2023.

Hao Xue và Flora D. Salim. Promptcast: Một mô hình học dựa trên prompt mới cho dự báo chuỗi thời gian. CoRR , abs/2210.08964, 2023.

Ling Yang và Shenda Hong. Học biểu diễn chuỗi thời gian không giám sát với sự kết hợp thời gian-phổ song tuyến lặp. Trong International Conference on Machine Learning , tập 162 của
Proceedings of Machine Learning Research , pp. 25038–25054, 2022.

Xinyu Yang, Zhenguo Zhang, và Rongyi Cui. Timeclr: Một khung học tương phản tự giám sát cho biểu diễn chuỗi thời gian đơn biến. Knowl. Based Syst. , 245:108606, 2022.

Jinsung Yoon, Daniel Jarrett, và Mihaela van der Schaar. Mạng đối nghịch tạo sinh chuỗi thời gian. Trong Advances in Neural Information Processing Systems 32: Annual Conference on Neural
Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC,
Canada , pp. 5509–5519, 2019.

--- TRANG 14 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
Zhihan Yue, Yujing Wang, Juanyong Duan, Tianmeng Yang, Congrui Huang, Yunhai Tong, và
Bixiong Xu. Ts2vec: Hướng tới biểu diễn phổ quát của chuỗi thời gian. Trong AAAI Conference on
Artificial Intelligence , pp. 8980–8987, 2022.

Ailing Zeng, Muxi Chen, Lei Zhang, và Qiang Xu. Transformer có hiệu quả cho dự báo chuỗi thời gian không? Trong AAAI Conference on Artificial Intelligence , pp. 11121–11128, 2023. doi: 10.
1609/aaai.v37i9.26317.

George Zerveas, Srideepika Jayaraman, Dhaval Patel, Anuradha Bhamidipaty, và Carsten Eickhoff.
Một khung dựa trên transformer cho học biểu diễn chuỗi thời gian đa biến. Trong ACM
SIGKDD Conference on Knowledge Discovery and Data Mining , pp. 2114–2124, 2021. doi:
10.1145/3447548.3467401.

Dejiao Zhang, Feng Nan, Xiaokai Wei, Shang-Wen Li, Henghui Zhu, Kathleen R. McKeown,
Ramesh Nallapati, Andrew O. Arnold, và Bing Xiang. Hỗ trợ phân cụm với học tương phản. Trong Proceedings of Conference of the North American Chapter of the Association
for Computational Linguistics: Human Language Technologies , pp. 5419–5430, 2021. doi:
10.18653/V1/2021.NAACL-MAIN.427.

Xuchao Zhang, Yifeng Gao, Jessica Lin, và Chang-Tien Lu. Tapnet: Phân loại chuỗi thời gian đa biến với mạng nguyên mẫu có chú ý. Trong AAAI Conference on Artificial Intelligence ,
pp. 6845–6852, 2020. doi: 10.1609/AAAI.V34I04.6165.

Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min,
Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen,
Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, và Ji-
Rong Wen. Một khảo sát về các mô hình ngôn ngữ lớn. CoRR , abs/2303.18223, 2023. doi: 10.48550/
arXiv.2303.18223.

Xiaochen Zheng, Xingyu Chen, Manuel Sch ¨urch, Amina Mollaysa, Ahmed Allam, và Michael
Krauthammer. Simts: Suy nghĩ lại về học biểu diễn tương phản cho dự báo chuỗi thời gian.
CoRR , abs/2303.18205, 2023.

Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, và Wancai Zhang.
Informer: Vượt ra ngoài transformer hiệu quả cho dự báo chuỗi thời gian chuỗi dài. Trong AAAI Conference on Artificial Intelligence , pp. 11106–11115, 2021. doi: 10.1609/aaai.v35i12.17325.

Tian Zhou, Ziqing Ma, Qingsong Wen, Xue Wang, Liang Sun, và Rong Jin. Fedformer: Transformer được tăng cường tần số phân tách cho dự báo chuỗi dài hạn. Trong International Conference
on Machine Learning , tập 162 của Proceedings of Machine Learning Research , pp. 27268–
27286, 2022.

Tian Zhou, PeiSong Niu, Xue Wang, Liang Sun, và Rong Jin. Một phù hợp với tất cả: phân tích chuỗi thời gian tổng quát bằng LM tiền huấn luyện. Trong Conference and Workshop on Neural Information Processing
Systems , 2023.

Rundong Zuo, Guozhong Li, Byron Choi, Sourav S. Bhowmick, Daphne Ngar-yin Mah, và
Grace Lai-Hung Wong. SVP-T: Một transformer vị trí biến cấp hình dạng cho phân loại chuỗi thời gian đa biến. Trong AAAI Conference on Artificial Intelligence , pp. 11497–11505, 2023. doi:
10.1609/AAAI.V37I9.26359.

--- TRANG 15 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
A PHỤ LỤC
A.1 CÔNG VIỆC LIÊN QUAN
Công việc của chúng tôi chủ yếu liên quan đến hai lĩnh vực nghiên cứu: Học Biểu diễn Phổ quát (URL) cho chuỗi thời gian dựa trên Học Tương phản (CL) và Mô hình Ngôn ngữ Lớn (LLM) + Chuỗi Thời gian (TS).

A.1.1 URL DỰA TRÊN CL CHO TS
Các cách tiếp cận URL không giám sát nhằm học các biểu diễn đặc trưng phân biệt từ dữ liệu không được gắn nhãn, mà không yêu cầu chú thích từng mẫu. Việc kích hoạt URL cực kỳ quan trọng đối với dữ liệu chuỗi thời gian, do nút cổ chai chú thích độc đáo của nó gây ra bởi các đặc điểm phức tạp và thiếu tín hiệu thị giác so với các phương thức dữ liệu khác.

Các phương pháp tương phản học biểu diễn có ý nghĩa từ chuỗi thời gian bằng cách tối ưu hóa các nhiệm vụ tự phân biệt. Thay vì mô hình hóa trực tiếp dữ liệu thô phức tạp, chúng sử dụng các nhiệm vụ pretext tận dụng độ tương tự cơ bản giữa các mẫu, điều này loại bỏ nhu cầu tái tạo đầu vào hoàn chỉnh và cho phép khám phá các yếu tố biến thiên cơ bản được ngữ cảnh hóa. Các phương pháp tương phản thường tạo ra các view tăng cường của dữ liệu thô thông qua các biến đổi khác nhau và sau đó học biểu diễn bằng cách tương phản các mẫu tích cực với các mẫu tiêu cực. Các URL dựa trên CL hiện có cho TS được liệt kê trong Bảng 4.

Các mô hình tương phản cấp instance coi các mẫu riêng lẻ độc lập cho mục đích phân biệt instance. Chúng sử dụng tăng cường dữ liệu để biến đổi đầu vào gốc thành một không gian embedding mới. Trong không gian này, các tăng cường bắt nguồn từ cùng một mẫu được coi như các cặp tích cực, trong khi những cặp từ các mẫu khác nhau được coi như các cặp tiêu cực. Trong quá trình huấn luyện, các mô hình này được tối ưu hóa bằng cách tối đa hóa độ tương tự giữa biểu diễn của các cặp tích cực, đồng thời giảm thiểu độ tương tự giữa biểu diễn của các cặp tiêu cực.

Các mô hình tương phản cấp nguyên mẫu phá vỡ sự độc lập giữa các mẫu và khám phá để khai thác ngữ nghĩa ẩn được chia sẻ bởi các mẫu trong cùng một cụm. Chúng có thể giải quyết hạn chế rằng các mô hình học tương phản cấp instance có xu hướng coi các mẫu tương tự về mặt ngữ nghĩa như tiêu cực.

Các mô hình tương phản cấp thời gian thay vào đó tập trung vào việc nắm bắt các biểu diễn bất biến quy mô tại mỗi timestamp riêng lẻ. Bằng cách xem xét cả chiến lược học biểu diễn cấp instance và cấp thời gian, các nhà nghiên cứu nhằm tăng cường khả năng của các phương pháp học tương phản trong việc nắm bắt sự phức tạp vốn có trong dữ liệu chuỗi thời gian.

A.1.2 LLM+TS
Các mô hình lớn, cụ thể được gọi là các mô hình ngôn ngữ lớn (LLM) và các mô hình nền tảng tiền huấn luyện (PFM), đã chứng kiến thành công đáng chú ý trên nhiều nhiệm vụ và lĩnh vực, chẳng hạn như xử lý ngôn ngữ tự nhiên (NLP), thị giác máy tính (CV). Với những thành tựu đáng chú ý của các mô hình lớn trong những lĩnh vực đa dạng này, một câu hỏi hấp dẫn nổi lên: liệu các mô hình lớn có thể được sử dụng hiệu quả để phân tích dữ liệu TS không?

Dữ liệu TS đã được nghiên cứu lâu dài và được chứng minh là không thể thiếu trong vô số ứng dụng thế giới thực, bao gồm các lĩnh vực như địa chất học, giao thông, năng lượng, chăm sóc sức khỏe, môi trường và

Loại Ưu điểm Nhược điểm Phương pháp
Dựa trên tái tạo Bỏ qua dữ liệu không quan trọng Sụp đổ không gian embedding; TimeNet Wu et al. (2023)
có thể chứa nhiễu Không thể đo lường mối quan hệ feature SimMTM Dong et al. (2023)
Đối nghịch Loại bỏ nhu cầu gắn nhãn Khó khăn trong hội tụ mô hình; TimeGAN Yoon et al. (2019)
thủ công đắt tiền Không thể đo lường mối quan hệ feature TS-GAN Brophy et al. (2023)
Dự đoán Tự giám sát Bị ảnh hưởng bởi nhiễu TST Zerveas et al. (2021)
TS-TCC Eldele et al. (2021a)
Tương phản Tự giám sát Các bộ dữ liệu khác nhau yêu cầu các Bảng 4
phương pháp tăng cường dữ liệu và
đánh giá độ tương tự khác nhau
Bảng 3: Phương pháp Học Biểu diễn của Chuỗi Thời gian

--- TRANG 16 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
Loại Phương pháp
Cấp instance SimCLR Chen et al. (2020) TimeCLR Yang et al. (2022) MoCo He et al. (2020) BYOL Grill et al. (2020)
CPC van den Oord et al. (2018) SimSiam Zheng et al. (2023) MCL Wickstrøm et al. (2022)
Cấp nguyên mẫu SwA V Caron et al. (2020b) PCL Li et al. (2021b) CCL Sharma et al. (2020) SCCL Zhang et al. (2021)
CC Li et al. (2021c) SLIC Khorasgani et al. (2022) MHCCL Meng et al. (2022)
Cấp thời gian TS2Vec Yue et al. (2022) TS-TCC Eldele et al. (2021b) TNC Tonekaboni et al. (2021) TCL
T-Loss Franceschi et al. (2019b) BTSF Yang & Hong (2022) CoST Woo et al. (2022a)
Bảng 4: Phương pháp Biểu diễn Phổ quát dựa trên Học Tương phản cho Chuỗi Thời gian

Phương tiện Ưu điểm Nhược điểm Công việc
Huấn luyện Chuyên biệt, Không phổ quát, Tiền huấn luyện Ma et al. (2023)
chính xác bộ dữ liệu lớn Earth transformer Bi et al. (2023)
TS Transformers Wu et al. (2023)
Tinh chỉnh Đầu-cuối, Nhiều thí nghiệm hơn, GPT4TS Zhou et al. (2023)
chính xác mất khả năng ngôn ngữ LLM4TS Chang et al. (2023)
LLMTime Gruver et al. (2023)
Time-LLM Jin et al. (2023)
Tool Augmented Hiệu quả tham số,
ít thí nghiệm hơn Cần chuyên gia,
cần chú thích PromptCast Xue & Salim (2023)
Health Learner Liu et al. (2023)
METS Li et al. (2024)
Text2ECG Chung et al. (2023)
External Encoder Hiệu quả tham số, Kém mạnh mẽ TEST
khả năng đa dạng
Bảng 5: Công việc hiện có về TS+LLM

Hình 5: Lộ trình Kỹ thuật của LLM+TS

tài chính. Trong khi các mô hình lớn đã đạt được tiến bộ đáng kể trong nhiều lĩnh vực khác nhau, lĩnh vực phân tích chuỗi thời gian đã theo một con đường từ từ hơn. Các phương pháp phân tích truyền thống chủ yếu dựa vào các mô hình thống kê. Sự xuất hiện của học sâu đã kích thích cộng đồng nghiên cứu khám phá các mô hình dựa trên dữ liệu mạnh mẽ hơn, thường được xây dựng trên cơ sở Mạng Neural Hồi quy (RNN), Mạng Neural Tích chập (CNN) và Transformer. Tuy nhiên, phần lớn các mô hình này vẫn tương đối nhỏ về quy mô và được thiết kế riêng cho các nhiệm vụ cụ thể, do đó thiếu khả năng thu được biểu diễn ngữ nghĩa và kiến thức toàn diện từ dữ liệu quy mô lớn cho lý luận đa nhiệm vụ.

Không có nhiều nghiên cứu được thực hiện về TS+LLM vì lĩnh vực này vẫn đang trong giai đoạn sơ khai. Chúng tôi tóm tắt các công việc hiện có trong Bảng 5. Khác với văn bản chính, chúng tôi phân loại công việc ở đây thông qua phương tiện kỹ thuật.

--- TRANG 17 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
A.2 MÔ HÌNH
https://github.com/SCXsunchenxi/TEST

A.2.1 ENCODER
Cốt lõi của TEST là huấn luyện một encoder và một soft prompt. Encoder phải có thể trích xuất thông tin liên quan từ TS, cần phải hiệu quả về thời gian và bộ nhớ, và phải cho phép đầu vào có độ dài biến đổi. Do đó, như được hiển thị trong Hình 6, chúng tôi xây dựng một TCN nhân quả với 10 lớp khối tích chập. Mỗi khối tích chập là một chuỗi GELU, DilatedConv, BatchNorm, GELU, DilatedConv, với kết nối bỏ qua qua mỗi khối. Các DilatedConv có dilation của 2i trong mỗi lớp i của khối tích chập. Một khối tích chập cuối cùng được sử dụng để ánh xạ các kênh ẩn đến kênh đầu ra có kích thước giống với kích thước embedding của LLM.

Kiến trúc chi tiết là: Số kênh trong các lớp trung gian của mạng nhân quả là 40; Số lớp (độ sâu của mạng nhân quả) là 10; Kích thước kernel của tất cả các tích chập là 3; Độ dốc âm của kích hoạt leaky ReLU là 0.01; Số kênh đầu ra của mạng nhân quả (trước max pooling) là 640; Chiều của các biểu diễn giống với kích thước embedding của LLM (ví dụ 1024 cho gpt2).

Hình 6: Minh họa Ba Tích chập Nhân quả Dilated Xếp chồng và Thành phần của Lớp thứ i của Kiến trúc Đã chọn

Chúng tôi huấn luyện các mô hình của mình với các tham số sau cho phân loại chuỗi thời gian. Lưu ý rằng không có tối ưu hóa siêu tham số nào được thực hiện trên các siêu tham số encoder: Trình tối ưu là Adam với tốc độ học α= 0.001 và tỷ lệ suy giảm β= (0.9,0.999); Số mẫu tiêu cực là K∈ {1,2,5,10} cho chuỗi thời gian đơn biến, K∈ {5,10,20} cho chuỗi đa biến; Kích thước batch là 10; Số bước tối ưu hóa là 2000 cho K≤10 (tức là 20 epoch cho bộ dữ liệu có kích thước 1000), 1500 nếu không.

A.2.2 LLM
Các LLM được sử dụng được liệt kê trong Bảng 6. Mỗi encoder và soft prompt của LLM được huấn luyện bằng trình tối ưu Adam trên 20 GPU NVIDIA Tesla V100-SXM2 với CUDA 11.3.

A.3 NHIỆM VỤ DỰ BÁO
Tất cả các mạng học sâu được triển khai trong PyTorch và huấn luyện trên GPU NVIDIA V100 32GB. Chúng tôi sử dụng sai số bình phương trung bình (MSE) và sai số tuyệt đối trung bình (MAE) làm số liệu. Đối với học zero-shot, sai số phần trăm tuyệt đối trung bình (MAPE) được sử dụng cho TOURISM; MAPE đối xứng (sMAPE) được sử dụng cho M3 và M4; độ lệch chuẩn hóa (ND) được sử dụng cho ELECTR. Tất cả các thí nghiệm được lặp lại 3 lần và trung bình của các số liệu được sử dụng trong kết quả cuối cùng.

--- TRANG 18 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
Mô hình Kích thước Chiều embed.
Bert Devlin et al. (2018) 110M, 335M 748, 1024
GPT2 Radford et al. (2019) 117M, 345M, 774M 768, 1024, 1280
ChatGLM Du et al. (2022) 6B 4096
LLaMa2 Touvron et al. (2023) 7B, 13B 4096
Bảng 6: Mô hình Ngôn ngữ được Sử dụng

A.3.1 CHI TIẾT BỘ DỮ LIỆU
Chi tiết của các bộ dữ liệu dự báo dài hạn và few-shot là: Bộ dữ liệu ETT Zhou et al. (2021) chứa tải điện của các độ phân giải khác nhau (ETTh & ETTm) từ hai trạm điện; Bộ dữ liệu Weather Wetterstation (2017) chứa 21 chỉ số khí tượng của Đức trong 1 năm; Bộ dữ liệu Illness CDC (2021) chứa các bệnh nhân giống cúm ở Hoa Kỳ. ILI không được sử dụng cho học few-shot do số lượng hạn chế khó tuân theo định nghĩa few-shot; Bộ dữ liệu Electricity SJ & B (2017) chứa tiêu thụ điện; Bộ dữ liệu Traffic PeMS (2021) chứa tỷ lệ chiếm đóng của hệ thống đường cao tốc trên toàn tiểu bang California. Bảng 7 tóm tắt chi tiết thống kê đặc trưng.

Bộ dữ liệu Độ dài Chiều Tần số
ETTh 17420 7 1 giờ
ETTm 69680 7 15 phút
Weather 52696 22 10 phút
ILI 966 7 7 ngày
Electricity 26304 321 1 giờ
Traffic 17544 862 1 giờ
Bảng 7: Chi tiết Bộ dữ liệu Dự báo Dài hạn và Few-shot

Bộ dữ liệu Ánh xạ
Độ dài Horizon M4 M3
M3 Yearly 645 6 Yearly -
M3 Quarterly 756 8 Quarterly -
M3 Monthly 1428 18 Monthly -
M3 Others 174 8 Monthly -
M4 Yearly 23000 18 - Yearly
M4 Quarterly 6 24000 - Quarterly
M4 Monthly 8 48000 - Monthly
M4 Weekly 359 13 - Monthly
M4 Daily 4227 14 - Monthly
M4 Hourly 414 48 - Monthly
TOURISM Yearly 518 4 Yearly Yearly
TOURISM Quarterly 427 8 Quarterly Quarterly
TOURISM Monthly 366 24 Monthly Monthly
ELECTR 1311 168 Hourly Monthly
Bảng 8: Chi tiết Bộ dữ liệu Dự báo Zero-term và Ánh xạ của Học Zero-shot

Chi tiết của các bộ dữ liệu dự báo zero-shot là: M4 là một bộ dữ liệu lớn và đa dạng chứa chuỗi thời gian của các tần số và lĩnh vực khác nhau, bao gồm dự báo kinh doanh, tài chính và kinh tế; M3 nhỏ hơn M4, nhưng cũng chứa chuỗi thời gian từ các lĩnh vực và tần số đa dạng; TOURISM là bộ dữ liệu của các hoạt động du lịch với tần số khác nhau và chứa tỷ lệ chuỗi thất thường cao hơn nhiều so với M4; ELECTR đại diện cho việc giám sát sử dụng điện của 370 khách hàng trong ba năm. Bảng 8 tóm tắt chi tiết các bộ dữ liệu và ánh xạ zero-shot giữa nguồn và đích.

A.3.2 CHI TIẾT BASELINE
Đối với dự báo dài hạn, chúng tôi tham khảo các phương pháp SOTA được báo cáo trong Wu et al. (2023): TimesNet Wu et al. (2023), ETSformer Woo et al. (2022c), DLinear Zeng et al. (2023), FEDformer Zhou et al. (2022), Informer Zhou et al. (2021), và phương pháp LLM for TS GPT4TS Zhou et al. (2023).

--- TRANG 19 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
Đối với dự báo few-shot, chúng tôi tham khảo các phương pháp SOTA được báo cáo trong Zhou et al. (2023): DLinear Zeng et al. (2023), PatchTST Nie et al. (2023), TimesNet Wu et al. (2023), FEDformer Zhou et al. (2022), Autoformer Wu et al. (2021), Stationary Liu et al. (2022), ETSformer Woo et al. (2022c), Informer Zhou et al. (2021), Reformer Kitaev et al. (2020)

Đối với dự báo zero-shot, chúng tôi tham khảo các phương pháp SOTA được báo cáo trong Zhou et al. (2023): N-BEATS Oreshkin et al. (2020), DLinear Zeng et al. (2023), PatchTST Nie et al. (2023), TimesNet Wu et al. (2023), FEDformer Zhou et al. (2022), Autoformer Wu et al. (2021), Stationary Liu et al. (2022), ETSformer Woo et al. (2022c), Informer Zhou et al. (2021), Reformer Kitaev et al. (2020)

Phương pháp TEST GPT4TS TimesNet ETSformer DLinear FEDformer Informer TCN LSTM
ETTm1 96 0.293 0.346 0.292 0.346 0.325 0.398 0.338 0.375 0.345 0.372 0.375 0.398 0.672 0.571 0.863 0.664 0.863 0.664
192 0.332 0.369 0.332 0.372 0.324 0.387 0.408 0.410 0.380 0.389 0.426 0.441 0.795 0.669 0.837 0.700 1.113 0.776
336 0.368 0.392 0.366 0.394 0.360 0.411 0.435 0.428 0.413 0.413 0.445 0.459 1.212 0.871 1.124 0.832 1.267 0.832
720 0.418 0.420 0.417 0.421 0.428 0.450 0.499 0.462 0.474 0.453 0.543 0.490 1.166 0.823 1.153 0.820 1.324 0.858
Avg 0.353 0.382 0.352 0.383 0.350 0.406 0.429 0.425 0.403 0.407 0.448 0.452 0.961 0.734 0.929 0.725 1.142 0.782
ETTh1 96 0.372 0.400 0.376 0.397 0.384 0.402 0.494 0.479 0.386 0.400 0.376 0.419 0.865 0.713 0.878 0.740 1.044 0.773
192 0.414 0.422 0.416 0.418 0.436 0.429 0.538 0.504 0.437 0.432 0.420 0.448 1.008 0.792 1.037 0.824 1.217 0.832
336 0.422 0.437 0.442 0.433 0.491 0.469 0.574 0.521 0.481 0.459 0.459 0.465 1.107 0.809 1.238 0.932 1.259 0.841
720 0.447 0.467 0.477 0.456 0.521 0.500 0.562 0.535 0.519 0.516 0.506 0.507 1.181 0.865 1.135 0.852 1.271 0.838
Avg 0.414 0.431 0.427 0.426 0.458 0.450 0.542 0.510 0.456 0.452 0.440 0.460 1.040 0.795 1.072 0.837 1.198 0.821
ETTh2 96 0.275 0.338 0.285 0.342 0.340 0.374 0.340 0.391 0.333 0.387 0.358 0.397 3.755 1.525 2.116 1.197 2.522 1.278
192 0.340 0.379 0.354 0.389 0.402 0.414 0.430 0.439 0.477 0.476 0.429 0.439 5.602 1.931 4.315 1.635 3.312 1.384
336 0.329 0.381 0.373 0.407 0.452 0.452 0.485 0.559 0.594 0.541 0.496 0.487 4.721 1.835 1.124 1.604 3.291 1.388
720 0.381 0.423 0.406 0.441 0.462 0.468 0.500 0.497 0.831 0.657 0.463 0.474 3.647 1.625 3.188 1.540 3.257 1.357
Avg 0.331 0.380 0.354 0.394 0.414 0.427 0.439 0.452 0.559 0.515 0.437 0.449 4.431 1.729 2.686 1.494 3.095 1.352
Electricity 96 0.132 0.223 0.139 0.238 0.168 0.222 0.187 0.304 0.197 0.282 0.193 0.308 0.274 0.368 0.258 0.357 0.375 0.437
192 0.158 0.241 0.153 0.251 0.184 0.239 0.199 0.196 0.285 0.201 0.315 0.296 0.386 0.266 0.368 0.348 0.442 0.473
336 0.163 0.260 0.169 0.266 0.198 0.260 0.212 0.329 0.209 0.301 0.214 0.329 0.300 0.394 0.280 0.380 0.439 0.473
720 0.199 0.291 0.206 0.297 0.220 0.300 0.233 0.345 0.245 0.333 0.246 0.355 0.373 0.439 0.283 0.376 0.980 0.814
Avg 0.162 0.253 0.167 0.263 0.192 0.245 0.208 0.323 0.212 0.300 0.214 0.327 0.311 0.397 0.313 0.401 0.559 0.549
Traffic 96 0.407 0.282 0 0.388 0.282 0.593 0.321 0.607 0.392 0.650 0.396 0.587 0.366 0.719 0.391 0.684 0.384 0.843 0.453
192 0.423 0.287 0.407 0.290 0.617 0.336 0.621 0.399 0.598 0.370 0.604 0.373 0.696 0.379 0.685 0.390 0.847 0.453
336 0.430 0.296 0.412 0.294 0.629 0.336 0.622 0.396 0.605 0.373 0.621 0.383 0.777 0.420 0.734 0.408 0.853 0.455
720 0.463 0.315 0.450 0.312 0.640 0.350 0.632 0.396 0.645 0.394 0.626 0.382 0.864 0.472 0.717 0.396 1.500 0.805
Avg 0.430 0.295 0.414 0.294 0.620 0.336 0.621 0.396 0.625 0.383 0.610 0.376 0.764 0.416 0.705 0.395 1.011 0.541
Weather 96 0.150 0.202 0.162 0.212 0.152 0.220 0.197 0.281 0.196 0.255 0.217 0.296 0.300 0.384 0.458 0.490 0.369 0.406
192 0.198 0.246 0.204 0.248 0.209 0.261 0.237 0.312 0.237 0.296 0.276 0.336 0.598 0.544 0.658 0.589 0.416 0.435
336 0.245 0.286 0.254 0.286 0.280 0.306 0.298 0.353 0.283 0.335 0.339 0.380 0.578 0.521 0.797 0.652 0.455 0.454
720 0.324 0.342 0.326 0.337 0.365 0.359 0.352 0.288 0.345 0.381 0.403 0.428 1.059 0.741 0.869 0.675 0.535 0.520
Avg 0.229 0.271 0.237 0.270 0.236 0.287 0.271 0.334 0.265 0.317 0.309 0.360 0.634 0.548 0.696 0.602 0.444 0.454
ILI 24 1.974 0.886 2.063 0.881 2.317 0.934 2.527 1.000 2.398 1.040 3.228 1.260 5.764 1.677 4.480 1.444 5.914 1.734
36 2.028 0.976 1.868 0.892 1.972 0.900 2.615 1.007 2.646 1.088 2.679 1.080 4.755 1.467 4.799 1.467 6.631 1.845
48 2.353 1.115 1.790 0.884 2.238 0.900 2.359 0.972 2.614 1.086 2.622 1.078 4.763 1.469 4.800 1.468 6.736 1.857
60 2.425 1.203 1.979 0.957 2.027 0.928 2.487 1.016 2.804 1.146 2.857 1.15 5.264 1.564 5.278 1.560 6.870 1.879
Avg 2.195 1.045 1.925 0.903 2.139 0.901 2.497 1.004 2.616 1.090 2.847 1.144 5.137 1.544 4.839 1.485 6.538 1.829
1st count 5 5 4 0 0 0 0 0 0
Bảng 9: Kết quả Dự báo Dài hạn (MSE, MAE). TEST sử dụng GPT2-Medium làm backbone. Độ dài chuỗi quá khứ được đặt là 36 cho ILI và 96 cho những cái khác. Tất cả kết quả được tính trung bình từ 4 độ dài dự đoán khác nhau, tức là {24, 36, 48, 60} cho ILI và {96, 192, 336, 720} cho những cái khác.

A.3.3 DỰ BÁO DÀI HẠN
Chúng tôi tuân theo các thiết lập thí nghiệm cổ điển và kết quả của các mô hình SOTA trong Wu et al. (2023) (ICLR 2023). Kết quả được hiển thị trong Bảng 9. Nhìn chung, TEST đạt được hiệu suất tương đương với các mô hình SOTA TimesNet và Dlinear, và vượt trội hơn các baseline khác.

A.3.4 DỰ BÁO FEW-SHOT
Đối với nhiệm vụ dự báo few-shot, chỉ 10% phần trăm timestep của dữ liệu huấn luyện được sử dụng, và hai phần còn lại vẫn không thay đổi. Chúng tôi tuân theo các thiết lập thí nghiệm cổ điển và kết quả của các mô hình SOTA trong Zhou et al. (2023) (NeurIPS 2023). Kết quả được hiển thị trong Bảng 10. Nhìn chung, TEST có hiệu suất tương đương với các baseline SOTA PatchTST và Dlinear, và phương pháp LLM SOTA for TS GPT4TS.

--- TRANG 20 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
Phương pháp TEST GPT4TS DLinear PatchTST TimesNet FEDformer Autoformer Stationary ETSformer LightTS Informer Reformer
Weather 96 0.163 0.213 0.163 0.215 0.171 0.224 0.165 0.215 0.184 0.230 0.188 0.253 0.221 0.297 0.192 0.234 0.199 0.272 0.217 0.269 0.374 0.401 0.335 0.380
192 0.230 0.263 0.210 0.254 0.215 0.263 0.210 0.257 0.245 0.283 0.250 0.304 0.270 0.322 0.269 0.295 0.279 0.332 0.259 0.304 0.552 0.478 0.522 0.462
336 0.278 0.282 0.256 0.292 0.258 0.299 0.259 0.297 0.305 0.321 0.312 0.346 0.320 0.351 0.370 0.357 0.356 0.386 0.303 0.334 0.724 0.541 0.715 0.535
720 0.301 0.328 0.321 0.339 0.320 0.346 0.332 0.346 0.381 0.371 0.387 0.393 0.390 0.396 0.441 0.405 0.437 0.448 0.377 0.382 0.739 0.558 0.611 0.500
Avg 0.243 0.272 0.238 0.275 0.241 0.283 0.242 0.279 0.279 0.301 0.284 0.324 0.300 0.342 0.318 0.323 0.318 0.360 0.289 0.322 0.597 0.495 0.546 0.469
ETTh1 96 0.455 0.457 0.458 0.456 0.492 0.495 0.516 0.485 0.861 0.628 0.512 0.499 0.613 0.552 0.918 0.639 1.112 0.806 1.298 0.838 1.179 0.792 1.184 0.790
192 0.572 0.519 0.570 0.516 0.565 0.538 0.598 0.524 0.797 0.593 0.624 0.555 0.722 0.598 0.915 0.629 1.155 0.823 1.322 0.854 1.199 0.806 1.295 0.850
336 0.611 0.531 0.608 0.535 0.721 0.622 0.657 0.550 0.941 0.648 0.691 0.574 0.750 0.619 0.939 0.644 1.179 0.832 1.347 0.870 1.202 0.811 1.294 0.854
720 0.723 0.594 0.725 0.591 0.986 0.743 0.762 0.610 0.877 0.641 0.728 0.614 0.721 0.616 0.887 0.645 1.273 0.874 1.534 0.947 1.217 0.825 1.223 0.838
Avg 0.479 0.525 0.590 0.525 0.691 0.600 0.633 0.542 0.869 0.628 0.639 0.561 0.702 0.596 0.915 0.639 1.180 0.834 1.375 0.877 1.199 0.809 1.249 0.833
ETTh2 96 0.332 0.374 0.331 0.374 0.357 0.411 0.353 0.389 0.378 0.409 0.382 0.416 0.413 0.451 0.389 0.411 0.678 0.619 2.022 1.006 3.837 1.508 3.788 1.533
192 0.401 0.433 0.402 0.411 0.569 0.519 0.403 0.414 0.490 0.467 0.478 0.474 0.474 0.477 0.473 0.455 0.785 0.666 2.329 1.104 3.856 1.513 3.552 1.483
336 0.408 0.440 0.406 0.433 0.671 0.572 0.426 0.441 0.537 0.494 0.504 0.501 0.547 0.543 0.507 0.480 0.839 0.694 2.453 1.122 3.952 1.526 3.395 1.526
720 0.459 0.480 0.449 0.464 0.824 0.648 0.477 0.480 0.510 0.491 0.499 0.509 0.516 0.523 0.477 0.472 1.273 0.874 3.816 1.407 3.842 1.503 3.205 1.401
Avg 0.401 0.432 0.397 0.421 0.605 0.538 0.415 0.431 0.479 0.465 0.466 0.475 0.488 0.499 0.462 0.455 0.894 0.713 2.655 1.160 3.872 1.513 3.485 1.486
ETTm1 96 0.392 0.401 0.390 0.404 0.352 0.392 0.410 0.419 0.583 0.501 0.578 0.518 0.774 0.614 0.761 0.568 0.911 0.688 0.921 0.682 1.162 0.785 1.442 0.847
192 0.423 0.426 0.429 0.423 0.382 0.412 0.437 0.434 0.630 0.528 0.617 0.546 0.754 0.592 0.781 0.574 0.955 0.703 0.957 0.701 1.172 0.793 1.444 0.862
336 0.471 0.444 0.469 0.439 0.419 0.434 0.476 0.454 0.725 0.568 0.998 0.775 0.869 0.677 0.803 0.587 0.991 0.719 0.998 0.716 1.227 0.908 1.450 0.866
720 0.552 0.501 0.569 0.498 0.490 0.477 0.681 0.556 0.769 0.549 0.693 0.579 0.810 0.630 0.844 0.581 1.062 0.747 1.007 0.719 1.207 0.797 1.366 0.850
Avg 0.574 0.443 0.464 0.441 0.411 0.429 0.501 0.466 0.677 0.537 0.722 0.605 0.802 0.628 0.797 0.578 0.980 0.714 0.971 0.705 1.192 0.821 1.426 0.856
ETTm2 96 0.233 0.262 0.188 0.269 0.213 0.303 0.191 0.274 0.212 0.285 0.291 0.399 0.352 0.454 0.229 0.308 0.331 0.430 0.813 0.688 3.203 1.407 4.195 1.628
192 0.303 0.302 0.251 0.309 0.278 0.345 0.252 0.317 0.270 0.323 0.307 0.379 0.694 0.691 0.291 0.343 0.400 0.464 1.008 0.768 3.112 1.387 4.042 1.601
336 0.359 0.341 0.307 0.346 0.338 0.385 0.306 0.353 0.323 0.353 0.543 0.559 2.408 1.407 0.348 0.376 0.469 0.498 1.031 0.775 3.255 1.421 3.963 1.585
720 0.452 0.419 0.426 0.417 0.436 0.440 0.433 0.427 0.474 0.449 0.712 0.614 1.913 1.166 0.461 0.438 0.589 0.557 1.096 0.791 3.909 1.543 3.711 1.532
Avg 0.317 0.309 0.293 0.335 0.316 0.368 0.296 0.343 0.320 0.353 0.463 0.488 1.342 0.930 0.332 0.366 0.447 0.487 0.987 0.756 3.370 1.440 3.978 1.587
Electricity 96 0.143 0.235 0.139 0.237 0.150 0.253 0.140 0.238 0.299 0.373 0.231 0.323 0.261 0.348 0.420 0.466 0.599 0.587 0.350 0.425 1.259 0.919 0.993 0.784
192 0.158 0.255 0.156 0.252 0.164 0.264 0.160 0.255 0.305 0.379 0.261 0.356 0.338 0.406 0.411 0.459 0.620 0.598 0.376 0.448 1.160 0.873 0.938 0.753
336 0.176 0.275 0.175 0.270 0.181 0.282 0.180 0.276 0.319 0.391 0.360 0.445 0.410 0.474 0.434 0.473 0.662 0.619 0.428 0.485 1.157 0.872 0.925 0.745
720 0.230 0.311 0.233 0.317 0.223 0.321 0.241 0.323 0.369 0.426 0.530 0.585 0.715 0.685 0.510 0.521 0.757 0.664 0.611 0.597 1.203 0.898 1.004 0.790
Avg 0.176 0.269 0.176 0.269 0.180 0.280 0.180 0.273 0.323 0.392 0.346 0.427 0.431 0.478 0.444 0.480 0.660 0.617 0.441 0.489 1.195 0.891 0.965 0.768
Traffic 96 0.415 0.317 0.414 0.297 0.419 0.298 0.403 0.289 0.719 0.416 0.639 0.400 0.672 0.405 1.412 0.802 1.643 0.855 1.157 0.636 1.557 0.821 1.527 0.815
192 0.425 0.300 0.426 0.301 0.434 0.305 0.415 0.296 0.748 0.428 0.637 0.416 0.727 0.424 1.419 0.806 1.641 0.854 1.207 0.661 1.454 0.765 1.538 0.817
336 0.436 0.310 0.434 0.303 0.449 0.313 0.426 0.304 0.853 0.471 0.655 0.427 0.749 0.454 1.443 0.815 1.711 0.878 1.334 0.713 1.521 0.812 1.550 0.819
720 0.489 0.338 0.487 0.337 0.484 0.336 0.474 0.331 1.485 0.825 0.722 0.456 0.847 0.499 1.539 0.837 2.660 1.157 1.292 0.726 1.605 0.846 1.588 0.833
Avg 0.441 0.316 0.440 0.310 0.447 0.313 0.430 0.305 0.951 0.535 0.663 0.425 0.749 0.446 1.453 0.815 1.914 0.936 1.248 0.684 1.534 0.811 1.551 0.821
1st count 5 5 4 0 0 0 0 0 0 0 0 0
Bảng 10: Kết quả Dự báo Few-shot (MSE, MAE). TEST sử dụng GPT2-Medium làm backbone. Tất cả kết quả được tính trung bình từ 4 độ dài dự đoán khác nhau, tức là {96, 192, 336, 720}.

Phương pháp M4 M3 TOURISM ELECTR
Metric sMAPE sMAPE MAPE ND×100 Average 1st count
N-BEATS 11.70 12.44 18.82 17.8 15.19 2
DLinear 15.33 14.03 28.51 17.6 18.86 0
TimesNet 13.55 14.17 28.84 19.3 18.96 0
PatchTST 13.22 13.06 27.10 17.3 17.67 0
ETSformer 27.74 16.03 180.40 44.2 67.09 0
LightTS 13.62 17.90 66.99 19.6 29.52 0
Stationary 13.32 15.29 43.75 22.0 23.59 0
FEDformer 15.04 13.53 31.55 18.4 19.63 0
Autoformer 20.02 15.87 40.39 33.9 27.54 0
Informer 19.04 15.82 35.82 21.2 22.97 0
Reformer 14.09 13.37 25.48 21.6 18.63 0
GPT2(6) 13.12 13.06 22.14 17.2 16.38 1
TEST 13.10 12.56 18.17 17.9 15.93 1
Bảng 11: Kết quả học zero-shot. Số liệu cụ thể theo bộ dữ liệu được tổng hợp trên mỗi bộ dữ liệu. Giá trị thấp hơn cho thấy hiệu suất tốt hơn. Bộ dữ liệu nguồn của M3, Tourism, Electricity là M4. Đối với M4, dữ liệu nguồn cho N-BEATS là FRED, và M3 cho các mô hình khác.

A.3.5 DỰ BÁO ZERO-SHOT
Nhiệm vụ Dự báo Zero-shot có thể đánh giá khả năng thích ứng chéo bộ dữ liệu. Có nghĩa là phương pháp được đánh giá để thực hiện trên một bộ dữ liệu (không có dữ liệu huấn luyện nào từ bộ dữ liệu này) khi nó được huấn luyện từ một bộ dữ liệu khác. Kết quả được tóm tắt trong Bảng 11. TEST vượt trội hơn tất cả các phương pháp SOTA gần đây. TEST có thể so sánh với N-BEATS mà không có thiết kế meta-learning nào và GPT4TS.

--- TRANG 21 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
A.4 NHIỆM VỤ PHÂN LOẠI
Tất cả các mạng học sâu được triển khai trong PyTorch và huấn luyện trên GPU NVIDIA V100 32GB. Chúng tôi sử dụng Diện tích Dưới Đường cong của Đặc tính Hoạt động Người nhận (AUC-ROC) làm số liệu. Trong khi đó, chúng tôi tính toán thứ hạng trung bình, số lượng độ chính xác Top-1, Top-3 và Top-5 để hiển thị tính mạnh mẽ của các phương pháp khác nhau. Tất cả các thí nghiệm được lặp lại 3 lần và trung bình của các số liệu được sử dụng trong kết quả cuối cùng.

A.4.1 CHI TIẾT BỘ DỮ LIỆU
Chúng tôi trình bày điểm độ chính xác cho tất cả 30 loại bộ dữ liệu TS đa biến trong kho lưu trữ UEA Bagnall et al. (2018). UEA bao gồm 30 bộ dữ liệu khác nhau. Chi tiết của các bộ dữ liệu này được hiển thị trong Bảng 12

Bộ dữ liệu Train Cases Test Cases Dimensions Length Classes
ArticularyWordRecognition 275 30 9 144 25
AtrialFibrillation 15 15 2 640 3
BasicMotions 40 40 4 100 4
CharacterTrajectories 1422 1436 3 182 20
Cricket 108 72 6 17984 5
DuckDuckGeese 60 40 1345 270 5
EigenWorms 128 131 6 17984 5
Epilepsy 137 138 3 206 4
EthanolConcentration 261 263 3 1751 4
ERing 30 20 4 65 6
FaceDetection 5890 3524 144 62 2
FingerMovements 316 100 28 50 2
HandMovementDirection 320 147 10 400 4
Handwriting 150 850 3 152 26
Heartbeat 204 105 61 495 2
JapaneseV owels 270 370 12 29 9
Libras 180 280 2 45 15
LSST 2459 2466 6 36 14
InsectWingbeat 30000 20000 200 78 10
MotorImagery 278 100 64 3000 2
NATOPS 180 180 24 51 6
PenDigits 7494 3498 2 8 10
PEMS-SF 267 173 963 144 7
Phoneme 3315 3353 11 217 39
RacketSports 151 152 6 30 4
SelfRegulationSCP1 268 293 6 896 2
SelfRegulationSCP2 200 180 7 1152 2
SpokenArabicDigits 6599 2199 13 93 10
StandWalkJump 12 15 4 2500 3
UWaveGestureLibrary 120 320 3 315 8
Bảng 12: Chi tiết Bộ dữ liệu Phân loại UEA

A.4.2 CHI TIẾT BASELINE
Đối với phân loại, chúng tôi tham khảo các phương pháp SOTA: Ba benchmark Bostrom et al. (2018) (EDI, DTWI và DTWD) dựa trên Khoảng cách Euclidean, dynamic time warping độc lập chiều và dynamic time warping phụ thuộc chiều; MLSTM-FCNs Karim et al. (2019) áp dụng một lớp LSTM và các lớp CNN xếp chồng để tạo đặc trưng; WEASEL-MUSE Sch ¨afer & Leser (2017) là một cách tiếp cận dựa trên bag-of-pattern trích xuất và biểu diễn đặc trưng thành từ. Scalable Representation Learning (SRL) Franceschi et al. (2019a) sử dụng kỹ thuật lấy mẫu tiêu cực với kiến trúc dựa trên encoder để học biểu diễn; TapNet Zhang et al. (2020) là một mô hình gần đây với học nguyên mẫu có chú ý trong mạng dựa trên học sâu của nó; ShapeNet Li et al. (2021a) chiếu các chuỗi con vào một không gian thống nhất và áp dụng phân cụm để tìm shapelet; Rocket và MiniRocket Dempster et al. (2021) sử dụng kernel tích chập ngẫu nhiên để trích xuất đặc trưng từ chuỗi thời gian đơn biến; RL-PAM Gao et al. (2022) giới thiệu học tăng cường vào khai thác mẫu; TStamp Transformer Zerveas et al. (2021) lấy các giá trị tại mỗi timestamp làm đầu vào cho một encoder transformer; SVP-T Zuo et al. (2023) sử dụng các biến và vị trí khác nhau (khoảng thời gian) làm đầu vào (cấp hình dạng).

--- TRANG 22 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
A.4.3 PHÂN LOẠI CHUỖI THỜI GIAN ĐA BIẾN
Chúng tôi tuân theo các thiết lập thí nghiệm cổ điển trong các nhiệm vụ phân loại chuỗi thời gian đa biến Bostrom et al. (2018). Kết quả được hiển thị trong Bảng 13. Nhìn chung, TEST đạt được hiệu suất tương đương với các mô hình SOTA và vượt trội hơn hầu hết các baseline.

EDI DTWI DTWD MLSTM-FCNs WEASEL+MUSE SRL TapNet ShapeNet Rocket MiniRocket RLPAM TStamp SVP-T TEST
AWR 0.970 0.980 0.987 0.973 0.990 0.987 0.987 0.987 0.996 0.992 0.923 0.983 0.993 0.994
AF 0.267 0.267 0.220 0.267 0.333 0.133 0.333 0.400 0.249 0.133 0.733 0.200 0.400 0.420
BM 0.676 1.000 0.975 0.950 1.000 1.000 1.000 1.000 0.990 1.000 1.000 0.975 1.000 1.000
CT 0.964 0.969 0.989 0.985 0.990 0.994 0.997 0.980 N/A 0.993 0.978 N/A 0.990 0.989
CK 0.944 0.986 1.000 0.917 1.000 0.986 0.958 0.986 1.000 0.986 1.000 0.958 1.000 1.000
DDG 0.275 0.550 0.600 0.675 0.575 0.675 0.575 0.725 0.461 0.650 0.700 0.480 0.700 0.675
EW 0.549 N/A 0.618 0.504 0.890 0.878 0.489 0.878 0.863 0.962 0.908 N/A 0.923 0.878
EP 0.666 0.978 0.964 0.761 1.000 0.957 0.971 0.987 0.991 1.000 0.978 0.920 0.986 0.985
ER 0.133 0.914 0.929 0.133 0.133 0.133 0.133 0.133 0.981 0.981 0.819 0.933 0.937 0.937
EC 0.293 0.304 0.323 0.373 0.430 0.236 0.323 0.312 0.447 0.468 0.369 0.337 0.331 0.373
FD 0.519 0.000 0.529 0.545 0.545 0.528 0.556 0.602 0.694 0.620 0.621 0.681 0.512 0.512
FM 0.550 0.520 0.530 0.580 0.490 0.540 0.530 0.580 0.553 0.550 0.640 0.776 0.600 0.770
HMD 0.278 0.306 0.231 0.365 0.365 0.270 0.378 0.338 0.446 0.392 0.635 0.608 0.392 0.444
HW 0.200 0.316 0.286 0.286 0.605 0.533 0.357 0.452 0.567 0.507 0.522 0.305 0.433 0.431
HB 0.619 0.658 0.717 0.663 0.727 0.737 0.751 0.756 0.718 0.771 0.779 0.712 0.790 0.791
IW 0.128 N/A N/A 0.167 N/A 0.160 0.208 0.250 N/A 0.595 0.352 0.684 0.184 0.572
JV 0.924 0.959 0.949 0.976 0.973 0.989 0.965 0.984 0.965 0.989 0.935 0.994 0.978 0.991
LB 0.833 0.894 0.870 0.856 0.878 0.867 0.850 0.856 0.906 0.922 0.794 0.844 0.883 0.884
LSST 0.456 0.575 0.551 0.373 0.590 0.558 0.568 0.590 0.632 0.643 0.643 0.381 0.666 0.595
MI 0.510 N/A 0.500 0.510 0.500 0.540 0.590 0.610 0.531 0.550 0.610 N/A 0.650 0.650
NT 0.850 0.850 0.883 0.889 0.870 0.944 0.939 0.883 0.885 0.928 0.950 0.900 0.906 0.902
PD 0.705 0.939 0.977 0.978 0.948 0.983 0.980 0.977 0.996 N/A 0.982 0.974 0.983 0.979
PM 0.973 0.734 0.711 0.699 0.000 0.688 0.751 0.751 0.856 0.522 0.632 0.919 0.867 0.860
PH 0.104 0.151 0.151 0.110 0.190 0.246 0.175 0.298 0.284 0.292 0.175 0.088 0.176 0.196
RS 0.868 0.842 0.803 0.803 0.934 0.862 0.868 0.882 0.928 0.868 0.868 0.829 0.842 0.851
SCP1 0.771 0.765 0.775 0.874 0.710 0.846 0.652 0.782 0.866 0.925 0.802 0.925 0.884 0.870
SCP2 0.483 0.533 0.539 0.472 0.460 0.556 0.550 0.578 0.514 0.522 0.632 0.589 0.600 0.579
SAD 0.967 0.959 0.963 0.990 0.982 0.956 0.983 0.975 0.630 0.620 0.621 0.993 0.986 0.982
SWJ 0.200 0.333 0.200 0.067 0.333 0.400 0.400 0.533 0.456 0.333 0.667 0.267 0.467 0.468
UGL 0.881 0.868 0.903 0.891 0.916 0.884 0.894 0.906 0.944 0.938 0.944 0.903 0.941 0.933
Avg.Rank 10.933 9.480 8.821 8.756 6.890 7.120 6.956 5.523 5.423 5.013 5.059 7.484 4.032 4.012
Num.Top-1 1 1 1 0 5 1 2 3 5 5 6 4 4 6
Num.Top-3 1 2 1 1 6 6 3 7 12 14 16 9 17 18
Num.Top-5 2 2 3 5 15 12 13 17 16 20 19 10 23 24
P-value 0.000 0.000 0.000 0.000 0.006 0.003 0.000 0.118 0.217 0.765 0.967 0.047 0.044 0.040
Bảng 13: Độ chính xác trên Tất cả Bộ dữ liệu của Kho lưu trữ UEA

A.5 NHIỆM VỤ BIỂU DIỄN
Chúng tôi đánh giá chất lượng của các biểu diễn đã học của chúng tôi trên các nhiệm vụ có giám sát theo cách tiêu chuẩn bằng cách sử dụng chúng cho phân loại chuỗi thời gian Franceschi et al. (2019b). Tất cả các mạng học sâu được triển khai trong PyTorch và huấn luyện trên GPU NVIDIA V100 32GB. Chúng tôi sử dụng Diện tích Dưới Đường cong của Đặc tính Hoạt động Người nhận (AUC-ROC) làm số liệu.

A.5.1 CHI TIẾT BỘ DỮ LIỆU
Chúng tôi trình bày kết quả cho tất cả 128 loại bộ dữ liệu TS đơn biến trong kho lưu trữ UCR Dau et al. (2019), là một tập hợp tiêu chuẩn của các bộ dữ liệu đơn biến đa dạng.

A.5.2 CHI TIẾT BASELINE
Phương pháp so sánh bao gồm SOTA của biểu diễn chuỗi thời gian không giám sát: T-Loss Franceschi et al. (2019b), TS-TCC Eldele et al. (2021b), TST Zerveas et al. (2021) và TNC Tonekaboni et al. (2021), TS2Vec Yue et al. (2022).

A.5.3 PHÂN LOẠI DỰA TRÊN BIỂU DIỄN
Chúng tôi đánh giá chất lượng của các biểu diễn đã học của chúng tôi trên các nhiệm vụ có giám sát theo cách tiêu chuẩn bằng cách sử dụng chúng cho phân loại chuỗi thời gian Franceschi et al. (2019b). Trong thiết lập này, chúng tôi cho thấy rằng phương pháp của chúng tôi vượt trội hơn các phương pháp không giám sát SOTA, và đáng chú ý là đạt được hiệu suất gần với phương pháp SOTA có giám sát như được hiển thị trong Bảng 14.

Đối với mỗi bộ dữ liệu được xem xét với chia train / test, chúng tôi huấn luyện không giám sát một encoder bằng cách sử dụng tập train của nó. Sau đó chúng tôi huấn luyện một SVM với kernel hàm cơ sở radial trên các đặc trưng đã học bằng cách sử dụng nhãn train của bộ dữ liệu, và xuất điểm phân loại tương ứng trên tập test.

--- TRANG 23 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
TEST TCN TS2Vec T-Loss TNC
Adiac 0.776 0.768 0.765 0.675 0.726
ArrowHead 0.825 0.857 0.817 0.766 0.703
Beef 0.766 0.768 0.633 0.667 0.733
BeetleFly 0.853 0.900 0.900 0.800 0.850
BirdChicken 0.808 0.803 0.800 0.850 0.750
Car 0.883 0.834 0.700 0.833 0.683
CBF 1.000 1.000 1.000 0.983 0.983
ChlorineConcentration 0.810 0.832 0.812 0.749 0.760
CinCECGTorso 0.815 0.829 0.825 0.713 0.669
Coffee 1.000 1.000 1.000 1.000 1.000
Computers 0.632 0.660 0.660 0.664 0.684
CricketX 0.802 0.787 0.805 0.713 0.623
CricketY 0.754 0.749 0.769 0.728 0.597
CricketZ 0.787 0.794 0.790 0.708 0.682
DiatomSizeReduction 0.980 0.985 0.987 0.984 0.993
DistalPhalanxOutlineCorrect 0.776 0.761 0.757 0.775 0.754
DistalPhalanxOutlineAgeGroup 0.714 0.727 0.719 0.727 0.741
DistalPhalanxTW 0.662 0.698 0.683 0.676 0.669
Earthquakes 0.746 0.748 0.748 0.748 0.748
ECG200 0.893 0.920 0.880 0.940 0.830
ECG5000 0.935 0.935 0.934 0.933 0.937
ECGFiveDays 1.000 1.000 1.000 1.000 0.999
ElectricDevices 0.714 0.721 0.719 0.707 0.700
FaceAll 0.789 0.771 0.805 0.786 0.766
FaceFour 0.834 0.932 0.932 0.920 0.659
FacesUCR 0.939 0.924 0.926 0.884 0.789
FiftyWords 0.781 0.771 0.774 0.732 0.653
Fish 0.937 0.926 0.937 0.891 0.817
FordA 0.940 0.936 0.948 0.928 0.902
FordB 0.789 0.794 0.807 0.793 0.733
GunPoint 0.983 0.980 0.987 0.980 0.967
Ham 0.714 0.714 0.724 0.724 0.752
HandOutlines 0.918 0.925 0.930 0.922 0.930
Haptics 0.510 0.526 0.536 0.490 0.474
Herring 0.625 0.644 0.609 0.594 0.594
InlineSkate 0.389 0.418 0.407 0.371 0.378
InsectWingbeatSound 0.620 0.630 0.624 0.597 0.549
ItalyPowerDemand 0.969 0.925 0.960 0.954 0.928
LargeKitchenAppliances0 0.855 0.845 0.875 0.789 0.776
Lightning2 0.846 0.869 0.820 0.869 0.869
Lightning7 0.866 0.863 0.822 0.795 0.767
Mallat 0.915 0.944 0.873 0.951 0.871
Meat 0.950 0.952 0.967 0.950 0.917
MedicalImages 0.792 0.789 0.793 0.750 0.754
MiddlePhalanxOutlineCorrect 0.811 0.838 0.825 0.825 0.818
MiddlePhalanxOutlineAgeGroup 0.636 0.636 0.630 0.656 0.643
MiddlePhalanxTW 0.591 0.584 0.578 0.591 0.571
MoteStrain 0.857 0.861 0.863 0.851 0.825
NonInvasiveFetalECGThorax1 0.923 0.930 0.919 0.878 0.898
NonInvasiveFetalECGThorax2 0.940 0.938 0.935 0.919 0.912
OliveOil 0.903 0.901 0.940 0.867 0.833
OSULeaf 0.872 0.851 0.843 0.760 0.723
PhalangesOutlinesCorrect 0.794 0.809 0.823 0.784 0.787
Phoneme 0.296 0.312 0.309 0.276 0.180
Plane 1.000 1.000 0.990 0.990 1.000
ProximalPhalanxOutlineCorrect 0.876 0.887 0.900 0.859 0.866
ProximalPhalanxOutlineAgeGroup 0.844 0.837 0.829 0.844 0.854
ProximalPhalanxTW 0.785 0.824 0.805 0.771 0.810
RefrigerationDevices 0.587 0.586 0.589 0.515 0.565
ScreenType 0.405 0.414 0.397 0.416 0.509
ShapeletSim 0.989 1.000 0.994 0.672 0.589
ShapesAll 0.897 0.902 0.905 0.848 0.788
SmallKitchenAppliances 0.723 0.731 0.733 0.677 0.725
SonyAIBORobotSurface1 0.874 0.903 0.900 0.902 0.804
SonyAIBORobotSurface2 0.893 0.871 0.889 0.889 0.834
StarLightCurves 0.970 0.968 0.971 0.964 0.968
Strawberry 0.962 0.966 0.965 0.954 0.951
SwedishLeaf 0.939 0.945 0.942 0.914 0.880
Symbols 0.973 0.977 0.972 0.963 0.885
SyntheticControl 0.997 0.997 0.993 0.987 1.000

--- TRANG 24 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
ToeSegmentation1 0.933 0.917 0.947 0.939 0.864
ToeSegmentation2 0.915 0.899 0.900 0.900 0.831
Trace 1.000 1.000 1.000 0.990 1.000
TwoLeadECG 0.982 0.986 0.987 0.999 0.993
TwoPatterns 1.000 1.000 1.000 0.999 1.000
UWaveGestureLibraryX 0.810 0.795 0.801 0.785 0.781
UWaveGestureLibraryY 0.729 0.719 0.720 0.710 0.697
UWaveGestureLibraryZ 0.761 0.774 0.768 0.757 0.721
UWaveGestureLibraryAll 0.935 0.930 0.934 0.896 0.903
Wafer 0.995 0.998 0.998 0.992 0.994
Wine 0.788 0.880 0.889 0.815 0.759
WordSynonyms 0.699 0.679 0.704 0.691 0.630
Worms 0.704 0.701 0.701 0.727 0.623
WormsTwoClass 0.805 0.806 0.753 0.792 0.727
Yoga 0.883 0.883 0.877 0.837 0.812
ACSF1 0.849 0.910 0.910 0.900 0.730
AllGestureWiimoteX 0.744 0.777 0.751 0.763 0.703
AllGestureWiimoteY 0.754 0.796 0.774 0.726 0.699
AllGestureWiimoteZ 0.744 0.749 0.770 0.723 0.646
BME 0.979 0.992 0.980 0.993 0.973
Chinatown 0.969 0.964 0.959 0.951 0.977
Crop 0.753 0.754 0.758 0.722 0.738
EOGHorizontalSignal 0.544 0.569 0.522 0.605 0.442
EOGVerticalSignal 0.467 0.503 0.472 0.434 0.392
EthanolLevel 0.480 0.468 0.484 0.382 0.424
FreezerRegularTrain 0.983 0.996 0.983 0.956 0.991
FreezerSmallTrain 0.893 0.875 0.872 0.933 0.982
Fungi 0.967 0.958 0.946 1.000 0.527
GestureMidAirD1 0.637 0.608 0.615 0.608 0.431
GestureMidAirD2 0.508 0.479 0.515 0.546 0.362
GestureMidAirD3 0.346 0.492 0.300 0.285 0.292
GesturePebbleZ1 0.878 0.930 0.884 0.919 0.378
GesturePebbleZ2 0.842 0.873 0.848 0.899 0.316
GunPointAgeSpan 0.994 0.987 0.968 0.994 0.984
GunPointMaleVersusFemale 1.000 1.000 1.000 0.997 0.994
GunPointOldVersusYoung 1.000 1.000 1.000 1.000 1.000
HouseTwenty 0.944 0.917 0.941 0.933 0.782
InsectEPGRegularTrain 1.000 1.000 1.000 1.000 1.000
InsectEPGSmallTrain 1.000 1.000 1.000 1.000 1.000
MelbournePedestrian 0.954 0.959 0.956 0.944 0.942
MixedShapesRegularTrain 0.915 0.917 0.922 0.905 0.911
MixedShapesSmallTrain 0.884 0.861 0.856 0.860 0.813
PickupGestureWiimoteZ 0.800 0.823 0.760 0.740 0.620
PigAirwayPressure 0.524 0.630 0.683 0.510 0.413
PigArtPressure 0.962 0.966 0.966 0.928 0.808
PigCVP 0.803 0.815 0.870 0.788 0.649
PLAID 0.551 0.561 0.549 0.555 0.495
PowerCons 0.967 0.961 0.972 0.900 0.933
Rock 0.660 0.700 0.700 0.580 0.580
SemgHandGenderCh2 0.952 0.963 0.962 0.890 0.882
SemgHandSubjectCh2 0.897 0.860 0.891 0.789 0.593
SemgHandMovementCh2 0.944 0.952 0.942 0.920 0.820
SmoothSubspace 0.967 0.980 0.993 0.960 0.913
UMD 1.000 1.000 0.993 0.993 0.993
Avg 0.826 0.832 0.827 0.806 0.761
Bảng 14: Độ chính xác trên Tất cả Bộ dữ liệu của Kho lưu trữ UCR

A.6 ABLATION
TEST chứa hai chiến lược học tương phản: tương phản theo instance và tương phản theo feature, và có thể sử dụng các vector embedding văn bản khác nhau làm nguyên mẫu, chúng tôi hiển thị tác động của các chiến lược này.

A.6.1 CHIẾN LƯỢC HỌC TƯƠNG PHẢN
Như được hiển thị trong Bảng 15 và 16, cả hai chiến lược học tương phản đều có thể tăng độ chính xác.

A.6.2 NGUYÊN MẪU VĂN BẢN
Số lượng và loại nguyên mẫu văn bản sẽ dẫn đến các kết quả khác nhau.

Như được hiển thị trong Bảng 17. Chúng tôi chọn ngẫu nhiên 1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22 nguyên mẫu. Độ chính xác và số lượng cơ bản có tương quan dương. Kết quả của 10 nguyên mẫu gần như tối ưu.

--- TRANG 25 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
ETTm1 ETTm2 ETTh1 ETTh2 Electricity Traffic Weather ILI
Instance-wise 0.621 0.550 0.755 0.630 0.493 0.453 0.580 0.612 0.293 0.396 0.788 0.620 0.463 0.349 3.301 4.535
Feature-wise 0.741 0.559 0.793 0.634 0.699 0.493 0.585 0.628 0.286 0.390 0.821 0.629 0.453 0.388 3.139 5.931
TEST 0.353 0.382 0.293 0.334 0.414 0.431 0.331 0.380 0.162 0.253 0.430 0.295 0.229 0.271 2.195 1.045
Bảng 15: Kết quả Dự báo Dài hạn (MSE, MAE). TEST sử dụng chiến lược học tương phản khác nhau. Tất cả kết quả được tính trung bình từ 4 độ dài dự đoán khác nhau, tức là {24, 36, 48, 60} cho ILI và {96, 192, 336, 720} cho những cái khác. Kết quả là trung bình.

TEST Instance-wise Feature-wise TimesNet N-BEATS ETSformer DLinear FEDformer Stationary Autoformer Informer Reformer
SMAPE 11.927 13.525 16.987 11.829 11.851 14.718 13.639 12.840 12.780 12.909 14.086 18.200
MASE 1.613 2.111 3.265 1.585 1.599 2.408 2.095 1.701 1.756 1.771 3.010 4.223
OWA 0.861 1.051 1.480 0.851 0.855 1.172 1.051 0.918 0.930 0.939 1.230 1.775
Bảng 16: Nhiệm vụ Dự báo Ngắn hạn trên M4. Độ dài dự đoán nằm trong [6, 48] và kết quả được tính trung bình từ nhiều bộ dữ liệu.

Như được hiển thị trong Bảng 18. Chúng tôi chọn ngẫu nhiên 10 nguyên mẫu 10 lần. Độ chính xác cơ bản nhất quán. Do đó, loại nguyên mẫu hầu như không có tác động đến kết quả.

1 2 4 6 8 10 12 14 16 18 20 22
SMAPE 30.901 20.201 17.415 16.997 13.820 11.927 11.710 11.638 11.094 11.098 10.953 10.885
MASE 6.590 4.515 3.910 3.595 2.580 1.613 1.408 1.195 1.301 1.306 1.471 1.310
OWA 3.779 2.050 1.451 1.484 0.990 0.861 0.872 0.801 0.910 0.902 0.838 0.830
Bảng 17: Nhiệm vụ Dự báo Ngắn hạn trên M4. Kết quả được báo cáo với số lượng nguyên mẫu văn bản khác nhau.

1 2 3 4 5 6 7 8 9 10 Avg. Std.
SMAPE 11.907 11.920 11.927 11.926 11.925 11.925 11.950 11.890 11.728 11.910 11.901 0.059
MASE 1.612 1.610 1.653 1.603 1.619 1.620 1.625 1.623 1.613 1.591 1.617 0.016
OWA 0.870 0.872 0.872 0.872 0.872 0.872 0.849 0.862 0.876 0.870 0.868, 0.009
Bảng 18: Nhiệm vụ Dự báo Ngắn hạn trên M4. Kết quả được báo cáo với các loại nguyên mẫu văn bản khác nhau.

Xem xét tại sao loại nguyên mẫu văn bản không ảnh hưởng đáng kể đến kết quả, chúng tôi nhận ra rằng trong không gian chiều cao, hầu như tất cả các vector đều trực giao từng cặp Hopcroft & Kannan (2013). Có nghĩa là, trong không gian chiều cao, việc tạo ra một số lượng lớn các vector gần như trực giao để biểu diễn các thuộc tính khác nhau là dễ dàng. Do đó, việc chọn ngẫu nhiên cùng số lượng vector, kích thước không gian được biểu diễn và số lượng đặc trưng được biểu hiện gần như giống nhau. Do đó, chìa khóa là số lượng chứ không phải loại.

Về mặt xác suất, "hai vector trực giao" tương đương với "hai vector vuông góc" tương đương với "hai vector không tương quan" tương đương với "cosθ= 0". Đối với không gian n chiều, hai vector ngẫu nhiên có: ∀ϵ,limn→∞P(|cosθ|> ϵ) = 0. Như được hiển thị trong Hình 7, khi chiều tăng, xác suất hai vector ngẫu nhiên tương tự giảm. Đối với LLM, n >1024, P(θ= 0) <0.00001.

Hình 7: Mật độ Xác suất của Góc giữa Hai Vector Ngẫu nhiên trong Không gian n chiều
